# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel 6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-11-11 08:52+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../gpu/tegra.rst:3
msgid "drm/tegra NVIDIA Tegra GPU and display driver"
msgstr ""

#: ../../../gpu/tegra.rst:5
msgid ""
"NVIDIA Tegra SoCs support a set of display, graphics and video functions via "
"the host1x controller. host1x supplies command streams, gathered from a push "
"buffer provided directly by the CPU, to its clients via channels. Software, "
"or blocks amongst themselves, can use syncpoints for synchronization."
msgstr ""

#: ../../../gpu/tegra.rst:10
msgid ""
"Up until, but not including, Tegra124 (aka Tegra K1) the drm/tegra driver "
"supports the built-in GPU, comprised of the gr2d and gr3d engines. Starting "
"with Tegra124 the GPU is based on the NVIDIA desktop GPU architecture and "
"supported by the drm/nouveau driver."
msgstr ""

#: ../../../gpu/tegra.rst:15
msgid ""
"The drm/tegra driver supports NVIDIA Tegra SoC generations since Tegra20. It "
"has three parts:"
msgstr ""

#: ../../../gpu/tegra.rst:18
msgid ""
"A host1x driver that provides infrastructure and access to the host1x "
"services."
msgstr ""

#: ../../../gpu/tegra.rst:21
msgid ""
"A KMS driver that supports the display controllers as well as a number of "
"outputs, such as RGB, HDMI, DSI, and DisplayPort."
msgstr ""

#: ../../../gpu/tegra.rst:24
msgid ""
"A set of custom userspace IOCTLs that can be used to submit jobs to the GPU "
"and video engines via host1x."
msgstr ""

#: ../../../gpu/tegra.rst:28
msgid "Driver Infrastructure"
msgstr ""

#: ../../../gpu/tegra.rst:30
msgid ""
"The various host1x clients need to be bound together into a logical device "
"in order to expose their functionality to users. The infrastructure that "
"supports this is implemented in the host1x driver. When a driver is "
"registered with the infrastructure it provides a list of compatible strings "
"specifying the devices that it needs. The infrastructure creates a logical "
"device and scan the device tree for matching device nodes, adding the "
"required clients to a list. Drivers for individual clients register with the "
"infrastructure as well and are added to the logical host1x device."
msgstr ""

#: ../../../gpu/tegra.rst:39
msgid ""
"Once all clients are available, the infrastructure will initialize the "
"logical device using a driver-provided function which will set up the bits "
"specific to the subsystem and in turn initialize each of its clients."
msgstr ""

#: ../../../gpu/tegra.rst:43
msgid ""
"Similarly, when one of the clients is unregistered, the infrastructure will "
"destroy the logical device by calling back into the driver, which ensures "
"that the subsystem specific bits are torn down and the clients destroyed in "
"turn."
msgstr ""

#: ../../../gpu/tegra.rst:48
msgid "Host1x Infrastructure Reference"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:37 include/linux/host1x.h:96
msgid "host1x buffer object cache"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:41 include/linux/host1x.h:68
#: include/linux/host1x.h:86 include/linux/host1x.h:372
msgid "**Definition**::"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:48 include/linux/host1x.h:79
#: include/linux/host1x.h:104 include/linux/host1x.h:383
msgid "**Members**"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:38
msgid "``mappings``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:39
msgid "list of mappings"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:39 include/linux/host1x.h:94
msgid "``lock``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:40
msgid "synchronizes accesses to the list of mappings"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:43 ../../../gpu/tegra:52:
#: drivers/gpu/host1x/bus.c:182 drivers/gpu/host1x/bus.c:244
#: drivers/gpu/host1x/bus.c:650 drivers/gpu/host1x/bus.c:687
#: drivers/gpu/host1x/bus.c:737 drivers/gpu/host1x/bus.c:773
#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:52
#: drivers/gpu/host1x/syncpt.c:112 drivers/gpu/host1x/syncpt.c:326
#: drivers/gpu/host1x/syncpt.c:363 drivers/gpu/host1x/syncpt.c:389
#: drivers/gpu/host1x/syncpt.c:404 drivers/gpu/host1x/syncpt.c:517
msgid "**Description**"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:40
msgid ""
"Note that entries are not periodically evicted from this cache and instead "
"need to be explicitly released. This is used primarily for DRM/KMS where the "
"cache's reference is released when the last reference to a buffer object "
"represented by a mapping in this cache is dropped."
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:64 include/linux/host1x.h:88
msgid "host1x client operations"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:65
msgid "``early_init``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:66
msgid "host1x client early initialization code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:66
msgid "``init``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:67
msgid "host1x client initialization code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:67
msgid "``exit``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:68
msgid "host1x client tear down code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:68
msgid "``late_exit``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:69
msgid "host1x client late tear down code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:69
msgid "``suspend``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:70
msgid "host1x client suspend code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:70
msgid "``resume``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:71
msgid "host1x client resume code"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:82
msgid "host1x client structure"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:83 include/linux/host1x.h:371
msgid "``list``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:84
msgid "list node for the host1x client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:84
msgid "``host``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:85
msgid "pointer to struct device representing the host1x controller"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:85
msgid "``dev``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:86
msgid "pointer to struct device backing this host1x client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:86
msgid "``group``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:87
msgid "IOMMU group that this client is a member of"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:87
msgid "``ops``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:88
msgid "``class``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:89
msgid "host1x class represented by this client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:89
msgid "``channel``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:90
msgid "host1x channel associated with this client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:90
msgid "``syncpts``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:91
msgid "array of syncpoints requested for this client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:91
msgid "``num_syncpts``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:92
msgid "number of syncpoints requested for this client"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:92
msgid "``parent``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:93
msgid "pointer to parent structure"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:93
msgid "``usecount``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:94
msgid "reference count for this structure"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:95
msgid "mutex for mutually exclusive concurrency"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:95
msgid "``cache``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:368
msgid "host1x logical device driver"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:369
msgid "``driver``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:370
msgid "core driver"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:370
msgid "``subdevs``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:371
msgid "table of OF device IDs matching subdevices for this driver"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:372
msgid "list node for the driver"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:372
msgid "``probe``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:373
msgid "called when the host1x logical device is probed"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:373
msgid "``remove``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:374
msgid "called when the host1x logical device is removed"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:374
msgid "``shutdown``"
msgstr ""

#: ../../../gpu/tegra:50: include/linux/host1x.h:375
msgid "called when the host1x logical device is shut down"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:179
msgid "initialize a host1x logical device"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:183
#: drivers/gpu/host1x/bus.c:245 drivers/gpu/host1x/bus.c:650
#: drivers/gpu/host1x/bus.c:688 drivers/gpu/host1x/bus.c:714
#: drivers/gpu/host1x/bus.c:728 drivers/gpu/host1x/bus.c:738
#: drivers/gpu/host1x/bus.c:774 ../../../gpu/tegra:58:
#: drivers/gpu/host1x/syncpt.c:51 drivers/gpu/host1x/syncpt.c:113
#: drivers/gpu/host1x/syncpt.c:127 drivers/gpu/host1x/syncpt.c:208
#: drivers/gpu/host1x/syncpt.c:218 drivers/gpu/host1x/syncpt.c:326
#: drivers/gpu/host1x/syncpt.c:364 drivers/gpu/host1x/syncpt.c:390
#: drivers/gpu/host1x/syncpt.c:405 drivers/gpu/host1x/syncpt.c:420
#: drivers/gpu/host1x/syncpt.c:445 drivers/gpu/host1x/syncpt.c:463
#: drivers/gpu/host1x/syncpt.c:479 drivers/gpu/host1x/syncpt.c:491
#: drivers/gpu/host1x/syncpt.c:501 drivers/gpu/host1x/syncpt.c:515
msgid "**Parameters**"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:185
#: drivers/gpu/host1x/bus.c:247
msgid "``struct host1x_device *device``"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:180
#: drivers/gpu/host1x/bus.c:242
msgid "host1x logical device"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:181
msgid ""
"The driver for the host1x logical device can call this during execution of "
"its :c:type:`host1x_driver.probe <host1x_driver>` implementation to "
"initialize each of its clients. The client drivers access the subsystem "
"specific driver data using the :c:type:`host1x_client.parent "
"<host1x_client>` field and driver data associated with it (usually by "
"calling dev_get_drvdata())."
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:241
msgid "uninitialize host1x logical device"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:243
msgid ""
"When the driver for a host1x logical device is unloaded, it can call this "
"function to tear down each of its clients. Typically this is done after a "
"subsystem-specific data structure is removed and the functionality can no "
"longer be used."
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:646
msgid "register a host1x driver"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:652
#: drivers/gpu/host1x/bus.c:690
msgid "``struct host1x_driver *driver``"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:647
#: drivers/gpu/host1x/bus.c:685
msgid "host1x driver"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:649
msgid "``struct module *owner``"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:648
msgid "owner module"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:649
msgid ""
"Drivers for host1x logical devices call this function to register a driver "
"with the infrastructure. Note that since these drive logical devices, the "
"registration of the driver actually triggers tho logical device creation. A "
"logical device will be created for each host1x instance."
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:684
msgid "unregister a host1x driver"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:686
msgid ""
"Unbinds the driver from each of the host1x logical devices that it is bound "
"to, effectively removing the subsystem devices that they represent."
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:710
msgid "initialize a host1x client"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:716
#: drivers/gpu/host1x/bus.c:730 drivers/gpu/host1x/bus.c:740
#: drivers/gpu/host1x/bus.c:776 ../../../gpu/tegra:58:
#: drivers/gpu/host1x/syncpt.c:328 drivers/gpu/host1x/syncpt.c:517
msgid "``struct host1x_client *client``"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:711
#: drivers/gpu/host1x/bus.c:725 drivers/gpu/host1x/bus.c:735
#: drivers/gpu/host1x/bus.c:771
msgid "host1x client"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:713
msgid "``struct lock_class_key *key``"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:712
msgid "lock class key for the client-specific mutex"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:724
msgid "uninitialize a host1x client"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:734
msgid "register a host1x client"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:736
msgid ""
"Registers a host1x client with each host1x controller instance. Note that "
"each client will only match their parent host1x controller and will only be "
"associated with that instance. Once all clients have been registered with "
"their parent host1x controller, the infrastructure will set up the logical "
"device and call host1x_device_init(), which will in turn call each client's :"
"c:type:`host1x_client_ops.init <host1x_client_ops>` implementation."
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:770
msgid "unregister a host1x client"
msgstr ""

#: ../../../gpu/tegra:52: drivers/gpu/host1x/bus.c:772
msgid ""
"Removes a host1x client from its host1x controller instance. If a logical "
"device has already been initialized, it will be torn down."
msgstr ""

#: ../../../gpu/tegra.rst:56
msgid "Host1x Syncpoint Reference"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:47
msgid "allocate a syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:53
#: drivers/gpu/host1x/syncpt.c:447 drivers/gpu/host1x/syncpt.c:465
msgid "``struct host1x *host``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:48
msgid "host1x device data"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:50
#: drivers/gpu/host1x/syncpt.c:325
msgid "``unsigned long flags``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:49
msgid "bitfield of HOST1X_SYNCPT_* flags"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:51
msgid "``const char *name``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:50
msgid "name for the syncpoint for use in debug prints"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:51
msgid ""
"Allocates a hardware syncpoint for the caller's use. The caller then has the "
"sole authority to mutate the syncpoint's value until it is freed again."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:54
msgid ""
"If no free syncpoints are available, or a NULL name was specified, returns "
"NULL."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:109
msgid "retrieve syncpoint ID"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:115
#: drivers/gpu/host1x/syncpt.c:129 drivers/gpu/host1x/syncpt.c:210
#: drivers/gpu/host1x/syncpt.c:220 drivers/gpu/host1x/syncpt.c:366
#: drivers/gpu/host1x/syncpt.c:392 drivers/gpu/host1x/syncpt.c:407
#: drivers/gpu/host1x/syncpt.c:422 drivers/gpu/host1x/syncpt.c:481
#: drivers/gpu/host1x/syncpt.c:493
msgid "``struct host1x_syncpt *sp``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:110
#: drivers/gpu/host1x/syncpt.c:124 drivers/gpu/host1x/syncpt.c:205
#: drivers/gpu/host1x/syncpt.c:215 drivers/gpu/host1x/syncpt.c:361
#: drivers/gpu/host1x/syncpt.c:387 drivers/gpu/host1x/syncpt.c:402
#: drivers/gpu/host1x/syncpt.c:417 drivers/gpu/host1x/syncpt.c:488
msgid "host1x syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:111
msgid ""
"Given a pointer to a struct host1x_syncpt, retrieves its ID. This ID is "
"often used as a value to program into registers that control how hardware "
"blocks interact with syncpoints."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:123
msgid "update the value sent to hardware"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:126
msgid "``u32 incrs``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:125
msgid "number of increments"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:204
msgid "increment syncpoint value from CPU, updating cache"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:214
msgid "wait for a syncpoint to reach a given value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:217
msgid "``u32 thresh``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:216
msgid "threshold"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:218
msgid "``long timeout``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:217
msgid "maximum time to wait for the syncpoint to reach the given value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:219
msgid "``u32 *value``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:218
msgid "return location for the syncpoint value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:322
msgid "request a syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:323
msgid "client requesting the syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:324
msgid "flags"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:325
msgid ""
"host1x client drivers can use this function to allocate a syncpoint for "
"subsequent use. A syncpoint returned by this function will be reserved for "
"use by the client exclusively. When no longer using a syncpoint, a host1x "
"client driver needs to release it using host1x_syncpt_put()."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:360
msgid "free a requested syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:362
msgid ""
"Release a syncpoint previously allocated using host1x_syncpt_request(). A "
"host1x client driver should call this when the syncpoint is no longer in use."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:386
msgid "read maximum syncpoint value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:388
msgid ""
"The maximum syncpoint value indicates how many operations there are in "
"queue, either in channel or in a software thread."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:401
msgid "read minimum syncpoint value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:403
msgid ""
"The minimum syncpoint value is a shadow of the current sync point value in "
"hardware."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:416
msgid "read the current syncpoint value"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:441
msgid "obtain a syncpoint by ID"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:442
#: drivers/gpu/host1x/syncpt.c:461
msgid "host1x controller"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:444
#: drivers/gpu/host1x/syncpt.c:463
msgid "``unsigned int id``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:443
#: drivers/gpu/host1x/syncpt.c:462
msgid "syncpoint ID"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:459
msgid "obtain a syncpoint by ID but don't increase the refcount."
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:475
msgid "increment syncpoint refcount"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:476
msgid "syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:487
msgid "obtain the wait base associated with a syncpoint"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:497
msgid "retrieve the ID of a syncpoint wait base"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:503
msgid "``struct host1x_syncpt_base *base``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:498
msgid "host1x syncpoint wait base"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:511
msgid "Make VBLANK syncpoint available for allocation"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:514
msgid "host1x bus client"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:516
msgid "``u32 syncpt_id``"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:515
msgid "syncpoint ID to make available"
msgstr ""

#: ../../../gpu/tegra:58: drivers/gpu/host1x/syncpt.c:516
msgid ""
"Makes VBLANK<i> syncpoint available for allocatation if it was reserved at "
"initialization time. This should be called by the display driver after it "
"has ensured that any VBLANK increment programming configured by the boot "
"chain has been disabled."
msgstr ""

#: ../../../gpu/tegra.rst:62
msgid "KMS driver"
msgstr ""

#: ../../../gpu/tegra.rst:64
msgid ""
"The display hardware has remained mostly backwards compatible over the "
"various Tegra SoC generations, up until Tegra186 which introduces several "
"changes that make it difficult to support with a parameterized driver."
msgstr ""

#: ../../../gpu/tegra.rst:69
msgid "Display Controllers"
msgstr ""

#: ../../../gpu/tegra.rst:71
msgid ""
"Tegra SoCs have two display controllers, each of which can be associated "
"with zero or more outputs. Outputs can also share a single display "
"controller, but only if they run with compatible display timings. Two "
"display controllers can also share a single framebuffer, allowing cloned "
"configurations even if modes on two outputs don't match. A display "
"controller is modelled as a CRTC in KMS terms."
msgstr ""

#: ../../../gpu/tegra.rst:78
msgid ""
"On Tegra186, the number of display controllers has been increased to three. "
"A display controller can no longer drive all of the outputs. While two of "
"these controllers can drive both DSI outputs and both SOR outputs, the third "
"cannot drive any DSI."
msgstr ""

#: ../../../gpu/tegra.rst:84
msgid "Windows"
msgstr ""

#: ../../../gpu/tegra.rst:86
msgid ""
"A display controller controls a set of windows that can be used to composite "
"multiple buffers onto the screen. While it is possible to assign arbitrary Z "
"ordering to individual windows (by programming the corresponding blending "
"registers), this is currently not supported by the driver. Instead, it will "
"assume a fixed Z ordering of the windows (window A is the root window, that "
"is, the lowest, while windows B and C are overlaid on top of window A). The "
"overlay windows support multiple pixel formats and can automatically convert "
"from YUV to RGB at scanout time. This makes them useful for displaying video "
"content. In KMS, each window is modelled as a plane. Each display controller "
"has a hardware cursor that is exposed as a cursor plane."
msgstr ""

#: ../../../gpu/tegra.rst:98
msgid "Outputs"
msgstr ""

#: ../../../gpu/tegra.rst:100
msgid ""
"The type and number of supported outputs varies between Tegra SoC "
"generations. All generations support at least HDMI. While earlier "
"generations supported the very simple RGB interfaces (one per display "
"controller), recent generations no longer do and instead provide standard "
"interfaces such as DSI and eDP/DP."
msgstr ""

#: ../../../gpu/tegra.rst:105
msgid "Outputs are modelled as a composite encoder/connector pair."
msgstr ""

#: ../../../gpu/tegra.rst:108
msgid "RGB/LVDS"
msgstr ""

#: ../../../gpu/tegra.rst:110
msgid ""
"This interface is no longer available since Tegra124. It has been replaced "
"by the more standard DSI and eDP interfaces."
msgstr ""

#: ../../../gpu/tegra.rst:114
msgid "HDMI"
msgstr ""

#: ../../../gpu/tegra.rst:116
msgid ""
"HDMI is supported on all Tegra SoCs. Starting with Tegra210, HDMI is "
"provided by the versatile SOR output, which supports eDP, DP and HDMI. The "
"SOR is able to support HDMI 2.0, though support for this is currently not "
"merged."
msgstr ""

#: ../../../gpu/tegra.rst:121
msgid "DSI"
msgstr ""

#: ../../../gpu/tegra.rst:123
msgid ""
"Although Tegra has supported DSI since Tegra30, the controller has changed "
"in several ways in Tegra114. Since none of the publicly available "
"development boards prior to Dalmore (Tegra114) have made use of DSI, only "
"Tegra114 and later are supported by the drm/tegra driver."
msgstr ""

#: ../../../gpu/tegra.rst:129
msgid "eDP/DP"
msgstr ""

#: ../../../gpu/tegra.rst:131
msgid ""
"eDP was first introduced in Tegra124 where it was used to drive the display "
"panel for notebook form factors. Tegra210 added support for full DisplayPort "
"support, though this is currently not implemented in the drm/tegra driver."
msgstr ""

#: ../../../gpu/tegra.rst:136
msgid "Userspace Interface"
msgstr ""

#: ../../../gpu/tegra.rst:138
msgid ""
"The userspace interface provided by drm/tegra allows applications to create "
"GEM buffers, access and control syncpoints as well as submit command streams "
"to host1x."
msgstr ""

#: ../../../gpu/tegra.rst:143
msgid "GEM Buffers"
msgstr ""

#: ../../../gpu/tegra.rst:145
msgid ""
"The ``DRM_IOCTL_TEGRA_GEM_CREATE`` IOCTL is used to create a GEM buffer "
"object with Tegra-specific flags. This is useful for buffers that should be "
"tiled, or that are to be scanned out upside down (useful for 3D content)."
msgstr ""

#: ../../../gpu/tegra.rst:149
msgid ""
"After a GEM buffer object has been created, its memory can be mapped by an "
"application using the mmap offset returned by the "
"``DRM_IOCTL_TEGRA_GEM_MMAP`` IOCTL."
msgstr ""

#: ../../../gpu/tegra.rst:154
msgid "Syncpoints"
msgstr ""

#: ../../../gpu/tegra.rst:156
msgid ""
"The current value of a syncpoint can be obtained by executing the "
"``DRM_IOCTL_TEGRA_SYNCPT_READ`` IOCTL. Incrementing the syncpoint is "
"achieved using the ``DRM_IOCTL_TEGRA_SYNCPT_INCR`` IOCTL."
msgstr ""

#: ../../../gpu/tegra.rst:160
msgid ""
"Userspace can also request blocking on a syncpoint. To do so, it needs to "
"execute the ``DRM_IOCTL_TEGRA_SYNCPT_WAIT`` IOCTL, specifying the value of "
"the syncpoint to wait for. The kernel will release the application when the "
"syncpoint reaches that value or after a specified timeout."
msgstr ""

#: ../../../gpu/tegra.rst:166
msgid "Command Stream Submission"
msgstr ""

#: ../../../gpu/tegra.rst:168
msgid ""
"Before an application can submit command streams to host1x it needs to open "
"a channel to an engine using the ``DRM_IOCTL_TEGRA_OPEN_CHANNEL`` IOCTL. "
"Client IDs are used to identify the target of the channel. When a channel is "
"no longer needed, it can be closed using the "
"``DRM_IOCTL_TEGRA_CLOSE_CHANNEL`` IOCTL. To retrieve the syncpoint "
"associated with a channel, an application can use the "
"``DRM_IOCTL_TEGRA_GET_SYNCPT``."
msgstr ""

#: ../../../gpu/tegra.rst:175
msgid ""
"After opening a channel, submitting command streams is easy. The application "
"writes commands into the memory backing a GEM buffer object and passes these "
"to the ``DRM_IOCTL_TEGRA_SUBMIT`` IOCTL along with various other parameters, "
"such as the syncpoints or relocations used in the job submission."
msgstr ""
