# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel 6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-27 13:54+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../filesystems/ceph.rst:5
msgid "Ceph Distributed File System"
msgstr ""

#: ../../../filesystems/ceph.rst:7
msgid ""
"Ceph is a distributed network file system designed to provide good "
"performance, reliability, and scalability."
msgstr ""

#: ../../../filesystems/ceph.rst:10
msgid "Basic features include:"
msgstr ""

#: ../../../filesystems/ceph.rst:12
msgid "POSIX semantics"
msgstr ""

#: ../../../filesystems/ceph.rst:13
msgid "Seamless scaling from 1 to many thousands of nodes"
msgstr ""

#: ../../../filesystems/ceph.rst:14
msgid "High availability and reliability.  No single point of failure."
msgstr ""

#: ../../../filesystems/ceph.rst:15
msgid "N-way replication of data across storage nodes"
msgstr ""

#: ../../../filesystems/ceph.rst:16
msgid "Fast recovery from node failures"
msgstr ""

#: ../../../filesystems/ceph.rst:17
msgid "Automatic rebalancing of data on node addition/removal"
msgstr ""

#: ../../../filesystems/ceph.rst:18
msgid "Easy deployment: most FS components are userspace daemons"
msgstr ""

#: ../../../filesystems/ceph.rst:20
msgid "Also,"
msgstr ""

#: ../../../filesystems/ceph.rst:22
msgid "Flexible snapshots (on any directory)"
msgstr ""

#: ../../../filesystems/ceph.rst:23
msgid "Recursive accounting (nested files, directories, bytes)"
msgstr ""

#: ../../../filesystems/ceph.rst:25
msgid ""
"In contrast to cluster filesystems like GFS, OCFS2, and GPFS that rely on "
"symmetric access by all clients to shared block devices, Ceph separates data "
"and metadata management into independent server clusters, similar to "
"Lustre.  Unlike Lustre, however, metadata and storage nodes run entirely as "
"user space daemons.  File data is striped across storage nodes in large "
"chunks to distribute workload and facilitate high throughputs.  When storage "
"nodes fail, data is re-replicated in a distributed fashion by the storage "
"nodes themselves (with some minimal coordination from a cluster monitor), "
"making the system extremely efficient and scalable."
msgstr ""

#: ../../../filesystems/ceph.rst:36
msgid ""
"Metadata servers effectively form a large, consistent, distributed in-memory "
"cache above the file namespace that is extremely scalable, dynamically "
"redistributes metadata in response to workload changes, and can tolerate "
"arbitrary (well, non-Byzantine) node failures.  The metadata server takes a "
"somewhat unconventional approach to metadata storage to significantly "
"improve performance for common workloads.  In particular, inodes with only a "
"single link are embedded in directories, allowing entire directories of "
"dentries and inodes to be loaded into its cache with a single I/O "
"operation.  The contents of extremely large directories can be fragmented "
"and managed by independent metadata servers, allowing scalable concurrent "
"access."
msgstr ""

#: ../../../filesystems/ceph.rst:48
msgid ""
"The system offers automatic data rebalancing/migration when scaling from a "
"small cluster of just a few nodes to many hundreds, without requiring an "
"administrator carve the data set into static volumes or go through the "
"tedious process of migrating data between servers. When the file system "
"approaches full, new nodes can be easily added and things will \"just work.\""
msgstr ""

#: ../../../filesystems/ceph.rst:55
msgid ""
"Ceph includes flexible snapshot mechanism that allows a user to create a "
"snapshot on any subdirectory (and its nested contents) in the system.  "
"Snapshot creation and deletion are as simple as 'mkdir .snap/foo' and "
"'rmdir .snap/foo'."
msgstr ""

#: ../../../filesystems/ceph.rst:60
msgid "Snapshot names have two limitations:"
msgstr ""

#: ../../../filesystems/ceph.rst:62
msgid ""
"They can not start with an underscore ('_'), as these names are reserved for "
"internal usage by the MDS."
msgstr ""

#: ../../../filesystems/ceph.rst:64
msgid ""
"They can not exceed 240 characters in size.  This is because the MDS makes "
"use of long snapshot names internally, which follow the format: `_<SNAPSHOT-"
"NAME>_<INODE-NUMBER>`.  Since filenames in general can't have more than 255 "
"characters, and `<node-id>` takes 13 characters, the long snapshot names can "
"take as much as 255 - 1 - 1 - 13 = 240."
msgstr ""

#: ../../../filesystems/ceph.rst:70
msgid ""
"Ceph also provides some recursive accounting on directories for nested files "
"and bytes.  You can run the commands::"
msgstr ""

#: ../../../filesystems/ceph.rst:76
msgid ""
"to get the total number of nested files and their combined size, "
"respectively. This makes the identification of large disk space consumers "
"relatively quick, as no 'du' or similar recursive scan of the file system is "
"required."
msgstr ""

#: ../../../filesystems/ceph.rst:80
msgid ""
"Finally, Ceph also allows quotas to be set on any directory in the system. "
"The quota can restrict the number of bytes or the number of files stored "
"beneath that point in the directory hierarchy.  Quotas can be set using "
"extended attributes 'ceph.quota.max_files' and 'ceph.quota.max_bytes', eg::"
msgstr ""

#: ../../../filesystems/ceph.rst:88
msgid ""
"A limitation of the current quotas implementation is that it relies on the "
"cooperation of the client mounting the file system to stop writers when a "
"limit is reached.  A modified or adversarial client cannot be prevented from "
"writing as much data as it needs."
msgstr ""

#: ../../../filesystems/ceph.rst:94
msgid "Mount Syntax"
msgstr ""

#: ../../../filesystems/ceph.rst:96
msgid "The basic mount syntax is::"
msgstr ""

#: ../../../filesystems/ceph.rst:100
msgid ""
"You only need to specify a single monitor, as the client will get the full "
"list when it connects.  (However, if the monitor you specify happens to be "
"down, the mount won't succeed.)  The port can be left off if the monitor is "
"using the default.  So if the monitor is at 1.2.3.4::"
msgstr ""

#: ../../../filesystems/ceph.rst:108
msgid ""
"is sufficient.  If /sbin/mount.ceph is installed, a hostname can be used "
"instead of an IP address and the cluster FSID can be left out (as the mount "
"helper will fill it in by reading the ceph configuration file)::"
msgstr ""

#: ../../../filesystems/ceph.rst:115
msgid ""
"Multiple monitor addresses can be passed by separating each address with a "
"slash (`/`)::"
msgstr ""

#: ../../../filesystems/ceph.rst:119
msgid ""
"When using the mount helper, monitor address can be read from ceph "
"configuration file if available. Note that, the cluster FSID (passed as part "
"of the device string) is validated by checking it with the FSID reported by "
"the monitor."
msgstr ""

#: ../../../filesystems/ceph.rst:125
msgid "Mount Options"
msgstr ""

#: ../../../filesystems/ceph.rst:127
msgid "mon_addr=ip_address[:port][/ip_address[:port]]"
msgstr ""

#: ../../../filesystems/ceph.rst:128
msgid ""
"Monitor address to the cluster. This is used to bootstrap the connection to "
"the cluster. Once connection is established, the monitor addresses in the "
"monitor map are followed."
msgstr ""

#: ../../../filesystems/ceph.rst:132
msgid "fsid=cluster-id"
msgstr ""

#: ../../../filesystems/ceph.rst:133
msgid "FSID of the cluster (from `ceph fsid` command)."
msgstr ""

#: ../../../filesystems/ceph.rst:135
msgid "ip=A.B.C.D[:N]"
msgstr ""

#: ../../../filesystems/ceph.rst:136
msgid ""
"Specify the IP and/or port the client should bind to locally. There is "
"normally not much reason to do this.  If the IP is not specified, the "
"client's IP address is determined by looking at the address its connection "
"to the monitor originates from."
msgstr ""

#: ../../../filesystems/ceph.rst:141
msgid "wsize=X"
msgstr ""

#: ../../../filesystems/ceph.rst:142
msgid "Specify the maximum write size in bytes.  Default: 64 MB."
msgstr ""

#: ../../../filesystems/ceph.rst:144
msgid "rsize=X"
msgstr ""

#: ../../../filesystems/ceph.rst:145
msgid "Specify the maximum read size in bytes.  Default: 64 MB."
msgstr ""

#: ../../../filesystems/ceph.rst:147
msgid "rasize=X"
msgstr ""

#: ../../../filesystems/ceph.rst:148
msgid "Specify the maximum readahead size in bytes.  Default: 8 MB."
msgstr ""

#: ../../../filesystems/ceph.rst:150
msgid "mount_timeout=X"
msgstr ""

#: ../../../filesystems/ceph.rst:151
msgid ""
"Specify the timeout value for mount (in seconds), in the case of a non-"
"responsive Ceph file system.  The default is 60 seconds."
msgstr ""

#: ../../../filesystems/ceph.rst:155
msgid "caps_max=X"
msgstr ""

#: ../../../filesystems/ceph.rst:156
msgid ""
"Specify the maximum number of caps to hold. Unused caps are released when "
"number of caps exceeds the limit. The default is 0 (no limit)"
msgstr ""

#: ../../../filesystems/ceph.rst:159
msgid "rbytes"
msgstr ""

#: ../../../filesystems/ceph.rst:160
msgid ""
"When stat() is called on a directory, set st_size to 'rbytes', the summation "
"of file sizes over all files nested beneath that directory.  This is the "
"default."
msgstr ""

#: ../../../filesystems/ceph.rst:164
msgid "norbytes"
msgstr ""

#: ../../../filesystems/ceph.rst:165
msgid ""
"When stat() is called on a directory, set st_size to the number of entries "
"in that directory."
msgstr ""

#: ../../../filesystems/ceph.rst:168
msgid "nocrc"
msgstr ""

#: ../../../filesystems/ceph.rst:169
msgid ""
"Disable CRC32C calculation for data writes.  If set, the storage node must "
"rely on TCP's error correction to detect data corruption in the data payload."
msgstr ""

#: ../../../filesystems/ceph.rst:173
msgid "dcache"
msgstr ""

#: ../../../filesystems/ceph.rst:174
msgid ""
"Use the dcache contents to perform negative lookups and readdir when the "
"client has the entire directory contents in its cache.  (This does not "
"change correctness; the client uses cached metadata only when a lease or "
"capability ensures it is valid.)"
msgstr ""

#: ../../../filesystems/ceph.rst:180
msgid "nodcache"
msgstr ""

#: ../../../filesystems/ceph.rst:181
msgid ""
"Do not use the dcache as above.  This avoids a significant amount of complex "
"code, sacrificing performance without affecting correctness, and is useful "
"for tracking down bugs."
msgstr ""

#: ../../../filesystems/ceph.rst:185
msgid "noasyncreaddir"
msgstr ""

#: ../../../filesystems/ceph.rst:186
msgid "Do not use the dcache as above for readdir."
msgstr ""

#: ../../../filesystems/ceph.rst:188
msgid "noquotadf"
msgstr ""

#: ../../../filesystems/ceph.rst:189
msgid ""
"Report overall filesystem usage in statfs instead of using the root "
"directory quota."
msgstr ""

#: ../../../filesystems/ceph.rst:192
msgid "nocopyfrom"
msgstr ""

#: ../../../filesystems/ceph.rst:193
msgid ""
"Don't use the RADOS 'copy-from' operation to perform remote object copies.  "
"Currently, it's only used in copy_file_range, which will revert to the "
"default VFS implementation if this option is used."
msgstr ""

#: ../../../filesystems/ceph.rst:197
msgid "recover_session=<no|clean>"
msgstr ""

#: ../../../filesystems/ceph.rst:198
msgid ""
"Set auto reconnect mode in the case where the client is blocklisted. The "
"available modes are \"no\" and \"clean\". The default is \"no\"."
msgstr ""

#: ../../../filesystems/ceph.rst:201
msgid ""
"no: never attempt to reconnect when client detects that it has been "
"blocklisted. Operations will generally fail after being blocklisted."
msgstr ""

#: ../../../filesystems/ceph.rst:204
msgid ""
"clean: client reconnects to the ceph cluster automatically when it detects "
"that it has been blocklisted. During reconnect, client drops dirty data/"
"metadata, invalidates page caches and writable file handles. After "
"reconnect, file locks become stale because the MDS loses track of them. If "
"an inode contains any stale file locks, read/write on the inode is not "
"allowed until applications release all stale file locks."
msgstr ""

#: ../../../filesystems/ceph.rst:212
msgid "More Information"
msgstr ""

#: ../../../filesystems/ceph.rst:214
msgid "For more information on Ceph, see the home page at"
msgstr ""

#: ../../../filesystems/ceph.rst:215
msgid "https://ceph.com/"
msgstr ""

#: ../../../filesystems/ceph.rst:217
msgid "The Linux kernel client source tree is available at"
msgstr ""

#: ../../../filesystems/ceph.rst:218
msgid "https://github.com/ceph/ceph-client.git"
msgstr ""

#: ../../../filesystems/ceph.rst:220
msgid "and the source for the full system is at"
msgstr ""

#: ../../../filesystems/ceph.rst:221
msgid "https://github.com/ceph/ceph.git"
msgstr ""
