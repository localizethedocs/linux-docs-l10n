# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel 6\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-14 08:59+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../gpu/v3d.rst:3
msgid "drm/v3d Broadcom V3D Graphics Driver"
msgstr ""

#: ../../../gpu/v3d:5: drivers/gpu/drm/v3d/v3d_drv.c:5
msgid ""
"This driver supports the Broadcom V3D 3.3 and 4.1 OpenGL ES GPUs. For V3D 2."
"x support, see the VC4 driver."
msgstr ""

#: ../../../gpu/v3d:5: drivers/gpu/drm/v3d/v3d_drv.c:8
msgid ""
"The V3D GPU includes a tiled render (composed of a bin and render "
"pipelines), the TFU (texture formatting unit), and the CSD (compute shader "
"dispatch)."
msgstr ""

#: ../../../gpu/v3d.rst:9
msgid "GPU buffer object (BO) management"
msgstr ""

#: ../../../gpu/v3d:11: drivers/gpu/drm/v3d/v3d_bo.c:5
msgid ""
"Compared to VC4 (V3D 2.x), V3D 3.3 introduces an MMU between the GPU and the "
"bus, allowing us to use shmem objects for our storage instead of CMA."
msgstr ""

#: ../../../gpu/v3d:11: drivers/gpu/drm/v3d/v3d_bo.c:9
msgid ""
"Physically contiguous objects may still be imported to V3D, but the driver "
"doesn't allocate physically contiguous objects on its own. Display engines "
"requiring physically contiguous allocations should look into Mesa's "
"\"renderonly\" support (as used by the Mesa pl111 driver) for an example of "
"how to integrate with V3D."
msgstr ""

#: ../../../gpu/v3d.rst:15
msgid "Address space management"
msgstr ""

#: ../../../gpu/v3d:16: drivers/gpu/drm/v3d/v3d_mmu.c:5
msgid ""
"The V3D 3.x hardware (compared to VC4) now includes an MMU. It has a single "
"level of page tables for the V3D's 4GB address space to map to AXI bus "
"addresses, thus it could need up to 4MB of physically contiguous memory to "
"store the PTEs."
msgstr ""

#: ../../../gpu/v3d:16: drivers/gpu/drm/v3d/v3d_mmu.c:10
msgid ""
"Because the 4MB of contiguous memory for page tables is precious, and "
"switching between them is expensive, we load all BOs into the same 4GB "
"address space."
msgstr ""

#: ../../../gpu/v3d:16: drivers/gpu/drm/v3d/v3d_mmu.c:14
msgid ""
"To protect clients from each other, we should use the GMP to quickly mask "
"out (at 128kb granularity) what pages are available to each client. This is "
"not yet implemented."
msgstr ""

#: ../../../gpu/v3d.rst:20
msgid "GPU Scheduling"
msgstr ""

#: ../../../gpu/v3d:21: drivers/gpu/drm/v3d/v3d_sched.c:5
msgid ""
"The shared DRM GPU scheduler is used to coordinate submitting jobs to the "
"hardware. Each DRM fd (roughly a client process) gets its own scheduler "
"entity, which will process jobs in order. The GPU scheduler will schedule "
"the clients with a FIFO scheduling algorithm."
msgstr ""

#: ../../../gpu/v3d:21: drivers/gpu/drm/v3d/v3d_sched.c:10
msgid ""
"For simplicity, and in order to keep latency low for interactive jobs when "
"bulk background jobs are queued up, we submit a new job to the HW only when "
"it has completed the last one, instead of filling up the CT[01]Q FIFOs with "
"jobs. Similarly, we use `drm_sched_job_add_dependency()` to manage the "
"dependency between bin and render, instead of having the clients submit jobs "
"using the HW's semaphores to interlock between them."
msgstr ""

#: ../../../gpu/v3d.rst:25
msgid "Interrupts"
msgstr ""

#: ../../../gpu/v3d:27: drivers/gpu/drm/v3d/v3d_irq.c:5
msgid ""
"When we take a bin, render, TFU done, or CSD done interrupt, we need to "
"signal the fence for that job so that the scheduler can queue up the next "
"one and unblock any waiters."
msgstr ""

#: ../../../gpu/v3d:27: drivers/gpu/drm/v3d/v3d_irq.c:9
msgid ""
"When we take the binner out of memory interrupt, we need to allocate some "
"new memory and pass it to the binner so that the current job can make "
"progress."
msgstr ""
