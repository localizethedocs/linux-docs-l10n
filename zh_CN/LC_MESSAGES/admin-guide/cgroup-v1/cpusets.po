# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-29 08:26+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../admin-guide/cgroup-v1/cpusets.rst:5
msgid "CPUSETS"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:7
msgid "Copyright (C) 2004 BULL SA."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:9
msgid "Written by Simon.Derr@bull.net"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:11
msgid "Portions Copyright (c) 2004-2006 Silicon Graphics, Inc."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:12
msgid "Modified by Paul Jackson <pj@sgi.com>"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:13
msgid "Modified by Christoph Lameter <cl@gentwo.org>"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:14
msgid "Modified by Paul Menage <menage@google.com>"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:15
msgid "Modified by Hidetoshi Seto <seto.hidetoshi@jp.fujitsu.com>"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:38
msgid "1. Cpusets"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:41
msgid "1.1 What are cpusets ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:43
msgid ""
"Cpusets provide a mechanism for assigning a set of CPUs and Memory Nodes to "
"a set of tasks.   In this document \"Memory Node\" refers to an on-line node "
"that contains memory."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:47
msgid ""
"Cpusets constrain the CPU and Memory placement of tasks to only the "
"resources within a task's current cpuset.  They form a nested hierarchy "
"visible in a virtual file system.  These are the essential hooks, beyond "
"what is already present, required to manage dynamic job placement on large "
"systems."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:53
msgid ""
"Cpusets use the generic cgroup subsystem described in Documentation/admin-"
"guide/cgroup-v1/cgroups.rst."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:56
msgid ""
"Requests by a task, using the sched_setaffinity(2) system call to include "
"CPUs in its CPU affinity mask, and using the mbind(2) and set_mempolicy(2) "
"system calls to include Memory Nodes in its memory policy, are both filtered "
"through that task's cpuset, filtering out any CPUs or Memory Nodes not in "
"that cpuset.  The scheduler will not schedule a task on a CPU that is not "
"allowed in its cpus_allowed vector, and the kernel page allocator will not "
"allocate a page on a node that is not allowed in the requesting task's "
"mems_allowed vector."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:65
msgid ""
"User level code may create and destroy cpusets by name in the cgroup virtual "
"file system, manage the attributes and permissions of these cpusets and "
"which CPUs and Memory Nodes are assigned to each cpuset, specify and query "
"to which cpuset a task is assigned, and list the task pids assigned to a "
"cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:73
msgid "1.2 Why are cpusets needed ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:75
msgid ""
"The management of large computer systems, with many processors (CPUs), "
"complex memory cache hierarchies and multiple Memory Nodes having non-"
"uniform access times (NUMA) presents additional challenges for the efficient "
"scheduling and memory placement of processes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:80
msgid ""
"Frequently more modest sized systems can be operated with adequate "
"efficiency just by letting the operating system automatically share the "
"available CPU and Memory resources amongst the requesting tasks."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:84
msgid ""
"But larger systems, which benefit more from careful processor and memory "
"placement to reduce memory access times and contention, and which typically "
"represent a larger investment for the customer, can benefit from explicitly "
"placing jobs on properly sized subsets of the system."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:90
msgid "This can be especially valuable on:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:92
msgid "Web Servers running multiple instances of the same web application,"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:93
msgid ""
"Servers running different applications (for instance, a web server and a "
"database), or"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:95
msgid ""
"NUMA systems running large HPC applications with demanding performance "
"characteristics."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:98
msgid ""
"These subsets, or \"soft partitions\" must be able to be dynamically "
"adjusted, as the job mix changes, without impacting other concurrently "
"executing jobs. The location of the running jobs pages may also be moved "
"when the memory locations are changed."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:103
msgid ""
"The kernel cpuset patch provides the minimum essential kernel mechanisms "
"required to efficiently implement such subsets.  It leverages existing CPU "
"and Memory Placement facilities in the Linux kernel to avoid any additional "
"impact on the critical scheduler or memory allocator code."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:111
msgid "1.3 How are cpusets implemented ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:113
msgid ""
"Cpusets provide a Linux kernel mechanism to constrain which CPUs and Memory "
"Nodes are used by a process or set of processes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:116
msgid ""
"The Linux kernel already has a pair of mechanisms to specify on which CPUs a "
"task may be scheduled (sched_setaffinity) and on which Memory Nodes it may "
"obtain memory (mbind, set_mempolicy)."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:120
msgid "Cpusets extends these two mechanisms as follows:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:122
msgid "Cpusets are sets of allowed CPUs and Memory Nodes, known to the kernel."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:124
msgid ""
"Each task in the system is attached to a cpuset, via a pointer in the task "
"structure to a reference counted cgroup structure."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:126
msgid ""
"Calls to sched_setaffinity are filtered to just those CPUs allowed in that "
"task's cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:128
msgid ""
"Calls to mbind and set_mempolicy are filtered to just those Memory Nodes "
"allowed in that task's cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:130
msgid "The root cpuset contains all the systems CPUs and Memory Nodes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:132
msgid ""
"For any cpuset, one can define child cpusets containing a subset of the "
"parents CPU and Memory Node resources."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:134
msgid ""
"The hierarchy of cpusets can be mounted at /dev/cpuset, for browsing and "
"manipulation from user space."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:136
msgid ""
"A cpuset may be marked exclusive, which ensures that no other cpuset (except "
"direct ancestors and descendants) may contain any overlapping CPUs or Memory "
"Nodes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:139
msgid "You can list all the tasks (by pid) attached to any cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:141
msgid ""
"The implementation of cpusets requires a few, simple hooks into the rest of "
"the kernel, none in performance critical paths:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:144
msgid "in init/main.c, to initialize the root cpuset at system boot."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:145
msgid "in fork and exit, to attach and detach a task from its cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:146
msgid ""
"in sched_setaffinity, to mask the requested CPUs by what's allowed in that "
"task's cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:148
msgid ""
"in sched.c migrate_live_tasks(), to keep migrating tasks within the CPUs "
"allowed by their cpuset, if possible."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:150
msgid ""
"in the mbind and set_mempolicy system calls, to mask the requested Memory "
"Nodes by what's allowed in that task's cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:152
msgid "in page_alloc.c, to restrict memory to allowed nodes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:153
msgid "in vmscan.c, to restrict page recovery to the current cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:155
msgid ""
"You should mount the \"cgroup\" filesystem type in order to enable browsing "
"and modifying the cpusets presently known to the kernel.  No new system "
"calls are added for cpusets - all support for querying and modifying cpusets "
"is via this cpuset file system."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:160
msgid ""
"The /proc/<pid>/status file for each task has four added lines, displaying "
"the task's cpus_allowed (on which CPUs it may be scheduled) and mems_allowed "
"(on which Memory Nodes it may obtain memory), in the two formats seen in the "
"following example::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:170
msgid ""
"Each cpuset is represented by a directory in the cgroup file system "
"containing (on top of the standard cgroup files) the following files "
"describing that cpuset:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:174
msgid "cpuset.cpus: list of CPUs in that cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:175
msgid "cpuset.mems: list of Memory Nodes in that cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:176
msgid "cpuset.memory_migrate flag: if set, move pages to cpusets nodes"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:177
msgid "cpuset.cpu_exclusive flag: is cpu placement exclusive?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:178
msgid "cpuset.mem_exclusive flag: is memory placement exclusive?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:179
msgid "cpuset.mem_hardwall flag:  is memory allocation hardwalled"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:180
msgid "cpuset.memory_pressure: measure of how much paging pressure in cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:181
msgid ""
"cpuset.memory_spread_page flag: if set, spread page cache evenly on allowed "
"nodes"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:182
msgid "cpuset.memory_spread_slab flag: OBSOLETE. Doesn't have any function."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:183
msgid ""
"cpuset.sched_load_balance flag: if set, load balance within CPUs on that "
"cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:184
msgid ""
"cpuset.sched_relax_domain_level: the searching range when migrating tasks"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:186
msgid "In addition, only the root cpuset has the following file:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:188
msgid "cpuset.memory_pressure_enabled flag: compute memory_pressure?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:190
msgid ""
"New cpusets are created using the mkdir system call or shell command.  The "
"properties of a cpuset, such as its flags, allowed CPUs and Memory Nodes, "
"and attached tasks, are modified by writing to the appropriate file in that "
"cpusets directory, as listed above."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:195
msgid ""
"The named hierarchical structure of nested cpusets allows partitioning a "
"large system into nested, dynamically changeable, \"soft-partitions\"."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:198
msgid ""
"The attachment of each task, automatically inherited at fork by any children "
"of that task, to a cpuset allows organizing the work load on a system into "
"related sets of tasks such that each set is constrained to using the CPUs "
"and Memory Nodes of a particular cpuset.  A task may be re-attached to any "
"other cpuset, if allowed by the permissions on the necessary cpuset file "
"system directories."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:205
msgid ""
"Such management of a system \"in the large\" integrates smoothly with the "
"detailed placement done on individual tasks and memory regions using the "
"sched_setaffinity, mbind and set_mempolicy system calls."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:209
msgid "The following rules apply to each cpuset:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:211
msgid "Its CPUs and Memory Nodes must be a subset of its parents."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:212
msgid "It can't be marked exclusive unless its parent is."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:213
msgid "If its cpu or memory is exclusive, they may not overlap any sibling."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:215
msgid ""
"These rules, and the natural hierarchy of cpusets, enable efficient "
"enforcement of the exclusive guarantee, without having to scan all cpusets "
"every time any of them change to ensure nothing overlaps a exclusive "
"cpuset.  Also, the use of a Linux virtual file system (vfs) to represent the "
"cpuset hierarchy provides for a familiar permission and name space for "
"cpusets, with a minimum of additional kernel code."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:222
msgid ""
"The cpus and mems files in the root (top_cpuset) cpuset are read-only.  The "
"cpus file automatically tracks the value of cpu_online_mask using a CPU "
"hotplug notifier, and the mems file automatically tracks the value of "
"node_states[N_MEMORY]--i.e., nodes with memory--using the "
"cpuset_track_online_nodes() hook."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:228
msgid ""
"The cpuset.effective_cpus and cpuset.effective_mems files are normally read-"
"only copies of cpuset.cpus and cpuset.mems files respectively.  If the "
"cpuset cgroup filesystem is mounted with the special \"cpuset_v2_mode\" "
"option, the behavior of these files will become similar to the corresponding "
"files in cpuset v2.  In other words, hotplug events will not change cpuset."
"cpus and cpuset.mems.  Those events will only affect cpuset.effective_cpus "
"and cpuset.effective_mems which show the actual cpus and memory nodes that "
"are currently used by this cpuset. See Documentation/admin-guide/cgroup-v2."
"rst for more information about cpuset v2 behavior."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:241
msgid "1.4 What are exclusive cpusets ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:243
msgid ""
"If a cpuset is cpu or mem exclusive, no other cpuset, other than a direct "
"ancestor or descendant, may share any of the same CPUs or Memory Nodes."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:247
msgid ""
"A cpuset that is cpuset.mem_exclusive *or* cpuset.mem_hardwall is "
"\"hardwalled\", i.e. it restricts kernel allocations for page, buffer and "
"other data commonly shared by the kernel across multiple users.  All "
"cpusets, whether hardwalled or not, restrict allocations of memory for user "
"space.  This enables configuring a system so that several independent jobs "
"can share common kernel data, such as file system pages, while isolating "
"each job's user allocation in its own cpuset.  To do this, construct a large "
"mem_exclusive cpuset to hold all the jobs, and construct child, non-"
"mem_exclusive cpusets for each individual job. Only a small amount of "
"typical kernel memory, such as requests from interrupt handlers, is allowed "
"to be taken outside even a mem_exclusive cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:262
msgid "1.5 What is memory_pressure ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:263
msgid ""
"The memory_pressure of a cpuset provides a simple per-cpuset metric of the "
"rate that the tasks in a cpuset are attempting to free up in use memory on "
"the nodes of the cpuset to satisfy additional memory requests."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:268
msgid ""
"This enables batch managers monitoring jobs running in dedicated cpusets to "
"efficiently detect what level of memory pressure that job is causing."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:272
msgid ""
"This is useful both on tightly managed systems running a wide mix of "
"submitted jobs, which may choose to terminate or re-prioritize jobs that are "
"trying to use more memory than allowed on the nodes assigned to them, and "
"with tightly coupled, long running, massively parallel scientific computing "
"jobs that will dramatically fail to meet required performance goals if they "
"start to use more memory than allowed to them."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:279
msgid ""
"This mechanism provides a very economical way for the batch manager to "
"monitor a cpuset for signs of memory pressure.  It's up to the batch manager "
"or other user code to decide what to do about it and take action."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:284
msgid "==>"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:285
msgid ""
"Unless this feature is enabled by writing \"1\" to the special file /dev/"
"cpuset/memory_pressure_enabled, the hook in the rebalance code of "
"__alloc_pages() for this metric reduces to simply noticing that the "
"cpuset_memory_pressure_enabled flag is zero.  So only systems that enable "
"this feature will compute the metric."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:291
msgid "Why a per-cpuset, running average:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:293
msgid ""
"Because this meter is per-cpuset, rather than per-task or mm, the system "
"load imposed by a batch scheduler monitoring this metric is sharply reduced "
"on large systems, because a scan of the tasklist can be avoided on each set "
"of queries."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:298
msgid ""
"Because this meter is a running average, instead of an accumulating counter, "
"a batch scheduler can detect memory pressure with a single read, instead of "
"having to read and accumulate results for a period of time."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:303
msgid ""
"Because this meter is per-cpuset rather than per-task or mm, the batch "
"scheduler can obtain the key information, memory pressure in a cpuset, with "
"a single read, rather than having to query and accumulate results over all "
"the (dynamically changing) set of tasks in the cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:309
msgid ""
"A per-cpuset simple digital filter (requires a spinlock and 3 words of data "
"per-cpuset) is kept, and updated by any task attached to that cpuset, if it "
"enters the synchronous (direct) page reclaim code."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:313
msgid ""
"A per-cpuset file provides an integer number representing the recent (half-"
"life of 10 seconds) rate of direct page reclaims caused by the tasks in the "
"cpuset, in units of reclaims attempted per second, times 1000."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:320
msgid "1.6 What is memory spread ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:321
msgid ""
"There are two boolean flag files per cpuset that control where the kernel "
"allocates pages for the file system buffers and related in kernel data "
"structures.  They are called 'cpuset.memory_spread_page' and 'cpuset."
"memory_spread_slab'."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:326
msgid ""
"If the per-cpuset boolean flag file 'cpuset.memory_spread_page' is set, then "
"the kernel will spread the file system buffers (page cache) evenly over all "
"the nodes that the faulting task is allowed to use, instead of preferring to "
"put those pages on the node where the task is running."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:331
msgid ""
"If the per-cpuset boolean flag file 'cpuset.memory_spread_slab' is set, then "
"the kernel will spread some file system related slab caches, such as for "
"inodes and dentries evenly over all the nodes that the faulting task is "
"allowed to use, instead of preferring to put those pages on the node where "
"the task is running."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:337
msgid ""
"The setting of these flags does not affect anonymous data segment or stack "
"segment pages of a task."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:340
msgid ""
"By default, both kinds of memory spreading are off, and memory pages are "
"allocated on the node local to where the task is running, except perhaps as "
"modified by the task's NUMA mempolicy or cpuset configuration, so long as "
"sufficient free memory pages are available."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:345
msgid ""
"When new cpusets are created, they inherit the memory spread settings of "
"their parent."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:348
msgid ""
"Setting memory spreading causes allocations for the affected page or slab "
"caches to ignore the task's NUMA mempolicy and be spread instead.    Tasks "
"using mbind() or set_mempolicy() calls to set NUMA mempolicies will not "
"notice any change in these calls as a result of their containing task's "
"memory spread settings.  If memory spreading is turned off, then the "
"currently specified NUMA mempolicy once again applies to memory page "
"allocations."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:356
msgid ""
"Both 'cpuset.memory_spread_page' and 'cpuset.memory_spread_slab' are boolean "
"flag files.  By default they contain \"0\", meaning that the feature is off "
"for that cpuset.  If a \"1\" is written to that file, then that turns the "
"named feature on."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:361
msgid "The implementation is simple."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:363
msgid ""
"Setting the flag 'cpuset.memory_spread_page' turns on a per-process flag "
"PFA_SPREAD_PAGE for each task that is in that cpuset or subsequently joins "
"that cpuset.  The page allocation calls for the page cache is modified to "
"perform an inline check for this PFA_SPREAD_PAGE task flag, and if set, a "
"call to a new routine cpuset_mem_spread_node() returns the node to prefer "
"for the allocation."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:370
msgid ""
"Similarly, setting 'cpuset.memory_spread_slab' turns on the flag "
"PFA_SPREAD_SLAB, and appropriately marked slab caches will allocate pages "
"from the node returned by cpuset_mem_spread_node()."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:374
msgid ""
"The cpuset_mem_spread_node() routine is also simple.  It uses the value of a "
"per-task rotor cpuset_mem_spread_rotor to select the next node in the "
"current task's mems_allowed to prefer for the allocation."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:378
msgid ""
"This memory placement policy is also known (in other contexts) as round-"
"robin or interleave."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:381
msgid ""
"This policy can provide substantial improvements for jobs that need to place "
"thread local data on the corresponding node, but that need to access large "
"file system data sets that need to be spread across the several nodes in the "
"jobs cpuset in order to fit.  Without this policy, especially for jobs that "
"might have one thread reading in the data set, the memory allocation across "
"the nodes in the jobs cpuset can become very uneven."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:390
msgid "1.7 What is sched_load_balance ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:392
msgid ""
"The kernel scheduler (kernel/sched/core.c) automatically load balances "
"tasks.  If one CPU is underutilized, kernel code running on that CPU will "
"look for tasks on other more overloaded CPUs and move those tasks to itself, "
"within the constraints of such placement mechanisms as cpusets and "
"sched_setaffinity."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:398
msgid ""
"The algorithmic cost of load balancing and its impact on key shared kernel "
"data structures such as the task list increases more than linearly with the "
"number of CPUs being balanced.  So the scheduler has support to partition "
"the systems CPUs into a number of sched domains such that it only load "
"balances within each sched domain. Each sched domain covers some subset of "
"the CPUs in the system; no two sched domains overlap; some CPUs might not be "
"in any sched domain and hence won't be load balanced."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:407
msgid ""
"Put simply, it costs less to balance between two smaller sched domains than "
"one big one, but doing so means that overloads in one of the two domains "
"won't be load balanced to the other one."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:411
msgid ""
"By default, there is one sched domain covering all CPUs, including those "
"marked isolated using the kernel boot time \"isolcpus=\" argument. However, "
"the isolated CPUs will not participate in load balancing, and will not have "
"tasks running on them unless explicitly assigned."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:416
msgid ""
"This default load balancing across all CPUs is not well suited for the "
"following two situations:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:419
msgid ""
"On large systems, load balancing across many CPUs is expensive. If the "
"system is managed using cpusets to place independent jobs on separate sets "
"of CPUs, full load balancing is unnecessary."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:422
msgid ""
"Systems supporting realtime on some CPUs need to minimize system overhead on "
"those CPUs, including avoiding task load balancing if that is not needed."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:426
msgid ""
"When the per-cpuset flag \"cpuset.sched_load_balance\" is enabled (the "
"default setting), it requests that all the CPUs in that cpusets allowed "
"'cpuset.cpus' be contained in a single sched domain, ensuring that load "
"balancing can move a task (not otherwised pinned, as by sched_setaffinity) "
"from any CPU in that cpuset to any other."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:432
msgid ""
"When the per-cpuset flag \"cpuset.sched_load_balance\" is disabled, then the "
"scheduler will avoid load balancing across the CPUs in that cpuset, --"
"except-- in so far as is necessary because some overlapping cpuset has "
"\"sched_load_balance\" enabled."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:437
msgid ""
"So, for example, if the top cpuset has the flag \"cpuset."
"sched_load_balance\" enabled, then the scheduler will have one sched domain "
"covering all CPUs, and the setting of the \"cpuset.sched_load_balance\" flag "
"in any other cpusets won't matter, as we're already fully load balancing."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:442
msgid ""
"Therefore in the above two situations, the top cpuset flag \"cpuset."
"sched_load_balance\" should be disabled, and only some of the smaller, child "
"cpusets have this flag enabled."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:446
msgid ""
"When doing this, you don't usually want to leave any unpinned tasks in the "
"top cpuset that might use non-trivial amounts of CPU, as such tasks may be "
"artificially constrained to some subset of CPUs, depending on the "
"particulars of this flag setting in descendant cpusets.  Even if such a task "
"could use spare CPU cycles in some other CPUs, the kernel scheduler might "
"not consider the possibility of load balancing that task to that underused "
"CPU."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:454
msgid ""
"Of course, tasks pinned to a particular CPU can be left in a cpuset that "
"disables \"cpuset.sched_load_balance\" as those tasks aren't going anywhere "
"else anyway."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:458
msgid ""
"There is an impedance mismatch here, between cpusets and sched domains. "
"Cpusets are hierarchical and nest.  Sched domains are flat; they don't "
"overlap and each CPU is in at most one sched domain."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:462
msgid ""
"It is necessary for sched domains to be flat because load balancing across "
"partially overlapping sets of CPUs would risk unstable dynamics that would "
"be beyond our understanding.  So if each of two partially overlapping "
"cpusets enables the flag 'cpuset.sched_load_balance', then we form a single "
"sched domain that is a superset of both.  We won't move a task to a CPU "
"outside its cpuset, but the scheduler load balancing code might waste some "
"compute cycles considering that possibility."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:470
msgid ""
"This mismatch is why there is not a simple one-to-one relation between which "
"cpusets have the flag \"cpuset.sched_load_balance\" enabled, and the sched "
"domain configuration.  If a cpuset enables the flag, it will get balancing "
"across all its CPUs, but if it disables the flag, it will only be assured of "
"no load balancing if no other overlapping cpuset enables the flag."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:477
msgid ""
"If two cpusets have partially overlapping 'cpuset.cpus' allowed, and only "
"one of them has this flag enabled, then the other may find its tasks only "
"partially load balanced, just on the overlapping CPUs. This is just the "
"general case of the top_cpuset example given a few paragraphs above.  In the "
"general case, as in the top cpuset case, don't leave tasks that might use "
"non-trivial amounts of CPU in such partially load balanced cpusets, as they "
"may be artificially constrained to some subset of the CPUs allowed to them, "
"for lack of load balancing to the other CPUs."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:487
msgid ""
"CPUs in \"cpuset.isolcpus\" were excluded from load balancing by the "
"isolcpus= kernel boot option, and will never be load balanced regardless of "
"the value of \"cpuset.sched_load_balance\" in any cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:492
msgid "1.7.1 sched_load_balance implementation details."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:494
msgid ""
"The per-cpuset flag 'cpuset.sched_load_balance' defaults to enabled "
"(contrary to most cpuset flags.)  When enabled for a cpuset, the kernel will "
"ensure that it can load balance across all the CPUs in that cpuset (makes "
"sure that all the CPUs in the cpus_allowed of that cpuset are in the same "
"sched domain.)"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:500
msgid ""
"If two overlapping cpusets both have 'cpuset.sched_load_balance' enabled, "
"then they will be (must be) both in the same sched domain."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:503
msgid ""
"If, as is the default, the top cpuset has 'cpuset.sched_load_balance' "
"enabled, then by the above that means there is a single sched domain "
"covering the whole system, regardless of any other cpuset settings."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:507
msgid ""
"The kernel commits to user space that it will avoid load balancing where it "
"can.  It will pick as fine a granularity partition of sched domains as it "
"can while still providing load balancing for any set of CPUs allowed to a "
"cpuset having 'cpuset.sched_load_balance' enabled."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:512
msgid ""
"The internal kernel cpuset to scheduler interface passes from the cpuset "
"code to the scheduler code a partition of the load balanced CPUs in the "
"system. This partition is a set of subsets (represented as an array of "
"struct cpumask) of CPUs, pairwise disjoint, that cover all the CPUs that "
"must be load balanced."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:518
msgid ""
"The cpuset code builds a new such partition and passes it to the scheduler "
"sched domain setup code, to have the sched domains rebuilt as necessary, "
"whenever:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:522
msgid ""
"the 'cpuset.sched_load_balance' flag of a cpuset with non-empty CPUs changes,"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:523
msgid "or CPUs come or go from a cpuset with this flag enabled,"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:524
msgid ""
"or 'cpuset.sched_relax_domain_level' value of a cpuset with non-empty CPUs "
"and with this flag enabled changes,"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:526
msgid "or a cpuset with non-empty CPUs and with this flag enabled is removed,"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:527
msgid "or a cpu is offlined/onlined."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:529
msgid ""
"This partition exactly defines what sched domains the scheduler should setup "
"- one sched domain for each element (struct cpumask) in the partition."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:533
msgid ""
"The scheduler remembers the currently active sched domain partitions. When "
"the scheduler routine partition_sched_domains() is invoked from the cpuset "
"code to update these sched domains, it compares the new partition requested "
"with the current, and updates its sched domains, removing the old and adding "
"the new, for each change."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:541
msgid "1.8 What is sched_relax_domain_level ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:543
msgid ""
"In sched domain, the scheduler migrates tasks in 2 ways; periodic load "
"balance on tick, and at time of some schedule events."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:546
msgid ""
"When a task is woken up, scheduler try to move the task on idle CPU. For "
"example, if a task A running on CPU X activates another task B on the same "
"CPU X, and if CPU Y is X's sibling and performing idle, then scheduler "
"migrate task B to CPU Y so that task B can start on CPU Y without waiting "
"task A on CPU X."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:552
msgid ""
"And if a CPU run out of tasks in its runqueue, the CPU try to pull extra "
"tasks from other busy CPUs to help them before it is going to be idle."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:556
msgid ""
"Of course it takes some searching cost to find movable tasks and/or idle "
"CPUs, the scheduler might not search all CPUs in the domain every time.  In "
"fact, in some architectures, the searching ranges on events are limited in "
"the same socket or node where the CPU locates, while the load balance on "
"tick searches all."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:562
msgid ""
"For example, assume CPU Z is relatively far from CPU X.  Even if CPU Z is "
"idle while CPU X and the siblings are busy, scheduler can't migrate woken "
"task B from X to Z since it is out of its searching range. As the result, "
"task B on CPU X need to wait task A or wait load balance on the next tick.  "
"For some applications in special situation, waiting 1 tick may be too long."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:569
msgid ""
"The 'cpuset.sched_relax_domain_level' file allows you to request changing "
"this searching range as you like.  This file takes int value which indicates "
"size of searching range in levels approximately as follows, otherwise "
"initial value -1 that indicates the cpuset has no request."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:575
msgid "-1"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:575
msgid "no request. use system default or follow request of others."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:576
msgid "0"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:576
msgid "no search."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:577
msgid "1"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:577
msgid "search siblings (hyperthreads in a core)."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:578
msgid "2"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:578
msgid "search cores in a package."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:579
msgid "3"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:579
msgid "search cpus in a node [= system wide on non-NUMA system]"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:580
msgid "4"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:580
msgid "search nodes in a chunk of node [on NUMA system]"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:581
msgid "5"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:581
msgid "search system wide [on NUMA system]"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:584
msgid ""
"Not all levels can be present and values can change depending on the system "
"architecture and kernel configuration. Check /sys/kernel/debug/sched/domains/"
"cpu*/domain*/ for system-specific details."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:589
msgid ""
"The system default is architecture dependent.  The system default can be "
"changed using the relax_domain_level= boot parameter."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:592
msgid ""
"This file is per-cpuset and affect the sched domain where the cpuset belongs "
"to.  Therefore if the flag 'cpuset.sched_load_balance' of a cpuset is "
"disabled, then 'cpuset.sched_relax_domain_level' have no effect since there "
"is no sched domain belonging the cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:597
msgid ""
"If multiple cpusets are overlapping and hence they form a single sched "
"domain, the largest value among those is used.  Be careful, if one requests "
"0 and others are -1 then 0 is used."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:601
msgid ""
"Note that modifying this file will have both good and bad effects, and "
"whether it is acceptable or not depends on your situation. Don't modify this "
"file if you are not sure."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:605
msgid "If your situation is:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:607
msgid ""
"The migration costs between each cpu can be assumed considerably small(for "
"you) due to your special application's behavior or special hardware support "
"for CPU cache etc."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:610
msgid ""
"The searching cost doesn't have impact(for you) or you can make the "
"searching cost enough small by managing cpuset to compact etc."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:612
msgid ""
"The latency is required even it sacrifices cache hit rate etc. then "
"increasing 'sched_relax_domain_level' would benefit you."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:617
msgid "1.9 How do I use cpusets ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:619
msgid ""
"In order to minimize the impact of cpusets on critical kernel code, such as "
"the scheduler, and due to the fact that the kernel does not support one task "
"updating the memory placement of another task directly, the impact on a task "
"of changing its cpuset CPU or Memory Node placement, or of changing to which "
"cpuset a task is attached, is subtle."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:626
msgid ""
"If a cpuset has its Memory Nodes modified, then for each task attached to "
"that cpuset, the next time that the kernel attempts to allocate a page of "
"memory for that task, the kernel will notice the change in the task's "
"cpuset, and update its per-task memory placement to remain within the new "
"cpusets memory placement.  If the task was using mempolicy MPOL_BIND, and "
"the nodes to which it was bound overlap with its new cpuset, then the task "
"will continue to use whatever subset of MPOL_BIND nodes are still allowed in "
"the new cpuset.  If the task was using MPOL_BIND and now none of its "
"MPOL_BIND nodes are allowed in the new cpuset, then the task will be "
"essentially treated as if it was MPOL_BIND bound to the new cpuset (even "
"though its NUMA placement, as queried by get_mempolicy(), doesn't change).  "
"If a task is moved from one cpuset to another, then the kernel will adjust "
"the task's memory placement, as above, the next time that the kernel "
"attempts to allocate a page of memory for that task."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:642
msgid ""
"If a cpuset has its 'cpuset.cpus' modified, then each task in that cpuset "
"will have its allowed CPU placement changed immediately.  Similarly, if a "
"task's pid is written to another cpuset's 'tasks' file, then its allowed CPU "
"placement is changed immediately.  If such a task had been bound to some "
"subset of its cpuset using the sched_setaffinity() call, the task will be "
"allowed to run on any CPU allowed in its new cpuset, negating the effect of "
"the prior sched_setaffinity() call."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:650
msgid ""
"In summary, the memory placement of a task whose cpuset is changed is "
"updated by the kernel, on the next allocation of a page for that task, and "
"the processor placement is updated immediately."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:654
msgid ""
"Normally, once a page is allocated (given a physical page of main memory) "
"then that page stays on whatever node it was allocated, so long as it "
"remains allocated, even if the cpusets memory placement policy 'cpuset.mems' "
"subsequently changes. If the cpuset flag file 'cpuset.memory_migrate' is set "
"true, then when tasks are attached to that cpuset, any pages that task had "
"allocated to it on nodes in its previous cpuset are migrated to the task's "
"new cpuset. The relative placement of the page within the cpuset is "
"preserved during these migration operations if possible. For example if the "
"page was on the second valid node of the prior cpuset then the page will be "
"placed on the second valid node of the new cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:666
msgid ""
"Also if 'cpuset.memory_migrate' is set true, then if that cpuset's 'cpuset."
"mems' file is modified, pages allocated to tasks in that cpuset, that were "
"on nodes in the previous setting of 'cpuset.mems', will be moved to nodes in "
"the new setting of 'mems.' Pages that were not in the task's prior cpuset, "
"or in the cpuset's prior 'cpuset.mems' setting, will not be moved."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:673
msgid ""
"There is an exception to the above.  If hotplug functionality is used to "
"remove all the CPUs that are currently assigned to a cpuset, then all the "
"tasks in that cpuset will be moved to the nearest ancestor with non-empty "
"cpus.  But the moving of some (or all) tasks might fail if cpuset is bound "
"with another cgroup subsystem which has some restrictions on task "
"attaching.  In this failing case, those tasks will stay in the original "
"cpuset, and the kernel will automatically update their cpus_allowed to allow "
"all online CPUs.  When memory hotplug functionality for removing Memory "
"Nodes is available, a similar exception is expected to apply there as well.  "
"In general, the kernel prefers to violate cpuset placement, over starving a "
"task that has had all its allowed CPUs or Memory Nodes taken offline."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:686
msgid ""
"There is a second exception to the above.  GFP_ATOMIC requests are kernel "
"internal allocations that must be satisfied, immediately. The kernel may "
"drop some request, in rare cases even panic, if a GFP_ATOMIC alloc fails.  "
"If the request cannot be satisfied within the current task's cpuset, then we "
"relax the cpuset, and look for memory anywhere we can find it.  It's better "
"to violate the cpuset than stress the kernel."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:694
msgid ""
"To start a new job that is to be contained within a cpuset, the steps are:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:696
msgid "mkdir /sys/fs/cgroup/cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:697
msgid "mount -t cgroup -ocpuset cpuset /sys/fs/cgroup/cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:698
msgid ""
"Create the new cpuset by doing mkdir's and write's (or echo's) in the /sys/"
"fs/cgroup/cpuset virtual file system."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:700
msgid "Start a task that will be the \"founding father\" of the new job."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:701
msgid ""
"Attach that task to the new cpuset by writing its pid to the /sys/fs/cgroup/"
"cpuset tasks file for that cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:703
msgid "fork, exec or clone the job tasks from this founding father task."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:705
msgid ""
"For example, the following sequence of commands will setup a cpuset named "
"\"Charlie\", containing just CPUs 2 and 3, and Memory Node 1, and then start "
"a subshell 'sh' in that cpuset::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:721
msgid "There are ways to query or modify cpusets:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:723
msgid ""
"via the cpuset file system directly, using the various cd, mkdir, echo, cat, "
"rmdir commands from the shell, or their equivalent from C."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:725
msgid "via the C library libcpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:726
msgid "via the C library libcgroup. (https://github.com/libcgroup/libcgroup/)"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:728
msgid "via the python application cset. (http://code.google.com/p/cpuset/)"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:731
msgid ""
"The sched_setaffinity calls can also be done at the shell prompt using SGI's "
"runon or Robert Love's taskset.  The mbind and set_mempolicy calls can be "
"done at the shell prompt using the numactl command (part of Andi Kleen's "
"numa package)."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:737
msgid "2. Usage Examples and Syntax"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:740
msgid "2.1 Basic Usage"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:742
msgid ""
"Creating, modifying, using the cpusets can be done through the cpuset "
"virtual filesystem."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:745
msgid ""
"To mount it, type: # mount -t cgroup -o cpuset cpuset /sys/fs/cgroup/cpuset"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:748
msgid ""
"Then under /sys/fs/cgroup/cpuset you can find a tree that corresponds to the "
"tree of the cpusets in the system. For instance, /sys/fs/cgroup/cpuset is "
"the cpuset that holds the whole system."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:752
msgid "If you want to create a new cpuset under /sys/fs/cgroup/cpuset::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:757
msgid "Now you want to do something with this cpuset::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:761
msgid "In this directory you can find several files::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:773
msgid ""
"Reading them will give you information about the state of this cpuset: the "
"CPUs and Memory Nodes it can use, the processes that are using it, its "
"properties.  By writing to these files you can manipulate the cpuset."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:778
msgid "Set some flags::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:782
msgid "Add some cpus::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:786
msgid "Add some mems::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:790
msgid "Now attach your shell to this cpuset::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:794
msgid ""
"You can also create cpusets inside your cpuset by using mkdir in this "
"directory::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:799
msgid "To remove a cpuset, just use rmdir::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:803
msgid ""
"This will fail if the cpuset is in use (has cpusets inside, or has processes "
"attached)."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:806
msgid ""
"Note that for legacy reasons, the \"cpuset\" filesystem exists as a wrapper "
"around the cgroup filesystem."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:809
msgid "The command::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:813
msgid "is equivalent to::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:819
msgid "2.2 Adding/removing cpus"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:821
msgid ""
"This is the syntax to use when writing in the cpus or mems files in cpuset "
"directories::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:827
msgid ""
"To add a CPU to a cpuset, write the new list of CPUs including the CPU to be "
"added. To add 6 to the above cpuset::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:832
msgid ""
"Similarly to remove a CPU from a cpuset, write the new list of CPUs without "
"the CPU to be removed."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:835
msgid "To remove all the CPUs::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:840
msgid "2.3 Setting flags"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:842
msgid "The syntax is very simple::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:848
msgid "2.4 Attaching processes"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:854
msgid ""
"Note that it is PID, not PIDs. You can only attach ONE task at a time. If "
"you have several tasks to attach, you have to do it one after another::"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:864
msgid "3. Questions"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:866
#: ../../../admin-guide/cgroup-v1/cpusets.rst:874
msgid "Q:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:867
msgid "what's up with this '/bin/echo' ?"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:869
#: ../../../admin-guide/cgroup-v1/cpusets.rst:877
msgid "A:"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:870
msgid ""
"bash's builtin 'echo' command does not check calls to write() against "
"errors. If you use it in the cpuset file system, you won't be able to tell "
"whether a command succeeded or failed."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:875
msgid ""
"When I attach processes, only the first of the line gets really attached !"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:878
msgid ""
"We can only return one error code per call to write(). So you should also "
"put only ONE pid."
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:882
msgid "4. Contact"
msgstr ""

#: ../../../admin-guide/cgroup-v1/cpusets.rst:884
msgid "Web: http://www.bullopensource.org/cpuset"
msgstr ""
