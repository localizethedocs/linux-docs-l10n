# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-01-06 06:05+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../gpu/xe/xe_cs.rst:5
msgid "Command submission"
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:28
msgid ""
"Execs have historically been rather complicated in DRM drivers (at least in "
"the i915) because a few things:"
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:31
msgid ""
"Passing in a list BO which are read / written to creating implicit syncs"
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:32
msgid "Binding at exec time"
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:33
msgid "Flow controlling the ring at exec time"
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:35
msgid ""
"In Xe we avoid all of this complication by not allowing a BO list to be "
"passed into an exec, using the dma-buf implicit sync uAPI, have binds as "
"separate operations, and using the DRM scheduler to flow control the ring. "
"Let's deep dive on each of these."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:40
msgid ""
"We can get away from a BO list by forcing the user to use in / out fences on "
"every exec rather than the kernel tracking dependencies of BO (e.g. if the "
"user knows an exec writes to a BO and reads from the BO in the next exec, it "
"is the user's responsibility to pass in / out fence between the two execs)."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:45
msgid ""
"We do not allow a user to trigger a bind at exec time rather we have a VM "
"bind IOCTL which uses the same in / out fence interface as exec. In that "
"sense, a VM bind is basically the same operation as an exec from the user "
"perspective. e.g. If an exec depends on a VM bind use the in / out fence "
"interface (struct drm_xe_sync) to synchronize like syncing between two "
"dependent execs."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:52
msgid ""
"Although a user cannot trigger a bind, we still have to rebind userptrs in "
"the VM that have been invalidated since the last exec, likewise we also have "
"to rebind BOs that have been evicted by the kernel. We schedule these "
"rebinds behind any pending kernel operations on any external BOs in VM or "
"any BOs private to the VM. This is accomplished by the rebinds waiting on "
"BOs DMA_RESV_USAGE_KERNEL slot (kernel ops) and kernel ops waiting on all "
"BOs slots (inflight execs are in the DMA_RESV_USAGE_BOOKKEEP for private BOs "
"and for external BOs)."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:61
msgid ""
"Rebinds / dma-resv usage applies to non-compute mode VMs only as for compute "
"mode VMs we use preempt fences and a rebind worker (TODO: add link)."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:64
msgid ""
"There is no need to flow control the ring in the exec as we write the ring "
"at submission time and set the DRM scheduler max job limit SIZE_OF_RING / "
"MAX_JOB_SIZE. The DRM scheduler will then hold all jobs until space in the "
"ring is available."
msgstr ""

#: ../../../gpu/xe/xe_cs:7: ../drivers/gpu/drm/xe/xe_exec.c:69
msgid "All of this results in a rather simple exec implementation."
msgstr ""
