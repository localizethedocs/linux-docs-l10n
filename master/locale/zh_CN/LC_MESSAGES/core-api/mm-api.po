# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2026-02-09 08:48+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../core-api/mm-api.rst:3
msgid "Memory Management APIs"
msgstr ""

#: ../../../core-api/mm-api.rst:6
msgid "User Space Memory Access"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:93
msgid "``get_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:91
msgid "Get a simple variable from user space."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:417 ../mm/page_alloc.c:444
#: ../mm/page_alloc.c:466 ../mm/page_alloc.c:491 ../mm/page_alloc.c:516
#: ../mm/page_alloc.c:536 ../mm/page_alloc.c:556 ../mm/page_alloc.c:2110
#: ../mm/page_alloc.c:3179 ../mm/page_alloc.c:5342 ../mm/page_alloc.c:5377
#: ../mm/page_alloc.c:5417 ../mm/page_alloc.c:5445 ../mm/page_alloc.c:5471
#: ../mm/page_alloc.c:5490 ../mm/page_alloc.c:5522 ../mm/page_alloc.c:5598
#: ../mm/page_alloc.c:6494 ../mm/page_alloc.c:6959 ../mm/page_alloc.c:7160
#: ../mm/page_alloc.c:7699 ../../../core-api/mm-api:101: ../mm/mempolicy.c:283
#: ../mm/mempolicy.c:315 ../mm/mempolicy.c:822 ../mm/mempolicy.c:2436
#: ../mm/mempolicy.c:2519 ../mm/mempolicy.c:2566 ../mm/mempolicy.c:2971
#: ../mm/mempolicy.c:3201 ../mm/mempolicy.c:3410 ../mm/mempolicy.c:3545
#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:18
#: ../include/linux/mm_inline.h:67 ../include/linux/mm_inline.h:85
#: ../include/linux/mm_inline.h:627 ../../../core-api/mm-api:105:
#: ../include/linux/page-flags.h:298 ../include/linux/page-flags.h:315
#: ../include/linux/page-flags.h:761 ../include/linux/page-flags.h:780
#: ../include/linux/page-flags.h:862 ../include/linux/page-flags.h:1074
#: ../include/linux/page-flags.h:1143 ../include/linux/page-flags.h:1229
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:237
#: ../include/linux/mm.h:656 ../include/linux/mm.h:1244
#: ../include/linux/mm.h:1260 ../include/linux/mm.h:1378
#: ../include/linux/mm.h:1411 ../include/linux/mm.h:1466
#: ../include/linux/mm.h:1476 ../include/linux/mm.h:1572
#: ../include/linux/mm.h:1605 ../include/linux/mm.h:1624
#: ../include/linux/mm.h:1665 ../include/linux/mm.h:2039
#: ../include/linux/mm.h:2064 ../include/linux/mm.h:2080
#: ../include/linux/mm.h:2096 ../include/linux/mm.h:2121
#: ../include/linux/mm.h:2180 ../include/linux/mm.h:2191
#: ../include/linux/mm.h:2260 ../include/linux/mm.h:2317
#: ../include/linux/mm.h:2336 ../include/linux/mm.h:2353
#: ../include/linux/mm.h:2366 ../include/linux/mm.h:2430
#: ../include/linux/mm.h:3131 ../include/linux/mm.h:3147
#: ../include/linux/mm.h:3159 ../include/linux/mm.h:3176
#: ../include/linux/mm.h:3187 ../include/linux/mm.h:3220
#: ../include/linux/mm.h:3765 ../include/linux/mm.h:3828
#: ../include/linux/mm.h:3855 ../include/linux/mm.h:3867
#: ../include/linux/mm.h:3885 ../include/linux/mm.h:4457
#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:75
#: ../include/linux/page_ref.h:256 ../../../core-api/mm-api:109:
#: ../include/linux/mmzone.h:1644 ../include/linux/mmzone.h:1685
#: ../include/linux/mmzone.h:1693 ../include/linux/mmzone.h:1732
#: ../include/linux/mmzone.h:1756 ../include/linux/mmzone.h:1781
#: ../include/linux/mmzone.h:1805 ../include/linux/mmzone.h:2161
#: ../../../core-api/mm-api:110: ../mm/util.c:685 ../../../core-api/mm-api:113:
#: ../mm/rmap.c:164 ../mm/rmap.c:750 ../mm/rmap.c:937 ../mm/rmap.c:1137
#: ../mm/rmap.c:1182 ../mm/rmap.c:1315 ../mm/rmap.c:1340 ../mm/rmap.c:1372
#: ../mm/rmap.c:1463 ../mm/rmap.c:1487 ../mm/rmap.c:1511 ../mm/rmap.c:1602
#: ../mm/rmap.c:1619 ../mm/rmap.c:1639 ../mm/rmap.c:1770 ../mm/rmap.c:1787
#: ../mm/rmap.c:1807 ../mm/rmap.c:2254 ../mm/rmap.c:2596 ../mm/rmap.c:2643
#: ../mm/rmap.c:2876 ../../../core-api/mm-api:114: ../mm/migrate.c:104
#: ../mm/migrate.c:190 ../mm/migrate.c:215 ../mm/migrate.c:884
#: ../mm/migrate.c:1009 ../mm/migrate.c:1031 ../../../core-api/mm-api:115:
#: ../mm/mmap.c:282 ../mm/mmap.c:878 ../mm/mmap.c:898 ../mm/mmap.c:915
#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1083 ../mm/kmemleak.c:1107
#: ../mm/kmemleak.c:1126 ../mm/kmemleak.c:1151 ../mm/kmemleak.c:1167
#: ../mm/kmemleak.c:1185 ../mm/kmemleak.c:1201 ../mm/kmemleak.c:1237
#: ../mm/kmemleak.c:1253 ../mm/kmemleak.c:1270 ../mm/kmemleak.c:1284
#: ../mm/kmemleak.c:1302 ../mm/kmemleak.c:1322 ../mm/kmemleak.c:1340
#: ../mm/kmemleak.c:1360 ../mm/kmemleak.c:1376 ../../../core-api/mm-api:118:
#: ../mm/memremap.c:359 ../mm/memremap.c:402 ../../../core-api/mm-api:119:
#: ../mm/hugetlb.c:1034 ../mm/hugetlb.c:6914 ../mm/hugetlb.c:7110
#: ../mm/hugetlb.c:7175 ../../../core-api/mm-api:11:
#: ../arch/x86/lib/usercopy_32.c:56 ../arch/x86/lib/usercopy_32.c:76
#: ../../../core-api/mm-api:120: ../mm/swap.c:447 ../mm/swap.c:496
#: ../mm/swap.c:520 ../mm/swap.c:681 ../mm/swap.c:722 ../mm/swap.c:941
#: ../mm/swap.c:1011 ../mm/swap.c:1071 ../../../core-api/mm-api:121:
#: ../mm/memcontrol.c:246 ../mm/memcontrol.c:267 ../mm/memcontrol.c:687
#: ../mm/memcontrol.c:764 ../mm/memcontrol.c:831 ../mm/memcontrol.c:902
#: ../mm/memcontrol.c:952 ../mm/memcontrol.c:973 ../mm/memcontrol.c:991
#: ../mm/memcontrol.c:1095 ../mm/memcontrol.c:1144 ../mm/memcontrol.c:1200
#: ../mm/memcontrol.c:1221 ../mm/memcontrol.c:1243 ../mm/memcontrol.c:1267
#: ../mm/memcontrol.c:1305 ../mm/memcontrol.c:1536 ../mm/memcontrol.c:1561
#: ../mm/memcontrol.c:1717 ../mm/memcontrol.c:1822 ../mm/memcontrol.c:2857
#: ../mm/memcontrol.c:2882 ../mm/memcontrol.c:3380 ../mm/memcontrol.c:3638
#: ../mm/memcontrol.c:3963 ../mm/memcontrol.c:4705 ../mm/memcontrol.c:4756
#: ../mm/memcontrol.c:4790 ../mm/memcontrol.c:4940 ../mm/memcontrol.c:4984
#: ../mm/memcontrol.c:5076 ../mm/memcontrol.c:5101 ../mm/memcontrol.c:5180
#: ../mm/memcontrol.c:5229 ../mm/memcontrol.c:5427 ../mm/memcontrol.c:5472
#: ../mm/memcontrol.c:5500 ../../../core-api/mm-api:123: ../mm/shmem.c:428
#: ../mm/shmem.c:1587 ../mm/shmem.c:2668 ../mm/shmem.c:5886 ../mm/shmem.c:5902
#: ../mm/shmem.c:5914 ../mm/shmem.c:5941 ../mm/shmem.c:5961 ../mm/shmem.c:5980
#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:80
#: ../mm/migrate_device.c:676 ../mm/migrate_device.c:783
#: ../mm/migrate_device.c:1246 ../mm/migrate_device.c:1262
#: ../mm/migrate_device.c:1345 ../mm/migrate_device.c:1379
#: ../mm/migrate_device.c:1425 ../../../core-api/mm-api:126:
#: ../mm/mapping_dirty_helpers.c:29 ../mm/mapping_dirty_helpers.c:80
#: ../mm/mapping_dirty_helpers.c:254 ../mm/mapping_dirty_helpers.c:282
#: ../../../core-api/mm-api:128: ../mm/percpu.c:212 ../mm/percpu.c:312
#: ../mm/percpu.c:359 ../mm/percpu.c:411 ../mm/percpu.c:496 ../mm/percpu.c:520
#: ../mm/percpu.c:547 ../mm/percpu.c:625 ../mm/percpu.c:738 ../mm/percpu.c:771
#: ../mm/percpu.c:803 ../mm/percpu.c:950 ../mm/percpu.c:1065
#: ../mm/percpu.c:1096 ../mm/percpu.c:1202 ../mm/percpu.c:1270
#: ../mm/percpu.c:1337 ../mm/percpu.c:1502 ../mm/percpu.c:1526
#: ../mm/percpu.c:1583 ../mm/percpu.c:1720 ../mm/percpu.c:1939
#: ../mm/percpu.c:1992 ../mm/percpu.c:2082 ../mm/percpu.c:2187
#: ../mm/percpu.c:2222 ../mm/percpu.c:2307 ../mm/percpu.c:2323
#: ../mm/percpu.c:2390 ../mm/percpu.c:2434 ../mm/percpu.c:2445
#: ../mm/percpu.c:2502 ../mm/percpu.c:2776 ../mm/percpu.c:2977
#: ../mm/percpu.c:3172 ../../../core-api/mm-api:129: ../mm/maccess.c:116
#: ../mm/maccess.c:145 ../mm/maccess.c:170 ../mm/maccess.c:210
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:226 ../mm/vmscan.c:410
#: ../mm/vmscan.c:815 ../mm/vmscan.c:841 ../mm/vmscan.c:1802
#: ../mm/vmscan.c:7833 ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:587
#: ../mm/memory_hotplug.c:2160 ../mm/memory_hotplug.c:2275
#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:173
#: ../mm/mmu_notifier.c:685 ../mm/mmu_notifier.c:739 ../mm/mmu_notifier.c:855
#: ../mm/mmu_notifier.c:961 ../mm/mmu_notifier.c:1033 ../mm/mmu_notifier.c:1087
#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:35
#: ../mm/balloon_compaction.c:64 ../../../core-api/mm-api:134:
#: ../mm/huge_memory.c:1599 ../mm/huge_memory.c:1707 ../mm/huge_memory.c:1743
#: ../mm/huge_memory.c:1769 ../mm/huge_memory.c:3588 ../mm/huge_memory.c:3688
#: ../mm/huge_memory.c:3919 ../mm/huge_memory.c:4111 ../mm/huge_memory.c:4209
#: ../mm/huge_memory.c:4240 ../../../core-api/mm-api:14: ../mm/gup.c:3276
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:392
#: ../include/linux/slab.h:441 ../include/linux/slab.h:520
#: ../include/linux/slab.h:768 ../include/linux/slab.h:786
#: ../include/linux/slab.h:898 ../include/linux/slab.h:996
#: ../include/linux/slab.h:1012 ../include/linux/slab.h:1043
#: ../include/linux/slab.h:1092 ../include/linux/slab.h:1172
#: ../../../core-api/mm-api:40: ../mm/slub.c:5305 ../mm/slub.c:5678
#: ../mm/slub.c:6780 ../mm/slub.c:6865 ../mm/slub.c:7038 ../mm/slub.c:7118
#: ../mm/slub.c:7183 ../mm/slub.c:7202 ../mm/slub.c:7220
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:261 ../mm/slab_common.c:371
#: ../mm/slab_common.c:558 ../mm/slab_common.c:588 ../mm/slab_common.c:1218
#: ../mm/slab_common.c:2115 ../mm/slab_common.c:2132
#: ../../../core-api/mm-api:46: ../mm/util.c:42 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:2993 ../mm/vmalloc.c:3012 ../mm/vmalloc.c:3046
#: ../mm/vmalloc.c:3417 ../mm/vmalloc.c:3481 ../mm/vmalloc.c:3509
#: ../mm/vmalloc.c:3589 ../mm/vmalloc.c:4097 ../mm/vmalloc.c:4137
#: ../mm/vmalloc.c:4156 ../mm/vmalloc.c:4179 ../mm/vmalloc.c:4199
#: ../mm/vmalloc.c:4217 ../mm/vmalloc.c:4237 ../mm/vmalloc.c:4375
#: ../mm/vmalloc.c:4391 ../mm/vmalloc.c:4750 ../../../core-api/mm-api:61:
#: ../mm/filemap.c:400 ../mm/filemap.c:427 ../mm/filemap.c:445
#: ../mm/filemap.c:472 ../mm/filemap.c:544 ../mm/filemap.c:568
#: ../mm/filemap.c:590 ../mm/filemap.c:615 ../mm/filemap.c:667
#: ../mm/filemap.c:714 ../mm/filemap.c:766 ../mm/filemap.c:803
#: ../mm/filemap.c:1495 ../mm/filemap.c:1515 ../mm/filemap.c:1545
#: ../mm/filemap.c:1565 ../mm/filemap.c:1578 ../mm/filemap.c:1641
#: ../mm/filemap.c:1673 ../mm/filemap.c:1698 ../mm/filemap.c:1787
#: ../mm/filemap.c:1824 ../mm/filemap.c:1923 ../mm/filemap.c:2218
#: ../mm/filemap.c:2239 ../mm/filemap.c:2311 ../mm/filemap.c:2755
#: ../mm/filemap.c:2934 ../mm/filemap.c:3034 ../mm/filemap.c:3489
#: ../mm/filemap.c:4114 ../mm/filemap.c:4138 ../mm/filemap.c:4181
#: ../mm/filemap.c:4385 ../mm/filemap.c:4440 ../mm/filemap.c:4471
#: ../mm/filemap.c:4504 ../../../core-api/mm-api:70: ../mm/readahead.c:201
#: ../mm/readahead.c:750 ../../../core-api/mm-api:76:
#: ../mm/page-writeback.c:2034 ../mm/page-writeback.c:2109
#: ../mm/page-writeback.c:2374 ../mm/page-writeback.c:2477
#: ../mm/page-writeback.c:2723 ../mm/page-writeback.c:2757
#: ../mm/page-writeback.c:2793 ../mm/page-writeback.c:3078
#: ../mm/page-writeback.c:3099 ../mm/page-writeback.c:3124
#: ../../../core-api/mm-api:82: ../mm/truncate.c:125 ../mm/truncate.c:347
#: ../mm/truncate.c:475 ../mm/truncate.c:494 ../mm/truncate.c:590
#: ../mm/truncate.c:666 ../mm/truncate.c:754 ../mm/truncate.c:769
#: ../mm/truncate.c:804 ../mm/truncate.c:828 ../mm/truncate.c:892
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:73
#: ../include/linux/pagemap.h:94 ../include/linux/pagemap.h:110
#: ../include/linux/pagemap.h:122 ../include/linux/pagemap.h:230
#: ../include/linux/pagemap.h:460 ../include/linux/pagemap.h:504
#: ../include/linux/pagemap.h:569 ../include/linux/pagemap.h:589
#: ../include/linux/pagemap.h:603 ../include/linux/pagemap.h:618
#: ../include/linux/pagemap.h:637 ../include/linux/pagemap.h:750
#: ../include/linux/pagemap.h:782 ../include/linux/pagemap.h:809
#: ../include/linux/pagemap.h:826 ../include/linux/pagemap.h:844
#: ../include/linux/pagemap.h:864 ../include/linux/pagemap.h:886
#: ../include/linux/pagemap.h:905 ../include/linux/pagemap.h:932
#: ../include/linux/pagemap.h:954 ../include/linux/pagemap.h:965
#: ../include/linux/pagemap.h:976 ../include/linux/pagemap.h:991
#: ../include/linux/pagemap.h:1036 ../include/linux/pagemap.h:1057
#: ../include/linux/pagemap.h:1124 ../include/linux/pagemap.h:1149
#: ../include/linux/pagemap.h:1178 ../include/linux/pagemap.h:1199
#: ../include/linux/pagemap.h:1321 ../include/linux/pagemap.h:1394
#: ../include/linux/pagemap.h:1416 ../include/linux/pagemap.h:1458
#: ../include/linux/pagemap.h:1503 ../include/linux/pagemap.h:1512
#: ../include/linux/pagemap.h:1521 ../include/linux/pagemap.h:1530
#: ../include/linux/pagemap.h:1539 ../include/linux/pagemap.h:1554
#: ../include/linux/pagemap.h:1582 ../../../core-api/mm-api:8:
#: ../arch/x86/include/asm/uaccess.h:95 ../arch/x86/include/asm/uaccess.h:115
#: ../arch/x86/include/asm/uaccess.h:196 ../arch/x86/include/asm/uaccess.h:215
#: ../../../core-api/mm-api:91: ../mm/mempool.c:198 ../mm/mempool.c:220
#: ../mm/mempool.c:276 ../mm/mempool.c:300 ../mm/mempool.c:338
#: ../mm/mempool.c:483 ../mm/mempool.c:542 ../mm/mempool.c:598
#: ../mm/mempool.c:619 ../mm/mempool.c:704 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2177 ../mm/memory.c:2413 ../mm/memory.c:2445
#: ../mm/memory.c:2527 ../mm/memory.c:2552 ../mm/memory.c:2623
#: ../mm/memory.c:2683 ../mm/memory.c:3082 ../mm/memory.c:3113
#: ../mm/memory.c:4253 ../mm/memory.c:4284 ../mm/memory.c:6720
#: ../mm/memory.c:6827 ../mm/memory.c:6844 ../mm/memory.c:7111
msgid "**Parameters**"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:97
#: ../arch/x86/include/asm/uaccess.h:117 ../arch/x86/include/asm/uaccess.h:198
#: ../arch/x86/include/asm/uaccess.h:217
msgid "``x``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:92
#: ../arch/x86/include/asm/uaccess.h:112
msgid "Variable to store result."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:94
#: ../arch/x86/include/asm/uaccess.h:114 ../arch/x86/include/asm/uaccess.h:195
#: ../arch/x86/include/asm/uaccess.h:214
msgid "``ptr``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:93
#: ../arch/x86/include/asm/uaccess.h:113
msgid "Source address, in user space."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5353
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2570
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:299
#: ../include/linux/page-flags.h:1073 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:1571 ../include/linux/mm.h:1609
#: ../include/linux/mm.h:1629 ../include/linux/mm.h:1669
#: ../include/linux/mm.h:2321 ../include/linux/mm.h:2338
#: ../include/linux/mm.h:2352 ../../../core-api/mm-api:113: ../mm/rmap.c:756
#: ../mm/rmap.c:2257 ../../../core-api/mm-api:120: ../mm/swap.c:683
#: ../mm/swap.c:947 ../../../core-api/mm-api:123: ../mm/shmem.c:2683
#: ../../../core-api/mm-api:128: ../mm/percpu.c:551 ../mm/percpu.c:1941
#: ../mm/percpu.c:1995 ../mm/percpu.c:2087 ../mm/percpu.c:2222
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:820 ../mm/vmscan.c:842
#: ../mm/vmscan.c:1815 ../../../core-api/mm-api:134: ../mm/huge_memory.c:3693
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:456
#: ../../../core-api/mm-api:40: ../mm/slub.c:7185 ../../../core-api/mm-api:43:
#: ../mm/slab_common.c:278 ../../../core-api/mm-api:52: ../mm/vmalloc.c:3422
#: ../../../core-api/mm-api:61: ../mm/filemap.c:1495 ../mm/filemap.c:1520
#: ../mm/filemap.c:1642 ../mm/filemap.c:1673 ../mm/filemap.c:4121
#: ../../../core-api/mm-api:70: ../mm/readahead.c:206
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3079
#: ../mm/page-writeback.c:3100 ../mm/page-writeback.c:3126
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:462
#: ../include/linux/pagemap.h:828 ../include/linux/pagemap.h:889
#: ../include/linux/pagemap.h:991 ../include/linux/pagemap.h:1040
#: ../include/linux/pagemap.h:1127 ../include/linux/pagemap.h:1159
#: ../include/linux/pagemap.h:1180 ../include/linux/pagemap.h:1200
#: ../include/linux/pagemap.h:1457 ../include/linux/pagemap.h:1583
#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:95
#: ../arch/x86/include/asm/uaccess.h:115 ../arch/x86/include/asm/uaccess.h:196
#: ../arch/x86/include/asm/uaccess.h:215 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2536 ../mm/memory.c:2556 ../mm/memory.c:2647
#: ../mm/memory.c:2694
msgid "**Context**"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:95
#: ../arch/x86/include/asm/uaccess.h:115 ../arch/x86/include/asm/uaccess.h:196
#: ../arch/x86/include/asm/uaccess.h:215
msgid "User context only. This function may sleep if pagefaults are enabled."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3 ../mm/page_alloc.c:468
#: ../mm/page_alloc.c:2111 ../mm/page_alloc.c:3180 ../mm/page_alloc.c:5342
#: ../mm/page_alloc.c:5377 ../mm/page_alloc.c:5417 ../mm/page_alloc.c:5447
#: ../mm/page_alloc.c:5471 ../mm/page_alloc.c:5489 ../mm/page_alloc.c:5598
#: ../mm/page_alloc.c:6963 ../mm/page_alloc.c:7164 ../mm/page_alloc.c:7700
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:283 ../mm/mempolicy.c:317
#: ../mm/mempolicy.c:823 ../mm/mempolicy.c:2521 ../mm/mempolicy.c:2566
#: ../mm/mempolicy.c:2973 ../mm/mempolicy.c:3201 ../mm/mempolicy.c:3410
#: ../mm/mempolicy.c:3546 ../../../core-api/mm-api:102:
#: ../include/linux/mm_types.h:292 ../include/linux/mm_types.h:393
#: ../include/linux/mm_types.h:571 ../include/linux/mm_types.h:1541
#: ../include/linux/mm_types.h:1694 ../../../core-api/mm-api:104:
#: ../include/linux/mm_inline.h:17 ../include/linux/mm_inline.h:628
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:297
#: ../include/linux/page-flags.h:315 ../include/linux/page-flags.h:761
#: ../include/linux/page-flags.h:779 ../include/linux/page-flags.h:1142
#: ../include/linux/page-flags.h:1228 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:237 ../include/linux/mm.h:284
#: ../include/linux/mm.h:655 ../include/linux/mm.h:1243
#: ../include/linux/mm.h:1259 ../include/linux/mm.h:1377
#: ../include/linux/mm.h:1604 ../include/linux/mm.h:1624
#: ../include/linux/mm.h:1664 ../include/linux/mm.h:2038
#: ../include/linux/mm.h:2064 ../include/linux/mm.h:2080
#: ../include/linux/mm.h:2096 ../include/linux/mm.h:2120
#: ../include/linux/mm.h:2179 ../include/linux/mm.h:2190
#: ../include/linux/mm.h:2316 ../include/linux/mm.h:2335
#: ../include/linux/mm.h:2366 ../include/linux/mm.h:2429
#: ../include/linux/mm.h:3146 ../include/linux/mm.h:3158
#: ../include/linux/mm.h:3175 ../include/linux/mm.h:3187
#: ../include/linux/mm.h:3219 ../include/linux/mm.h:4456
#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:74
#: ../include/linux/page_ref.h:255 ../../../core-api/mm-api:109:
#: ../include/linux/mmzone.h:1692 ../include/linux/mmzone.h:1733
#: ../include/linux/mmzone.h:1757 ../include/linux/mmzone.h:1784
#: ../include/linux/mmzone.h:1807 ../include/linux/mmzone.h:2160
#: ../../../core-api/mm-api:110: ../mm/util.c:684 ../../../core-api/mm-api:113:
#: ../mm/rmap.c:163 ../mm/rmap.c:751 ../mm/rmap.c:939 ../mm/rmap.c:1140
#: ../mm/rmap.c:1187 ../mm/rmap.c:1315 ../mm/rmap.c:1467 ../mm/rmap.c:1490
#: ../mm/rmap.c:1513 ../mm/rmap.c:1604 ../mm/rmap.c:1620 ../mm/rmap.c:1640
#: ../mm/rmap.c:1772 ../mm/rmap.c:1788 ../mm/rmap.c:1808 ../mm/rmap.c:2254
#: ../mm/rmap.c:2596 ../mm/rmap.c:2645 ../../../core-api/mm-api:114:
#: ../mm/migrate.c:104 ../mm/migrate.c:189 ../mm/migrate.c:216
#: ../mm/migrate.c:886 ../mm/migrate.c:1011 ../mm/migrate.c:1033
#: ../../../core-api/mm-api:115: ../mm/mmap.c:331 ../mm/mmap.c:917
#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1089 ../mm/kmemleak.c:1108
#: ../mm/kmemleak.c:1127 ../mm/kmemleak.c:1150 ../mm/kmemleak.c:1168
#: ../mm/kmemleak.c:1184 ../mm/kmemleak.c:1200 ../mm/kmemleak.c:1236
#: ../mm/kmemleak.c:1252 ../mm/kmemleak.c:1283 ../mm/kmemleak.c:1304
#: ../mm/kmemleak.c:1321 ../../../core-api/mm-api:119: ../mm/hugetlb.c:1033
#: ../mm/hugetlb.c:6916 ../mm/hugetlb.c:7110 ../mm/hugetlb.c:7174
#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:56
#: ../arch/x86/lib/usercopy_32.c:76 ../../../core-api/mm-api:120:
#: ../mm/swap.c:446 ../mm/swap.c:495 ../mm/swap.c:520 ../mm/swap.c:680
#: ../mm/swap.c:721 ../mm/swap.c:941 ../mm/swap.c:1011 ../mm/swap.c:1070
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:245 ../mm/memcontrol.c:266
#: ../mm/memcontrol.c:765 ../mm/memcontrol.c:901 ../mm/memcontrol.c:992
#: ../mm/memcontrol.c:1145 ../mm/memcontrol.c:1199 ../mm/memcontrol.c:1220
#: ../mm/memcontrol.c:1243 ../mm/memcontrol.c:1269 ../mm/memcontrol.c:1304
#: ../mm/memcontrol.c:1717 ../mm/memcontrol.c:1822 ../mm/memcontrol.c:2858
#: ../mm/memcontrol.c:3383 ../mm/memcontrol.c:3637 ../mm/memcontrol.c:3962
#: ../mm/memcontrol.c:4705 ../mm/memcontrol.c:4756 ../mm/memcontrol.c:4792
#: ../mm/memcontrol.c:4940 ../mm/memcontrol.c:4984 ../mm/memcontrol.c:5077
#: ../mm/memcontrol.c:5180 ../mm/memcontrol.c:5426 ../mm/memcontrol.c:5472
#: ../mm/memcontrol.c:5500 ../../../core-api/mm-api:123: ../mm/shmem.c:429
#: ../mm/shmem.c:1588 ../mm/shmem.c:2671 ../mm/shmem.c:5981
#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:80
#: ../mm/migrate_device.c:678 ../mm/migrate_device.c:793
#: ../mm/migrate_device.c:1247 ../mm/migrate_device.c:1261
#: ../mm/migrate_device.c:1344 ../mm/migrate_device.c:1380
#: ../mm/migrate_device.c:1425 ../../../core-api/mm-api:126:
#: ../mm/mapping_dirty_helpers.c:31 ../mm/mapping_dirty_helpers.c:83
#: ../mm/mapping_dirty_helpers.c:291 ../../../core-api/mm-api:128:
#: ../mm/percpu.c:3 ../mm/percpu.c:313 ../mm/percpu.c:360 ../mm/percpu.c:414
#: ../mm/percpu.c:496 ../mm/percpu.c:519 ../mm/percpu.c:547 ../mm/percpu.c:626
#: ../mm/percpu.c:738 ../mm/percpu.c:771 ../mm/percpu.c:804 ../mm/percpu.c:951
#: ../mm/percpu.c:1067 ../mm/percpu.c:1098 ../mm/percpu.c:1204
#: ../mm/percpu.c:1270 ../mm/percpu.c:1337 ../mm/percpu.c:1503
#: ../mm/percpu.c:1527 ../mm/percpu.c:1582 ../mm/percpu.c:1722
#: ../mm/percpu.c:1938 ../mm/percpu.c:2186 ../mm/percpu.c:2221
#: ../mm/percpu.c:2306 ../mm/percpu.c:2322 ../mm/percpu.c:2390
#: ../mm/percpu.c:2433 ../mm/percpu.c:2445 ../mm/percpu.c:2502
#: ../mm/percpu.c:2778 ../mm/percpu.c:2980 ../mm/percpu.c:3172
#: ../../../core-api/mm-api:129: ../mm/maccess.c:117 ../mm/maccess.c:146
#: ../mm/maccess.c:173 ../mm/maccess.c:210 ../../../core-api/mm-api:130:
#: ../mm/vmscan.c:225 ../mm/vmscan.c:815 ../mm/vmscan.c:840 ../mm/vmscan.c:1801
#: ../mm/vmscan.c:7833 ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:588
#: ../mm/memory_hotplug.c:2159 ../../../core-api/mm-api:132:
#: ../mm/mmu_notifier.c:3 ../mm/mmu_notifier.c:173 ../mm/mmu_notifier.c:685
#: ../mm/mmu_notifier.c:740 ../mm/mmu_notifier.c:854 ../mm/mmu_notifier.c:964
#: ../mm/mmu_notifier.c:1032 ../../../core-api/mm-api:133:
#: ../mm/balloon_compaction.c:36 ../mm/balloon_compaction.c:66
#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1600
#: ../mm/huge_memory.c:1708 ../mm/huge_memory.c:3596 ../mm/huge_memory.c:3691
#: ../mm/huge_memory.c:3923 ../mm/huge_memory.c:4111 ../mm/huge_memory.c:4212
#: ../mm/huge_memory.c:4239 ../../../core-api/mm-api:14: ../mm/gup.c:3279
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:3
#: ../include/linux/slab.h:84 ../include/linux/slab.h:104
#: ../include/linux/slab.h:197 ../include/linux/slab.h:229
#: ../include/linux/slab.h:370 ../include/linux/slab.h:398
#: ../include/linux/slab.h:520 ../include/linux/slab.h:768
#: ../include/linux/slab.h:786 ../include/linux/slab.h:898
#: ../include/linux/slab.h:1014 ../include/linux/slab.h:1172
#: ../../../core-api/mm-api:40: ../mm/slub.c:5306 ../mm/slub.c:6780
#: ../mm/slub.c:6864 ../mm/slub.c:7041 ../mm/slub.c:7122 ../mm/slub.c:7182
#: ../mm/slub.c:7202 ../mm/slub.c:7223 ../../../core-api/mm-api:43:
#: ../mm/slab_common.c:3 ../mm/slab_common.c:265 ../mm/slab_common.c:378
#: ../mm/slab_common.c:557 ../mm/slab_common.c:587 ../mm/slab_common.c:1217
#: ../mm/slab_common.c:2132 ../../../core-api/mm-api:46: ../mm/util.c:41
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3 ../mm/vmalloc.c:3047
#: ../mm/vmalloc.c:3416 ../mm/vmalloc.c:3480 ../mm/vmalloc.c:3511
#: ../mm/vmalloc.c:3590 ../mm/vmalloc.c:4100 ../mm/vmalloc.c:4136
#: ../mm/vmalloc.c:4157 ../mm/vmalloc.c:4178 ../mm/vmalloc.c:4198
#: ../mm/vmalloc.c:4217 ../mm/vmalloc.c:4237 ../mm/vmalloc.c:4374
#: ../mm/vmalloc.c:4390 ../mm/vmalloc.c:4753 ../../../core-api/mm-api:61:
#: ../mm/filemap.c:401 ../mm/filemap.c:428 ../mm/filemap.c:444
#: ../mm/filemap.c:473 ../mm/filemap.c:545 ../mm/filemap.c:569
#: ../mm/filemap.c:591 ../mm/filemap.c:614 ../mm/filemap.c:668
#: ../mm/filemap.c:714 ../mm/filemap.c:767 ../mm/filemap.c:803
#: ../mm/filemap.c:1494 ../mm/filemap.c:1515 ../mm/filemap.c:1544
#: ../mm/filemap.c:1564 ../mm/filemap.c:1577 ../mm/filemap.c:1640
#: ../mm/filemap.c:1672 ../mm/filemap.c:1788 ../mm/filemap.c:1825
#: ../mm/filemap.c:1926 ../mm/filemap.c:2220 ../mm/filemap.c:2241
#: ../mm/filemap.c:2314 ../mm/filemap.c:2756 ../mm/filemap.c:2934
#: ../mm/filemap.c:3037 ../mm/filemap.c:3488 ../mm/filemap.c:4116
#: ../mm/filemap.c:4139 ../mm/filemap.c:4182 ../mm/filemap.c:4385
#: ../mm/filemap.c:4440 ../mm/filemap.c:4471 ../mm/filemap.c:4507
#: ../../../core-api/mm-api:70: ../mm/readahead.c:202 ../mm/readahead.c:751
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2034
#: ../mm/page-writeback.c:2108 ../mm/page-writeback.c:2375
#: ../mm/page-writeback.c:2479 ../mm/page-writeback.c:2723
#: ../mm/page-writeback.c:2757 ../mm/page-writeback.c:2792
#: ../mm/page-writeback.c:3077 ../mm/page-writeback.c:3098
#: ../mm/page-writeback.c:3123 ../../../core-api/mm-api:82:
#: ../mm/truncate.c:126 ../mm/truncate.c:348 ../mm/truncate.c:475
#: ../mm/truncate.c:493 ../mm/truncate.c:591 ../mm/truncate.c:667
#: ../mm/truncate.c:753 ../mm/truncate.c:769 ../mm/truncate.c:804
#: ../mm/truncate.c:829 ../mm/truncate.c:893 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:73 ../include/linux/pagemap.h:94
#: ../include/linux/pagemap.h:109 ../include/linux/pagemap.h:121
#: ../include/linux/pagemap.h:230 ../include/linux/pagemap.h:459
#: ../include/linux/pagemap.h:504 ../include/linux/pagemap.h:568
#: ../include/linux/pagemap.h:588 ../include/linux/pagemap.h:603
#: ../include/linux/pagemap.h:618 ../include/linux/pagemap.h:636
#: ../include/linux/pagemap.h:698 ../include/linux/pagemap.h:749
#: ../include/linux/pagemap.h:784 ../include/linux/pagemap.h:809
#: ../include/linux/pagemap.h:826 ../include/linux/pagemap.h:844
#: ../include/linux/pagemap.h:864 ../include/linux/pagemap.h:886
#: ../include/linux/pagemap.h:906 ../include/linux/pagemap.h:932
#: ../include/linux/pagemap.h:976 ../include/linux/pagemap.h:1036
#: ../include/linux/pagemap.h:1123 ../include/linux/pagemap.h:1148
#: ../include/linux/pagemap.h:1177 ../include/linux/pagemap.h:1198
#: ../include/linux/pagemap.h:1322 ../include/linux/pagemap.h:1360
#: ../include/linux/pagemap.h:1397 ../include/linux/pagemap.h:1419
#: ../include/linux/pagemap.h:1582 ../../../core-api/mm-api:8:
#: ../arch/x86/include/asm/uaccess.h:98 ../arch/x86/include/asm/uaccess.h:118
#: ../arch/x86/include/asm/uaccess.h:199 ../arch/x86/include/asm/uaccess.h:218
#: ../../../core-api/mm-api:91: ../mm/mempool.c:198 ../mm/mempool.c:220
#: ../mm/mempool.c:280 ../mm/mempool.c:305 ../mm/mempool.c:340
#: ../mm/mempool.c:485 ../mm/mempool.c:542 ../mm/mempool.c:598
#: ../mm/mempool.c:620 ../mm/mempool.c:704 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2178 ../mm/memory.c:2416 ../mm/memory.c:2446
#: ../mm/memory.c:2528 ../mm/memory.c:2553 ../mm/memory.c:2625
#: ../mm/memory.c:2684 ../mm/memory.c:3114 ../mm/memory.c:4255
#: ../mm/memory.c:6719 ../mm/memory.c:6826 ../mm/memory.c:6847
#: ../mm/memory.c:7114
msgid "**Description**"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:97
#: ../arch/x86/include/asm/uaccess.h:117
msgid ""
"This macro copies a single simple variable from user space to kernel space.  "
"It supports simple types like char and int, but not larger data types like "
"structures or arrays."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:101
#: ../arch/x86/include/asm/uaccess.h:121
msgid ""
"**ptr** must have pointer-to-simple-variable type, and the result of "
"dereferencing **ptr** must be assignable to **x** without a cast."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:419 ../mm/page_alloc.c:445
#: ../mm/page_alloc.c:466 ../mm/page_alloc.c:5424 ../mm/page_alloc.c:5449
#: ../mm/page_alloc.c:5494 ../mm/page_alloc.c:5522 ../mm/page_alloc.c:5605
#: ../mm/page_alloc.c:6969 ../mm/page_alloc.c:7175 ../mm/page_alloc.c:7706
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:284 ../mm/mempolicy.c:827
#: ../mm/mempolicy.c:2439 ../mm/mempolicy.c:2526 ../mm/mempolicy.c:2574
#: ../mm/mempolicy.c:2976 ../mm/mempolicy.c:3412 ../../../core-api/mm-api:104:
#: ../include/linux/mm_inline.h:20 ../include/linux/mm_inline.h:84
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:305
#: ../include/linux/page-flags.h:766 ../include/linux/page-flags.h:861
#: ../include/linux/page-flags.h:1075 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:660 ../include/linux/mm.h:1245
#: ../include/linux/mm.h:1390 ../include/linux/mm.h:1410
#: ../include/linux/mm.h:1475 ../include/linux/mm.h:2040
#: ../include/linux/mm.h:2066 ../include/linux/mm.h:2082
#: ../include/linux/mm.h:2098 ../include/linux/mm.h:2137
#: ../include/linux/mm.h:2259 ../include/linux/mm.h:2325
#: ../include/linux/mm.h:2342 ../include/linux/mm.h:2355
#: ../include/linux/mm.h:2396 ../include/linux/mm.h:3130
#: ../include/linux/mm.h:3189 ../include/linux/mm.h:3765
#: ../include/linux/mm.h:4458 ../../../core-api/mm-api:108:
#: ../include/linux/page_ref.h:84 ../include/linux/page_ref.h:259
#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1645
#: ../include/linux/mmzone.h:1738 ../include/linux/mmzone.h:1765
#: ../include/linux/mmzone.h:2164 ../../../core-api/mm-api:113:
#: ../mm/rmap.c:761 ../mm/rmap.c:940 ../mm/rmap.c:1149 ../mm/rmap.c:2673
#: ../../../core-api/mm-api:114: ../mm/migrate.c:1016 ../mm/migrate.c:1037
#: ../../../core-api/mm-api:115: ../mm/mmap.c:305 ../mm/mmap.c:879
#: ../mm/mmap.c:898 ../mm/mmap.c:919 ../../../core-api/mm-api:119:
#: ../mm/hugetlb.c:1035 ../mm/hugetlb.c:6922 ../mm/hugetlb.c:7119
#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:57
#: ../arch/x86/lib/usercopy_32.c:78 ../../../core-api/mm-api:121:
#: ../mm/memcontrol.c:1203 ../mm/memcontrol.c:1224 ../mm/memcontrol.c:1247
#: ../../../core-api/mm-api:123: ../mm/shmem.c:434 ../mm/shmem.c:2686
#: ../mm/shmem.c:5940 ../mm/shmem.c:5961 ../../../core-api/mm-api:124:
#: ../mm/migrate_device.c:675 ../../../core-api/mm-api:126:
#: ../mm/mapping_dirty_helpers.c:260 ../mm/mapping_dirty_helpers.c:310
#: ../../../core-api/mm-api:128: ../mm/percpu.c:212 ../mm/percpu.c:500
#: ../mm/percpu.c:1068 ../mm/percpu.c:1105 ../mm/percpu.c:1211
#: ../mm/percpu.c:1272 ../mm/percpu.c:1341 ../mm/percpu.c:1584
#: ../mm/percpu.c:1726 ../mm/percpu.c:2309 ../mm/percpu.c:2337
#: ../mm/percpu.c:2395 ../mm/percpu.c:2787 ../mm/percpu.c:2999
#: ../mm/percpu.c:3177 ../../../core-api/mm-api:130: ../mm/vmscan.c:817
#: ../mm/vmscan.c:1811 ../../../core-api/mm-api:133:
#: ../mm/balloon_compaction.c:38 ../mm/balloon_compaction.c:74
#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1601
#: ../mm/huge_memory.c:1709 ../mm/huge_memory.c:1744 ../mm/huge_memory.c:1771
#: ../mm/huge_memory.c:3619 ../mm/huge_memory.c:3696 ../mm/huge_memory.c:3931
#: ../mm/huge_memory.c:4124 ../mm/huge_memory.c:4224 ../mm/huge_memory.c:4242
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:402
#: ../include/linux/slab.h:459 ../include/linux/slab.h:770
#: ../include/linux/slab.h:806 ../../../core-api/mm-api:40: ../mm/slub.c:5310
#: ../mm/slub.c:5680 ../mm/slub.c:7068 ../mm/slub.c:7131 ../mm/slub.c:7239
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:281 ../mm/slab_common.c:379
#: ../mm/slab_common.c:559 ../mm/slab_common.c:593 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:3052 ../mm/vmalloc.c:3516 ../mm/vmalloc.c:4105
#: ../mm/vmalloc.c:4141 ../mm/vmalloc.c:4161 ../mm/vmalloc.c:4184
#: ../mm/vmalloc.c:4200 ../mm/vmalloc.c:4222 ../mm/vmalloc.c:4240
#: ../mm/vmalloc.c:4376 ../mm/vmalloc.c:4392 ../mm/vmalloc.c:4751
#: ../../../core-api/mm-api:61: ../mm/filemap.c:406 ../mm/filemap.c:430
#: ../mm/filemap.c:446 ../mm/filemap.c:475 ../mm/filemap.c:552
#: ../mm/filemap.c:598 ../mm/filemap.c:621 ../mm/filemap.c:672
#: ../mm/filemap.c:730 ../mm/filemap.c:774 ../mm/filemap.c:1579
#: ../mm/filemap.c:1796 ../mm/filemap.c:1833 ../mm/filemap.c:1932
#: ../mm/filemap.c:2223 ../mm/filemap.c:2244 ../mm/filemap.c:2321
#: ../mm/filemap.c:2758 ../mm/filemap.c:2945 ../mm/filemap.c:3040
#: ../mm/filemap.c:3504 ../mm/filemap.c:4124 ../mm/filemap.c:4147
#: ../mm/filemap.c:4188 ../mm/filemap.c:4396 ../mm/filemap.c:4443
#: ../mm/filemap.c:4480 ../../../core-api/mm-api:76:
#: ../mm/page-writeback.c:2039 ../mm/page-writeback.c:2496
#: ../mm/page-writeback.c:2760 ../mm/page-writeback.c:2798
#: ../mm/page-writeback.c:3106 ../../../core-api/mm-api:82:
#: ../mm/truncate.c:596 ../mm/truncate.c:669 ../mm/truncate.c:755
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:621
#: ../include/linux/pagemap.h:638 ../include/linux/pagemap.h:787
#: ../include/linux/pagemap.h:811 ../include/linux/pagemap.h:831
#: ../include/linux/pagemap.h:847 ../include/linux/pagemap.h:892
#: ../include/linux/pagemap.h:953 ../include/linux/pagemap.h:964
#: ../include/linux/pagemap.h:978 ../include/linux/pagemap.h:994
#: ../include/linux/pagemap.h:1044 ../include/linux/pagemap.h:1130
#: ../include/linux/pagemap.h:1203 ../include/linux/pagemap.h:1326
#: ../include/linux/pagemap.h:1460 ../include/linux/pagemap.h:1554
#: ../include/linux/pagemap.h:1587 ../../../core-api/mm-api:8:
#: ../arch/x86/include/asm/uaccess.h:104 ../arch/x86/include/asm/uaccess.h:127
#: ../arch/x86/include/asm/uaccess.h:205 ../arch/x86/include/asm/uaccess.h:227
#: ../../../core-api/mm-api:91: ../mm/mempool.c:282 ../mm/mempool.c:310
#: ../mm/mempool.c:348 ../mm/mempool.c:490 ../mm/mempool.c:548
#: ../mm/mempool.c:601 ../mm/mempool.c:623 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2467 ../mm/memory.c:2539 ../mm/memory.c:2559
#: ../mm/memory.c:2650 ../mm/memory.c:2697 ../mm/memory.c:3087
#: ../mm/memory.c:3120 ../mm/memory.c:6743 ../mm/memory.c:7115
msgid "**Return**"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:105
#: ../arch/x86/include/asm/uaccess.h:128
msgid ""
"zero on success, or -EFAULT on error. On error, the variable **x** is set to "
"zero."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:113
msgid "``__get_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:111
msgid "Get a simple variable from user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:124
#: ../arch/x86/include/asm/uaccess.h:224
msgid ""
"Caller must check the pointer with access_ok() before calling this function."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:194
msgid "``put_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:192
msgid "Write a simple value into user space."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:193
#: ../arch/x86/include/asm/uaccess.h:212
msgid "Value to copy to user space."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:53
#: ../arch/x86/lib/usercopy_32.c:73 ../../../core-api/mm-api:8:
#: ../arch/x86/include/asm/uaccess.h:194 ../arch/x86/include/asm/uaccess.h:213
msgid "Destination address, in user space."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:198
#: ../arch/x86/include/asm/uaccess.h:217
msgid ""
"This macro copies a single simple value from kernel space to user space.  It "
"supports simple types like char and int, but not larger data types like "
"structures or arrays."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:202
#: ../arch/x86/include/asm/uaccess.h:221
msgid ""
"**ptr** must have pointer-to-simple-variable type, and **x** must be "
"assignable to the result of dereferencing **ptr**."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:206
#: ../arch/x86/include/asm/uaccess.h:228
msgid "zero on success, or -EFAULT on error."
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:213
msgid "``__put_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: ../arch/x86/include/asm/uaccess.h:211
msgid "Write a simple value into user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:52
#: ../arch/x86/lib/usercopy_32.c:55
msgid "Zero a block of memory in user space."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:58
#: ../arch/x86/lib/usercopy_32.c:78
msgid "``void __user *to``"
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:55
#: ../arch/x86/lib/usercopy_32.c:75
msgid "``unsigned long n``"
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:54
#: ../arch/x86/lib/usercopy_32.c:74
msgid "Number of bytes to zero."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:58
#: ../arch/x86/lib/usercopy_32.c:79
msgid ""
"number of bytes that could not be cleared. On success, this will be zero."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:72
msgid "Zero a block of memory in user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:11: ../arch/x86/lib/usercopy_32.c:75
msgid ""
"Zero a block of memory in user space.  Caller must check the specified block "
"with access_ok() before calling this function."
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3272
msgid "pin user pages in memory"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6961
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3828
#: ../include/linux/mm.h:3867 ../../../core-api/mm-api:124:
#: ../mm/migrate_device.c:1378 ../../../core-api/mm-api:132:
#: ../mm/mmu_notifier.c:963 ../../../core-api/mm-api:14: ../mm/gup.c:3278
msgid "``unsigned long start``"
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3273
msgid "starting user address"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1463 ../mm/rmap.c:1602
#: ../mm/rmap.c:1770 ../../../core-api/mm-api:121: ../mm/memcontrol.c:1268
#: ../../../core-api/mm-api:14: ../mm/gup.c:3275
msgid "``int nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3274
msgid "number of pages from start to pin"
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3276 ../../../core-api/mm-api:97:
#: ../mm/memory.c:7113
msgid "``unsigned int gup_flags``"
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3275
msgid "flags modifying pin behaviour"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:629
#: ../../../core-api/mm-api:14: ../mm/gup.c:3277 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:3048 ../mm/vmalloc.c:3511 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2413 ../mm/memory.c:2526 ../mm/memory.c:2551
msgid "``struct page **pages``"
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3276
msgid ""
"array that receives pointers to the pages pinned. Should be at least "
"nr_pages long."
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3278
msgid ""
"Attempt to pin user pages in memory without taking mm->mmap_lock. If not "
"successful, it will fall back to taking the lock and calling "
"get_user_pages()."
msgstr ""

#: ../../../core-api/mm-api:14: ../mm/gup.c:3282
msgid ""
"Returns number of pages pinned. This may be fewer than the number requested. "
"If nr_pages is 0 or negative, returns 0. If no pages were pinned, returns -"
"errno."
msgstr ""

#: ../../../core-api/mm-api.rst:20
msgid "Memory Allocation Controls"
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:118
msgid ""
"These flags provide hints about how mobile the page is. Pages with similar "
"mobility are placed within the same pageblocks to minimise problems due to "
"external fragmentation."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:122
msgid ""
"``__GFP_MOVABLE`` (also a zone modifier) indicates that the page can be "
"moved by page migration during memory compaction or can be reclaimed."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:125
msgid ""
"``__GFP_RECLAIMABLE`` is used for slab allocations that specify "
"SLAB_RECLAIM_ACCOUNT and whose pages can be freed via shrinkers."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:128
msgid ""
"``__GFP_WRITE`` indicates the caller intends to dirty the page. Where "
"possible, these pages will be spread between local zones to avoid all the "
"dirty pages being in one zone (fair zone allocation policy)."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:132
msgid "``__GFP_HARDWALL`` enforces the cpuset memory allocation policy."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:134
msgid ""
"``__GFP_THISNODE`` forces the allocation to be satisfied from the requested "
"node with no fallbacks or placement policy enforcements."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:137
msgid "``__GFP_ACCOUNT`` causes the allocation to be accounted to kmemcg."
msgstr ""

#: ../../../core-api/mm-api:22: ../include/linux/gfp_types.h:139
msgid ""
"``__GFP_NO_OBJ_EXT`` causes slab allocation to have no object extension."
msgstr ""

#: ../../../core-api/mm-api:25: ../include/linux/gfp_types.h:154
msgid ""
"``__GFP_HIGH`` indicates that the caller is high-priority and that granting "
"the request is necessary before the system can make forward progress. For "
"example creating an IO context to clean pages and requests from atomic "
"context."
msgstr ""

#: ../../../core-api/mm-api:25: ../include/linux/gfp_types.h:159
msgid ""
"``__GFP_MEMALLOC`` allows access to all memory. This should only be used "
"when the caller guarantees the allocation will allow more memory to be freed "
"very shortly e.g. process exiting or swapping. Users either should be the MM "
"or co-ordinating closely with the VM (e.g. swap over NFS). Users of this "
"flag have to be extremely careful to not deplete the reserve completely and "
"implement a throttling mechanism which controls the consumption of the "
"reserve based on the amount of freed memory. Usage of a pre-allocated pool "
"(e.g. mempool) should be always considered before using this flag."
msgstr ""

#: ../../../core-api/mm-api:25: ../include/linux/gfp_types.h:169
msgid ""
"``__GFP_NOMEMALLOC`` is used to explicitly forbid access to emergency "
"reserves. This takes precedence over the ``__GFP_MEMALLOC`` flag if both are "
"set."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:181
msgid ""
"Please note that all the following flags are only applicable to sleepable "
"allocations (e.g. ``GFP_NOWAIT`` and ``GFP_ATOMIC`` will ignore them)."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:184
msgid "``__GFP_IO`` can start physical IO."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:186
msgid ""
"``__GFP_FS`` can call down to the low-level FS. Clearing the flag avoids the "
"allocator recursing into the filesystem which might already be holding locks."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:190
msgid ""
"``__GFP_DIRECT_RECLAIM`` indicates that the caller may enter direct reclaim. "
"This flag can be cleared to avoid unnecessary delays when a fallback option "
"is available."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:194
msgid ""
"``__GFP_KSWAPD_RECLAIM`` indicates that the caller wants to wake kswapd when "
"the low watermark is reached and have it reclaim pages until the high "
"watermark is reached. A caller may wish to clear this flag when fallback "
"options are available and the reclaim is likely to disrupt the system. The "
"canonical example is THP allocation where a fallback is cheap but reclaim/"
"compaction may cause indirect stalls."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:201
msgid ""
"``__GFP_RECLAIM`` is shorthand to allow/forbid both direct and kswapd "
"reclaim."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:203
msgid ""
"The default allocator behavior depends on the request size. We have a "
"concept of so-called costly allocations (with order > "
"``PAGE_ALLOC_COSTLY_ORDER``). !costly allocations are too essential to fail "
"so they are implicitly non-failing by default (with some exceptions like OOM "
"victims might fail so the caller still has to check for failures) while "
"costly requests try to be not disruptive and back off even without invoking "
"the OOM killer. The following three modifiers might be used to override some "
"of these implicit rules. Please note that all of them must be used along "
"with ``__GFP_DIRECT_RECLAIM`` flag."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:213
msgid ""
"``__GFP_NORETRY``: The VM implementation will try only very lightweight "
"memory direct reclaim to get some memory under memory pressure (thus it can "
"sleep). It will avoid disruptive actions like OOM killer. The caller must "
"handle the failure which is quite likely to happen under heavy memory "
"pressure. The flag is suitable when failure can easily be handled at small "
"cost, such as reduced throughput."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:220
msgid ""
"``__GFP_RETRY_MAYFAIL``: The VM implementation will retry memory reclaim "
"procedures that have previously failed if there is some indication that "
"progress has been made elsewhere.  It can wait for other tasks to attempt "
"high-level approaches to freeing memory such as compaction (which removes "
"fragmentation) and page-out. There is still a definite limit to the number "
"of retries, but it is a larger limit than with ``__GFP_NORETRY``. "
"Allocations with this flag may fail, but only when there is genuinely little "
"unused memory. While these allocations do not directly trigger the OOM "
"killer, their failure indicates that the system is likely to need to use the "
"OOM killer soon.  The caller must handle failure, but can reasonably do so "
"by failing a higher-level request, or completing it only in a much less "
"efficient manner. If the allocation does fail, and the caller is in a "
"position to free some non-essential memory, doing so could benefit the "
"system as a whole."
msgstr ""

#: ../../../core-api/mm-api:28: ../include/linux/gfp_types.h:238
msgid ""
"``__GFP_NOFAIL``: The VM implementation _must_ retry infinitely: the caller "
"cannot handle allocation failures. The allocation could block indefinitely "
"but will never return with failure. Testing for failure is pointless. It "
"_must_ be blockable and used together with __GFP_DIRECT_RECLAIM. It should "
"_never_ be used in non-sleepable contexts. New users should be evaluated "
"carefully (and the flag should be used only when there is no reasonable "
"failure policy) but it is definitely preferable to use the flag rather than "
"opencode endless loop around allocator. Allocating pages from the buddy with "
"__GFP_NOFAIL and order > 1 is not supported. Please consider using "
"kvmalloc() instead."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:304
msgid ""
"Useful GFP flag combinations that are commonly used. It is recommended that "
"subsystems start with one of these combinations and then set/clear "
"``__GFP_FOO`` flags as necessary."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:308
msgid ""
"``GFP_ATOMIC`` users can not sleep and need the allocation to succeed. A "
"lower watermark is applied to allow access to \"atomic reserves\". The "
"current implementation doesn't support NMI and few other strict non-"
"preemptive contexts (e.g. raw_spin_lock). The same applies to ``GFP_NOWAIT``."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:313
msgid ""
"``GFP_KERNEL`` is typical for kernel-internal allocations. The caller "
"requires ``ZONE_NORMAL`` or a lower zone for direct access but can direct "
"reclaim."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:316
msgid ""
"``GFP_KERNEL_ACCOUNT`` is the same as GFP_KERNEL, except the allocation is "
"accounted to kmemcg."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:319
msgid ""
"``GFP_NOWAIT`` is for kernel allocations that should not stall for direct "
"reclaim, start physical IO or use any filesystem callback.  It is very "
"likely to fail to allocate memory, even for very small allocations."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:323
msgid ""
"``GFP_NOIO`` will use direct reclaim to discard clean pages or slab pages "
"that do not require the starting of any physical IO. Please try to avoid "
"using this flag directly and instead use memalloc_noio_{save,restore} to "
"mark the whole scope which cannot perform any IO with a short explanation "
"why. All allocation requests will inherit GFP_NOIO implicitly."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:330
msgid ""
"``GFP_NOFS`` will use direct reclaim but will not use any filesystem "
"interfaces. Please try to avoid using this flag directly and instead use "
"memalloc_nofs_{save,restore} to mark the whole scope which cannot/shouldn't "
"recurse into the FS layer with a short explanation why. All allocation "
"requests will inherit GFP_NOFS implicitly."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:336
msgid ""
"``GFP_USER`` is for userspace allocations that also need to be directly "
"accessibly by the kernel or hardware. It is typically used by hardware for "
"buffers that are mapped to userspace (e.g. graphics) that hardware still "
"must DMA to. cpuset limits are enforced for these allocations."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:341
msgid ""
"``GFP_DMA`` exists for historical reasons and should be avoided where "
"possible. The flags indicates that the caller requires that the lowest zone "
"be used (``ZONE_DMA`` or 16M on x86-64). Ideally, this would be removed but "
"it would require careful auditing as some users really require it and others "
"use the flag to avoid lowmem reserves in ``ZONE_DMA`` and treat the lowest "
"zone as a type of emergency reserve."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:348
msgid ""
"``GFP_DMA32`` is similar to ``GFP_DMA`` except that the caller requires a 32-"
"bit address. Note that kmalloc(..., GFP_DMA32) does not return DMA32 memory "
"because the DMA32 kmalloc cache array is not implemented. (Reason: there is "
"no such user in kernel)."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:353
msgid ""
"``GFP_HIGHUSER`` is for userspace allocations that may be mapped to "
"userspace, do not need to be directly accessible by the kernel but that "
"cannot move once in use. An example may be a hardware allocation that maps "
"data directly into userspace but has no addressing limitations."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:358
msgid ""
"``GFP_HIGHUSER_MOVABLE`` is for userspace allocations that the kernel does "
"not need direct access to but can use kmap() when access is required. They "
"are expected to be movable via page reclaim or page migration. Typically, "
"pages on the LRU would also be allocated with ``GFP_HIGHUSER_MOVABLE``."
msgstr ""

#: ../../../core-api/mm-api:31: ../include/linux/gfp_types.h:363
msgid ""
"``GFP_TRANSHUGE`` and ``GFP_TRANSHUGE_LIGHT`` are used for THP allocations. "
"They are compound allocations that will generally fail quickly if memory is "
"not available and will not wake kswapd/kcompactd on failure. The _LIGHT "
"version does not attempt reclaim/compaction at all and is by default used in "
"page fault path, while the non-light is used by khugepaged."
msgstr ""

#: ../../../core-api/mm-api.rst:35
msgid "The Slab Cache"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:84
msgid "``SLAB_HWCACHE_ALIGN``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:82
msgid "Align objects on cache line boundaries."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:83
msgid ""
"Sufficiently large objects are aligned on cache line boundary. For object "
"size smaller than a half of cache line size, the alignment is on the half of "
"cache line size. In general, if object size is smaller than 1/2^n of cache "
"line size, the alignment is adjusted to 1/2^n."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:88
msgid ""
"If explicit alignment is also requested by the respective :c:type:`struct "
"kmem_cache_args <kmem_cache_args>` field, the greater of both is alignments "
"is applied."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:104
msgid "``SLAB_TYPESAFE_BY_RCU``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:102
msgid "**WARNING** READ THIS!"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:103
msgid ""
"This delays freeing the SLAB page by a grace period, it does _NOT_ delay "
"object freeing. This means that if you do kmem_cache_free() that memory "
"location is free to be reused at any time. Thus it may be possible to see "
"another object there in the same RCU grace period."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:108
msgid ""
"This feature only ensures the memory location backing the object stays "
"valid, the trick to using this is relying on an independent object "
"validation pass. Something like:"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:130
msgid ""
"This is useful if we need to approach a kernel structure obliquely, from its "
"address obtained without the usual locking. We can lock the structure to "
"stabilize it and check it's still at the given address, only if we can be "
"sure that the memory has not been meanwhile reused for some other kind of "
"object (which our subsystem's lock might corrupt)."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:136
msgid ""
"rcu_read_lock before reading the address, then rcu_read_unlock after taking "
"the spinlock within the structure expected at that address."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:139
msgid ""
"Note that object identity check has to be done *after* acquiring a "
"reference, therefore user has to ensure proper ordering for loads. "
"Similarly, when initializing objects allocated with SLAB_TYPESAFE_BY_RCU, "
"the newly allocated object has to be fully initialized *before* its refcount "
"gets initialized and proper ordering for stores is required. refcount_{add|"
"inc}_not_zero_acquire() and refcount_set_release() are designed with the "
"proper fences required for reference counting objects allocated with "
"SLAB_TYPESAFE_BY_RCU."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:148
msgid ""
"Note that it is not possible to acquire a lock within a structure allocated "
"with SLAB_TYPESAFE_BY_RCU without first acquiring a reference as described "
"above.  The reason is that SLAB_TYPESAFE_BY_RCU pages are not zeroed before "
"being given to the slab, which means that any locks must be initialized "
"after each and every kmem_struct_alloc(). Alternatively, make the ctor "
"passed to kmem_cache_create() initialize the locks at page-allocation time, "
"as is done in __i915_request_ctor(), sighand_ctor(), and anon_vma_ctor().  "
"Such a ctor permits readers to safely acquire those ctor-initialized locks "
"under rcu_read_lock() protection."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:159
msgid ""
"Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:197
msgid "``SLAB_ACCOUNT``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:195
msgid "Account allocations to memcg."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:196
msgid ""
"All object allocations from this cache will be memcg accounted, regardless "
"of __GFP_ACCOUNT being or not being passed to individual allocations."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:229
msgid "``SLAB_RECLAIM_ACCOUNT``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:227
msgid "Objects are reclaimable."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:228
msgid ""
"Use this flag for caches that have an associated shrinker. As a result, slab "
"pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by "
"mobility, and are accounted in SReclaimable counter in /proc/meminfo"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:270
msgid "Less common arguments for kmem_cache_create()"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:362
#: ../include/linux/mm_types.h:554 ../../../core-api/mm-api:126:
#: ../mm/mapping_dirty_helpers.c:15 ../mm/mapping_dirty_helpers.c:59
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:274
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1347
msgid "**Definition**::"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:418
#: ../include/linux/mm_types.h:590 ../../../core-api/mm-api:126:
#: ../mm/mapping_dirty_helpers.c:24 ../mm/mapping_dirty_helpers.c:69
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:286
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1355
msgid "**Members**"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:283
msgid "``align``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:284
#: ../include/linux/slab.h:392
msgid "The required alignment for the objects."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:286
msgid "``0`` means no specific alignment is requested."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:289
msgid "``useroffset``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:290
msgid "Usercopy region offset."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:292
msgid "``0`` is a valid offset, when **usersize** is non-``0``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:295
msgid "``usersize``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:296
msgid "Usercopy region size."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:298
msgid "``0`` means no usercopy region is specified."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:301
msgid "``freeptr_offset``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:302
msgid ""
"Custom offset for the free pointer in :c:type:`SLAB_TYPESAFE_BY_RCU` caches"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:305
msgid ""
"By default :c:type:`SLAB_TYPESAFE_BY_RCU` caches place the free pointer "
"outside of the object. This might cause the object to grow in size. Cache "
"creators that have a reason to avoid this can specify a custom free pointer "
"offset in their struct where the free pointer will be placed."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:311
msgid ""
"Note that placing the free pointer inside the object requires the caller to "
"ensure that no fields are invalidated that are required to guard against "
"object recycling (See :c:type:`SLAB_TYPESAFE_BY_RCU` for details)."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:316
msgid ""
"Using ``0`` as a value for **freeptr_offset** is valid. If "
"**freeptr_offset** is specified, ``use_freeptr_offset`` must be set ``true``."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:319
msgid ""
"Note that **ctor** currently isn't supported with custom free pointers as a "
"**ctor** requires an external free pointer."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:323
msgid "``use_freeptr_offset``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:324
msgid "Whether a **freeptr_offset** is used."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:327
msgid "``ctor``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:328
msgid "A constructor for the objects."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:330
msgid ""
"The constructor is invoked for each object in a newly allocated slab page. "
"It is the cache user's responsibility to free object in the same state as "
"after calling the constructor, or deal appropriately with any differences "
"between a freshly constructed and a reallocated object."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:336
msgid "``NULL`` means no constructor."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:339
msgid "``sheaf_capacity``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:340
msgid "Enable sheaves of given capacity for the cache."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:342
msgid ""
"With a non-zero value, allocations from the cache go through caching arrays "
"called sheaves. Each cpu has a main sheaf that's always present, and a spare "
"sheaf that may be not present. When both become empty, there's an attempt to "
"replace an empty sheaf with a full sheaf from the per-node barn."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:348
msgid ""
"When no full sheaf is available, and gfp flags allow blocking, a sheaf is "
"allocated and filled from slab(s) using bulk allocation. Otherwise the "
"allocation falls back to the normal operation allocating a single object "
"from a slab."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:353
msgid ""
"Analogically when freeing and both percpu sheaves are full, the barn may "
"replace it with an empty sheaf, unless it's over capacity. In that case a "
"sheaf is bulk freed to slab pages."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:357
msgid ""
"The sheaves do not enforce NUMA placement of objects, so allocations via "
"kmem_cache_alloc_node() with a node specified other than NUMA_NO_NODE will "
"bypass them."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:361
msgid ""
"Bulk allocation and free operations also try to use the cpu sheaves and "
"barn, but fallback to using slab pages directly."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:364
msgid ""
"When slub_debug is enabled for the cache, the sheaf_capacity argument is "
"ignored."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:367
msgid "``0`` means no sheaves will be created."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:271
msgid ""
"Any uninitialized fields of the structure are interpreted as unused. The "
"exception is **freeptr_offset** where ``0`` is a valid value, so "
"**use_freeptr_offset** must be also set to ``true`` in order to interpret "
"the field as used. For **useroffset** ``0`` is also valid, but only with non-"
"``0`` **usersize**."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:277
msgid ""
"When ``NULL`` args is passed to kmem_cache_create(), it is equivalent to all "
"fields unused."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:388
msgid "Create a kmem cache with a region suitable for copying to userspace."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5888 ../mm/shmem.c:5904
#: ../mm/shmem.c:5913 ../../../core-api/mm-api:37: ../include/linux/slab.h:394
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:263 ../mm/slab_common.c:373
msgid "``const char *name``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:390
#: ../include/linux/slab.h:438 ../../../core-api/mm-api:43:
#: ../mm/slab_common.c:258
msgid "A string which is used in /proc/slabinfo to identify this cache."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:392
msgid "``unsigned int size``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:391
#: ../include/linux/slab.h:439 ../../../core-api/mm-api:43:
#: ../mm/slab_common.c:259
msgid "The size of objects to be created in this cache."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:393
msgid "``unsigned int align``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:394
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:263 ../mm/slab_common.c:372
msgid "``slab_flags_t flags``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:393
msgid "SLAB flags"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:395
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:373
msgid "``unsigned int useroffset``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:394
msgid "Usercopy region offset"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:396
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:375
msgid "``unsigned int usersize``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:395
msgid "Usercopy region size"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:397
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:377
msgid "``void (*ctor)(void *)``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:396
msgid "A constructor for the objects, or ``NULL``."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:397
msgid ""
"This is a legacy wrapper, new code should use either KMEM_CACHE_USERCOPY() "
"if whitelisting a single field is sufficient, or kmem_cache_create() with "
"the necessary parameters passed via the args parameter (see :c:type:`struct "
"kmem_cache_args <kmem_cache_args>`)"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:403
#: ../include/linux/slab.h:459 ../../../core-api/mm-api:43:
#: ../mm/slab_common.c:281
msgid "a pointer to the cache on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:439
msgid "``kmem_cache_create (__name, __object_size, __args, ...)``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:437
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:257
msgid "Create a kmem cache."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:443
msgid "``__name``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:440
msgid "``__object_size``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:441
msgid "``__args``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:440
msgid ""
"Optional arguments, see :c:type:`struct kmem_cache_args <kmem_cache_args>`. "
"Passing ``NULL`` means defaults will be used for all the arguments."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:443
msgid "``...``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1
msgid "variable arguments"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:442
msgid ""
"This is currently implemented as a macro using ``_Generic()`` to call either "
"the new variant of the function, or a legacy one."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:445
msgid ""
"The new variant has 4 parameters: ``kmem_cache_create(name, object_size, "
"args, flags)``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:448
msgid "See __kmem_cache_create_args() which implements this."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:450
msgid ""
"The legacy variant has 5 parameters: ``kmem_cache_create(name, object_size, "
"align, flags, ctor)``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:453
msgid ""
"The align and ctor parameters map to the respective fields of :c:type:"
"`struct kmem_cache_args <kmem_cache_args>`"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:457
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:279
msgid "Cannot be called within a interrupt, but can be interrupted."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:516
msgid "Report actual allocation size of associated object"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:522
msgid "``const void *objp``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:518
msgid "Pointer returned from a prior kmalloc()-family allocation."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:519
msgid ""
"This should not be used for writing beyond the originally requested "
"allocation size. Either use krealloc() or round up the allocation size with "
"kmalloc_size_roundup() prior to allocation. If this is used to access beyond "
"the originally requested allocation size, UBSAN_BOUNDS and/or FORTIFY_SOURCE "
"may trip, since they only know about the originally allocated size via the "
"__alloc_size attribute."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:764
msgid "Allocate an object"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:770
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:560
msgid "``struct kmem_cache *cachep``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:765
#: ../../../core-api/mm-api:40: ../mm/slub.c:5302
msgid "The cache to allocate from."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:767
#: ../include/linux/slab.h:897 ../include/linux/slab.h:996
#: ../include/linux/slab.h:1013 ../include/linux/slab.h:1091
#: ../../../core-api/mm-api:40: ../mm/slub.c:7039 ../mm/slub.c:7120
#: ../mm/slub.c:7221
msgid "``gfp_t flags``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:766
#: ../../../core-api/mm-api:40: ../mm/slub.c:5303
msgid "See kmalloc()."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:767
msgid ""
"Allocate an object from this cache. See kmem_cache_zalloc() for a shortcut "
"of adding __GFP_ZERO to flags."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:771
#: ../../../core-api/mm-api:40: ../mm/slub.c:5311
msgid "pointer to the new object or ``NULL`` in case of error"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:782
msgid "memcg charge an already allocated slab memory"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:788
msgid "``void *objp``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:783
msgid "address of the slab object to memcg charge"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:785
#: ../../../core-api/mm-api:40: ../mm/slub.c:5304
msgid "``gfp_t gfpflags``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:784
#: ../include/linux/slab.h:896
msgid "describe the allocation context"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:785
msgid ""
"kmem_cache_charge allows charging a slab object to the current memcg, "
"primarily in cases where charging at allocation time might not be possible "
"because the target memcg is not known (i.e. softirq context)"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:789
msgid ""
"The objp should be pointer returned by the slab allocator functions like "
"kmalloc (with __GFP_ACCOUNT in flags) or kmem_cache_alloc. The memcg charge "
"behavior can be controlled through gfpflags parameter, which affects how the "
"necessary internal metadata can be allocated. Including __GFP_NOFAIL denotes "
"that overcharging is requested instead of failure, but is not applied for "
"the internal metadata allocation."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:796
msgid ""
"There are several cases where it will return true even if the charging was "
"not done: More specifically:"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:800
msgid "For !CONFIG_MEMCG or cgroup_disable=memory systems."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:801
msgid "Already charged slab objects."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:802
msgid ""
"For slab objects from KMALLOC_NORMAL caches - allocated by kmalloc() without "
"__GFP_ACCOUNT"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:804
msgid "Allocating internal metadata has failed"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:807
msgid "true if charge was successful otherwise false."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:894
msgid "allocate kernel memory"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5419
#: ../mm/page_alloc.c:5445 ../mm/page_alloc.c:5470
#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1082 ../mm/kmemleak.c:1106
#: ../mm/kmemleak.c:1125 ../mm/kmemleak.c:1167 ../mm/kmemleak.c:1302
#: ../mm/kmemleak.c:1340 ../mm/kmemleak.c:1361 ../../../core-api/mm-api:121:
#: ../mm/memcontrol.c:5471 ../mm/memcontrol.c:5499
#: ../../../core-api/mm-api:128: ../mm/percpu.c:498 ../mm/percpu.c:1722
#: ../../../core-api/mm-api:129: ../mm/maccess.c:116 ../mm/maccess.c:145
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:900
#: ../include/linux/slab.h:995 ../include/linux/slab.h:1094
#: ../include/linux/slab.h:1174 ../../../core-api/mm-api:40: ../mm/slub.c:5680
#: ../mm/slub.c:7219 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:752
msgid "``size_t size``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:895
#: ../include/linux/slab.h:1089 ../../../core-api/mm-api:40: ../mm/slub.c:7036
msgid "how many bytes of memory are required."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:897
msgid ""
"kmalloc is the normal method of allocating memory for objects smaller than "
"page size in the kernel."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:900
msgid ""
"The allocated object address is aligned to at least ARCH_KMALLOC_MINALIGN "
"bytes. For **size** of power of two bytes, the alignment is also guaranteed "
"to be at least to the size. For other sizes, the alignment is guaranteed to "
"be at least the largest power-of-two divisor of **size**."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:905
msgid ""
"The **flags** argument may be one of the GFP flags defined at include/linux/"
"gfp_types.h and described at :ref:`Documentation/core-api/mm-api.rst <mm-api-"
"gfp-flags>`"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:909
msgid ""
"The recommended usage of the **flags** is described at :ref:`Documentation/"
"core-api/memory-allocation.rst <memory_allocation>`"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:912
msgid "Below is a brief outline of the most useful GFP flags"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:914
msgid "``GFP_KERNEL``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:915
msgid "Allocate normal kernel ram. May sleep."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:917
msgid "``GFP_NOWAIT``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:918
msgid "Allocation will not sleep."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:920
msgid "``GFP_ATOMIC``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:921
msgid "Allocation will not sleep.  May use emergency pools."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:923
msgid ""
"Also it is possible to set different flags by OR'ing in one or more of the "
"following additional **flags**:"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:926
msgid "``__GFP_ZERO``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:927
msgid "Zero the allocated memory before returning. Also see kzalloc()."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:929
msgid "``__GFP_HIGH``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:930
msgid "This allocation has high priority and may use emergency pools."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:932
msgid "``__GFP_NOFAIL``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:933
msgid ""
"Indicate that this allocation is in no way allowed to fail (think twice "
"before using)."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:936
msgid "``__GFP_NORETRY``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:937
msgid "If memory is not immediately available, then give up at once."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:940
msgid "``__GFP_NOWARN``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:941
msgid "If allocation fails, don't issue any warnings."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:943
msgid "``__GFP_RETRY_MAYFAIL``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:944
msgid "Try really hard to succeed the allocation but fail eventually."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:992
msgid "allocate memory for an array."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:998
msgid "``size_t n``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:993
#: ../include/linux/slab.h:1040
msgid "number of elements."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:994
#: ../include/linux/slab.h:1041
msgid "element size."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:995
#: ../include/linux/slab.h:1042 ../include/linux/slab.h:1090
msgid "the type of memory to allocate (see kmalloc)."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1008
msgid "reallocate memory for an array."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1014
msgid "``void *p``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1009
msgid "pointer to the memory chunk to reallocate"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1011
msgid "``size_t new_n``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1010
msgid "new number of elements to alloc"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1012
#: ../../../core-api/mm-api:40: ../mm/slub.c:7037
msgid "``size_t new_size``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1011
msgid "new size of a single member of the array"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1012
msgid "the type of memory to allocate (see kmalloc)"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1013
#: ../../../core-api/mm-api:40: ../mm/slub.c:7046 ../mm/slub.c:7228
msgid ""
"If __GFP_ZERO logic is requested, callers must ensure that, starting with "
"the initial memory allocation, every subsequent call to this API for the "
"same memory allocation is flagged with __GFP_ZERO. Otherwise, it is possible "
"that __GFP_ZERO is not fully honored by this API."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1018
msgid "See krealloc_noprof() for further details."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1020
#: ../../../core-api/mm-api:40: ../mm/slub.c:7065 ../mm/slub.c:7233
msgid ""
"In any case, the contents of the object pointed to are preserved up to the "
"lesser of the new and old sizes."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1041
msgid "``kcalloc (n, size, flags)``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1039
msgid "allocate memory for an array. The memory is set to zero."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:314
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1045
msgid "``n``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1042
#: ../../../core-api/mm-api:40: ../mm/slub.c:7120
msgid "``size``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:359
#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1043
msgid "``flags``"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1088
msgid "allocate memory. The memory is set to zero."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1168
msgid "Report allocation bucket size for the given size"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1170
msgid "Number of bytes to round up from."
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1171
msgid ""
"This returns the number of bytes that would be available in a kmalloc() "
"allocation of **size** bytes. For example, a 126 byte request would be "
"rounded up to the next sized kmalloc bucket, 128 bytes. (This is strictly "
"for the general-purpose kmalloc()-based allocations, and is not for the pre-"
"sized kmem_cache_alloc()-based allocations.)"
msgstr ""

#: ../../../core-api/mm-api:37: ../include/linux/slab.h:1177
msgid ""
"Use this to kmalloc() the full bucket size ahead of time instead of using "
"ksize() to query the size after an allocation."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5301
msgid "Allocate an object on the specified node"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5307 ../mm/slub.c:6782
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2134
msgid "``struct kmem_cache *s``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5600
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:285 ../mm/mempolicy.c:317
#: ../../../core-api/mm-api:40: ../mm/slub.c:5305 ../mm/slub.c:5679
#: ../mm/slub.c:7121 ../../../core-api/mm-api:52: ../mm/vmalloc.c:3046
#: ../mm/vmalloc.c:4098 ../mm/vmalloc.c:4156 ../mm/vmalloc.c:4216
#: ../mm/vmalloc.c:4236
msgid "``int node``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5304 ../mm/slub.c:5678
msgid "node number of the target node."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5305
msgid ""
"Identical to kmem_cache_alloc but it will allocate memory on the given node, "
"which can improve the performance for cpu bound structures."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5308
msgid "Fallback to other node is possible if __GFP_THISNODE is not set."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5674
msgid "Allocate an object of given size from any context."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5675
msgid "size to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7701
#: ../../../core-api/mm-api:40: ../mm/slub.c:5677
msgid "``gfp_t gfp_flags``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5676
msgid "GFP flags. Only __GFP_ACCOUNT, __GFP_ZERO, __GFP_NO_OBJ_EXT allowed."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:5680
msgid ""
"pointer to the new object or NULL in case of error. NULL does not mean EBUSY "
"or EAGAIN. It means ENOMEM. There is no reason to call it again and expect !"
"NULL."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6776
msgid "Deallocate an object"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6777
msgid "The cache the allocation was from."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6779
msgid "``void *x``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6778
msgid "The previously allocated object."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6779
msgid "Free an object which was previously allocated from this cache."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6861
msgid "free previously allocated memory"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6867
msgid "``const void *object``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6862
msgid "pointer returned by kmalloc() or kmem_cache_alloc()"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:6863
msgid "If **object** is NULL, no operation is performed."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7034
msgid "reallocate memory. The contents will remain unchanged."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7040 ../mm/slub.c:7222
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1220
msgid "``const void *p``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7035
msgid "object to reallocate memory for."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7038 ../mm/slub.c:7119
#: ../mm/slub.c:7220 ../../../core-api/mm-api:52: ../mm/vmalloc.c:4096
msgid "``unsigned long align``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7037 ../mm/slub.c:7118
msgid "desired alignment."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7038
msgid "the type of memory to allocate."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5447
#: ../mm/page_alloc.c:7162 ../mm/page_alloc.c:7698
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2438
#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2162
#: ../../../core-api/mm-api:40: ../mm/slub.c:7040 ../mm/slub.c:7222
msgid "``int nid``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7039
msgid "NUMA node or NUMA_NO_NODE"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7040
msgid ""
"If **p** is ``NULL``, krealloc() behaves exactly like kmalloc().  If "
"**new_size** is 0 and **p** is not a ``NULL`` pointer, the object pointed to "
"is freed."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7043 ../mm/slub.c:7121
#: ../mm/slub.c:7225
msgid ""
"Only alignments up to those guaranteed by kmalloc() will be honored. Please "
"see Documentation/core-api/memory-allocation.rst for more details."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7051
msgid ""
"When slub_debug_orig_size() is off, krealloc() only knows about the bucket "
"size of an allocation (but not the exact size it was allocated with) and "
"hence implements the following semantics for shrinking and growing buffers "
"with __GFP_ZERO::"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7061
msgid ""
"Otherwise, the original allocation size 'orig_size' could be used to "
"precisely clear the requested size, and the new size will also be stored as "
"the new 'orig_size'."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7069 ../mm/slub.c:7240
msgid "pointer to the allocated memory or ``NULL`` in case of error"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7114
msgid ""
"attempt to allocate physically contiguous memory, but upon failure, fall "
"back to non-contiguous (vmalloc) allocation."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7116
msgid "size of the request."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7118
msgid "``b``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7117
msgid "which set of kmalloc buckets to allocate from."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7119
msgid ""
"gfp mask for the allocation - must be compatible (superset) with GFP_KERNEL."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7120
msgid "numa node to allocate from"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7124
msgid ""
"Uses kmalloc to get the memory but if the allocation fails then falls back "
"to the vmalloc allocator. Use kvfree for freeing the memory."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7127
msgid ""
"GFP_NOWAIT and GFP_ATOMIC are supported, the __GFP_NORETRY modifier is not. "
"__GFP_RETRY_MAYFAIL is supported, and it should be used only if kmalloc is "
"preferable to the vmalloc fallback, due to visible performance drawbacks."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7132
msgid "pointer to the allocated memory of ``NULL`` in case of failure"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7179
msgid "Free memory."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7185 ../mm/slub.c:7204
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3419 ../mm/vmalloc.c:3483
msgid "``const void *addr``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7180
msgid "Pointer to allocated memory."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7181
msgid ""
"kvfree frees memory allocated by any of vmalloc(), kmalloc() or kvmalloc(). "
"It is slightly more efficient to use kfree() or vfree() if you are certain "
"that you know which one to use."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7186
msgid "Either preemptible task context or not-NMI interrupt."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7198
msgid "Free a data object containing sensitive information."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7199
msgid "address of the data object to be freed."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7201 ../../../core-api/mm-api:61:
#: ../mm/filemap.c:3035 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:783
msgid "``size_t len``"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7200
msgid "length of the data object."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7201
msgid ""
"Use the special memzero_explicit() function to clear the content of a "
"kvmalloc'ed object containing sensitive data to make sure that the compiler "
"won't optimize out the data clearing."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7216
msgid "reallocate memory; contents remain unchanged"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7217
msgid "object to reallocate memory for"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7218
msgid "the size to reallocate"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7219 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:4095
msgid "desired alignment"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7220
msgid "the flags for the page level allocator"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7221
msgid "NUMA node id"
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7222
msgid ""
"If **p** is ``NULL``, kvrealloc() behaves exactly like kvmalloc(). If "
"**size** is 0 and **p** is not a ``NULL`` pointer, the object pointed to is "
"freed."
msgstr ""

#: ../../../core-api/mm-api:40: ../mm/slub.c:7236
msgid ""
"This function must not be called concurrently with itself or kvfree() for "
"the same memory allocation."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:260
msgid "``unsigned int object_size``"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:261
msgid "``struct kmem_cache_args *args``"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:260
msgid ""
"Additional arguments for the cache creation (see :c:type:`struct "
"kmem_cache_args <kmem_cache_args>`)."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:262
msgid ""
"See the descriptions of individual flags. The common ones are listed in the "
"description below."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:264
msgid ""
"Not to be called directly, use the kmem_cache_create() wrapper with the same "
"parameters."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:267
msgid "Commonly used **flags**:"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:269
msgid ":c:type:`SLAB_ACCOUNT` - Account allocations to memcg."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:271
msgid ":c:type:`SLAB_HWCACHE_ALIGN` - Align objects on cache line boundaries."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:273
msgid ":c:type:`SLAB_RECLAIM_ACCOUNT` - Objects are reclaimable."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:275
msgid ""
":c:type:`SLAB_TYPESAFE_BY_RCU` - Slab page (not individual objects) freeing "
"delayed by a grace period - see the full description before using."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:367
msgid ""
"Create a set of caches that handle dynamic sized allocations via "
"kmem_buckets_alloc()"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:369
msgid ""
"A prefix string which is used in /proc/slabinfo to identify this cache. The "
"individual caches with have their sizes as the suffix."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:371
msgid "SLAB flags (see kmem_cache_create() for details)."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:372
msgid ""
"Starting offset within an allocation that may be copied to/from userspace."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:374
msgid ""
"How many bytes, starting at **useroffset**, may be copied to/from userspace."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:376
msgid "A constructor for the objects, run when new allocations are made."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:377
msgid "Cannot be called within an interrupt, but can be interrupted."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:380
msgid ""
"a pointer to the cache on success, NULL on failure. When CONFIG_SLAB_BUCKETS "
"is not enabled, ZERO_SIZE_PTR is returned, and subsequent calls to "
"kmem_buckets_alloc() will fall back to kmalloc(). (i.e. callers only need to "
"check for NULL on failure.)"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:554
msgid "Shrink a cache."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:555
msgid "The cache to shrink."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:556
msgid ""
"Releases as many slabs as possible for a cache. To help debugging, a zero "
"exit status indicates all slabs were released."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:560
msgid "``0`` if all slabs were released, non-zero otherwise"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:584
msgid "Print available slab provenance information"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:590
msgid "``void *object``"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:585
msgid "slab object for which to find provenance information."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:586
msgid ""
"This function uses pr_cont(), so that the caller is expected to have printed "
"out whatever preamble is appropriate.  The provenance information depends on "
"the type of object and on how much debugging is enabled. For a slab-cache "
"object, the fact that it is a slab object is printed, and, if available, the "
"slab name, return address, and stack trace from the allocation and last free "
"path of that object."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:594
msgid ""
"``true`` if the pointer is to a not-yet-freed object from kmalloc() or "
"kmem_cache_alloc(), either ``true`` or ``false`` if the pointer is to an "
"already-freed object, and ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1214
msgid "Clear sensitive information in memory before freeing"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1215
msgid "object to free memory of"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1216
msgid ""
"The memory of the object **p** points to is zeroed before freed. If **p** is "
"``NULL``, kfree_sensitive() does nothing."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6918
#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:255
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1219
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2492
#: ../../../core-api/mm-api:82: ../mm/truncate.c:477
#: ../../../core-api/mm-api:97: ../mm/memory.c:3085
msgid "**Note**"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:1220
msgid ""
"this function zeroes the whole allocated buffer which can be a good deal "
"bigger than the requested buffer size passed to kmalloc(). So be careful "
"when using this function in performance sensitive code."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2111
msgid "Wait until all in-flight kvfree_rcu() complete."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5524
#: ../mm/page_alloc.c:6496 ../../../core-api/mm-api:121: ../mm/memcontrol.c:954
#: ../../../core-api/mm-api:128: ../mm/percpu.c:1994 ../mm/percpu.c:2084
#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1089
#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2117
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:2995
msgid "``void``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:1
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1
#: ../../../core-api/mm-api:128: ../mm/percpu.c:1 ../../../core-api/mm-api:132:
#: ../mm/mmu_notifier.c:1 ../../../core-api/mm-api:43: ../mm/slab_common.c:1
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:1
msgid "no arguments"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2112
msgid ""
"Note that a single argument of kvfree_rcu() call has a slow path that "
"triggers synchronize_rcu() following by freeing a pointer. It is done before "
"the return from the function. Therefore for any single-argument call that "
"will result in a kfree() to a cache that is to be destroyed during module "
"exit, it is developer's responsibility to ensure that all such calls have "
"returned before the call to kmem_cache_destroy()."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2128
msgid "Wait for in-flight kvfree_rcu() calls on a specific slab cache."
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2130
msgid "slab cache to wait for"
msgstr ""

#: ../../../core-api/mm-api:43: ../mm/slab_common.c:2131
msgid "See the description of kvfree_rcu_barrier() for details."
msgstr ""

#: ../../../core-api/mm-api:46: ../mm/util.c:38
msgid "conditionally free memory"
msgstr ""

#: ../../../core-api/mm-api:46: ../mm/util.c:44
msgid "``const void *x``"
msgstr ""

#: ../../../core-api/mm-api:46: ../mm/util.c:39
msgid "pointer to the memory"
msgstr ""

#: ../../../core-api/mm-api:46: ../mm/util.c:40
msgid "Function calls kfree only if **x** is not in .rodata section."
msgstr ""

#: ../../../core-api/mm-api.rst:50
msgid "Virtually Contiguous Mappings"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:2989
msgid "unmap outstanding lazy aliases in the vmap layer"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:2990
msgid ""
"The vmap/vmalloc layer lazily flushes kernel virtual mappings primarily to "
"amortize TLB flushing overheads. What this means is that any page you have "
"now, may, in a former life, have been mapped into kernel virtual address by "
"the vmap layer and so there might be some CPUs with TLB entries still "
"referencing that page (additional to the regular 1:1 kernel mapping)."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:2996
msgid ""
"vm_unmap_aliases flushes all such lazy mappings. After it returns, we can be "
"sure that none of the pages we have control over will have any aliases from "
"the vmap layer."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3008
msgid "unmap linear kernel address space set up by vm_map_ram"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3014
msgid "``const void *mem``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3009
msgid "the pointer returned by vm_map_ram"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3011 ../mm/vmalloc.c:3045
#: ../mm/vmalloc.c:3508 ../mm/vmalloc.c:3588 ../../../core-api/mm-api:91:
#: ../mm/mempool.c:483 ../mm/mempool.c:619
msgid "``unsigned int count``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3010
msgid "the count passed to that vm_map_ram call (cannot unmap partial)"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3042
msgid "map pages linearly into kernel virtual address (vmalloc space)"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3043
msgid "an array of pointers to the pages to be mapped"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1009 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:3044
msgid "number of pages"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3045
msgid "prefer to allocate data structures on this node"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3046
msgid ""
"If you use this function for less than VMAP_MAX_ALLOC pages, it could be "
"faster than vmap so it's good.  But if you mix long-life and short-life "
"objects with vm_map_ram(), it could consume lots of address space through "
"fragmentation (especially on a 32bit machine).  You could see failures in "
"the end.  Please use this function for short-lived objects."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3053
msgid "a pointer to the address that has been mapped, or ``NULL`` on failure"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3413
msgid "Release memory allocated by vmalloc()"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3414
msgid "Memory base address"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3415
msgid ""
"Free the virtually continuous memory area starting at **addr**, as obtained "
"from one of the vmalloc() family of APIs.  This will usually also free the "
"physical memory underlying the virtual allocation, but that memory is "
"reference counted, so it will not be freed until the last user goes away."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3420
msgid "If **addr** is NULL, no operation is performed."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3423
msgid ""
"May sleep if called *not* from interrupt context. Must not be called in NMI "
"context (strictly speaking, it could be if we have "
"CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG, but making the calling conventions for "
"vfree() arch-dependent would be a really bad idea)."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3477
msgid "release virtual mapping obtained by vmap()"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3478
msgid "memory base address"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3479
msgid ""
"Free the virtually contiguous memory area starting at **addr**, which was "
"created from the page array passed to vmap()."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3482
msgid "Must not be called in interrupt context."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3505
msgid "map an array of pages into virtually contiguous space"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3506
msgid "array of page pointers"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3507 ../mm/vmalloc.c:3587
msgid "number of pages to map"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:492
#: ../../../core-api/mm-api:115: ../mm/mmap.c:320 ../../../core-api/mm-api:123:
#: ../mm/shmem.c:5890 ../mm/shmem.c:5902 ../mm/shmem.c:5915
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3509
msgid "``unsigned long flags``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3508
msgid "vm_area->flags"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3510 ../mm/vmalloc.c:3589
#: ../../../core-api/mm-api:97: ../mm/memory.c:3084
msgid "``pgprot_t prot``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3509 ../mm/vmalloc.c:3588
msgid "page protection for the mapping"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3510
msgid ""
"Maps **count** pages from **pages** into contiguous kernel virtual space. If "
"**flags** contains ``VM_MAP_PUT_PAGES`` the ownership of the pages array "
"itself (which must be kmalloc or vmalloc memory) and one reference per pages "
"in it are transferred from the caller to vmap(), and will be freed / dropped "
"when vfree() is called on the return value."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3517
msgid "the address of the area or ``NULL`` on failure"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3585
msgid "map an array of PFNs into virtually contiguous space"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3591
msgid "``unsigned long *pfns``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3586
msgid "array of PFNs"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:3589
msgid ""
"Maps **count** PFNs from **pfns** into contiguous kernel virtual space and "
"returns the start address of the mapping."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4093 ../mm/vmalloc.c:4133
msgid "allocate virtually contiguous memory"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3830
#: ../include/linux/mm.h:3869 ../../../core-api/mm-api:52: ../mm/vmalloc.c:4099
#: ../mm/vmalloc.c:4139 ../mm/vmalloc.c:4158 ../mm/vmalloc.c:4181
#: ../mm/vmalloc.c:4201 ../mm/vmalloc.c:4219 ../mm/vmalloc.c:4239
#: ../mm/vmalloc.c:4377 ../mm/vmalloc.c:4393 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2177 ../mm/memory.c:3083
msgid "``unsigned long size``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4094 ../mm/vmalloc.c:4134
#: ../mm/vmalloc.c:4153 ../mm/vmalloc.c:4176 ../mm/vmalloc.c:4196
#: ../mm/vmalloc.c:4214 ../mm/vmalloc.c:4234 ../mm/vmalloc.c:4372
#: ../mm/vmalloc.c:4388
msgid "allocation size"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5416
#: ../mm/page_alloc.c:5446 ../mm/page_alloc.c:6960 ../mm/page_alloc.c:7159
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5076
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4097 ../mm/vmalloc.c:4155
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:905
#: ../../../core-api/mm-api:91: ../mm/mempool.c:303 ../mm/mempool.c:541
msgid "``gfp_t gfp_mask``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4096 ../mm/vmalloc.c:4154
msgid "flags for the page level allocator"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4097 ../mm/vmalloc.c:4155
msgid "node to use for allocation or NUMA_NO_NODE"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4099
msgid "``const void *caller``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4098
msgid "caller's return address"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4099
msgid ""
"Allocate enough pages to cover **size** from the page level allocator with "
"**gfp_mask** flags.  Map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4102
msgid ""
"Semantics of **gfp_mask** (including reclaim/retry modifiers such as "
"__GFP_NOFAIL) are the same as in __vmalloc_node_range_noprof()."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4106 ../mm/vmalloc.c:4142
#: ../mm/vmalloc.c:4162 ../mm/vmalloc.c:4185 ../mm/vmalloc.c:4201
#: ../mm/vmalloc.c:4223 ../mm/vmalloc.c:4241 ../mm/vmalloc.c:4377
#: ../mm/vmalloc.c:4393
msgid "pointer to the allocated memory or ``NULL`` on error"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4135 ../mm/vmalloc.c:4216
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4138 ../mm/vmalloc.c:4181
#: ../mm/vmalloc.c:4219
msgid ""
"For tight control over page level allocator and protection flags use "
"__vmalloc() instead."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4152
msgid "allocate virtually contiguous memory, allow huge pages"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4156
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space. If **size** is greater than "
"or equal to PMD_SIZE, allow using huge pages for the memory"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4175
msgid "allocate virtually contiguous memory with zero fill"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4177 ../mm/vmalloc.c:4236
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space. The memory allocated is set "
"to zero."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4195
msgid "allocate zeroed virtually contiguous memory for userspace"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4197
msgid ""
"The resulting memory area is zeroed so it can be mapped to userspace without "
"leaking data."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4213
msgid "allocate memory on a specific node"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4215 ../mm/vmalloc.c:4235
msgid "numa node"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4233
msgid "allocate memory on a specific node with zero fill"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4371
msgid "allocate virtually contiguous memory (32bit addressable)"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4373
msgid ""
"Allocate enough 32bit PA addressable pages to cover **size** from the page "
"level allocator and map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4387
msgid "allocate zeroed virtually contiguous 32bit memory"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4389
msgid ""
"The resulting memory area is 32bit addressable and zeroed so it can be "
"mapped to userspace without leaking data."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4746
msgid "map vmalloc pages to userspace"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:821 ../mm/mempolicy.c:2519
#: ../../../core-api/mm-api:113: ../mm/rmap.c:166 ../mm/rmap.c:1186
#: ../mm/rmap.c:1314 ../mm/rmap.c:1339 ../mm/rmap.c:1372 ../mm/rmap.c:1464
#: ../mm/rmap.c:1487 ../mm/rmap.c:1510 ../mm/rmap.c:1603 ../mm/rmap.c:1619
#: ../mm/rmap.c:1639 ../mm/rmap.c:1771 ../mm/rmap.c:1787 ../mm/rmap.c:1807
#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:1036 ../mm/hugetlb.c:6913
#: ../../../core-api/mm-api:120: ../mm/swap.c:519 ../../../core-api/mm-api:123:
#: ../mm/shmem.c:5943 ../../../core-api/mm-api:134: ../mm/huge_memory.c:1771
#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4752
#: ../../../core-api/mm-api:97: ../mm/memory.c:2179 ../mm/memory.c:2415
#: ../mm/memory.c:2447 ../mm/memory.c:2529 ../mm/memory.c:2554
#: ../mm/memory.c:2625 ../mm/memory.c:2685 ../mm/memory.c:3084
#: ../mm/memory.c:3115 ../mm/memory.c:6846
msgid "``struct vm_area_struct *vma``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4747
msgid "vma to cover (map full range of vma)"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:211 ../mm/percpu.c:1585
#: ../mm/percpu.c:2325 ../../../core-api/mm-api:52: ../mm/vmalloc.c:4749
msgid "``void *addr``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4748
msgid "vmalloc memory"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:323 ../../../core-api/mm-api:52:
#: ../mm/vmalloc.c:4750
msgid "``unsigned long pgoff``"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4749
msgid "number of pages into addr before first page to map"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4751
msgid "0 for success, -Exxx on failure"
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4752
msgid ""
"This function checks that addr is a valid vmalloc'ed area, and that it is "
"big enough to cover the vma. Will return failure if that criteria isn't met."
msgstr ""

#: ../../../core-api/mm-api:52: ../mm/vmalloc.c:4756
msgid "Similar to remap_pfn_range() (see mm/memory.c)"
msgstr ""

#: ../../../core-api/mm-api.rst:56
msgid "File Mapping and Page Cache"
msgstr ""

#: ../../../core-api/mm-api.rst:59
msgid "Filemap"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:396
msgid "start writeback on mapping dirty pages in range"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1139 ../mm/rmap.c:2879
#: ../../../core-api/mm-api:114: ../mm/migrate.c:886 ../mm/migrate.c:1011
#: ../mm/migrate.c:1033 ../../../core-api/mm-api:123: ../mm/shmem.c:5982
#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:256
#: ../mm/mapping_dirty_helpers.c:284 ../../../core-api/mm-api:130:
#: ../mm/vmscan.c:817 ../../../core-api/mm-api:134: ../mm/huge_memory.c:3594
#: ../../../core-api/mm-api:61: ../mm/filemap.c:402 ../mm/filemap.c:429
#: ../mm/filemap.c:447 ../mm/filemap.c:474 ../mm/filemap.c:546
#: ../mm/filemap.c:570 ../mm/filemap.c:617 ../mm/filemap.c:669
#: ../mm/filemap.c:1789 ../mm/filemap.c:1826 ../mm/filemap.c:1925
#: ../mm/filemap.c:2220 ../mm/filemap.c:2241 ../mm/filemap.c:2313
#: ../mm/filemap.c:4116 ../mm/filemap.c:4140 ../mm/filemap.c:4183
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2036
#: ../mm/page-writeback.c:2111 ../mm/page-writeback.c:2376
#: ../mm/page-writeback.c:2479 ../mm/page-writeback.c:2725
#: ../../../core-api/mm-api:82: ../mm/truncate.c:349 ../mm/truncate.c:477
#: ../mm/truncate.c:496 ../mm/truncate.c:592 ../mm/truncate.c:668
#: ../mm/truncate.c:756 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:75 ../include/linux/pagemap.h:96
#: ../include/linux/pagemap.h:112 ../include/linux/pagemap.h:232
#: ../include/linux/pagemap.h:462 ../include/linux/pagemap.h:781
#: ../include/linux/pagemap.h:811 ../include/linux/pagemap.h:828
#: ../include/linux/pagemap.h:846 ../include/linux/pagemap.h:866
#: ../include/linux/pagemap.h:888 ../include/linux/pagemap.h:907
#: ../include/linux/pagemap.h:934 ../include/linux/pagemap.h:1323
#: ../include/linux/pagemap.h:1396 ../include/linux/pagemap.h:1418
#: ../../../core-api/mm-api:97: ../mm/memory.c:4255 ../mm/memory.c:4286
msgid "``struct address_space *mapping``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:397
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2371
#: ../mm/page-writeback.c:2474
msgid "address space structure to write"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:399 ../mm/filemap.c:426
#: ../mm/filemap.c:4504
msgid "``loff_t start``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:398 ../mm/filemap.c:470
#: ../mm/filemap.c:542 ../mm/filemap.c:566 ../mm/filemap.c:588
#: ../mm/filemap.c:665 ../mm/filemap.c:764 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:1319
msgid "offset in bytes where the range starts"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:400 ../mm/filemap.c:427
#: ../mm/filemap.c:4505
msgid "``loff_t end``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:399 ../mm/filemap.c:471
#: ../mm/filemap.c:543 ../mm/filemap.c:567 ../mm/filemap.c:589
#: ../mm/filemap.c:666 ../mm/filemap.c:765 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:1320
msgid "offset in bytes where the range ends (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:400
msgid ""
"Start writeback against all of a mapping's dirty pages that lie within the "
"byte offsets <start, end> inclusive."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:403
msgid ""
"This is a data integrity operation that waits upon dirty or in writeback "
"pages."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:407 ../mm/filemap.c:431
#: ../mm/filemap.c:447 ../mm/filemap.c:731 ../mm/filemap.c:775
#: ../../../core-api/mm-api:91: ../mm/mempool.c:283 ../mm/mempool.c:349
#: ../../../core-api/mm-api:97: ../mm/memory.c:2468 ../mm/memory.c:3087
#: ../mm/memory.c:3121
msgid "``0`` on success, negative error code otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:423
msgid "start writeback on a range"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:424 ../mm/filemap.c:442
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:929
msgid "target address_space"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:425
msgid "index to start writeback on"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:426
msgid "last (inclusive) index for writeback"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:427
msgid ""
"This is a non-integrity writeback helper, to start writing back folios for "
"the indicated range."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:441
msgid "mostly a non-blocking flush"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:443
msgid ""
"This is a mostly non-blocking flush.  Not suitable for data-integrity "
"purposes - I/O may not be started against all dirty pages."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:468
msgid "check if a page exists in range."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:469
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1318
msgid "address space within which to check"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:471 ../mm/filemap.c:543
#: ../mm/filemap.c:567 ../mm/filemap.c:589 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:1320
msgid "``loff_t start_byte``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:472 ../mm/filemap.c:544
#: ../mm/filemap.c:568 ../mm/filemap.c:590 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:1321
msgid "``loff_t end_byte``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:472
msgid ""
"Find at least one page in the range supplied, usually used to check if "
"direct writing in this range will trigger a writeback."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:476
msgid ""
"``true`` if at least one page exists in the specified range, ``false`` "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:540 ../mm/filemap.c:564
#: ../mm/filemap.c:586
msgid "wait for writeback to complete"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:541 ../mm/filemap.c:565
#: ../mm/filemap.c:612
msgid "address space structure to wait for"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:544
msgid ""
"Walk the list of under-writeback pages of the given address space in the "
"given range and wait for all of them.  Check error status of the address "
"space and return it."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:548
msgid ""
"Since the error status of the address space is cleared by this function, "
"callers are responsible for checking the return value and handling and/or "
"reporting the error."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:553 ../mm/filemap.c:622
#: ../mm/filemap.c:673
msgid "error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:568
msgid ""
"Walk the list of under-writeback pages of the given address space in the "
"given range and wait for all of them.  Unlike filemap_fdatawait_range(), "
"this function does not clear error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:572 ../mm/filemap.c:617
msgid ""
"Use this function if callers don't handle errors themselves.  Expected call "
"sites are system-wide / filesystem-wide data flushers: e.g. sync(2), "
"fsfreeze(8)"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:284 ../../../core-api/mm-api:61:
#: ../mm/filemap.c:592 ../mm/filemap.c:716 ../mm/filemap.c:768
#: ../mm/filemap.c:4115 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:124 ../include/linux/pagemap.h:1394
#: ../include/linux/pagemap.h:1416
msgid "``struct file *file``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:587
msgid "file pointing to address space structure to wait for"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:590
msgid ""
"Walk the list of under-writeback pages of the address space that file refers "
"to, in the given range and wait for all of them.  Check error status of the "
"address space vs. the file->f_wb_err cursor and return it."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:594
msgid ""
"Since the error status of the file is advanced by this function, callers are "
"responsible for checking the return value and handling and/or reporting the "
"error."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:599
msgid "error status of the address space vs. the file->f_wb_err cursor."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:611
msgid "wait for writeback without clearing errors"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:613
msgid ""
"Walk the list of under-writeback pages of the given address space and wait "
"for all of them.  Unlike filemap_fdatawait(), this function does not clear "
"error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:663 ../mm/filemap.c:762
msgid "write out & wait on a file range"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:664
msgid "the address_space for the pages"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:666 ../mm/filemap.c:765
#: ../../../core-api/mm-api:82: ../mm/truncate.c:346 ../mm/truncate.c:474
#: ../mm/truncate.c:891
msgid "``loff_t lstart``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:667 ../mm/filemap.c:766
#: ../../../core-api/mm-api:82: ../mm/truncate.c:892
msgid "``loff_t lend``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:667 ../mm/filemap.c:766
msgid "Write out and wait upon file offsets lstart->lend, inclusive."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:669 ../mm/filemap.c:768
msgid ""
"Note that **lend** is inclusive (describes the last byte to be written) so "
"that this function can be used to write to the very end-of-file (end = -1)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:710
msgid ""
"report wb error (if any) that was previously and advance wb_err to current "
"one"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:712
msgid "struct file on which the error is being reported"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:713
msgid ""
"When userland calls fsync (or something like nfsd does the equivalent), we "
"want to report any writeback errors that occurred since the last fsync (or "
"since the file was opened if there haven't been any)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:717
msgid ""
"Grab the wb_err from the mapping. If it matches what we have in the file, "
"then just quickly return 0. The file is all caught up."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:720
msgid ""
"If it doesn't match, then take the mapping value, set the \"seen\" flag in "
"it and try to swap it into place. If it works, or another task beat us to it "
"with the new value, then update the f_wb_err and return the error portion. "
"The error at this point must be reported via proper channels (a'la fsync, or "
"NFS COMMIT operation, etc.)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:726
msgid ""
"While we handle mapping->wb_err with atomic operations, the f_wb_err value "
"is protected by the f_lock since we must ensure that it reflects the latest "
"value swapped in for this file descriptor."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:763
msgid "file pointing to address_space with pages"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:771
msgid ""
"After writing out and waiting on the data, we check and advance the f_wb_err "
"cursor to the latest value, and return any errors detected there."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:799
msgid "replace a pagecache folio with a new one"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4942
#: ../mm/memcontrol.c:4986 ../../../core-api/mm-api:61: ../mm/filemap.c:805
msgid "``struct folio *old``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:800
msgid "folio to be replaced"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4939
#: ../mm/memcontrol.c:4983 ../../../core-api/mm-api:61: ../mm/filemap.c:802
msgid "``struct folio *new``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:801
msgid "folio to replace with"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:802
msgid ""
"This function replaces a folio in the pagecache with a new one.  On success "
"it acquires the pagecache reference for the new folio and drops it for the "
"old folio.  Both the old and new folios must be locked.  This function does "
"not add the new folio to the LRU, the caller must do that."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:808
msgid "The remove + add is atomic.  This function cannot fail."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1491
msgid "Unlock a locked folio."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:824 ../mm/mempolicy.c:2973
#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:69
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:763
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1262
#: ../include/linux/mm.h:1574 ../include/linux/mm.h:1607
#: ../include/linux/mm.h:1626 ../include/linux/mm.h:2123
#: ../include/linux/mm.h:2319 ../include/linux/mm.h:2368
#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:258
#: ../../../core-api/mm-api:113: ../mm/rmap.c:939 ../mm/rmap.c:1317
#: ../mm/rmap.c:1342 ../mm/rmap.c:1465 ../mm/rmap.c:1489 ../mm/rmap.c:1513
#: ../mm/rmap.c:1604 ../mm/rmap.c:1621 ../mm/rmap.c:1641 ../mm/rmap.c:1772
#: ../mm/rmap.c:1789 ../mm/rmap.c:1809 ../mm/rmap.c:2256 ../mm/rmap.c:2598
#: ../mm/rmap.c:2878 ../../../core-api/mm-api:119: ../mm/hugetlb.c:7112
#: ../mm/hugetlb.c:7177 ../../../core-api/mm-api:120: ../mm/swap.c:449
#: ../mm/swap.c:498 ../mm/swap.c:522 ../mm/swap.c:683 ../mm/swap.c:724
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:248 ../mm/memcontrol.c:975
#: ../mm/memcontrol.c:1202 ../mm/memcontrol.c:1223 ../mm/memcontrol.c:1245
#: ../mm/memcontrol.c:4758 ../mm/memcontrol.c:4792 ../mm/memcontrol.c:5182
#: ../../../core-api/mm-api:123: ../mm/shmem.c:1589
#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:82
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:814 ../mm/vmscan.c:843
#: ../mm/vmscan.c:1804 ../../../core-api/mm-api:134: ../mm/huge_memory.c:1742
#: ../mm/huge_memory.c:3590 ../mm/huge_memory.c:3690 ../mm/huge_memory.c:3921
#: ../mm/huge_memory.c:4113 ../mm/huge_memory.c:4211 ../mm/huge_memory.c:4242
#: ../../../core-api/mm-api:61: ../mm/filemap.c:1497 ../mm/filemap.c:1517
#: ../mm/filemap.c:1547 ../mm/filemap.c:1567 ../mm/filemap.c:1580
#: ../mm/filemap.c:1643 ../mm/filemap.c:1675 ../mm/filemap.c:1700
#: ../mm/filemap.c:4473 ../../../core-api/mm-api:76:
#: ../mm/page-writeback.c:2477 ../mm/page-writeback.c:2722
#: ../mm/page-writeback.c:2756 ../mm/page-writeback.c:2795
#: ../mm/page-writeback.c:3080 ../mm/page-writeback.c:3101
#: ../mm/page-writeback.c:3126 ../../../core-api/mm-api:82:
#: ../mm/truncate.c:127 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:571 ../include/linux/pagemap.h:591
#: ../include/linux/pagemap.h:605 ../include/linux/pagemap.h:620
#: ../include/linux/pagemap.h:639 ../include/linux/pagemap.h:978
#: ../include/linux/pagemap.h:1126 ../include/linux/pagemap.h:1151
#: ../include/linux/pagemap.h:1201 ../include/linux/pagemap.h:1417
msgid "``struct folio *folio``"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:312
#: ../include/linux/page-flags.h:758 ../include/linux/page-flags.h:777
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:234
#: ../include/linux/mm.h:1241 ../include/linux/mm.h:1257
#: ../include/linux/mm.h:1375 ../include/linux/mm.h:1408
#: ../include/linux/mm.h:1569 ../include/linux/mm.h:1602
#: ../include/linux/mm.h:1621 ../include/linux/mm.h:2036
#: ../include/linux/mm.h:2118 ../include/linux/mm.h:2257
#: ../include/linux/mm.h:2333 ../include/linux/mm.h:2350
#: ../include/linux/mm.h:2364 ../../../core-api/mm-api:108:
#: ../include/linux/page_ref.h:72 ../include/linux/page_ref.h:253
#: ../../../core-api/mm-api:110: ../mm/util.c:682 ../../../core-api/mm-api:61:
#: ../mm/filemap.c:1492 ../mm/filemap.c:1512 ../mm/filemap.c:1542
#: ../mm/filemap.c:1638 ../mm/filemap.c:1670 ../../../core-api/mm-api:76:
#: ../mm/page-writeback.c:2755 ../mm/page-writeback.c:2790
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:566
#: ../include/linux/pagemap.h:586 ../include/linux/pagemap.h:988
#: ../include/linux/pagemap.h:1054 ../include/linux/pagemap.h:1580
msgid "The folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1493
msgid "Unlocks the folio and wakes up any thread sleeping on the page lock."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1496 ../mm/filemap.c:1521
msgid ""
"May be called from interrupt or process context.  May not be called from NMI "
"context."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1511
msgid "End read on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1514
msgid "``bool success``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1513
msgid "True if all reads completed successfully."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1514
msgid ""
"When all reads against a folio have completed, filesystems should call this "
"function to let the pagecache know that no more reads are outstanding.  This "
"will unlock the folio and wake up any thread sleeping on the lock.  The "
"folio will also be marked uptodate if all reads succeeded."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1541
msgid "Clear PG_private_2 and wake any waiters."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1543
msgid ""
"Clear the PG_private_2 bit on a folio and wake up any sleepers waiting for "
"it.  The folio reference held for PG_private_2 being set is released."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1546
msgid ""
"This is, for example, used when a netfs folio is being written to a local "
"disk cache, thereby allowing writes to the cache for the same folio to be "
"serialised."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1561 ../mm/filemap.c:1563
#: ../mm/filemap.c:1574
msgid "Wait for PG_private_2 to be cleared on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1562 ../mm/filemap.c:1575
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3121
msgid "The folio to wait on."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1576
msgid ""
"Wait for PG_private_2 to be cleared on a folio or until a fatal signal is "
"received by the calling task."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1580
msgid "0 if successful."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1581
msgid "-EINTR if a fatal signal was encountered."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1637 ../mm/filemap.c:1669
msgid "End writeback against a folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1639
msgid ""
"The folio must actually be under writeback. This call is intended for "
"filesystems that need to defer dropbehind."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1643 ../mm/filemap.c:1674
msgid "May be called from process or interrupt context."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1671
msgid "The folio must actually be under writeback."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1694
msgid "Get a lock on the folio, assuming we need to sleep to get it."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1695
msgid "The folio to lock"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1783
msgid "Find the next gap in the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1784 ../mm/filemap.c:1821
msgid "Mapping."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2667 ../mm/shmem.c:5979
#: ../../../core-api/mm-api:61: ../mm/filemap.c:1786 ../mm/filemap.c:1823
#: ../mm/filemap.c:1922 ../mm/filemap.c:4113 ../mm/filemap.c:4137
#: ../mm/filemap.c:4180 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:503 ../include/linux/pagemap.h:782
#: ../include/linux/pagemap.h:808 ../include/linux/pagemap.h:825
#: ../include/linux/pagemap.h:843 ../include/linux/pagemap.h:885
#: ../include/linux/pagemap.h:904 ../include/linux/pagemap.h:931
#: ../include/linux/pagemap.h:975 ../include/linux/pagemap.h:990
#: ../include/linux/pagemap.h:1395
msgid "``pgoff_t index``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1785 ../mm/filemap.c:1822
msgid "Index."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1787 ../mm/filemap.c:1824
msgid "``unsigned long max_scan``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1786 ../mm/filemap.c:1823
msgid "Maximum range to search."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1787
msgid ""
"Search the range [index, min(index + max_scan - 1, ULONG_MAX)] for the gap "
"with the lowest index."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1790
msgid ""
"This function may be called under the rcu_read_lock.  However, this will not "
"atomically search a snapshot of the cache at a single point in time. For "
"example, if a gap is created at index 5, then subsequently a gap is created "
"at index 10, page_cache_next_miss covering both indices may return 10 if "
"called under the rcu_read_lock."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1797
msgid ""
"The index of the gap if found, otherwise an index outside the range "
"specified (in which case 'return - index >= max_scan' will be true). In the "
"rare case of index wrap-around, 0 will be returned."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1820
msgid "Find the previous gap in the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1824
msgid ""
"Search the range [max(index - max_scan + 1, 0), index] for the gap with the "
"highest index."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1827
msgid ""
"This function may be called under the rcu_read_lock.  However, this will not "
"atomically search a snapshot of the cache at a single point in time. For "
"example, if a gap is created at index 10, then subsequently a gap is created "
"at index 5, page_cache_prev_miss() covering both indices may return 5 if "
"called under the rcu_read_lock."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1834
msgid ""
"The index of the gap if found, otherwise an index outside the range "
"specified (in which case 'index - return >= max_scan' will be true). In the "
"rare case of wrap-around, ULONG_MAX will be returned."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1919
msgid "Find and get a reference to a folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1920
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:806
#: ../include/linux/pagemap.h:823
msgid "The address_space to search."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1921
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:502
#: ../include/linux/pagemap.h:807 ../include/linux/pagemap.h:824
msgid "The page index."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1923
msgid "``fgf_t fgp_flags``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1922
msgid "``FGP`` flags modify how the folio is returned."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2438 ../mm/mempolicy.c:2521
#: ../mm/mempolicy.c:2568 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:3189 ../../../core-api/mm-api:116:
#: ../mm/kmemleak.c:1088 ../mm/kmemleak.c:1107 ../mm/kmemleak.c:1126
#: ../mm/kmemleak.c:1303 ../mm/kmemleak.c:1341 ../../../core-api/mm-api:121:
#: ../mm/memcontrol.c:2856 ../mm/memcontrol.c:4755 ../mm/memcontrol.c:4790
#: ../../../core-api/mm-api:123: ../mm/shmem.c:5980
#: ../../../core-api/mm-api:128: ../mm/percpu.c:495 ../mm/percpu.c:1721
#: ../../../core-api/mm-api:61: ../mm/filemap.c:1924 ../mm/filemap.c:4138
#: ../mm/filemap.c:4181 ../mm/filemap.c:4470
msgid "``gfp_t gfp``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1923
msgid "Memory allocation flags to use if ``FGP_CREAT`` is specified."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1925
msgid "``struct mempolicy *policy``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1924
msgid "NUMA memory allocation policy to follow."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1925
msgid "Looks up the page cache entry at **mapping** & **index**."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1927
msgid ""
"If ``FGP_LOCK`` or ``FGP_CREAT`` are specified then the function may sleep "
"even if the ``GFP`` flags specified for ``FGP_CREAT`` are atomic."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1930
msgid ""
"If this function returns a folio, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:1933
msgid "The found folio or an ERR_PTR() otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2214
msgid "Get a batch of folios"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2215 ../mm/filemap.c:2236
#: ../mm/filemap.c:2308
msgid "The address_space to search"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:287
#: ../../../core-api/mm-api:61: ../mm/filemap.c:2217 ../mm/filemap.c:2238
#: ../mm/filemap.c:2310
msgid "``pgoff_t *start``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2216 ../mm/filemap.c:2237
#: ../mm/filemap.c:2309
msgid "The starting page index"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2218 ../mm/filemap.c:2239
#: ../mm/filemap.c:2311 ../../../core-api/mm-api:76:
#: ../mm/page-writeback.c:2374 ../../../core-api/mm-api:82:
#: ../mm/truncate.c:590 ../mm/truncate.c:666
msgid "``pgoff_t end``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2217 ../mm/filemap.c:2238
#: ../mm/filemap.c:2310
msgid "The final page index (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1073
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:7835
#: ../../../core-api/mm-api:61: ../mm/filemap.c:2219 ../mm/filemap.c:2240
#: ../mm/filemap.c:2313
msgid "``struct folio_batch *fbatch``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2218
msgid "The batch to fill."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2219
msgid ""
"Search for and return a batch of folios in the mapping starting at index "
"**start** and up to index **end** (inclusive).  The folios are returned in "
"**fbatch** with an elevated reference count."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2224
msgid ""
"The number of folios which were found. We also update **start** to index the "
"next folio for the traversal."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2235
msgid "Get a batch of contiguous folios"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2239 ../mm/filemap.c:2312
msgid "The batch to fill"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2240
msgid ""
"filemap_get_folios_contig() works exactly like filemap_get_folios(), except "
"the returned folios are guaranteed to be contiguous. This may not return all "
"contiguous folios if the batch gets filled up."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2245
msgid ""
"The number of folios found. Also update **start** to be positioned for "
"traversal of the next folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2307
msgid "Get a batch of folios matching **tag**"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2312
msgid "``xa_mark_t tag``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2311
msgid "The tag index"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2313
msgid ""
"The first folio may start before **start**; if it does, it will contain "
"**start**.  The final folio may extend beyond **end**; if it does, it will "
"contain **end**.  The folios have ascending indices.  There may be gaps "
"between the folios if there are indices which have no folio in the page "
"cache.  If folios are added to or removed from the page cache while this is "
"running, they may or may not be found by this call. Only returns folios that "
"are tagged with **tag**."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2322
msgid ""
"The number of folios found. Also update **start** to index the next folio "
"for traversal."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2751
msgid "Read data from the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2757 ../mm/filemap.c:2936
#: ../mm/filemap.c:4387 ../mm/filemap.c:4442
msgid "``struct kiocb *iocb``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2752
msgid "The iocb to read."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2754 ../mm/filemap.c:2933
msgid "``struct iov_iter *iter``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2753
msgid "Destination for the data."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2755
msgid "``ssize_t already_read``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2754
msgid "Number of bytes already read by the caller."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2755
msgid ""
"Copies data from the page cache.  If the data is not currently present, uses "
"the readahead and read_folio address_space operations to fetch it."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2759
msgid ""
"Total number of bytes copied, including those already read by the caller.  "
"If an error happens before any bytes are copied, returns a negative error "
"number."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2930
msgid "generic filesystem read routine"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2931
msgid "kernel I/O control block"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2932
msgid "destination for the data read"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2933
msgid ""
"This is the \"read_iter()\" routine for all filesystems that can use the "
"page cache directly."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2936
msgid ""
"The IOCB_NOWAIT flag in iocb->ki_flags indicates that -EAGAIN shall be "
"returned when no data can be read without waiting for I/O requests to "
"complete; it doesn't prevent readahead."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2940
msgid ""
"The IOCB_NOIO flag in iocb->ki_flags indicates that no new I/O requests "
"shall be made for the read or for readahead.  When no data can be read, -"
"EAGAIN shall be returned.  When readahead would be triggered, a partial, "
"possibly empty read shall be returned."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2946
msgid "number of bytes copied, even for partial reads"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:2947
msgid "negative error code (or 0 if IOCB_NOIO) if nothing was read"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3030
msgid "Splice data from a file's pagecache into a pipe"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3036
msgid "``struct file *in``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3031
msgid "The file to read from"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3033
msgid "``loff_t *ppos``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3032
msgid "Pointer to the file position to read from"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3034
msgid "``struct pipe_inode_info *pipe``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3033
msgid "The pipe to splice into"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3034
msgid "The amount to splice"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3036
#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2033
msgid "``unsigned int flags``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3035
msgid "The SPLICE_F_* flags"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3036
msgid ""
"This function gets folios from a file's pagecache and splices them into the "
"pipe.  Readahead will be called as necessary to fill more folios.  This may "
"be used for blockdevs also."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3041
msgid ""
"On success, the number of bytes read will be returned and ***ppos** will be "
"updated if appropriate; 0 will be returned if there is no more data to be "
"read; -EAGAIN will be returned if the pipe had no space, and some other "
"negative error code will be returned on error.  A short read may occur if "
"the pipe has insufficient space, we reach the end of the data or we hit a "
"hole."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3485
msgid "read in file data for page fault handling"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2971
#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1601
#: ../mm/huge_memory.c:1709 ../mm/huge_memory.c:1745
#: ../../../core-api/mm-api:61: ../mm/filemap.c:3491
msgid "``struct vm_fault *vmf``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3486
msgid "struct vm_fault containing details of the fault"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3487
msgid ""
"filemap_fault() is invoked via the vma operations vector for a mapped memory "
"region to read in file data during a page fault."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3490
msgid ""
"The goto's are kind of ugly, but this streamlines the normal case of having "
"it in the page cache, and handles the special cases reasonably without "
"having a lot of duplicated code."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3494
msgid "vma->vm_mm->mmap_lock must be held on entry."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3496
msgid ""
"If our return value has VM_FAULT_RETRY set, it's because the mmap_lock may "
"be dropped before doing I/O or by lock_folio_maybe_drop_mmap()."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3499
msgid ""
"If our return value does not have VM_FAULT_RETRY set, the mmap_lock has not "
"been released."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3502
msgid "We never return with VM_FAULT_RETRY and a bit from VM_FAULT_ERROR set."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:3505
msgid "bitwise-OR of ``VM_FAULT_`` codes."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4110
msgid "Read into page cache, fill it if needed."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4111
msgid "The address_space to read from."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4112
msgid "The index to read."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4114
msgid "``filler_t filler``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4113
msgid "Function to perform the read, or NULL to use aops->read_folio()."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4114
msgid "Passed to filler function, may be NULL if not required."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4115
msgid ""
"Read one page into the page cache.  If it succeeds, the folio returned will "
"contain **index**, but it may not be the first page of the folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4118
msgid ""
"If the filler function returns an error, it will be returned to the caller."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4122
msgid "May sleep.  Expects mapping->invalidate_lock to be held."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4123
msgid "An uptodate folio on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4134
msgid "Read into page cache, using specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4135
msgid "The address_space for the folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4136
msgid "The index that the allocated folio will contain."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4137
msgid "The page allocator flags to use if allocating."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4138
msgid ""
"This is the same as \"read_cache_folio(mapping, index, NULL, NULL)\", but "
"with any new memory allocations done using the specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4141
msgid ""
"The most likely error from this function is EIO, but ENOMEM is possible and "
"so is EINTR.  If ->read_folio returns another error, that will be returned "
"to the caller."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4145 ../mm/filemap.c:4186
msgid "The function expects mapping->invalidate_lock to be already held."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4148
msgid "Uptodate folio on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5976
#: ../../../core-api/mm-api:61: ../mm/filemap.c:4177
msgid "read into page cache, using specified page allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4178
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:902
msgid "the page's address_space"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4179
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:862
#: ../include/linux/pagemap.h:884 ../include/linux/pagemap.h:930
msgid "the page index"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5979
#: ../../../core-api/mm-api:61: ../mm/filemap.c:4180
msgid "the page allocator flags to use if allocating"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4181
msgid ""
"This is the same as \"read_mapping_page(mapping, index, NULL)\", but with "
"any new page allocations done using the specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4184
msgid "If the page does not get brought uptodate, return -EIO."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4189
msgid "up to date page on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4381 ../mm/filemap.c:4436
msgid "write data to a file"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4382
msgid "IO state structure (file, offset, etc.)"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4384 ../mm/filemap.c:4439
msgid "``struct iov_iter *from``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4383 ../mm/filemap.c:4438
msgid "iov_iter with data to write"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4384
msgid ""
"This function does all the work needed for actually writing data to a file. "
"It does all basic checks, removes SUID from the file, updates modification "
"times and calls proper subroutines depending on whether we do direct IO or a "
"standard buffered write."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4389
msgid ""
"It expects i_rwsem to be grabbed unless we work on a block device or similar "
"object which does not need locking at all."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4392
msgid ""
"This function does *not* take care of syncing data in case of O_SYNC write. "
"A caller has to handle it. This is mainly due to the fact that we want to "
"avoid syncing under i_rwsem."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4397 ../mm/filemap.c:4445
msgid "number of bytes written, even for truncated writes"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4398
msgid "negative error code if no data has been written at all"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4437
msgid "IO state structure"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4439
msgid ""
"This is a wrapper around __generic_file_write_iter() to be used by most "
"filesystems. It takes care of syncing the file in case of O_SYNC file and "
"acquires i_rwsem as needed."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4443
msgid ""
"negative error code if no data has been written at all of vfs_fsync_range() "
"failed for a synchronous write"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4467
msgid "Release fs-specific metadata on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4468
msgid "The folio which the kernel is trying to free."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4469
msgid "Memory allocation flags (and I/O mode)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4470
msgid ""
"The address_space is trying to release any data attached to a folio "
"(presumably at folio->private)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4473
msgid ""
"This will also be called if the private_2 flag is set on a page, indicating "
"that the folio has other metadata associated with it."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4476
msgid ""
"The **gfp** argument specifies whether I/O may be performed to release this "
"page (__GFP_IO), and whether the call may block (__GFP_RECLAIM & __GFP_FS)."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4481
msgid "``true`` if the release was successful, otherwise ``false``."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4500
msgid "Invalidate/forcibly write back a range of an inode's pagecache"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:430 ../mm/shmem.c:2670
#: ../../../core-api/mm-api:61: ../mm/filemap.c:4506
#: ../../../core-api/mm-api:82: ../mm/truncate.c:771 ../mm/truncate.c:806
#: ../mm/truncate.c:830 ../mm/truncate.c:894
msgid "``struct inode *inode``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4501
msgid "The inode to flush"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4503
msgid "``bool flush``"
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4502
msgid "Set to write back rather than simply invalidate."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4503
msgid "First byte to in range."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4504
msgid ""
"Last byte in range (inclusive), or LLONG_MAX for everything from start "
"onwards."
msgstr ""

#: ../../../core-api/mm-api:61: ../mm/filemap.c:4506
msgid ""
"Invalidate all the folios on an inode that contribute to the specified "
"range, possibly writing them back first.  Whilst the operation is "
"undertaken, the invalidate lock is held to prevent new folios from being "
"installed."
msgstr ""

#: ../../../core-api/mm-api.rst:65
msgid "Readahead"
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:12
msgid ""
"Readahead is used to read content into the page cache before it is "
"explicitly requested by the application.  Readahead only ever attempts to "
"read folios that are not yet in the page cache.  If a folio is present but "
"not up-to-date, readahead will not try to read it. In that case a simple -"
">read_folio() will be requested."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:18
msgid ""
"Readahead is triggered when an application read request (whether a system "
"call or a page fault) finds that the requested folio is not in the page "
"cache, or that it is in the page cache and has the readahead flag set.  This "
"flag indicates that the folio was read as part of a previous readahead "
"request and now that it has been accessed, it is time for the next readahead."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:25
msgid ""
"Each readahead request is partly synchronous read, and partly async "
"readahead.  This is reflected in the struct file_ra_state which contains -"
">size being the total number of pages, and ->async_size which is the number "
"of pages in the async section.  The readahead flag will be set on the first "
"folio in this async section to trigger a subsequent readahead.  Once a "
"series of sequential reads has been established, there should be no need for "
"a synchronous component and all readahead request will be fully asynchronous."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:34
msgid ""
"When either of the triggers causes a readahead, three numbers need to be "
"determined: the start of the region to read, the size of the region, and the "
"size of the async tail."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:38
msgid ""
"The start of the region is simply the first page address at or after the "
"accessed address, which is not currently populated in the page cache.  This "
"is found with a simple search in the page cache."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:42
msgid ""
"The size of the async tail is determined by subtracting the size that was "
"explicitly requested from the determined request size, unless this would be "
"less than zero - then zero is used.  NOTE THIS CALCULATION IS WRONG WHEN THE "
"START OF THE REGION IS NOT THE ACCESSED PAGE.  ALSO THIS CALCULATION IS NOT "
"USED CONSISTENTLY."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:48
msgid ""
"The size of the region is normally determined from the size of the previous "
"readahead which loaded the preceding pages.  This may be discovered from the "
"struct file_ra_state for simple sequential reads, or from examining the "
"state of the page cache when multiple sequential reads are interleaved.  "
"Specifically: where the readahead was triggered by the readahead flag, the "
"size of the previous readahead is assumed to be the number of pages from the "
"triggering page to the start of the new readahead.  In these cases, the size "
"of the previous readahead is scaled, often doubled, for the new readahead, "
"though see get_next_ra_size() for details."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:59
msgid ""
"If the size of the previous read cannot be determined, the number of "
"preceding pages in the page cache is used to estimate the size of a previous "
"read.  This estimate could easily be misled by random reads being "
"coincidentally adjacent, so it is ignored unless it is larger than the "
"current request, and it is not scaled up, unless it is at the start of file."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:66
msgid ""
"In general readahead is accelerated at the start of the file, as reads from "
"there are often sequential.  There are other minor adjustments to the "
"readahead size in various special cases and these are best discovered by "
"reading the code."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:71
msgid ""
"The above calculation, based on the previous readahead size, determines the "
"size of the readahead, to which any requested read size may be added."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:75
msgid ""
"Readahead requests are sent to the filesystem using the ->readahead() "
"address space operation, for which mpage_readahead() is a canonical "
"implementation.  ->readahead() should normally initiate reads on all folios, "
"but may fail to read any or all folios without causing an I/O error.  The "
"page cache reading code will issue a ->read_folio() request for any folio "
"which ->readahead() did not read, and only an error from this will be final."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:83
msgid ""
"->readahead() will generally call readahead_folio() repeatedly to get each "
"folio from those prepared for readahead.  It may fail to read a folio by:"
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:87
msgid ""
"not calling readahead_folio() sufficiently many times, effectively ignoring "
"some folios, as might be appropriate if the path to storage is congested."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:91
msgid ""
"failing to actually submit a read request for a given folio, possibly due to "
"insufficient resources, or"
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:94
msgid "getting an error during subsequent processing of a request."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:96
msgid ""
"In the last two cases, the folio should be unlocked by the filesystem to "
"indicate that the read attempt has failed.  In the first case the folio will "
"be unlocked by the VFS."
msgstr ""

#: ../../../core-api/mm-api:67: ../mm/readahead.c:100
msgid ""
"Those folios not in the final ``async_size`` of the request should be "
"considered to be important and ->readahead() should not fail them due to "
"congestion or temporary resource unavailability, but should wait for "
"necessary resources (e.g.  memory or indexing information) to become "
"available.  Folios in the final ``async_size`` may be considered less urgent "
"and failure to read them is more acceptable. In this case it is best to use "
"filemap_remove_folio() to remove the folios from the page cache as is "
"automatically done for folios that were not fetched with readahead_folio().  "
"This will allow a subsequent synchronous readahead request to try them "
"again.  If they are left in the page cache, then they will be read "
"individually using ->read_folio() which may be less efficient."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:197
msgid "Start unchecked readahead."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:203 ../mm/readahead.c:752
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1460
msgid "``struct readahead_control *ractl``"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:198
msgid "Readahead control."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:200
msgid "``unsigned long nr_to_read``"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:199
msgid "The number of pages to read."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:201
msgid "``unsigned long lookahead_size``"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:200
msgid "Where to start the next readahead."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:201
msgid ""
"This function is for filesystems to call when they want to start readahead "
"beyond a file's stated i_size.  This is almost certainly not the function "
"you want to call.  Use page_cache_async_readahead() or "
"page_cache_sync_readahead() instead."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:207
msgid ""
"File is referenced by caller.  Mutexes may be held by caller. May sleep, but "
"will not reenter filesystem to reclaim memory."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:746
msgid "Expand a readahead request"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:747
msgid "The request to be expanded"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:749
msgid "``loff_t new_start``"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:748
msgid "The revised start"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:750
msgid "``size_t new_len``"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:749
msgid "The revised size of the request"
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:750
msgid ""
"Attempt to expand a readahead request outwards from the current size to the "
"specified size by inserting locked pages before and after the current window "
"to increase the size to the new window.  This may involve the insertion of "
"THPs, in which case the window may get expanded even beyond what was "
"requested."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:756
msgid ""
"The algorithm will stop if it encounters a conflicting page already in the "
"pagecache and leave a smaller expansion than requested."
msgstr ""

#: ../../../core-api/mm-api:70: ../mm/readahead.c:759
msgid ""
"The caller must check for this by examining the revised **ractl** object for "
"a different expansion than was requested."
msgstr ""

#: ../../../core-api/mm-api.rst:74
msgid "Writeback"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2030
msgid "Balance dirty memory state."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2031
#: ../mm/page-writeback.c:2106
msgid "address_space which was dirtied."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2032
msgid "BDP flags."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2033
#: ../mm/page-writeback.c:2107
msgid ""
"Processes which are dirtying memory should call in here once for each page "
"which was newly dirtied.  The function will periodically check the system's "
"dirty state and will initiate writeback if needed."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2037
msgid "See balance_dirty_pages_ratelimited() for details."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2040
msgid ""
"If **flags** contains BDP_ASYNC, it may return -EAGAIN to indicate that "
"memory is out of balance and the caller must wait for I/O to complete.  "
"Otherwise, it will return 0 to indicate that either memory was already in "
"balance, or it was able to sleep until the amount of dirty memory returned "
"to balance."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2105
msgid "balance dirty memory state."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2111
msgid ""
"Once we're over the dirty memory limit we decrease the ratelimiting by a "
"lot, to prevent individual processes from overshooting the limit by "
"(ratelimit_pages) each."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2370
msgid "tag pages to be written by writeback"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2373
#: ../../../core-api/mm-api:82: ../mm/truncate.c:589 ../mm/truncate.c:665
#: ../../../core-api/mm-api:97: ../mm/memory.c:4252
msgid "``pgoff_t start``"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2372
msgid "starting page index"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2373
msgid "ending page index (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2374
msgid ""
"This function scans the page range from **start** to **end** (inclusive) and "
"tags all pages that have DIRTY tag set with a special TOWRITE tag.  The "
"caller can then use the TOWRITE tag to identify pages eligible for "
"writeback. This mechanism is used to avoid livelocking of writeback by a "
"process steadily creating new dirty pages in the file (thus it is important "
"for this function to be quick so that it can tag pages faster than a "
"dirtying process can create them)."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2473
msgid "iterate folio of a mapping for writeback"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2476
#: ../mm/page-writeback.c:2759
msgid "``struct writeback_control *wbc``"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2475
msgid "writeback context"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2476
msgid "previously iterated folio (``NULL`` to start)"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2478
msgid "``int *error``"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2477
msgid "in-out pointer for writeback errors (see below)"
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2478
msgid ""
"This function returns the next folio for the writeback operation described "
"by **wbc** on **mapping** and  should be called in a while loop in the -"
">writepages implementation."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2482
msgid ""
"To start the writeback operation, ``NULL`` is passed in the **folio** "
"argument, and for every subsequent iteration the folio returned previously "
"should be passed back in."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2486
msgid ""
"If there was an error in the per-folio writeback inside the writeback_iter() "
"loop, **error** should be set to the error value."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2489
msgid ""
"Once the writeback described in **wbc** has finished, this function will "
"return ``NULL`` and if there was an error in any iteration restore it to "
"**error**."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2493
msgid ""
"callers should not manually break out of the loop using break or goto but "
"must keep calling writeback_iter() until it returns ``NULL``."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2496
msgid "the folio to write or ``NULL`` if the loop is done."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2719
msgid "Mark a folio dirty for filesystems which do not use buffer_heads."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2720
msgid "Address space this folio belongs to."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2721
msgid "Folio to be marked as dirty."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2722
msgid ""
"Filesystems which do not use buffer heads should call this function from "
"their dirty_folio address space operation.  It ignores the contents of "
"folio_get_private(), so if the filesystem marks individual blocks as dirty, "
"the filesystem should handle that itself."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2727
msgid ""
"This is also sometimes used by filesystems which use buffer_heads when a "
"single buffer is being dirtied: we want to set the folio dirty in that case, "
"but not all the buffers.  This is a \"bottom-up\" dirtying, whereas "
"block_dirty_folio() is a \"top-down\" dirtying."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2732
msgid ""
"The caller must ensure this doesn't race with truncation.  Most will simply "
"hold the folio lock, but e.g. zap_pte_range() calls with the folio mapped "
"and the pte lock held, which also locks out truncation."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2753
msgid "Decline to write a dirty folio."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2754
msgid "The writeback control."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2756
msgid ""
"When a writepage implementation decides that it doesn't want to write "
"**folio** for some reason, it should call this function, unlock **folio** "
"and return 0."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2761
msgid ""
"True if we redirtied the folio.  False if someone else dirtied it first."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2789
msgid "Mark a folio as being modified."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2791
msgid ""
"The folio may not be truncated while this function is running. Holding the "
"folio lock is sufficient to prevent truncation, but some callers cannot "
"acquire a sleeping lock.  These callers instead hold the page table lock for "
"a page table which contains at least one page in this folio.  Truncation "
"will block on the page table lock as it unmaps pages before removing the "
"folio from its mapping."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:2799
msgid "True if the folio was newly dirtied, false if it was already dirty."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3074
#: ../mm/page-writeback.c:3095
msgid "Wait for a folio to finish writeback."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3075
#: ../mm/page-writeback.c:3096
msgid "The folio to wait for."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3076
msgid ""
"If the folio is currently being written back to storage, wait for the I/O to "
"complete."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3080
#: ../mm/page-writeback.c:3101 ../mm/page-writeback.c:3127
msgid ""
"Sleeps.  Must be called in process context and with no spinlocks held.  "
"Caller should hold a reference on the folio. If the folio is not locked, "
"writeback may start again after writeback has finished."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3097
msgid ""
"If the folio is currently being written back to storage, wait for the I/O to "
"complete or a fatal signal to arrive."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3105
msgid "0 on success, -EINTR if we get a fatal signal while waiting."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3120
msgid "wait for writeback to finish, if necessary."
msgstr ""

#: ../../../core-api/mm-api:76: ../mm/page-writeback.c:3122
msgid ""
"This function determines if the given folio is related to a backing device "
"that requires folio contents to be held stable during writeback. If so, then "
"it will wait for any pending writeback to complete."
msgstr ""

#: ../../../core-api/mm-api.rst:80
msgid "Truncate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:121
msgid "Invalidate part or all of a folio."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:122
msgid "The folio which is affected."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:124
msgid "``size_t offset``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:123
msgid "start of the range to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:125
msgid "``size_t length``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:124
msgid "length of the range to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:125
msgid ""
"folio_invalidate() is called when all or part of the folio has become "
"invalidated by a truncate operation."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:128
msgid ""
"folio_invalidate() does not have to release all buffers, but it must ensure "
"that no dirty buffer is left outside **offset** and that no I/O is underway "
"against any of the blocks which are outside the truncation point.  Because "
"the caller is about to free (and possibly reuse) those blocks on-disk."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:343
msgid "truncate range of pages specified by start & end byte offsets"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:344 ../mm/truncate.c:472
#: ../mm/truncate.c:491
msgid "mapping to truncate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:345 ../mm/truncate.c:473
msgid "offset from which to truncate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:347
msgid "``uoff_t lend``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:346
msgid "offset to which to truncate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:347
msgid ""
"Truncate the page cache, removing the pages that are between specified "
"offsets (and zeroing out partial pages if lstart or lend + 1 is not page "
"aligned)."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:351
msgid ""
"Truncate takes two passes - the first pass is nonblocking.  It will not "
"block on page locks and it will not block on writeback.  The second pass "
"will wait.  This is to prevent as much IO as possible in the affected "
"region. The first pass will remove most pages, so the search cost of the "
"second pass is low."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:357
msgid ""
"We pass down the cache-hot hint to the page freeing code.  Even if the "
"mapping is large, it is probably the case that the final pages are the most "
"recently touched, and freeing happens in ascending file offset order."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:361
msgid ""
"Note that since ->invalidate_folio() accepts range to invalidate "
"truncate_inode_pages_range is able to handle cases where lend + 1 is not "
"page aligned properly."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:471
msgid "truncate *all* the pages from an offset"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:474
msgid ""
"Called under (and serialised by) inode->i_rwsem and mapping->invalidate_lock."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:478
msgid ""
"When this function returns, there can be a page in the process of deletion "
"(inside __filemap_remove_folio()) in the specified range.  Thus mapping-"
">nrpages can be non-zero when this function returns even after truncation of "
"the whole mapping."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:490
msgid "truncate *all* pages before inode dies"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:492
msgid "Called under (and serialized by) inode->i_rwsem."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:494
msgid ""
"Filesystems have to use this in the .evict_inode path to inform the VM that "
"this is the final truncate and the inode is going away."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:586
msgid "Invalidate all clean, unlocked cache of one inode"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:587
msgid "the address_space which holds the cache to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:588
msgid "the offset 'from' which to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:589
msgid "the offset 'to' which to invalidate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:590
msgid ""
"This function removes pages that are clean, unmapped and unlocked, as well "
"as shadow entries. It will not block on IO activity."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:593
msgid ""
"If you want to remove all the pages of one inode, regardless of their use "
"and writeback state, use truncate_inode_pages()."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:597
msgid "The number of indices that had their contents invalidated"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:662
msgid "remove range of pages from an address_space"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:663 ../mm/truncate.c:751
msgid "the address_space"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:664
msgid "the page offset 'from' which to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:665
msgid "the page offset 'to' which to invalidate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:666 ../mm/truncate.c:752
msgid ""
"Any pages which are found to be mapped into pagetables are unmapped prior to "
"invalidation."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:670 ../mm/truncate.c:756
msgid "-EBUSY if any pages could not be invalidated."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:750
msgid "remove all pages from an address_space"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:765
msgid "unmap and remove pagecache that has been truncated"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:766 ../mm/truncate.c:801
#: ../mm/truncate.c:889
msgid "inode"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:768 ../mm/truncate.c:803
msgid "``loff_t newsize``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:767 ../mm/truncate.c:802
msgid "new file size"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:768
msgid ""
"inode's new i_size must already be written before truncate_pagecache is "
"called."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:771 ../mm/truncate.c:892
msgid ""
"This function should typically be called before the filesystem releases "
"resources associated with the freed range (eg. deallocates blocks). This "
"way, pagecache will always stay logically coherent with on-disk format, and "
"the filesystem would not have to deal with situations such as writepage "
"being called for a page that has already had its underlying blocks "
"deallocated."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:800
msgid "update inode and pagecache for a new file size"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:803
msgid ""
"truncate_setsize updates i_size and performs pagecache truncation (if "
"necessary) to **newsize**. It will be typically be called from the "
"filesystem's setattr function when ATTR_SIZE is passed in."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:807
msgid ""
"Must be called with a lock serializing truncates and writes (generally "
"i_rwsem but e.g. xfs uses a different lock) and before all filesystem "
"specific block truncation has been performed."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:824
msgid "update pagecache after extension of i_size"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:825
msgid "inode for which i_size was extended"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:827
msgid "``loff_t from``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:826
msgid "original inode size"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:828
msgid "``loff_t to``"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:827
msgid "new inode size"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:828
msgid ""
"Handle extension of inode size either caused by extending truncate or by "
"write starting after current i_size.  We mark the page straddling current "
"i_size RO so that page_mkwrite() is called on the first write access to the "
"page.  The filesystem will update its per-block information before user "
"writes to the page via mmap after the i_size has been changed."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:835
msgid ""
"The function must be called after i_size is updated so that page fault "
"coming after we unlock the folio will already see the new i_size. The "
"function must be called while we still hold i_rwsem - this not only makes "
"sure i_size is stable but also that userspace cannot observe new i_size "
"value before we are prepared to store mmap writes at new inode size."
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:888
msgid "unmap and remove pagecache that is hole-punched"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:890
msgid "offset of beginning of hole"
msgstr ""

#: ../../../core-api/mm-api:82: ../mm/truncate.c:891
msgid "offset of last byte of hole"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:69
msgid "set a writeback error on an address_space"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:70
msgid "mapping in which to set writeback error"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:72
msgid "``int err``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:71
msgid "error to be set in mapping"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:72
#: ../include/linux/pagemap.h:229
msgid ""
"When writeback fails in some way, we must record that error so that "
"userspace can be informed when fsync and the like are called.  We endeavor "
"to report errors on any file that was open at the time of the error.  Some "
"internal callers also need to know when writeback errors have occurred."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:77
msgid ""
"When a writeback error occurs, most filesystems will want to call "
"filemap_set_wb_err to record the error in the mapping so that it will be "
"automatically reported whenever fsync is called on the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:90
msgid "has an error occurred since the mark was sampled?"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:91
msgid "mapping to check for writeback errors"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:93
msgid "``errseq_t since``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:92
msgid "previously-sampled errseq_t"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:93
msgid ""
"Grab the errseq_t value from the mapping, and see if it has changed "
"\"since\" the given value was sampled."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:96
msgid "If it has then report the latest error set, otherwise return 0."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:106
#: ../include/linux/pagemap.h:118
msgid "sample the current errseq_t to test for later errors"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:107
msgid "mapping to be sampled"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:108
msgid ""
"Writeback errors are always reported relative to a particular sample point "
"in the past. This function provides those sample points."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:119
msgid "file pointer to be sampled"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:120
msgid ""
"Grab the most current superblock-level errseq_t value for the given struct "
"file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:226
msgid "record a writeback error in the address_space"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:227
msgid "the mapping in which an error should be set"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:229
msgid "``int error``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:228
msgid "the error to set in the mapping"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:234
msgid ""
"When a writeback error occurs, most filesystems will want to call "
"mapping_set_error to record the error in the mapping so that it can be "
"reported when the application calls fsync(2)."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:456
msgid "Indicate the file supports large folios."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:457
msgid "The address space of the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:458
msgid ""
"The filesystem should call this function in its inode constructor to "
"indicate that the VFS can use large folios to cache the contents of the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:463
msgid ""
"This should not be called while the inode is active as it is non-atomic."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:500
msgid "Align index for this mapping."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:506
msgid "``const struct address_space *mapping``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:501
msgid "The address_space."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:503
msgid ""
"The index of a folio must be naturally aligned.  If you are adding a new "
"folio to the page cache and need to know what index to give it, call this "
"function."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:565
msgid "Find the file mapping this folio belongs to."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:567
msgid ""
"For folios which are in the page cache, return the mapping that this page "
"belongs to.  Anonymous folios return NULL, even if they're in the swap "
"cache.  Other kinds of folio also return NULL."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:571
msgid ""
"This is ONLY used by architecture cache flushing code.  If you aren't "
"writing cache flushing code, you want either folio_mapping() or "
"folio_file_mapping()."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:585
msgid "Get the host inode for this folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:587
msgid ""
"For folios which are in the page cache, return the inode that this folio "
"belongs to."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:590
msgid "Do not call this for folios which aren't in the page cache."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:599
msgid "Attach private data to a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:600
msgid "Folio to attach data to."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:602
#: ../include/linux/pagemap.h:617
msgid "``void *data``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:601
msgid "Data to attach to folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:602
msgid ""
"Attaching private data to a folio increments the page's reference count. The "
"data must be detached before the folio will be freed."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:614
msgid "Change private data on a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:615
msgid "Folio to change the data on."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:616
msgid "Data to set on the folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:617
msgid ""
"Change the private data attached to a folio and return the old data.  The "
"page must previously have had data attached and the data must be detached "
"before the folio will be freed."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:622
msgid "Data that was previously attached to the folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:633
msgid "Detach private data from a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:634
msgid "Folio to detach data from."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:635
msgid ""
"Removes the data that was previously attached to the folio and decrements "
"the refcount on the page."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:639
msgid "Data that was attached to the folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:696
msgid "Flags for getting folios from the page cache."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:697
msgid ""
"Most users of the page cache will not need to use these flags; there are "
"convenience functions such as filemap_get_folio() and filemap_lock_folio().  "
"For users which need more control over exactly what is done with the folios, "
"these flags to __filemap_get_folio() are available."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:703
msgid "``FGP_ACCESSED`` - The folio will be marked accessed."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:704
msgid "``FGP_LOCK`` - The folio is returned locked."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:705
msgid ""
"``FGP_CREAT`` - If no folio is present then a new folio is allocated, added "
"to the page cache and the VM's LRU list.  The folio is returned locked."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:708
msgid ""
"``FGP_FOR_MMAP`` - The caller wants to do its own locking dance if the folio "
"is already in cache.  If the folio was allocated, unlock it before returning "
"so the caller can do the same dance."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:711
msgid "``FGP_WRITE`` - The folio will be written to by the caller."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:712
msgid "``FGP_NOFS`` - __GFP_FS will get cleared in gfp."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:713
msgid "``FGP_NOWAIT`` - Don't block on the folio lock."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:714
msgid "``FGP_STABLE`` - Wait for the folio to be stable (finished writeback)"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:715
msgid "``FGP_DONTCACHE`` - Uncached buffered IO"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:716
msgid ""
"``FGP_WRITEBEGIN`` - The flags to use in a filesystem write_begin() "
"implementation."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:746
msgid "Encode a length in the fgf_t flags."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:747
msgid "The suggested size of the folio to create."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:748
msgid ""
"The caller of __filemap_get_folio() can use this to suggest a preferred size "
"for the folio that is created.  If there is already a folio at the index, it "
"will be returned, no matter what its size.  If a folio is freshly created, "
"it may be of a different size than requested due to alignment constraints, "
"memory pressure, or the presence of other folios at nearby indices."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:778
msgid "Get folio for write_begin with flags."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:784
msgid "``const struct kiocb *iocb``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:779
msgid "The kiocb passed from write_begin (may be NULL)."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:780
msgid "The address space to search."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:781
msgid "The page cache index."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:782
msgid "Length of data being written."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:783
msgid ""
"This is a helper for filesystem write_begin() implementations. It wraps "
"__filemap_get_folio(), setting appropriate flags in the write begin context."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:788
msgid "A folio or an ERR_PTR."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:805
msgid "Find and get a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:808
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If a folio is "
"present, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:812
#: ../include/linux/pagemap.h:830
msgid ""
"A folio or ERR_PTR(-ENOENT) if there is no folio in the cache for this "
"index.  Will not return a shadow, swap or DAX entry."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:822
msgid "Find and lock a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:825
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If a folio is "
"present, it is returned locked with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2684
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:829
#: ../include/linux/pagemap.h:890
msgid "May sleep."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:840
msgid "grab a folio from the page cache"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:841
msgid "The address space to search"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:842
msgid "The page index"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:843
msgid ""
"Looks up the page cache entry at **mapping** & **index**. If no folio is "
"found, a new folio is created. The folio is locked, marked as accessed, and "
"returned."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:848
msgid ""
"A found or created folio. ERR_PTR(-ENOMEM) if no folio is found and failed "
"to create a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:860
msgid "find and get a page reference"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:861
#: ../include/linux/pagemap.h:883
msgid "the address_space to search"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:863
msgid "``pgoff_t offset``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:863
msgid ""
"Looks up the page cache slot at **mapping** & **offset**.  If there is a "
"page cache page, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:866
msgid "Otherwise, ``NULL`` is returned."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:882
msgid "locate, pin and lock a pagecache page"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:885
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If there is a "
"page cache page, it is returned locked and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:891
msgid ""
"A struct page or ``NULL`` if there is no page in the cache for this index."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:901
msgid "locate or add a pagecache page"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:903
msgid "the page's index into the mapping"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:904
msgid "page allocation mode"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:905
msgid ""
"Looks up the page cache slot at **mapping** & **offset**.  If there is a "
"page cache page, it is returned locked and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:909
msgid ""
"If the page is not present, a new page is allocated using **gfp_mask** and "
"added to the page cache and the VM's LRU list.  The page is returned locked "
"and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:913
msgid "On memory exhaustion, ``NULL`` is returned."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:915
msgid ""
"find_or_create_page() may sleep, even if **gfp_flags** specifies an atomic "
"allocation!"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:928
msgid "returns locked page at given index in given cache"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:931
msgid ""
"Returns locked page at given index in given cache, creating it if needed, "
"but do not wait if the page is locked or to reclaim memory. This is intended "
"for speculative data generators, where the data can be regenerated if the "
"page couldn't be grabbed.  This routine should be safe to call while holding "
"the lock for another page."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:937
msgid ""
"Clear __GFP_FS when allocating the page to avoid recursion into the fs and "
"deadlock against the caller's locked page."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:950
msgid "Get the index of the next folio."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:20
#: ../include/linux/mm_inline.h:87 ../../../core-api/mm-api:105:
#: ../include/linux/page-flags.h:782 ../include/linux/page-flags.h:864
#: ../include/linux/page-flags.h:1231 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:239 ../include/linux/mm.h:1246
#: ../include/linux/mm.h:1380 ../include/linux/mm.h:1413
#: ../include/linux/mm.h:2041 ../include/linux/mm.h:2066
#: ../include/linux/mm.h:2082 ../include/linux/mm.h:2098
#: ../include/linux/mm.h:2193 ../include/linux/mm.h:2262
#: ../include/linux/mm.h:2338 ../include/linux/mm.h:2355
#: ../include/linux/mm.h:2432 ../../../core-api/mm-api:108:
#: ../include/linux/page_ref.h:77 ../../../core-api/mm-api:110:
#: ../mm/util.c:687 ../../../core-api/mm-api:113: ../mm/rmap.c:752
#: ../mm/rmap.c:1374 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:956 ../include/linux/pagemap.h:967
#: ../include/linux/pagemap.h:993 ../include/linux/pagemap.h:1038
#: ../include/linux/pagemap.h:1059 ../include/linux/pagemap.h:1556
#: ../include/linux/pagemap.h:1581
msgid "``const struct folio *folio``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:951
#: ../include/linux/pagemap.h:962
msgid "The current folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:953
msgid "The index of the folio which follows this folio in the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:961
msgid "Get the file position of the next folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:964
msgid "The position of the folio which follows this folio in the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:972
msgid "The page for a particular index."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:973
msgid "The folio which contains this index."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:974
msgid "The index we want to look up."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:975
msgid ""
"Sometimes after looking up a folio in the page cache, we need to obtain the "
"specific page for an index (eg a page fault)."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:979
msgid "The page containing the file data for this index."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:987
msgid "Does this folio contain this index?"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:989
msgid "The page index within the file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:991
msgid ""
"The caller should have the folio locked and ensure e.g., shmem did not move "
"this folio to the swap cache."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:993
msgid "true or false."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1032
msgid "Calculate the logical page offset of this page."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1033
msgid "The folio containing this page."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:419 ../mm/page_alloc.c:446
#: ../mm/page_alloc.c:468 ../mm/page_alloc.c:518 ../mm/page_alloc.c:538
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1076
#: ../include/linux/page-flags.h:1145 ../../../core-api/mm-api:106:
#: ../include/linux/mm.h:236 ../include/linux/mm.h:2182
#: ../../../core-api/mm-api:113: ../mm/rmap.c:749 ../mm/rmap.c:1371
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1035
msgid "``const struct page *page``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1034
msgid "The page which we need the offset of."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1035
msgid ""
"For file pages, this is the offset from the beginning of the file in units "
"of PAGE_SIZE.  For anonymous pages, this is the offset from the beginning of "
"the anon_vma in units of PAGE_SIZE.  This will return nonsense for KSM pages."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1041
msgid ""
"Caller must have a reference on the folio or otherwise prevent it from being "
"split or freed."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1044
msgid "The offset in units of PAGE_SIZE."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1053
msgid "Returns the byte position of this folio in its file."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1120
msgid "Attempt to lock a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1121
msgid "The folio to attempt to lock."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1122
msgid ""
"Sometimes it is undesirable to wait for a folio to be unlocked (eg when the "
"locks are being taken in the wrong order, or if making progress through a "
"batch of folios is more important than processing them in order).  Usually "
"folio_lock() is the correct function to call."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1073
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1128
msgid "Any context."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1129
msgid "Whether the lock was successfully acquired."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1145
msgid "Lock this folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1146
#: ../include/linux/pagemap.h:1196
msgid "The folio to lock."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1147
msgid ""
"The folio lock protects against many things, probably more than it should.  "
"It is primarily held while a folio is being brought uptodate, either from "
"its backing file or from swap.  It is also held while a folio is being "
"truncated from its address_space, so holding the lock is sufficient to keep "
"folio->mapping stable."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1153
msgid ""
"The folio lock is also held while write() is modifying the page to provide "
"POSIX atomicity guarantees (as long as the write does not cross a page "
"boundary).  Other modifications to the data in the folio do not hold the "
"folio lock and can race with writes, eg DMA and stores to mapped pages."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1160
msgid ""
"May sleep.  If you need to acquire the locks of two or more folios, they "
"must be in order of ascending index, if they are in the same address_space.  "
"If they are in different address_spaces, acquire the lock of the folio which "
"belongs to the address_space which has the lowest address in memory first."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1174
msgid "Lock the folio containing this page."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:493 ../mm/page_alloc.c:558
#: ../mm/page_alloc.c:2109 ../mm/page_alloc.c:3181 ../mm/page_alloc.c:5344
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1468
#: ../include/linux/mm.h:1478 ../../../core-api/mm-api:113: ../mm/rmap.c:1462
#: ../mm/rmap.c:1486 ../mm/rmap.c:1601 ../mm/rmap.c:1618 ../mm/rmap.c:1638
#: ../mm/rmap.c:1769 ../mm/rmap.c:1786 ../mm/rmap.c:1806
#: ../../../core-api/mm-api:114: ../mm/migrate.c:106 ../mm/migrate.c:192
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:269 ../mm/memcontrol.c:2859
#: ../mm/memcontrol.c:2884 ../../../core-api/mm-api:124:
#: ../mm/migrate_device.c:790 ../../../core-api/mm-api:85:
#: ../include/linux/pagemap.h:1180 ../../../core-api/mm-api:97:
#: ../mm/memory.c:2445
msgid "``struct page *page``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1175
msgid "The page to lock."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1176
msgid ""
"See folio_lock() for a description of what the lock protects. This is a "
"legacy function and new code should probably use folio_lock() instead."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1181
msgid ""
"May sleep.  Pages in the same folio share a lock, so do not attempt to lock "
"two pages which share a folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1195
msgid "Lock this folio, interruptible by a fatal signal."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1197
msgid ""
"Attempts to lock the folio, like folio_lock(), except that the sleep to "
"acquire the lock is interruptible by a fatal signal."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1201
msgid "May sleep; see folio_lock()."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1202
msgid "0 if the lock was acquired; -EINTR if a fatal signal was received."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1317
msgid "check if range potentially needs writeback"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1321
msgid ""
"Find at least one page in the range supplied, usually used to check if "
"direct writing in this range will trigger a writeback. Used by O_DIRECT read/"
"write with IOCB_NOWAIT, to see if the caller needs to do "
"filemap_write_and_wait_range() before proceeding."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1327
msgid ""
"``true`` if the caller should do filemap_write_and_wait_range() before doing "
"O_DIRECT to a page in this range, ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1343
msgid "Describes a readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1353
msgid "``file``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1354
msgid ""
"The file, used primarily by network filesystems for authentication. May be "
"NULL if invoked internally by the filesystem."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:362
#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1355
msgid "``mapping``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1356
msgid "Readahead this filesystem object."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1356
msgid "``ra``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1357
msgid "File readahead state.  May be NULL."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1344
msgid ""
"A readahead request is for consecutive pages.  Filesystems which implement "
"the ->readahead method should call readahead_folio() or __readahead_batch() "
"in a loop and attempt to start reads into each folio in the request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1349
msgid ""
"Most of the fields in this struct are private and should be accessed by the "
"functions below."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1390
msgid "generic file readahead"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1391
#: ../include/linux/pagemap.h:1413
msgid "address_space which holds the pagecache and I/O vectors"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1393
#: ../include/linux/pagemap.h:1415
msgid "``struct file_ra_state *ra``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1392
#: ../include/linux/pagemap.h:1414
msgid "file_ra_state which holds the readahead state"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1393
#: ../include/linux/pagemap.h:1415
msgid "Used by the filesystem for authentication."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1394
msgid "Index of first page to be read."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1396
#: ../include/linux/pagemap.h:1418
msgid "``unsigned long req_count``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1395
#: ../include/linux/pagemap.h:1417
msgid "Total number of pages being read by the caller."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1396
msgid ""
"page_cache_sync_readahead() should be called when a cache miss happened: it "
"will submit the read.  The readahead logic may decide to piggyback more "
"pages onto the read request if access patterns suggest it will improve "
"performance."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1412
msgid "file readahead for marked pages"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1416
msgid "The folio which triggered the readahead call."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1418
msgid ""
"page_cache_async_readahead() should be called when a page is used which is "
"marked as PageReadahead; this is a marker to suggest that the application "
"has used up enough of the readahead window that we should start pulling in "
"more pages."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1454
msgid "Get the next folio to read."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1455
msgid "The current readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1457
msgid ""
"The folio is locked.  The caller should unlock the folio once all I/O to "
"that folio has completed."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1459
msgid "A pointer to the next folio, or ``NULL`` if we are done."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1499
msgid "The byte offset into the file of this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1505
#: ../include/linux/pagemap.h:1514 ../include/linux/pagemap.h:1523
#: ../include/linux/pagemap.h:1532 ../include/linux/pagemap.h:1541
msgid "``const struct readahead_control *rac``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1500
#: ../include/linux/pagemap.h:1509 ../include/linux/pagemap.h:1518
#: ../include/linux/pagemap.h:1527 ../include/linux/pagemap.h:1536
msgid "The readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1508
msgid "The number of bytes in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1517
msgid "The index of the first page in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1526
msgid "The number of pages in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1535
msgid "The number of bytes in the current batch."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1550
msgid "check if folio was truncated"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1551
msgid "the folio to check"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1553
#: ../include/linux/pagemap.h:1584
msgid "``const struct inode *inode``"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1552
msgid "the inode to check the folio against"
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1554
msgid ""
"the number of bytes in the folio up to EOF, or -EFAULT if the folio was "
"truncated."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1578
msgid "How many blocks fit in this folio."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1579
msgid "The inode which contains the blocks."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1581
msgid "If the block size is larger than the size of this folio, return zero."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1584
msgid ""
"The caller should hold a refcount on the folio to prevent it from being "
"split."
msgstr ""

#: ../../../core-api/mm-api:85: ../include/linux/pagemap.h:1586
msgid "The number of filesystem blocks covered by this folio."
msgstr ""

#: ../../../core-api/mm-api.rst:89
msgid "Memory pools"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:194
msgid "exit a mempool initialized with mempool_init()"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:200 ../mm/mempool.c:222
#: ../mm/mempool.c:278 ../mm/mempool.c:340 ../mm/mempool.c:485
#: ../mm/mempool.c:544 ../mm/mempool.c:600 ../mm/mempool.c:621
#: ../mm/mempool.c:703
msgid "``struct mempool *pool``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:195
msgid "pointer to the memory pool which was initialized with mempool_init()."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:197 ../mm/mempool.c:219
msgid ""
"Free all reserved elements in **pool** and **pool** itself.  This function "
"only sleeps if the free_fn() function sleeps."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:200
msgid ""
"May be called on a zeroed but uninitialized mempool (i.e. allocated with "
"kzalloc())."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:216
msgid "deallocate a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:217 ../mm/mempool.c:335
msgid "pointer to the memory pool which was allocated via mempool_create()."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:272
msgid "initialize a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:273
msgid "pointer to the memory pool that should be initialized"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:275 ../mm/mempool.c:302
msgid "``int min_nr``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:274 ../mm/mempool.c:297
msgid ""
"the minimum number of elements guaranteed to be allocated for this pool."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:277 ../mm/mempool.c:300
msgid "``mempool_alloc_t *alloc_fn``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:276 ../mm/mempool.c:299
msgid "user-defined element-allocation function."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:278 ../mm/mempool.c:301
msgid "``mempool_free_t *free_fn``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:277 ../mm/mempool.c:300
msgid "user-defined element-freeing function."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:279 ../mm/mempool.c:302
msgid "``void *pool_data``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:278 ../mm/mempool.c:301
msgid "optional private data available to the user-defined functions."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:279
msgid ""
"Like mempool_create(), but initializes the pool in (i.e. embedded in another "
"structure)."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:296
msgid "create a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:302
msgid "memory allocation flags"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:304
msgid "``int node_id``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:303
msgid "numa node to allocate on"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:304
msgid ""
"this function creates and allocates a guaranteed size, preallocated memory "
"pool. The pool can be used from the mempool_alloc() and mempool_free() "
"functions. This function might sleep. Both the alloc_fn() and the free_fn() "
"functions might sleep - as long as the mempool_alloc() function is not "
"called from IRQ contexts."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:311
msgid "pointer to the created memory pool object or ``NULL`` on error."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:334
msgid "resize an existing memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:338
msgid "``int new_min_nr``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:337
msgid ""
"the new minimum number of elements guaranteed to be allocated for this pool."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:339
msgid ""
"This function shrinks/grows the pool. In the case of growing, it cannot be "
"guaranteed that the pool will be grown to the new size immediately, but new "
"mempool_free() calls will refill it. This function may sleep."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:344
msgid ""
"Note, the caller must guarantee that no mempool_destroy is called while this "
"function is running. mempool_alloc() & mempool_free() might be called (eg. "
"from IRQ contexts) while this function executes."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:479
msgid "allocate multiple elements from a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:480 ../mm/mempool.c:539
#: ../mm/mempool.c:596 ../mm/mempool.c:616 ../mm/mempool.c:702
msgid "pointer to the memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:482 ../mm/mempool.c:618
msgid "``void **elems``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:481
msgid "partially or fully populated elements array"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:482
msgid "number of entries in **elem** that need to be allocated"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:484
msgid "``unsigned int allocated``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:483
msgid "number of entries in **elem** already allocated"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:484
msgid ""
"Allocate elements for each slot in **elem** that is non-``NULL``. This is "
"done by first calling into the alloc_fn supplied at pool initialization "
"time, and dipping into the reserved pool when alloc_fn fails to allocate an "
"element."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:488
msgid "On return all **count** elements in **elems** will be populated."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:491
msgid "Always 0.  If it wasn't for %$#^$ alloc tags, it would return void."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:538
msgid "allocate an element from a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:540
msgid "GFP_* flags.  ``__GFP_ZERO`` is not supported."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:541
msgid ""
"Allocate an element from **pool**.  This is done by first calling into the "
"alloc_fn supplied at pool initialization time, and dipping into the reserved "
"pool when alloc_fn fails to allocate an element."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:545
msgid ""
"This function only sleeps if the alloc_fn callback sleeps, or when waiting "
"for elements to become available in the pool."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:549
msgid ""
"pointer to the allocated element or ``NULL`` when failing to allocate an "
"element.  Allocation failure can only happen when **gfp_mask** does not "
"include ``__GFP_DIRECT_RECLAIM``."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:594
msgid ""
"allocate an element from preallocated elements belonging to a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:597
msgid ""
"This function is similar to mempool_alloc(), but it only attempts allocating "
"an element from the preallocated elements. It only takes a single spinlock_t "
"and immediately returns if no preallocated elements are available."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:602
msgid ""
"pointer to the allocated element or ``NULL`` if no elements are available."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:615
msgid "return elements to a mempool"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:617
msgid "elements to return"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:618
msgid "number of elements to return"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:619
msgid ""
"Returns a number of elements from the start of **elem** to **pool** if "
"**pool** needs replenishing and sets their slots in **elem** to NULL.  Other "
"elements are left in **elem**."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:624
msgid ""
"number of elements transferred to **pool**.  Elements are always transferred "
"from the beginning of **elem**, so the return value can be used as an offset "
"into **elem** for the freeing the remaining elements in the caller."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:700
msgid "return an element to the pool."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:706
msgid "``void *element``"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:701
msgid "element to return"
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:703
msgid ""
"Returns **element** to **pool** if it needs replenishing, else frees it "
"using the free_fn callback in **pool**."
msgstr ""

#: ../../../core-api/mm-api:91: ../mm/mempool.c:706
msgid "This function only sleeps if the free_fn callback sleeps."
msgstr ""

#: ../../../core-api/mm-api.rst:95
msgid "More Memory Management Functions"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2173
msgid "remove ptes mapping the vma"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2174
msgid "vm_area_struct holding ptes to be zapped"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1340 ../mm/rmap.c:1373
#: ../mm/rmap.c:1465 ../mm/rmap.c:1488 ../mm/rmap.c:1511
#: ../../../core-api/mm-api:97: ../mm/memory.c:2176
msgid "``unsigned long address``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2175
msgid "starting address of pages to zap"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2176
msgid "number of bytes to zap"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2177
msgid "This function only unmaps ptes assigned to VM_PFNMAP vmas."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2179
msgid "The entire address range must be fully contained within the vma."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2409
msgid "insert multiple pages into user vma, batching the pmd lock."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2410 ../mm/memory.c:2442
#: ../mm/memory.c:2524 ../mm/memory.c:2549 ../mm/memory.c:2620
#: ../mm/memory.c:2680 ../mm/memory.c:3079 ../mm/memory.c:3110
msgid "user vma to map to"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5379
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2520 ../mm/mempolicy.c:2972
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3764
#: ../../../core-api/mm-api:113: ../mm/rmap.c:2642
#: ../../../core-api/mm-api:115: ../mm/mmap.c:313 ../mm/mmap.c:897
#: ../mm/mmap.c:915 ../../../core-api/mm-api:119: ../mm/hugetlb.c:6914
#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:789
#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:28
#: ../mm/mapping_dirty_helpers.c:80 ../../../core-api/mm-api:128:
#: ../mm/percpu.c:2309 ../../../core-api/mm-api:134: ../mm/huge_memory.c:1768
#: ../../../core-api/mm-api:97: ../mm/memory.c:2412 ../mm/memory.c:2444
#: ../mm/memory.c:2622 ../mm/memory.c:2682 ../mm/memory.c:3081
#: ../mm/memory.c:6843 ../mm/memory.c:7110
msgid "``unsigned long addr``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2411
msgid "target start user address of these pages"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2412
msgid "source kernel pages"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2414
msgid "``unsigned long *num``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2413
msgid ""
"in: number of pages to map. out: number of pages that were *not* mapped. (0 "
"means all pages were successfully mapped)."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2415
msgid "Preferred over vm_insert_page() when inserting multiple pages."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2417
msgid ""
"In case of error, we may have mapped a subset of the provided pages. It is "
"the caller's responsibility to account for this case."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2420
msgid "The same restrictions apply as in vm_insert_page()."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2441
msgid "insert single page into user vma"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2443 ../mm/memory.c:2621
#: ../mm/memory.c:2681
msgid "target user address of this page"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2444
msgid "source kernel page"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2445
msgid ""
"This allows drivers to insert individual pages they've allocated into a user "
"vma. The zeropage is supported in some VMAs, see vm_mixed_zeropage_allowed()."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2449
msgid ""
"The page has to be a nice clean _individual_ kernel allocation. If you "
"allocate a compound page, you need to have marked it as such (__GFP_COMP), "
"or manually just split the page up yourself (see split_page())."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2454
msgid ""
"NOTE! Traditionally this was done with \"remap_pfn_range()\" which took an "
"arbitrary page protection parameter. This doesn't allow that. Your vma "
"protection will have to be set up correctly, which means that if you want a "
"shared writable mapping, you'd better ask for a shared writable mapping!"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2460
msgid "The page does not need to be reserved."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2462
msgid ""
"Usually this function is called from f_op->mmap() handler under mm-"
">mmap_lock write-lock, so it can change vma->vm_flags. Caller must set "
"VM_MIXEDMAP on vma if it wants to call this function from other places, for "
"example from page-fault handler."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2523
msgid "maps range of kernel pages starts with non zero offset"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2525 ../mm/memory.c:2550
msgid "pointer to array of source kernel pages"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2527 ../mm/memory.c:2552
msgid "``unsigned long num``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2526 ../mm/memory.c:2551
msgid "number of pages in page array"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2527
msgid ""
"Maps an object consisting of **num** pages, catering for the user's "
"requested vm_pgoff"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2530
msgid ""
"If we fail to insert any page into the vma, the function will return "
"immediately leaving any previously inserted pages present.  Callers from the "
"mmap handler may immediately return the error as their caller will destroy "
"the vma, removing any successfully inserted pages. Other callers should make "
"their own arrangements for calling unmap_region()."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2537 ../mm/memory.c:2557
msgid "Process context. Called by mmap handlers."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2538 ../mm/memory.c:2558
msgid "0 on success and error code otherwise."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2548
msgid "map range of kernel pages starts with zero offset"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2552
msgid ""
"Similar to vm_map_pages(), except that it explicitly sets the offset to 0. "
"This function is intended for the drivers that did not consider vm_pgoff."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2619
msgid "insert single pfn into user vma with specified pgprot"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:417 ../mm/page_alloc.c:443
#: ../mm/page_alloc.c:465 ../mm/page_alloc.c:491 ../mm/page_alloc.c:515
#: ../mm/page_alloc.c:535 ../../../core-api/mm-api:109:
#: ../include/linux/mmzone.h:2163 ../../../core-api/mm-api:113:
#: ../mm/rmap.c:1138 ../mm/rmap.c:1184 ../../../core-api/mm-api:118:
#: ../mm/memremap.c:404 ../../../core-api/mm-api:131:
#: ../mm/memory_hotplug.c:589 ../../../core-api/mm-api:134:
#: ../mm/huge_memory.c:1598 ../mm/huge_memory.c:1706
#: ../../../core-api/mm-api:97: ../mm/memory.c:2623 ../mm/memory.c:2683
#: ../mm/memory.c:3082
msgid "``unsigned long pfn``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2622 ../mm/memory.c:2682
msgid "source kernel pfn"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2063
#: ../include/linux/mm.h:2079 ../include/linux/mm.h:2095
#: ../../../core-api/mm-api:97: ../mm/memory.c:2624
msgid "``pgprot_t pgprot``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2623
msgid "pgprot flags for the inserted page"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2624
msgid ""
"This is exactly like vmf_insert_pfn(), except that it allows drivers to "
"override pgprot on a per-page basis."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2627
msgid ""
"This only makes sense for IO mappings, and it makes no sense for COW "
"mappings.  In general, using multiple vmas is preferable; "
"vmf_insert_pfn_prot should only be used if using multiple VMAs is "
"impractical."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2632
msgid ""
"pgprot typically only differs from **vma->vm_page_prot** when drivers set "
"caching- and encryption bits different than those of **vma->vm_page_prot**, "
"because the caching- or encryption mode may not be known at mmap() time."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2636
msgid ""
"This is ok as long as **vma->vm_page_prot** is not used by the core vm to "
"set caching and encryption bits for those vmas (except for COW pages). This "
"is ensured by core vm only modifying these page table entries using "
"functions that don't touch caching- or encryption bits, using pte_modify() "
"if needed. (See for example mprotect())."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2642
msgid ""
"Also when new page-table entries are created, this is only done using the "
"fault() callback, and never using the value of vma->vm_page_prot, except for "
"page-table entries that point to anonymous pages as the result of COW."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2648 ../mm/memory.c:2695
msgid "Process context.  May allocate using ``GFP_KERNEL``."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1602
#: ../mm/huge_memory.c:1710 ../mm/huge_memory.c:1744
#: ../../../core-api/mm-api:97: ../mm/memory.c:2649 ../mm/memory.c:2696
msgid "vm_fault_t value."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2679
msgid "insert single pfn into user vma"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2683
msgid ""
"Similar to vm_insert_page, this allows drivers to insert individual pages "
"they've allocated into a user vma. Same comments apply."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2686
msgid ""
"This function should only be called from a vm_ops->fault handler, and in "
"that case the handler should return the result of this function."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2689
msgid "vma cannot be a COW mapping."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:2691
msgid ""
"As this is called only for pages that do not currently exist, we do not need "
"to flush old virtual caches or the TLB."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3078
msgid "remap kernel memory to userspace"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3080
msgid "target page aligned user address to start at"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3081
msgid "page frame number of kernel physical memory address"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3082
msgid "size of mapping area"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3083
msgid "page protection flags for this mapping"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3085
msgid "this is only safe if the mm semaphore is held when called."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3109
msgid "remap memory to userspace"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3112
msgid "``phys_addr_t start``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3111
msgid "start of the physical memory to be mapped"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:316 ../../../core-api/mm-api:97:
#: ../mm/memory.c:3113
msgid "``unsigned long len``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1064
#: ../../../core-api/mm-api:97: ../mm/memory.c:3112
msgid "size of area"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3113
msgid ""
"This is a simplified io_remap_pfn_range() for common driver use. The driver "
"just needs to give us the physical memory range to be mapped, we'll figure "
"out the rest from the vma information."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:3117
msgid ""
"NOTE! Some drivers might want to tweak vma->vm_page_prot first to get "
"whatever write-combining details or similar."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4249
msgid "Unmap pages from processes."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4250
msgid "The address space containing pages to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4251
msgid "Index of first page to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:254
#: ../mm/mapping_dirty_helpers.c:283 ../../../core-api/mm-api:97:
#: ../mm/memory.c:4253
msgid "``pgoff_t nr``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4252
msgid "Number of pages to be unmapped.  0 to unmap to end of file."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4254
msgid "``bool even_cows``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4253
msgid "Whether to unmap even private COWed pages."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4254
msgid ""
"Unmap the pages in this address space from any userspace process which has "
"them mmaped.  Generally, you want to remove COWed pages as well when a file "
"is being truncated, but not when invalidating pages from the page cache."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4280
msgid ""
"unmap the portion of all mmaps in the specified address_space corresponding "
"to the specified byte range in the underlying file."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4284
msgid "the address space containing mmaps to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4286
msgid "``loff_t const holebegin``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4285
msgid ""
"byte in first page to unmap, relative to the start of the underlying file.  "
"This will be rounded down to a PAGE_SIZE boundary.  Note that this is "
"different from truncate_pagecache(), which must keep the partial page.  In "
"contrast, we must get rid of partial pages."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4291
msgid "``loff_t const holelen``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4290
msgid ""
"size of prospective hole in bytes.  This will be rounded up to a PAGE_SIZE "
"boundary.  A holelen of zero truncates to the end of the file."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4294
msgid "``int even_cows``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:4293
msgid ""
"1 when truncating a file, unmap even private COWed pages; but 0 when "
"invalidating pagecache, don't throw away private data."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6716
msgid "Look up a pfn mapping at a user virtual address"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6722 ../mm/memory.c:6829
msgid "``struct follow_pfnmap_args *args``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6717 ../mm/memory.c:6824
msgid "Pointer to struct **follow_pfnmap_args**"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6718
msgid ""
"The caller needs to setup args->vma and args->address to point to the "
"virtual address as the target of such lookup.  On a successful return, the "
"results will be put into other output fields."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6722
msgid ""
"After the caller finished using the fields, the caller must invoke another "
"follow_pfnmap_end() to proper releases the locks and resources of such look "
"up request."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6726
msgid ""
"During the start() and end() calls, the results in **args** will be valid as "
"proper locks will be held.  After the end() is called, all the fields in "
"**follow_pfnmap_args** will be invalid to be further accessed.  Further use "
"of such information after end() may require proper synchronizations by the "
"caller with page table updates, otherwise it can create a security bug."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6733
msgid ""
"If the PTE maps a refcounted page, callers are responsible to protect "
"against invalidation with MMU notifiers; otherwise access to the PFN at a "
"later point in time can trigger use-after-free."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6737
msgid ""
"Only IO mappings and raw PFN mappings are allowed.  The mmap semaphore "
"should be taken for read, and the mmap semaphore cannot be released before "
"the end() is invoked."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6741
msgid "This function must not be used to modify PTE content."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6744
msgid "zero on success, negative otherwise."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6823
msgid "End a follow_pfnmap_start() process"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6825
msgid ""
"Must be used in pair of follow_pfnmap_start().  See the start() function "
"above for more information."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6840
msgid "generic implementation for iomem mmap access"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6841
msgid "the vma to access"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6842
msgid "userspace address, not relative offset within **vma**"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6844 ../mm/memory.c:7111
msgid "``void *buf``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6843
msgid "buffer to read/write"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6845 ../mm/memory.c:7112
msgid "``int len``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6844
msgid "length of transfer"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6846
msgid "``int write``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6845
msgid "set to FOLL_WRITE when writing, otherwise reading"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:6846
msgid ""
"This is a generic implementation for :c:type:`vm_operations_struct.access "
"<vm_operations_struct>` for an iomem mapping. This callback is used by "
"access_process_vm() when the **vma** is not page based."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7107
msgid "copy a string from another process's address space."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7113
msgid "``struct task_struct *tsk``"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7108
msgid "the task of the target address space"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7109
msgid "start address to read from"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7110
msgid "destination buffer"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7111
msgid "number of bytes to copy"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7112
msgid "flags modifying lookup behaviour"
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7113
msgid "The caller must hold a reference on **mm**."
msgstr ""

#: ../../../core-api/mm-api:97: ../mm/memory.c:7116
msgid ""
"number of bytes copied from **addr** (source) to **buf** (destination); not "
"including the trailing NUL. Always guaranteed to leave NUL-terminated "
"buffer. On any error, return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:413
msgid ""
"Return the requested group of flags for a pageblock_nr_pages block of pages"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:415 ../mm/page_alloc.c:441
#: ../mm/page_alloc.c:463 ../mm/page_alloc.c:489 ../mm/page_alloc.c:513
#: ../mm/page_alloc.c:533 ../mm/page_alloc.c:553
msgid "The page within the block of interest"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:416 ../mm/page_alloc.c:442
#: ../mm/page_alloc.c:464 ../mm/page_alloc.c:490 ../mm/page_alloc.c:514
#: ../mm/page_alloc.c:534
msgid "The target page frame number"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:418 ../mm/page_alloc.c:493
#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:760
msgid "``unsigned long mask``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:417 ../mm/page_alloc.c:492
msgid "mask of bits that the caller is interested in"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:419
msgid "pageblock_bits flags"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:440
msgid "Check if a standalone bit of a pageblock is set"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:444 ../mm/page_alloc.c:516
#: ../mm/page_alloc.c:536
msgid "``enum pageblock_bits pb_bit``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:443
msgid "pageblock bit to check"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:445
msgid "true if the bit is set, otherwise false"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:462
msgid "Return the migratetype of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:466
msgid "The migratetype of the pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:467
msgid ""
"Use get_pfnblock_migratetype() if caller already has both **page** and "
"**pfn** to save a call to page_to_pfn()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:487
msgid ""
"Set the requested group of flags for a pageblock_nr_pages block of pages"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:491
msgid "The flags to set"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:512
msgid "Set a standalone bit of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:515
msgid "pageblock bit to set"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:532
msgid "Clear a standalone bit of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:535
msgid "pageblock bit to clear"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:552
msgid "Set the migratetype of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:555
msgid "``enum migratetype migratetype``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:554
msgid "migratetype to set"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2106
msgid "move free pages in block for page isolation"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2112
msgid "``struct zone *zone``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2107
msgid "the zone"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2108
msgid "the pageblock page"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2110
msgid "``bool isolate``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2109
msgid "to isolate the given pageblock or unisolate it"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2110
msgid ""
"This is similar to move_freepages_block(), but handles the special case "
"encountered in page isolation, where the block of interest might be part of "
"a larger buddy spanning multiple pageblocks."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2114
msgid ""
"Unlike the regular page allocator path, which moves pages while stealing "
"buddies off the freelist, page isolation is interested in arbitrary pfn "
"ranges that may have overlapping buddies on both ends."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2118
msgid ""
"This function handles that. Straddling buddies are split into individual "
"pageblocks. Only the block of interest is moved."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:2121
msgid "Returns ``true`` if pages could be moved, ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3175
msgid "Return a now-isolated page back where we got it"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3176
msgid "Page that was isolated"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3178
#: ../mm/page_alloc.c:5341 ../mm/page_alloc.c:5376 ../mm/page_alloc.c:7699
#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2435 ../mm/mempolicy.c:2565
#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3186
msgid "``unsigned int order``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3177
msgid "Order of the isolated page"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3179
msgid "``int mt``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3178
msgid "The page's pageblock's migratetype"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:3179
msgid ""
"This function is meant to return a page pulled from the free lists via "
"__isolate_free_page back to the free lists they were pulled from."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5338
msgid "Free pages allocated with alloc_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5339
msgid "The page pointer returned from alloc_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5340
#: ../mm/page_alloc.c:5375
msgid "The order of the allocation."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5341
msgid ""
"This function can free multi-page allocations that are not compound pages.  "
"It does not check that the **order** passed in matches that of the "
"allocation, so it is easy to leak memory.  Freeing more memory than was "
"allocated will probably emit a warning."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5346
msgid ""
"If the last reference to this page is speculative, it will be released by "
"put_page() which only frees the first page of a non-compound allocation.  To "
"prevent the remaining pages from being leaked, we free the subsequent pages "
"here.  If you want to use the page's reference count to decide when to free "
"the allocation, you should allocate a compound page, and use put_page() "
"instead of __free_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5354
msgid ""
"May be called in interrupt context or while holding a normal spinlock, but "
"not in NMI context or while holding a raw spinlock."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5373
msgid "Free pages allocated with __get_free_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5374
msgid "The virtual address tied to a page returned from __get_free_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5376
msgid ""
"This function behaves the same as __free_pages(). Use this function to free "
"pages when you only have a valid virtual address. If you have the page, call "
"__free_pages() instead."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5413
msgid "allocate an exact number physically-contiguous pages."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5414
#: ../mm/page_alloc.c:5444
msgid "the number of bytes to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5415
#: ../mm/page_alloc.c:5445
msgid "GFP flags for the allocation, must not contain __GFP_COMP"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5416
msgid ""
"This function is similar to alloc_pages(), except that it allocates the "
"minimum number of pages to satisfy the request.  alloc_pages() can only "
"allocate memory in power-of-two pages."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5420
msgid "This function is also limited by MAX_PAGE_ORDER."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5422
msgid ""
"Memory allocated by this function must be released by free_pages_exact()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5425
#: ../mm/page_alloc.c:5450
msgid "pointer to the allocated area or ``NULL`` in case of error."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5441
msgid "allocate an exact number of physically-contiguous pages on a node."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5443
msgid "the preferred node ID where memory should be allocated"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5446
msgid ""
"Like alloc_pages_exact(), but try to allocate on node nid first before "
"falling back."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5467
msgid "release memory allocated via alloc_pages_exact()"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5473
msgid "``void *virt``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5468
msgid "the value returned by alloc_pages_exact."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5469
msgid "size of allocation, same value as passed to alloc_pages_exact()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5470
msgid "Release the memory allocated by a previous call to alloc_pages_exact."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5486
#: ../mm/page_alloc.c:5518
msgid "count number of pages beyond high watermark"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5492
msgid "``int offset``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5487
msgid "The zone index of the highest zone"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5488
msgid ""
"nr_free_zone_pages() counts the number of pages which are beyond the high "
"watermark within all zones at or below a given zone index.  For each zone, "
"the number of pages is calculated as:"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5492
msgid "nr_free_zone_pages = managed_pages - high_pages"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5495
msgid "number of pages beyond high watermark."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5519
msgid ""
"nr_free_buffer_pages() counts the number of pages which are beyond the high "
"watermark within ZONE_DMA and ZONE_NORMAL."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5523
msgid "number of pages beyond high watermark within ZONE_DMA and ZONE_NORMAL."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5594
msgid "find the next node that should appear in a given node's fallback list"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5595
msgid "node whose fallback list we're appending"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5597
msgid "``nodemask_t *used_node_mask``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5596
msgid "nodemask_t of already used nodes"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5597
msgid ""
"We use a number of factors to determine which is the next node that should "
"appear on a given node's fallback list.  The node should not have appeared "
"already in **node**'s fallback list, and it should be the next closest node "
"according to the distance array (which contains arbitrary distance values "
"from each node to each node in the system), and should also prefer nodes "
"with no CPUs, since presumably they'll have very little allocation pressure "
"on them otherwise."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:5606
msgid "node id of the found node or ``NUMA_NO_NODE`` if no node is found."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6490
msgid ""
"called when min_free_kbytes changes or when memory is hot-{added|removed}"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6491
msgid ""
"Ensures that the watermark[min,low,high] values for each zone are set "
"correctly with respect to min_free_kbytes."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6955
msgid "tries to allocate given range of pages"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6956
msgid "start PFN to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6958
#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:29
#: ../mm/mapping_dirty_helpers.c:81
msgid "``unsigned long end``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6957
msgid "one-past-the-last PFN to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6959
msgid "``acr_flags_t alloc_flags``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6958
msgid "allocation information"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6959
msgid ""
"GFP mask. Node/zone/placement hints are ignored; only some action and "
"reclaim modifiers are supported. Reclaim modifiers control allocation "
"behavior during compaction/migration/reclaim."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6962
msgid ""
"The PFN range does not have to be pageblock aligned. The PFN range must "
"belong to a single zone."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6965
msgid ""
"The first thing this routine does is attempt to MIGRATE_ISOLATE all "
"pageblocks in the range.  Once isolated, the pageblocks should not be "
"modified by others."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:6970
msgid ""
"zero on success or negative error code.  On success all pages which PFN is "
"in [start, end) are allocated for the caller and need to be freed with "
"free_contig_range()."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7156
msgid "tries to find and allocate contiguous range of pages"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7162
#: ../../../core-api/mm-api:113: ../mm/rmap.c:1139 ../mm/rmap.c:1184
#: ../mm/rmap.c:2885 ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:586
msgid "``unsigned long nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7157
msgid "Number of contiguous pages to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7158
msgid ""
"GFP mask. Node/zone/placement hints limit the search; only some action and "
"reclaim modifiers are supported. Reclaim modifiers control allocation "
"behavior during compaction/migration/reclaim."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7161
msgid "Target node"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7163
msgid "``nodemask_t *nodemask``"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7162
msgid "Mask for other possible nodes"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7163
msgid ""
"This routine is a wrapper around alloc_contig_range(). It scans over zones "
"on an applicable zonelist to find a contiguous pfn range which can then be "
"tried for allocation with alloc_contig_range(). This routine is intended for "
"allocation requests which can not be fulfilled with the buddy allocator."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7168
msgid ""
"The allocated memory is always aligned to a page boundary. If nr_pages is a "
"power of two, then allocated range is also guaranteed to be aligned to same "
"nr_pages (e.g. 1GB request would be aligned to 1GB)."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7172
msgid ""
"Allocated pages can be freed with free_contig_range() or by manually calling "
"__free_page() on each allocated page."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7176
msgid "pointer to contiguous pages on success, or NULL if not successful."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7695
msgid "opportunistic reentrant allocation from any context"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7696
msgid "GFP flags. Only __GFP_ACCOUNT allowed."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7697
msgid "node to allocate from"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7698
msgid "allocation order size"
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7699
msgid ""
"Allocates pages of a given order from the given node. This is safe to call "
"from any context (from atomic, NMI, and also reentrant allocator -> "
"tracepoint -> alloc_pages_nolock_noprof). Allocation is best effort and to "
"be expected to fail easily so nobody should rely on the success. Failures "
"are not reported via warn_alloc(). See always fail conditions below."
msgstr ""

#: ../../../core-api/mm-api:100: ../mm/page_alloc.c:7707
msgid ""
"allocated page or NULL on failure. NULL does not mean EBUSY or EAGAIN. It "
"means ENOMEM. There is no reason to call it again and expect !NULL."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:279
msgid "Find nearest node by state"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:280
msgid "Node id to start the search"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:282
msgid "``unsigned int state``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:281
msgid "State to filter the search"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:282
msgid "Lookup the closest node by distance if **nid** is not in state."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:285
msgid "this **node** if it is in state, otherwise the closest node by distance"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:311
msgid "Find the node in **mask** at the nearest distance from **node**."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:314
msgid "a valid node ID to start the search from."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:316
msgid "``nodemask_t *mask``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:315
msgid "a pointer to a nodemask representing the allowed nodes."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:316
msgid ""
"This function iterates over all nodes in **mask** and calculates the "
"distance from the starting **node**, then it returns the node ID that is the "
"closest to **node**, or MAX_NUMNODES if no node is found."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:320
msgid ""
"Note that **node** must be a valid node ID usable with node_distance(), "
"providing an invalid node ID (e.g., NUMA_NO_NODE) may result in crashes or "
"unexpected behavior."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:818
msgid "check whether the folio can map prot numa"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:819
msgid "The folio whose mapping considered for being made NUMA hintable"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:820
msgid "The VMA that the folio belongs to."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:822
msgid "``bool is_private_single_threaded``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:821
msgid "Is this a single-threaded private VMA or not"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:822
msgid ""
"This function checks to see if the folio actually indicates that we need to "
"make the mapping one which causes a NUMA hinting fault, as there are cases "
"where it's simply unnecessary, and the folio's access time is adjusted for "
"memory tiering if prot numa needed."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:828
msgid "True if the mapping of the folio needs to be changed, false otherwise."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2432
msgid "Allocate pages according to NUMA mempolicy."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2433 ../mm/mempolicy.c:2516
#: ../mm/mempolicy.c:2563
msgid "GFP flags."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2434
msgid "Order of the page allocation."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2436 ../mm/mempolicy.c:3545
msgid "``struct mempolicy *pol``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2435
msgid "Pointer to the NUMA mempolicy."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2437
msgid "``pgoff_t ilx``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2436
msgid "Index for interleave mempolicy (also distinguishes alloc_pages())."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2437
msgid "Preferred node (usually numa_node_id() but **mpol** may override it)."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2439 ../mm/mempolicy.c:2573
msgid "The page on success or NULL if allocation fails."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2515
msgid "Allocate a folio for a VMA."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2518
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2857
#: ../mm/memcontrol.c:2881
msgid "``int order``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2517
msgid "Order of the folio."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2518
msgid "Pointer to VMA."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2519
msgid "Virtual address of the allocation.  Must be inside **vma**."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2520
msgid ""
"Allocate a folio for a specific address in **vma**, using the appropriate "
"NUMA policy.  The caller must hold the mmap_lock of the mm_struct of the VMA "
"to prevent it from going away.  Should be used for all allocations for "
"folios that will be mapped into user space, excepting hugetlbfs, and "
"excepting where direct use of folio_alloc_mpol() is more appropriate."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2527
msgid "The folio on success or NULL if allocation fails."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2562
msgid "Allocate pages."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2564
msgid "Power of two of number of pages to allocate."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2565
msgid ""
"Allocate 1 << **order** contiguous pages.  The physical address of the first "
"page is naturally aligned (eg an order-3 allocation will be aligned to a "
"multiple of 8 * PAGE_SIZE bytes).  The NUMA policy of the current process is "
"honoured when in process context."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2571
msgid ""
"Can be called from any context, providing the appropriate GFP flags are used."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2967
msgid "check whether current folio node is valid in policy"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2969
msgid "folio to be checked"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2970
msgid "structure describing the fault"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2971
msgid ""
"virtual address in **vma** for shared policy lookup and interleave policy"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2972
msgid ""
"Lookup current policy node id for vma,addr and \"compare to\" folio's node "
"id.  Policy determination \"mimics\" alloc_page_vma(). Called from fault "
"path where we know the vma and faulting address."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:2977
msgid ""
"NUMA_NO_NODE if the page is in a node that is valid for this policy, or a "
"suitable node ID to allocate a replacement folio from."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3197
msgid "initialize shared policy for inode"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3203
msgid "``struct shared_policy *sp``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3198
msgid "pointer to inode shared policy"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3200
msgid "``struct mempolicy *mpol``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3199
msgid "struct mempolicy to install"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3200
msgid ""
"Install non-NULL **mpol** in inode's shared policy rb-tree. On entry, the "
"current task has a reference on a non-NULL **mpol**. This must be released "
"on exit. This is called at get_inode() calls and we can use GFP_KERNEL."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3406
msgid "parse string to mempolicy, for tmpfs mpol mount option."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3412
msgid "``char *str``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3407
msgid "string containing mempolicy to parse"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3409
msgid "``struct mempolicy **mpol``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3408
msgid "pointer to struct mempolicy pointer, returned on success."
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3409
msgid "Format of input:"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3410
msgid "<mode>[=<flags>][:<nodelist>]"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3413
msgid "``0`` on success, else ``1``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3541
msgid "format a mempolicy structure for printing"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3547
msgid "``char *buffer``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3542
msgid "to contain formatted mempolicy string"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3544
msgid "``int maxlen``"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3543
msgid "length of **buffer**"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3544
msgid "pointer to mempolicy to be formatted"
msgstr ""

#: ../../../core-api/mm-api:101: ../mm/mempolicy.c:3545
msgid ""
"Convert **pol** into a string.  If **buffer** is too short, truncate the "
"string. Recommend a **maxlen** of at least 51 for the longest mode, "
"\"weighted interleave\", plus the longest flag flags, \"relative|"
"balancing\", and to display at least a few node ids."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:290
msgid ""
"Describes a page table software leaf entry, abstracted from its architecture-"
"specific encoding."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:291
msgid ""
"Page table leaf entries are those which do not reference any descendent page "
"tables but rather either reference a data page, are an empty (or 'none' "
"entry), or contain a non-present entry."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:295
msgid ""
"If referencing another page table or a data page then the page table entry "
"is pertinent to hardware - that is it tells the hardware how to decode the "
"page table entry."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:299
msgid ""
"Otherwise it is a software-defined leaf page table entry, which this type "
"describes. See leafops.h and specifically **softleaf_type** for a list of "
"all possible kinds of software leaf entry."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:303
msgid ""
"A softleaf_t entry is abstracted from the hardware page table entry, so is "
"not architecture-specific."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:306
#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1537
#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2160
#: ../mm/memory_hotplug.c:2275
msgid "**NOTE**"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:308
msgid "While we transition from the confusing swp_entry_t type used for this"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:309
msgid ""
"purpose, we simply alias this type. This will be removed once the transition "
"is complete."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:358
msgid "Represents a contiguous set of bytes."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:360
msgid "Identical to the page flags."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1
msgid "``{unnamed_union}``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:2
msgid "anonymous"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:360
msgid "``lru``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:361
msgid "Least Recently Used list; tracks how recently this folio was used."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:361
msgid "``mlock_count``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:362
msgid "Number of times this folio has been pinned by mlock()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:375
msgid "``pgmap``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:376
msgid "Metadata for ZONE_DEVICE mappings"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:363
msgid ""
"The file this page belongs to, or refers to the anon_vma for anonymous "
"memory."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:364
msgid "``index``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:365
msgid ""
"Offset within the file, in units of pages.  For anonymous memory, this is "
"the index from the beginning of the mmap."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:366
msgid "``share``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:367
msgid ""
"number of DAX mappings that reference this folio. See dax_associate_entry."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:368
msgid "``private``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:369
msgid "Filesystem per-folio data (see folio_attach_private())."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:369
msgid "``swap``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:370
msgid "Used for swp_entry_t if folio_test_swapcache()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:370
msgid "``_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:371
msgid ""
"Do not access this member directly.  Use folio_mapcount() to find out how "
"many times this folio is mapped by userspace."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:372
msgid "``_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:373
msgid ""
"Do not access this member directly.  Use folio_ref_count() to find how many "
"references there are to this folio."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:374
msgid "``memcg_data``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:375
msgid "Memory Control Group data."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:391
msgid "``_unused_slab_obj_exts``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:392
msgid "Placeholder to match obj_exts in struct slab."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:376
msgid "``virtual``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:377
msgid "Virtual address in the kernel direct map."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:377
msgid "``_last_cpupid``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:378
msgid "IDs of last CPU and last process that accessed the folio."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:379
msgid "``_large_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:380
msgid "Do not use directly, call folio_mapcount()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:380
msgid "``_nr_pages_mapped``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:381
msgid "Do not use outside of rmap and debug code."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:378
msgid "``_entire_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:379
msgid "Do not use directly, call folio_entire_mapcount()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:381
msgid "``_pincount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:382
msgid "Do not use directly, call folio_maybe_dma_pinned()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:385
msgid "``_mm_id_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:384
#: ../include/linux/mm_types.h:385 ../include/linux/mm_types.h:386
msgid "Do not use outside of rmap code."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:383
msgid "``_mm_id``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:384
msgid "``_mm_ids``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:382
msgid "``_nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:383
msgid "Do not use directly, call folio_nr_pages()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:390
msgid "``_deferred_list``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:391
msgid "Folios to be split under memory pressure."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:386
msgid "``_hugetlb_subpool``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:387
msgid "Do not use directly, use accessor in hugetlb.h."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:387
msgid "``_hugetlb_cgroup``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:388
#: ../include/linux/mm_types.h:389
msgid "Do not use directly, use accessor in hugetlb_cgroup.h."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:388
msgid "``_hugetlb_cgroup_rsvd``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:389
msgid "``_hugetlb_hwpoison``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:390
msgid "Do not use directly, call raw_hwp_list_head()."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:392
msgid ""
"A folio is a physically, virtually and logically contiguous set of bytes.  "
"It is a power-of-two in size, and it is aligned to that same power-of-two.  "
"It is at least as large as ``PAGE_SIZE``.  If it is in the page cache, it is "
"at a file offset which is a multiple of that power-of-two.  It may be mapped "
"into userspace at an address which is at an arbitrary page offset, but its "
"kernel virtual address is aligned to its size."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:550
msgid "Memory descriptor for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:551
msgid "``pt_flags``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:552
msgid "enum pt_flags plus zone/node/section."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:552
msgid "``pt_rcu_head``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:553
msgid "For freeing page table pages."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:553
msgid "``pt_list``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:554
msgid ""
"List of used page tables. Used for s390 gmap shadow pages (which are not "
"linked into the user page tables) and x86 pgds."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1
msgid "``{unnamed_struct}``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:556
msgid "``_pt_pad_1``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:557
msgid "Padding that aliases with page's compound head."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:557
msgid "``pmd_huge_pte``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:558
msgid "Protected by ptdesc->ptl, used for THPs."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:558
msgid "``__page_mapping``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:559
msgid "Aliases with page->mapping. Unused for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:559
msgid "``pt_index``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:560
msgid "Used for s390 gmap."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:560
msgid "``pt_mm``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:561
msgid "Used for x86 pgds."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:561
msgid "``pt_frag_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:562
msgid "For fragmented page table tracking. Powerpc only."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:562
msgid "``pt_share_count``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:563
msgid "Used for HugeTLB PMD page table share count."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:563
msgid "``_pt_pad_2``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:564
msgid "Padding to ensure proper alignment."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:564
msgid "``ptl``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:565
msgid "Lock for the page table."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:565
msgid "``__page_type``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:566
msgid "Same as page->page_type. Unused for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:566
msgid "``__page_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:567
msgid "Same as page refcount."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:567
msgid "``pt_memcg_data``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:568
msgid "Memcg data. Tracked for page tables here."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:568
msgid ""
"This struct overlays struct page for now. Do not modify without a good "
"understanding of the issues."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1539
msgid "Return type for page fault handlers."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1540
msgid "Page fault handlers return a bitmask of ``VM_FAULT`` values."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1546
msgid ""
"Page fault handlers return a bitmask of these values to tell the core VM "
"what happened when handling the fault. Used to decide whether a process gets "
"delivered SIGBUS or just gets major/minor fault counters bumped up."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1550
#: ../include/linux/mm_types.h:1650
msgid "**Constants**"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1552
msgid "``VM_FAULT_OOM``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1553
msgid "Out Of Memory"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1555
msgid "``VM_FAULT_SIGBUS``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1556
msgid "Bad access"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1558
msgid "``VM_FAULT_MAJOR``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1559
msgid "Page read from storage"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1561
msgid "``VM_FAULT_HWPOISON``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1562
msgid "Hit poisoned small page"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1564
msgid "``VM_FAULT_HWPOISON_LARGE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1565
msgid "Hit poisoned large page. Index encoded in upper bits"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1568
msgid "``VM_FAULT_SIGSEGV``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1569
msgid "segmentation fault"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1571
msgid "``VM_FAULT_NOPAGE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1572
msgid "->fault installed the pte, not return page"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1574
msgid "``VM_FAULT_LOCKED``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1575
msgid "->fault locked the returned page"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1577
msgid "``VM_FAULT_RETRY``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1578
msgid "->fault blocked, must retry"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1580
msgid "``VM_FAULT_FALLBACK``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1581
msgid "huge page fault failed, fall back to small"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1583
msgid "``VM_FAULT_DONE_COW``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1584
msgid "->fault has fully handled COW"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1586
msgid "``VM_FAULT_NEEDDSYNC``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1587
msgid ""
"->fault did not modify page tables and needs fsync() to complete (for "
"synchronous page faults in DAX)"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1591
msgid "``VM_FAULT_COMPLETED``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1592
msgid "->fault completed, meanwhile mmap lock released"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1594
msgid "``VM_FAULT_HINDEX_MASK``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1595
msgid "mask HINDEX value"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1646
msgid "Fault flag definitions."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1652
msgid "``FAULT_FLAG_WRITE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1653
msgid "Fault was a write fault."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1655
msgid "``FAULT_FLAG_MKWRITE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1656
msgid "Fault was mkwrite of existing PTE."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1658
msgid "``FAULT_FLAG_ALLOW_RETRY``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1659
msgid "Allow to retry the fault if blocked."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1661
msgid "``FAULT_FLAG_RETRY_NOWAIT``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1662
msgid "Don't drop mmap_lock and wait when retrying."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1664
msgid "``FAULT_FLAG_KILLABLE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1665
msgid "The fault task is in SIGKILL killable region."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1667
msgid "``FAULT_FLAG_TRIED``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1668
msgid "The fault has been tried once."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1670
msgid "``FAULT_FLAG_USER``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1671
msgid "The fault originated in userspace."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1673
msgid "``FAULT_FLAG_REMOTE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1674
msgid "The fault is not for current task/mm."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1676
msgid "``FAULT_FLAG_INSTRUCTION``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1677
msgid "The fault was during an instruction fetch."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1679
msgid "``FAULT_FLAG_INTERRUPTIBLE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1680
msgid "The fault can be interrupted by non-fatal signals."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1682
msgid "``FAULT_FLAG_UNSHARE``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1683
msgid ""
"The fault is an unsharing request to break COW in a COW mapping, making sure "
"that an exclusive anon page is mapped after the fault."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1687
msgid "``FAULT_FLAG_ORIG_PTE_VALID``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1688
msgid ""
"whether the fault has vmf->orig_pte cached. We should only access orig_pte "
"if this flag set."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1691
msgid "``FAULT_FLAG_VMA_LOCK``"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1692
msgid "The fault is handled under VMA lock."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1663
msgid ""
"About **FAULT_FLAG_ALLOW_RETRY** and **FAULT_FLAG_TRIED**: we can specify "
"whether we would allow page faults to retry by specifying these two fault "
"flags correctly.  Currently there can be three legal combinations:"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1667
msgid "ALLOW_RETRY and !TRIED:  this means the page fault allows retry, and"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1668
msgid "this is the first try"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1670
msgid "ALLOW_RETRY and TRIED:   this means the page fault allows retry, and"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1671
msgid "we've already tried at least once"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1673
msgid "!ALLOW_RETRY and !TRIED: this means the page fault does not allow retry"
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1675
msgid ""
"The unlisted combination (!ALLOW_RETRY && TRIED) is illegal and should never "
"be used.  Note that page faults can be allowed to retry for multiple times, "
"in which case we'll have an initial fault with flags (a) then later on "
"continuous faults with flags (b).  We should always try to detect pending "
"signals before a retry to make sure the continuous page faults can still be "
"interrupted if necessary."
msgstr ""

#: ../../../core-api/mm-api:102: ../include/linux/mm_types.h:1682
msgid ""
"The combination FAULT_FLAG_WRITE|FAULT_FLAG_UNSHARE is illegal. "
"FAULT_FLAG_UNSHARE is ignored and treated like an ordinary read fault when "
"applied to mappings that are not COW mappings."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:14
msgid "Should the folio be on a file LRU or anon LRU?"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:15
#: ../include/linux/mm_inline.h:82 ../../../core-api/mm-api:105:
#: ../include/linux/page-flags.h:859 ../../../core-api/mm-api:113:
#: ../mm/rmap.c:934
msgid "The folio to test."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:16
msgid ""
"We would like to get this info without a page flag, but the state needs to "
"survive until the folio is last deleted from the LRU, which could be as far "
"down as __page_cache_release."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:21
msgid ""
"An integer (not a boolean!) used to sort a folio onto the right LRU list and "
"to account folios correctly. 1 if **folio** is a regular filesystem backed "
"page cache folio or a lazily freed anonymous folio (e.g. via MADV_FREE). 0 "
"if **folio** is a normal anonymous folio, a tmpfs folio or otherwise ram or "
"swap backed folio."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:63
msgid "Clear page lru flags before releasing a page."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:64
msgid "The folio that was on lru and now has a zero reference."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:81
msgid "Which LRU list should a folio be on?"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:84
msgid ""
"The LRU list a folio should be on, as an index into the array of LRU lists."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:623
msgid "determine the number of contiguous pages that represent contiguous PFNs"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:625
msgid "an array of page pointers"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:627
msgid "``size_t nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:626
msgid "length of the array, at least 1"
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:627
msgid ""
"Determine the number of contiguous pages that represent contiguous PFNs in "
"**pages**, starting from the first page."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:630
msgid ""
"In some kernel configs contiguous PFNs will not have contiguous struct "
"pages. In these configurations num_pages_contiguous() will return a num "
"smaller than ideal number. The caller should continue to check for pfn "
"contiguity after each call to num_pages_contiguous()."
msgstr ""

#: ../../../core-api/mm-api:104: ../include/linux/mm_inline.h:635
msgid "Returns the number of contiguous pages."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:296
msgid "``page_folio (p)``"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:294
msgid "Converts from page to folio."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:300
msgid "``p``"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:295
#: ../../../core-api/mm-api:114: ../mm/migrate.c:101
msgid "The page."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:296
msgid ""
"Every page is part of a folio.  This function cannot be called on a NULL "
"pointer."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:300
msgid ""
"No reference, nor lock is required on **page**.  If the caller does not hold "
"a reference, this call may race with a folio split, so it should re-check "
"the folio still contains this page after gaining a reference on the folio."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:304
msgid "The folio which contains this page."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:313
msgid "``folio_page (folio, n)``"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:311
msgid "Return a page from a folio."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:317
msgid "``folio``"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:313
msgid "The page number to return."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:314
msgid ""
"**n** is relative to the start of the folio.  This function does not check "
"that the page number lies within **folio**; the caller is presumed to have a "
"reference to the page."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:757
msgid "Change some folio flags."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:759
msgid "Bits set in this word will be changed."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:760
msgid ""
"This must only be used for flags which are changed with the folio lock "
"held.  For example, it is unsafe to use for PG_dirty as that can be set "
"without the folio lock held.  It can also only be used on flags which are in "
"the range 0-6 as some of the implementations only affect those bits."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:767
msgid "Whether there are tasks waiting on the folio."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:776
msgid "Is this folio up to date?"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:778
msgid ""
"The uptodate flag is set on a folio when every byte in the folio is at least "
"as new as the corresponding bytes on storage.  Anonymous and CoW folios are "
"always uptodate.  If the folio is not uptodate, some of the bytes in it may "
"be; see the is_partially_uptodate() address_space operation."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:858
msgid "Does this folio contain more than one page?"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:861
msgid "True if the folio is larger than one page."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1070
msgid "Determine if the page belongs to hugetlbfs"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1071
#: ../include/linux/page-flags.h:1140
msgid "The page to test."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1074
msgid ""
"True for hugetlbfs pages, false for anon pages or pages belonging to other "
"filesystems."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1139
msgid "test for a movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1141
msgid ""
"Test whether this is a movable_ops page. Such pages will stay that way until "
"freed."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1144
msgid "Returns true if this is a movable_ops page, otherwise false."
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1225
msgid "Determine if folio has private stuff"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1226
msgid "The folio to be checked"
msgstr ""

#: ../../../core-api/mm-api:105: ../include/linux/page-flags.h:1227
msgid ""
"Determine if a folio has private stuff, indicating that release routines "
"should be invoked upon it."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:233
msgid "Return the number of a page in a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:235
msgid "The folio page."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:236
msgid ""
"This function expects that the page is actually part of the folio. The "
"returned number is relative to the start of the folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:282
msgid "specifies an individual VMA flag by bit number."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:283
msgid ""
"This value is made type safe by sparse to avoid passing invalid flag values "
"around."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:652
msgid "check ALLOW_RETRY the first time"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:658
msgid "``enum fault_flag flags``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:653
msgid "Fault flags."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:654
msgid ""
"This is mostly used for places where we want to try to avoid taking the "
"mmap_lock for too long a time when waiting for another condition to change, "
"in which case we can try to be polite to release the mmap_lock in the first "
"round to avoid potential starvation of other processes that would also want "
"the mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:661
msgid ""
"true if the page fault allows retry and this is the first attempt of the "
"fault handling; false otherwise."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1240
msgid "The allocation order of a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1242
msgid ""
"A folio is composed of 2^order pages.  See get_order() for the definition of "
"order."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1246
msgid "The order of the folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1256
msgid "Reset the folio order and derived _nr_pages"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1258
msgid ""
"Reset the order and derived _nr_pages to 0. Must only be used in the process "
"of splitting large folios."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1374
msgid "Number of mappings of this folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1376
msgid ""
"The folio mapcount corresponds to the number of present user page table "
"entries that reference any part of a folio. Each such present user page "
"table entry must be paired with exactly on folio reference."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1380
msgid ""
"For ordindary folios, each user page table entry (PTE/PMD/PUD/...) counts "
"exactly once."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1383
msgid ""
"For hugetlb folios, each abstracted \"hugetlb\" user page table entry that "
"references the entire folio counts exactly once, even when such special page "
"table entries are comprised of multiple ordinary page table entries."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1387
msgid ""
"Will report 0 for pages which cannot be mapped into userspace, such as slab, "
"page tables and similar."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1391
msgid "The number of times this folio is mapped."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1407
msgid "Is this folio mapped into userspace?"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1410
msgid "True if any page in this folio is referenced by user page tables."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1462
msgid "Order of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1463
#: ../include/linux/mm.h:1473
msgid "Head page of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1472
msgid "Size of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1475
msgid "Number of bytes in this page."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1568
msgid "Increment the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1571
msgid ""
"May be called in any context, as long as you know that you have a refcount "
"on the folio.  If you do not already have one, folio_try_get() may be the "
"right interface for you to use."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1601
msgid "Decrement the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1603
msgid ""
"If the folio's reference count reaches zero, the memory will be released "
"back to the page allocator and may be used by another allocation "
"immediately.  Do not access the memory or the struct folio after calling "
"folio_put() unless you can be sure that it wasn't the last reference."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1610
#: ../include/linux/mm.h:1630 ../include/linux/mm.h:1670
#: ../../../core-api/mm-api:120: ../mm/swap.c:948
msgid ""
"May be called in process or interrupt context, but not in NMI context.  May "
"be called while holding a spinlock."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1620
msgid "Reduce the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1623
msgid "``int refs``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1622
msgid "The amount to subtract from the folio's reference count."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1623
msgid ""
"If the folio's reference count reaches zero, the memory will be released "
"back to the page allocator and may be used by another allocation "
"immediately.  Do not access the memory or the struct folio after calling "
"folio_put_refs() unless you can be sure that these weren't the last "
"references."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1661
msgid "Decrement the reference count on an array of folios."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1667
#: ../../../core-api/mm-api:120: ../mm/swap.c:943
msgid "``struct folio_batch *folios``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1662
#: ../../../core-api/mm-api:120: ../mm/swap.c:938
msgid "The folios."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:1663
msgid ""
"Like folio_put(), but for a batch of folios.  This is more efficient than "
"writing the loop yourself as it will optimise the locks which need to be "
"taken if the folios are freed.  The folios batch is returned empty and ready "
"to be reused for another batch; there is no need to reinitialise it."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2035
msgid "Return the Page Frame Number of a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2037
msgid ""
"A folio may contain multiple pages.  The pages have consecutive Page Frame "
"Numbers."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2041
msgid "The Page Frame Number of the first page in the folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2060
msgid "Create a PTE for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2061
msgid "The folio to create a PTE for"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2062
#: ../include/linux/mm.h:2078 ../include/linux/mm.h:2094
msgid "The page protection bits to use"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2063
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_ptes()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2067
#: ../include/linux/mm.h:2083 ../include/linux/mm.h:2099
msgid "A page table entry suitable for mapping this folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2076
msgid "Create a PMD for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2077
msgid "The folio to create a PMD for"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2079
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_pmd_at()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2092
msgid "Create a PUD for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2093
msgid "The folio to create a PUD for"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2095
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_pud_at()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2117
msgid "Report if a folio may be pinned for DMA."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2119
msgid ""
"This function checks if a folio has been pinned via a call to a function in "
"the pin_user_pages() family."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2122
msgid ""
"For small folios, the return value is partially fuzzy: false is not fuzzy, "
"because it means \"definitely not pinned for DMA\", but true means "
"\"probably pinned for DMA, but possibly a false positive due to having at "
"least GUP_PIN_COUNTING_BIAS worth of normal folio references\"."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2127
msgid ""
"False positives are OK, because: a) it's unlikely for a folio to get that "
"many refcounts, and b) all the callers of this routine are expected to be "
"able to deal gracefully with a false positive."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2131
msgid ""
"For most large folios, the result will be exactly correct. That's because we "
"have more tracking data available: the _pincount field is used instead of "
"the GUP_PIN_COUNTING_BIAS scheme."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2135
msgid ""
"For more information, please see Documentation/core-api/pin_user_pages.rst."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2138
msgid ""
"True, if it is likely that the folio has been \"dma-pinned\". False, if the "
"folio is definitely not dma-pinned."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2176
msgid "Query if a page is a zero page"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2177
msgid "The page to query"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2178
msgid "This returns true if **page** is one of the permanent zero pages."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2187
msgid "Query if a folio is a zero page"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2188
msgid "The folio to query"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2189
msgid "This returns true if **folio** is one of the permanent zero pages."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2256
msgid "The number of pages in the folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2259
msgid "A positive power of two."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2313
msgid "Move to the next physical folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2314
msgid "The folio we're currently operating on."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2315
msgid ""
"If you have physically contiguous memory which may span more than one folio "
"(eg a :c:type:`struct bio_vec <bio_vec>`), use this function to move from "
"one folio to the next.  Do not use it if the memory is only virtually "
"contiguous as the folios are almost certainly not adjacent to each other.  "
"This is the folio equivalent to writing ``page++``."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2322
msgid ""
"We assume that the folios are refcounted and/or locked at a higher level and "
"do not adjust the reference counts."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2324
msgid "The next struct folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2332
msgid "The size of the memory described by this folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2334
msgid ""
"A folio represents a number of bytes which is a power-of-two in size. This "
"function tells you which power-of-two the folio is.  See also folio_size() "
"and folio_order()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2339
#: ../include/linux/mm.h:2352
msgid ""
"The caller should have a reference on the folio to prevent it from being "
"split.  It is not necessary for the folio to be locked."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2341
msgid "The base-2 logarithm of the size of this folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2349
msgid "The number of bytes in a folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2354
msgid "The number of bytes in this folio."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2362
msgid "Whether the folio is mapped into the page tables of more than one MM"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2365
msgid ""
"This function checks if the folio maybe currently mapped into more than one "
"MM (\"maybe mapped shared\"), or if the folio is certainly mapped into a "
"single MM (\"mapped exclusively\")."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2369
msgid ""
"For KSM folios, this function also returns \"mapped shared\" when a folio is "
"mapped multiple times into the same MM, because the individual page mappings "
"are independent."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2373
msgid ""
"For small anonymous folios and anonymous hugetlb folios, the return value "
"will be exactly correct: non-KSM folios can only be mapped at most once into "
"an MM, and they cannot be partially mapped. KSM folios are considered shared "
"even if mapped multiple times into the same MM."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2378
msgid "For other folios, the result can be fuzzy:"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2379
msgid ""
"For partially-mappable large folios (THP), the return value can wrongly "
"indicate \"mapped shared\" (false positive) if a folio was mapped by more "
"than two MMs at one point in time."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2382
msgid ""
"For pagecache folios (including hugetlb), the return value can wrongly "
"indicate \"mapped shared\" (false positive) when two VMAs in the same MM "
"cover the same file range."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2386
msgid ""
"Further, this function only considers current page table mappings that are "
"tracked using the folio mapcount(s)."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2389
msgid "This function does not consider:"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2390
msgid ""
"If the folio might get mapped in the (near) future (e.g., swapcache, "
"pagecache, temporary unmapping for migration)."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2392
msgid "If the folio is mapped differently (VM_PFNMAP)."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2393
msgid ""
"If hugetlb page table sharing applies. Callers might want to check "
"hugetlb_pmd_shared()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2397
msgid "Whether the folio is estimated to be mapped into more than one MM."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2426
msgid "calculate the expected folio refcount"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2427
msgid "the folio"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2428
msgid ""
"Calculate the expected folio refcount, taking references from the pagecache, "
"swapcache, PG_private and page table mappings into account. Useful in "
"combination with folio_ref_count() to detect unexpected references (e.g., "
"GUP or other temporary references)."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2433
msgid ""
"Does currently not consider references from the LRU cache. If the folio was "
"isolated from the LRU (which is the case during migration or split), the LRU "
"cache does not apply."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2437
msgid ""
"Calling this function on an unmapped folio -- !folio_mapped() -- that is "
"locked will return a stable result."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2440
msgid ""
"Calling this function on a mapped folio will not result in a stable result, "
"because nothing stops additional page table mappings from coming (e.g., "
"fork()) or going (e.g., munmap())."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2444
msgid ""
"Calling this function without the folio lock will also not result in a "
"stable result: for example, the folio might get dropped from the swapcache "
"concurrently."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2448
msgid ""
"However, even when called without the folio lock or on a mapped folio, this "
"function can be used to detect unexpected references early (for example, if "
"it makes sense to even lock the folio and unmap it)."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2452
msgid ""
"The caller must add any reference (e.g., from folio_try_get()) it might be "
"holding itself to the result."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:2455
msgid "Returns the expected folio refcount."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3127
msgid "Virtual address of page table."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3133
msgid "``const struct ptdesc *pt``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3128
msgid "Page table descriptor."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3130
msgid "The first byte of the page table described by **pt**."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3143
msgid "Mark a ptdesc used to map the kernel"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3149
#: ../include/linux/mm.h:3161
msgid "``struct ptdesc *ptdesc``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3144
msgid "The ptdesc to be marked"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3145
msgid ""
"Kernel page tables often need special handling. Set a flag so that the "
"handling code knows this ptdesc will not be used for userspace."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3155
msgid "Mark a ptdesc as no longer used to map the kernel"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3156
msgid "The ptdesc to be unmarked"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3157
msgid ""
"Use when the ptdesc is no longer used to map the kernel and no longer needs "
"special handling."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3172
msgid "Check if a ptdesc is used to map the kernel"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3178
msgid "``const struct ptdesc *ptdesc``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3173
msgid "The ptdesc being tested"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3174
msgid "Call to tell if the ptdesc used to map the kernel."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3183
msgid "Allocate pagetables"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3184
msgid "GFP flags"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3185
msgid "desired pagetable order"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3186
msgid ""
"pagetable_alloc allocates memory for page tables as well as a page table "
"descriptor to describe that memory."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3190
msgid "The ptdesc describing the allocated page tables."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3216
msgid "Free pagetables"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3222
msgid "``struct ptdesc *pt``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3217
msgid "The page table descriptor"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3218
msgid ""
"pagetable_free frees the memory of all page tables described by a page table "
"descriptor and the memory for the descriptor itself."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3761
msgid "Find a VMA at a specific address"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3767
#: ../../../core-api/mm-api:113: ../mm/rmap.c:2645
#: ../../../core-api/mm-api:115: ../mm/mmap.c:880 ../mm/mmap.c:900
#: ../mm/mmap.c:917 ../../../core-api/mm-api:121: ../mm/memcontrol.c:904
#: ../mm/memcontrol.c:4789 ../../../core-api/mm-api:132:
#: ../mm/mmu_notifier.c:684 ../mm/mmu_notifier.c:739 ../mm/mmu_notifier.c:960
msgid "``struct mm_struct *mm``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3762
#: ../../../core-api/mm-api:115: ../mm/mmap.c:875
msgid "The process address space."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3763
msgid "The user address."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3765
msgid "The vm_area_struct at the given address, ``NULL`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3824
msgid ""
"helper for mmap_prepare hook to specify that a pure PFN remap is required."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3830
#: ../include/linux/mm.h:3857 ../include/linux/mm.h:3869
#: ../include/linux/mm.h:3887 ../../../core-api/mm-api:123: ../mm/shmem.c:5963
msgid "``struct vm_area_desc *desc``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3826
#: ../include/linux/mm.h:3853 ../include/linux/mm.h:3865
#: ../include/linux/mm.h:3883
msgid "The VMA descriptor for the VMA requiring remap."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3827
#: ../include/linux/mm.h:3866
msgid "The virtual address to start the remap from, must be within the VMA."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3829
#: ../include/linux/mm.h:3855 ../include/linux/mm.h:3868
#: ../include/linux/mm.h:3885
msgid "``unsigned long start_pfn``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3828
#: ../include/linux/mm.h:3854 ../include/linux/mm.h:3867
#: ../include/linux/mm.h:3884
msgid "The first PFN in the range to remap."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3829
#: ../include/linux/mm.h:3868
msgid ""
"The size of the range to remap, in bytes, at most spanning to the end of the "
"VMA."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3851
msgid ""
"helper for mmap_prepare hook to specify that the entirety of a VMA should be "
"PFN remapped."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3863
msgid ""
"helper for mmap_prepare hook to specify that a pure PFN I/O remap is "
"required."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:3881
msgid ""
"helper for mmap_prepare hook to specify that the entirety of a VMA should be "
"PFN I/O remapped."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:4453
msgid "Are transhuge page-table entries considered special?"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:4459
#: ../../../core-api/mm-api:113: ../mm/rmap.c:750
msgid "``const struct vm_area_struct *vma``"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:4454
msgid "Pointer to the struct vm_area_struct to consider"
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:4455
msgid ""
"Whether transhuge page-table entries are considered \"special\" following "
"the definition in vm_normal_page()."
msgstr ""

#: ../../../core-api/mm-api:106: ../include/linux/mm.h:4459
msgid ""
"true if transhuge page-table entries should be considered special, false "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:71
msgid "The reference count on this folio."
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:73
msgid ""
"The refcount is usually incremented by calls to folio_get() and decremented "
"by calls to folio_put().  Some typical users of the folio refcount:"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:77
msgid "Each reference from a page table"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:78
msgid "The page cache"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:79
msgid "Filesystem private data"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:80
msgid "The LRU list"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:81
msgid "Pipes"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:82
msgid "Direct IO which references this page in the process address space"
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:85
msgid "The number of references to this folio."
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:252
msgid "Attempt to increase the refcount on a folio."
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:254
msgid ""
"If you do not already have a reference to a folio, you can attempt to get "
"one using this function.  It may fail if, for example, the folio has been "
"freed since you found a pointer to it, or it is frozen for the purposes of "
"splitting or migration."
msgstr ""

#: ../../../core-api/mm-api:108: ../include/linux/page_ref.h:260
msgid "True if the reference count was successfully incremented."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1640
msgid ""
"helper function to quickly check if a struct zone is a highmem zone or not. "
"This is an attempt to keep references to ZONE_{DMA/NORMAL/HIGHMEM/etc} in "
"general code to a minimum."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1646
msgid "``const struct zone *zone``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1643
#: ../include/linux/mmzone.h:1690
msgid "pointer to struct zone variable"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1644
msgid "1 for a highmem zone, 0 otherwise"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1683
msgid "``for_each_online_pgdat (pgdat)``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1681
msgid "helper macro to iterate over all online nodes"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1687
msgid "``pgdat``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1682
msgid "pointer to a pg_data_t variable"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1691
msgid "``for_each_zone (zone)``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1689
msgid "helper macro to iterate over all memory zones"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1695
#: ../include/linux/mmzone.h:1783 ../include/linux/mmzone.h:1807
msgid "``zone``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1691
msgid ""
"The user only needs to declare the zone variable, for_each_zone fills it in."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1728
msgid ""
"Returns the next zone at or below highest_zoneidx within the allowed "
"nodemask using a cursor within a zonelist as a starting point"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1734
msgid "``struct zoneref *z``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1729
msgid "The cursor used as a starting point for the search"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1731
#: ../include/linux/mmzone.h:1755
msgid "``enum zone_type highest_zoneidx``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1730
#: ../include/linux/mmzone.h:1754 ../include/linux/mmzone.h:1781
#: ../include/linux/mmzone.h:1805
msgid "The zone index of the highest zone to return"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1732
#: ../include/linux/mmzone.h:1756
msgid "``nodemask_t *nodes``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1731
#: ../include/linux/mmzone.h:1755
msgid "An optional nodemask to filter the zonelist with"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1732
msgid ""
"This function returns the next zone at or below a given zone index that is "
"within the allowed nodemask using a cursor as the starting point for the "
"search. The zoneref returned is a cursor that represents the current zone "
"being examined. It should be advanced by one before calling "
"next_zones_zonelist again."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1739
msgid ""
"the next zone at or below highest_zoneidx within the allowed nodemask using "
"a cursor within a zonelist as a starting point"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1752
msgid ""
"Returns the first zone at or below highest_zoneidx within the allowed "
"nodemask in a zonelist"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1758
msgid "``struct zonelist *zonelist``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1753
msgid "The zonelist to search for a suitable zone"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1756
msgid ""
"This function returns the first zone at or below a given zone index that is "
"within the allowed nodemask. The zoneref returned is a cursor that can be "
"used to iterate the zonelist with next_zones_zonelist by advancing it by one "
"before calling."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1761
msgid ""
"When no eligible zone is found, zoneref->zone is NULL (zoneref itself is "
"never NULL). This may happen either genuinely, or due to concurrent nodemask "
"update due to cpuset modification."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1766
msgid "Zoneref pointer for the first suitable zone found"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1779
msgid "``for_each_zone_zonelist_nodemask (zone, z, zlist, highidx, nodemask)``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1777
msgid ""
"helper macro to iterate over valid zones in a zonelist at or below a given "
"zone index and within a nodemask"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1778
#: ../include/linux/mmzone.h:1802
msgid "The current zone in the iterator"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1780
#: ../include/linux/mmzone.h:1804
msgid "``z``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1779
msgid "The current pointer within zonelist->_zonerefs being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1781
#: ../include/linux/mmzone.h:1805
msgid "``zlist``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1780
#: ../include/linux/mmzone.h:1804
msgid "The zonelist being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1782
#: ../include/linux/mmzone.h:1806
msgid "``highidx``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1783
msgid "``nodemask``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1782
msgid "Nodemask allowed by the allocator"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1783
msgid ""
"This iterator iterates though all zones at or below a given zone index and "
"within a given nodemask"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1803
msgid "``for_each_zone_zonelist (zone, z, zlist, highidx)``"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1801
msgid ""
"helper macro to iterate over valid zones in a zonelist at or below a given "
"zone index"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1803
msgid "The current pointer within zonelist->zones being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:1806
msgid "This iterator iterates though all zones at or below a given zone index."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:2157
msgid "check if there is a valid memory map entry for a PFN"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:2158
msgid "the page frame number to check"
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:2159
msgid ""
"Check if there is a valid memory map entry aka struct page for the **pfn**. "
"Note, that availability of the memory map entry does not imply that there is "
"actual usable memory at that **pfn**. The struct page may represent a hole "
"or an unusable page frame."
msgstr ""

#: ../../../core-api/mm-api:109: ../include/linux/mmzone.h:2165
msgid "1 for PFNs that have memory map entries and 0 otherwise"
msgstr ""

#: ../../../core-api/mm-api:110: ../mm/util.c:681
msgid "Find the mapping where this folio is stored."
msgstr ""

#: ../../../core-api/mm-api:110: ../mm/util.c:683
msgid ""
"For folios which are in the page cache, return the mapping that this page "
"belongs to.  Folios in the swap cache return the swap mapping this page is "
"stored in (which is different from the mapping for the swap file or swap "
"device where the data is stored)."
msgstr ""

#: ../../../core-api/mm-api:110: ../mm/util.c:688
msgid ""
"You can call this for folios which aren't in the swap cache or page cache "
"and it will return NULL."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:160
msgid "attach an anon_vma to a memory region"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:161
msgid "the memory region in question"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:162
msgid ""
"This makes sure the memory mapping described by 'vma' has an 'anon_vma' "
"attached to it, so that we can associate the anonymous pages mapped into it "
"with that anon_vma."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:166
msgid ""
"The common case will be that we already have one, which is handled inline by "
"anon_vma_prepare(). But if not we either need to find an adjacent mapping "
"that we can re-use the anon_vma from (very common when the only reason for "
"splitting a vma has been mprotect()), or we allocate a new one."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:173
msgid ""
"Anon-vma allocations are very subtle, because we may have optimistically "
"looked up an anon_vma in folio_lock_anon_vma_read() and that may actually "
"touch the rwsem even in the newly allocated vma (it depends on RCU to make "
"sure that the anon_vma isn't actually destroyed)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:179
msgid ""
"As a result, we need to do proper anon_vma locking even for the new "
"allocation. At the same time, we do not want to do any locking for the "
"common case of already having an anon_vma."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:746
msgid "The virtual address of a page in this VMA."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:747
msgid "The folio containing the page."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:748
msgid "The page within the folio."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:749
msgid "The VMA we need to know the address in."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:750
msgid ""
"Calculates the user virtual address of this page in the specified VMA. It is "
"the caller's responsibility to check the page is actually within the VMA.  "
"There may not currently be a PTE pointing at this page, but if a page fault "
"occurs at this address, this is the page which will be accessed."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:757
msgid ""
"Caller should hold a reference to the folio.  Caller should hold a lock (eg "
"the i_mmap_lock or the mmap_lock) which keeps the VMA from being altered."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:761
msgid "The virtual address corresponding to this page in the VMA."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:933
msgid "Test if the folio was referenced."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:936
msgid "``int is_locked``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:935
msgid "Caller holds lock on the folio."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:937 ../../../core-api/mm-api:121:
#: ../mm/memcontrol.c:689 ../mm/memcontrol.c:833 ../mm/memcontrol.c:1146
#: ../mm/memcontrol.c:1307 ../mm/memcontrol.c:1538 ../mm/memcontrol.c:1563
#: ../mm/memcontrol.c:1824 ../mm/memcontrol.c:4704
msgid "``struct mem_cgroup *memcg``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:936
msgid "target memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:938
msgid "``vm_flags_t *vm_flags``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:937
msgid "A combination of all the vma->vm_flags which referenced the folio."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:938
msgid "Quick test_and_clear_referenced for all mappings of a folio,"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:941
msgid ""
"The number of mappings which referenced the folio. Return -1 if the function "
"bailed out due to rmap lock contention."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1133
msgid "Write-protect all mappings in a specified range."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1135
msgid "The mapping whose reverse mapping should be traversed."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1137 ../mm/rmap.c:1185
msgid "``pgoff_t pgoff``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1136
msgid "The page offset at which **pfn** is mapped within **mapping**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1137
msgid "The PFN of the page mapped in **mapping** at **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1138
msgid "The number of physically contiguous base pages spanned."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1139
msgid ""
"Traverses the reverse mapping, finding all VMAs which contain a shared "
"mapping of the pages in the specified range in **mapping**, and write-"
"protects them (that is, updates the page tables to mark the mappings read-"
"only such that a write protection fault arises when the mappings are written "
"to)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1144
msgid ""
"The **pfn** value need not refer to a folio, but rather can reference a "
"kernel allocation which is mapped into userland. We therefore do not require "
"that the page maps to a folio with a valid mapping or index field, rather "
"the caller specifies these in **mapping** and **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1150
msgid "the number of write-protected PTEs, or an error."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1178
msgid ""
"Cleans the PTEs (including PMDs) mapped with range of [**pfn**, **pfn** + "
"**nr_pages**) at the specific offset (**pgoff**) within the **vma** of "
"shared mappings. And since clean PTEs should also be readonly, write "
"protects them too."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1182
msgid "start pfn."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1183
msgid "number of physically contiguous pages srarting with **pfn**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1184
msgid "page offset that the **pfn** mapped with."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1185
msgid "vma that **pfn** mapped within."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1186
msgid "Returns the number of cleaned PTEs (including PMDs)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1311
msgid "move a folio to our anon_vma"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1312
msgid "The folio to move to our anon_vma"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1313
msgid "The vma the folio belongs to"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1314
msgid ""
"When a folio belongs exclusively to one process after a COW event, that "
"folio can be moved into the anon_vma that belongs to just that process, so "
"the rmap code will not search the parent or sibling processes."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1336
msgid "set up a new anonymous rmap for a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1337
msgid "The folio to set up the new anonymous rmap for."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1338
msgid "VM area to add the folio to."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1339
msgid "User virtual address of the mapping"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1341
msgid "``bool exclusive``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1340
msgid "Whether the folio is exclusive to the process."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1368
msgid "sanity check anonymous rmap addition"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1369
msgid "The folio containing **page**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1370
msgid "the page to check the mapping of"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1371 ../mm/rmap.c:1509
msgid "the vm area in which the mapping is added"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1372 ../mm/rmap.c:1510
msgid "the user virtual address mapped"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1459
msgid "add PTE mappings to a page range of an anon folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1460 ../mm/rmap.c:1599
msgid "The folio to add the mappings to"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1461 ../mm/rmap.c:1485
#: ../mm/rmap.c:1600 ../mm/rmap.c:1617 ../mm/rmap.c:1637
msgid "The first page to add"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1462
msgid "The number of pages which will be mapped"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1463 ../mm/rmap.c:1602
msgid "The vm area in which the mappings are added"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1464 ../mm/rmap.c:1487
msgid "The user virtual address of the first page to map"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1466 ../mm/rmap.c:1489
#: ../mm/rmap.c:1512
msgid "``rmap_t flags``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1465 ../mm/rmap.c:1488
#: ../mm/rmap.c:1511
msgid "The rmap flags"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1466
msgid ""
"The page range of folio is defined by [first_page, first_page + nr_pages)"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1468
msgid ""
"The caller needs to hold the page table lock, and the page must be locked in "
"the anon_vma case: to serialize mapping,index checking after setting, and to "
"ensure that an anon folio is not being upgraded racily to a KSM folio (but "
"KSM folios are never downgraded)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1483
msgid "add a PMD mapping to a page range of an anon folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1484 ../mm/rmap.c:1616
#: ../mm/rmap.c:1636
msgid "The folio to add the mapping to"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1486 ../mm/rmap.c:1618
#: ../mm/rmap.c:1638
msgid "The vm area in which the mapping is added"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1489
msgid ""
"The page range of folio is defined by [first_page, first_page + HPAGE_PMD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1491
msgid ""
"The caller needs to hold the page table lock, and the page must be locked in "
"the anon_vma case: to serialize mapping,index checking after setting."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1507
msgid "Add mapping to a new anonymous folio."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1508
msgid "The folio to add the mapping to."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1512
msgid ""
"Like folio_add_anon_rmap_*() but must only be called on *new* folios. This "
"means the inc-and-test can be bypassed. The folio doesn't necessarily need "
"to be locked while it's exclusive unless two threads map it concurrently. "
"However, the folio must be locked if it's shared."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1518
msgid "If the folio is pmd-mappable, it is accounted as a THP."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1598
msgid "add PTE mappings to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1601
msgid "The number of pages that will be mapped using PTEs"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1603 ../mm/rmap.c:1771
msgid "The page range of the folio is defined by [page, page + nr_pages)"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1605 ../mm/rmap.c:1621
#: ../mm/rmap.c:1641 ../mm/rmap.c:1773 ../mm/rmap.c:1789 ../mm/rmap.c:1809
msgid "The caller needs to hold the page table lock."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1615
msgid "add a PMD mapping to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1619 ../mm/rmap.c:1787
msgid "The page range of the folio is defined by [page, page + HPAGE_PMD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1635
msgid "add a PUD mapping to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1639 ../mm/rmap.c:1807
msgid "The page range of the folio is defined by [page, page + HPAGE_PUD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1766
msgid "remove PTE mappings from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1767
msgid "The folio to remove the mappings from"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1768 ../mm/rmap.c:1785
#: ../mm/rmap.c:1805
msgid "The first page to remove"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1769
msgid "The number of pages that will be removed from the mapping"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1770
msgid "The vm area from which the mappings are removed"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1783
msgid "remove a PMD mapping from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1784 ../mm/rmap.c:1804
msgid "The folio to remove the mapping from"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1786 ../mm/rmap.c:1806
msgid "The vm area from which the mapping is removed"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:1803
msgid "remove a PUD mapping from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2250
msgid "Try to remove all page table mappings to a folio."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2251
msgid "The folio to unmap."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2253 ../mm/rmap.c:2595
msgid "``enum ttu_flags flags``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2252 ../mm/rmap.c:2594
msgid "action and flags"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2253
msgid ""
"Tries to remove all the page table entries which are mapping this folio.  It "
"is the caller's responsibility to check if the folio is still mapped if "
"needed (use TTU_SYNC to prevent accounting races)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2258
msgid "Caller must hold the folio lock."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2592
msgid "try to replace all page table mappings with swap entries"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2593
msgid "the folio to replace page table entries for"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2595
msgid ""
"Tries to remove all the page table entries which are mapping this folio and "
"replace them with special swap entries. Caller must hold the folio lock."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2639
msgid "Mark a page for exclusive use by a device"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2640
msgid "mm_struct of associated target process"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2641
msgid "the virtual address to mark for exclusive device access"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2643
msgid "``void *owner``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2642
msgid "passed to MMU_NOTIFY_EXCLUSIVE range notifier to allow filtering"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2644
#: ../../../core-api/mm-api:123: ../mm/shmem.c:2669
msgid "``struct folio **foliop``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2643
msgid "folio pointer will be stored here on success."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2644
msgid ""
"This function looks up the page mapped at the given address, grabs a folio "
"reference, locks the folio and replaces the PTE with special device-"
"exclusive PFN swap entry, preventing access through the process page tables. "
"The function will return with the folio locked and referenced."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2649
msgid ""
"On fault, the device-exclusive entries are replaced with the original PTE "
"under folio lock, after calling MMU notifiers."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2652
msgid ""
"Only anonymous non-hugetlb folios are supported and the VMA must have write "
"permissions such that we can fault in the anonymous page writable in order "
"to mark it exclusive. The caller must hold the mmap_lock in read mode."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2657
msgid ""
"A driver using this to program access from a device must use a mmu notifier "
"critical section to hold a device specific lock during programming. Once "
"programming is complete it should drop the folio lock and reference after "
"which point CPU access to the page will revoke the exclusive access."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2662
#: ../../../core-api/mm-api:118: ../mm/memremap.c:359
msgid "**Notes**"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2663
msgid ""
"This function always operates on individual PTEs mapping individual pages. "
"PMD-sized THPs are first remapped to be mapped by PTEs before the conversion "
"happens on a single PTE corresponding to **addr**."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2666
msgid ""
"While concurrent access through the process page tables is prevented, "
"concurrent access through other page references (e.g., earlier GUP "
"invocation) is not handled and not supported."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2669
msgid ""
"device-exclusive entries are considered \"clean\" and \"old\" by core-mm. "
"Device drivers must update the folio state when informed by MMU notifiers."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2674
msgid "pointer to mapped page on success, otherwise a negative error."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2872
msgid ""
"Traverse the reverse mapping for a file-backed mapping of a page mapped "
"within a specified page cache object at a specified offset."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2875
msgid ""
"Either the folio whose mappings to traverse, or if NULL, the callbacks "
"specified in **rwc** will be configured such as to be able to look up "
"mappings correctly."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2878
msgid ""
"The page cache object whose mapping VMAs we intend to traverse. If **folio** "
"is non-NULL, this should be equal to folio_mapping(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2882
msgid "``pgoff_t pgoff_start``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2881
msgid ""
"The offset within **mapping** of the page which we are looking up. If "
"**folio** is non-NULL, this should be equal to folio_pgoff(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2884
msgid ""
"The number of pages mapped by the mapping. If **folio** is non-NULL, this "
"should be equal to folio_nr_pages(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2887
msgid "``struct rmap_walk_control *rwc``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2886
msgid ""
"The reverse mapping walk control object describing how the traversal should "
"proceed."
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2889
msgid "``bool locked``"
msgstr ""

#: ../../../core-api/mm-api:113: ../mm/rmap.c:2888
msgid "Is the **mapping** already locked? If not, we acquire the lock."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:100
msgid "isolate a movable_ops page for migration"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:103
msgid "``isolate_mode_t mode``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:102
msgid "The isolation mode."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:103
msgid ""
"Try to isolate a movable_ops page for migration. Will fail if the page is "
"not a movable_ops page, if the page is already isolated for migration or if "
"the page was just was released by its owner."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:107
msgid ""
"Once isolated, the page cannot get freed until it is either putback or "
"migrated."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:110
msgid "Returns true if isolation succeeded, otherwise false."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:186
msgid "putback an isolated movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:187
msgid "The isolated page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:188
msgid "Putback an isolated movable_ops page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:190
msgid "After the page was putback, it might get freed instantly."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:211
msgid "migrate an isolated movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:217
msgid "``struct page *dst``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:212
msgid "The destination page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:214
msgid "``struct page *src``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:213
msgid "The source page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:215 ../mm/migrate.c:885
#: ../mm/migrate.c:1010 ../mm/migrate.c:1032
msgid "``enum migrate_mode mode``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:214
msgid "The migration mode."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:215
msgid "Migrate an isolated movable_ops page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:217
msgid ""
"If the src page was already released by its owner, the src page is un-"
"isolated (putback) and migration succeeds; the migration core will be the "
"owner of both pages."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:221
msgid ""
"If the src page was not released by its owner and the migration was "
"successful, the owner of the src page and the dst page are swapped and the "
"src page is un-isolated."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:225
msgid ""
"If migration fails, the ownership stays unmodified and the src page remains "
"isolated: migration may be retried later or the page can be putback."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:228
msgid ""
"TODO: migration core will treat both pages as folios and lock them before "
"this call to unlock them after this call. Further, the folio refcounts on "
"src and dst are also released by migration core. These pages will not be "
"folios in the future, so that must be reworked."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:233
msgid "Returns 0 on success, otherwise a negative error code."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:880
msgid "Simple folio migration."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:881
msgid "The address_space containing the folio."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:883 ../mm/migrate.c:1008
#: ../mm/migrate.c:1030
msgid "``struct folio *dst``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:882
msgid "The folio to migrate the data to."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:884 ../mm/migrate.c:1009
#: ../mm/migrate.c:1031
msgid "``struct folio *src``"
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:883
msgid "The folio containing the current data."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:884
msgid "How to migrate the page."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:885
msgid ""
"Common logic to directly migrate a single LRU folio suitable for folios that "
"do not have private data."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:888
msgid "Folios are locked upon entry and exit."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1005 ../mm/migrate.c:1027
msgid "Migration function for folios with buffers."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1006 ../mm/migrate.c:1028
msgid "The address space containing **src**."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1007 ../mm/migrate.c:1029
msgid "The folio to migrate to."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1008 ../mm/migrate.c:1030
msgid "The folio to migrate from."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1009 ../mm/migrate.c:1031
msgid "How to migrate the folio."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1010
msgid ""
"This function can only be used if the underlying filesystem guarantees that "
"no other references to **src** exist. For example attached buffer heads are "
"accessed only under the folio lock.  If your filesystem cannot provide this "
"guarantee, buffer_migrate_folio_norefs() may be more appropriate."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1017 ../mm/migrate.c:1038
msgid "0 on success or a negative errno on failure."
msgstr ""

#: ../../../core-api/mm-api:114: ../mm/migrate.c:1032
msgid ""
"Like buffer_migrate_folio() except that this variant is more careful and "
"checks that there are also no buffer head references. This function is the "
"right one for mappings where buffer heads are directly looked up and "
"referenced (such as block device mappings)."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:278
msgid ""
"Perform a userland memory mapping into the current process address space of "
"length **len** with protection bits **prot**, mmap flags **flags** (from "
"which VMA flags will be inferred), and any additional VMA flags to apply "
"**vm_flags**. If this is a file-backed mapping then the file is specified in "
"**file** and page offset into the file via **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:310
msgid ""
"An optional struct file pointer describing the file which is to be mapped, "
"if a file-backed mapping."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:312
msgid ""
"If non-zero, hints at (or if **flags** has MAP_FIXED set, specifies) the "
"address at which to perform this mapping. See mmap (2) for details. Must be "
"page-aligned."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:315
msgid ""
"The length of the mapping. Will be page-aligned and must be at least 1 page "
"in size."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:318
msgid "``unsigned long prot``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:317
msgid ""
"Protection bits describing access required to the mapping. See mmap (2) for "
"details."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:319
msgid ""
"Flags specifying how the mapping should be performed, see mmap (2) for "
"details."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:322
msgid "``vm_flags_t vm_flags``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:321
msgid "VMA flags which should be set by default, or 0 otherwise."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:322
msgid "Page offset into the **file** if file-backed, should be 0 otherwise."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:324
msgid "``unsigned long *populate``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:323
msgid ""
"A pointer to a value which will be set to 0 if no population of the range is "
"required, or the number of bytes to populate if it is. Must be non-NULL. See "
"mmap (2) for details as to under what circumstances population of the range "
"occurs."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:328
msgid "``struct list_head *uf``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:327
msgid ""
"An optional pointer to a list head to track userfaultfd unmap events should "
"unmapping events arise. If provided, it is up to the caller to manage this."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:279
msgid ""
"This function does not perform security checks on the file and assumes, if "
"**uf** is non-NULL, the caller has provided a list head to track unmap "
"events for userfaultfd **uf**."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:283
msgid ""
"It also simply indicates whether memory population is required by setting "
"**populate**, which must be non-NULL, expecting the caller to actually "
"perform this task itself if appropriate."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:287
msgid ""
"This function will invoke architecture-specific (and if provided and "
"relevant, file system-specific) logic to determine the most appropriate "
"unmapped area in which to place the mapping if not MAP_FIXED."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:291
msgid ""
"Callers which require userland mmap() behaviour should invoke vm_mmap(), "
"which is also exported for module use."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:294
msgid ""
"Those which require this behaviour less security checks, userfaultfd and "
"populate behaviour, and who handle the mmap write lock themselves, should "
"call this function."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:298
msgid ""
"Note that the returned address may reside within a merged VMA if an "
"appropriate merge were to take place, so it doesn't necessarily specify the "
"start of a VMA, rather only the start of a valid mapped range of length "
"**len** bytes, rounded down to the nearest page size."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:303
msgid "The caller must write-lock current->mm->mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:331
msgid ""
"Either an error, or the address at which the requested mapping has been "
"performed."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:874
msgid "Look up the first VMA which intersects the interval"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:877
msgid "``unsigned long start_addr``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:876
msgid "The inclusive start user address."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:878
msgid "``unsigned long end_addr``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:877
msgid "The exclusive end user address."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:879
msgid ""
"The first VMA within the provided range, ``NULL`` otherwise.  Assumes "
"start_addr < end_addr."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:894
msgid "Find the VMA for a given address, or the next VMA."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:895 ../mm/mmap.c:913
msgid "The mm_struct to check"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:896 ../mm/mmap.c:914
msgid "The address"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:898
msgid ""
"The VMA associated with addr, or the next VMA. May return ``NULL`` in the "
"case of no VMA at addr or above."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:911
msgid ""
"Find the VMA for a given address, or the next vma and set ``pprev`` to the "
"previous VMA, if any."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:916
msgid "``struct vm_area_struct **pprev``"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:915
msgid "The pointer to set to the previous VMA"
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:916
msgid ""
"Note that RCU lock is missing here since the external mmap_lock() is used "
"instead."
msgstr ""

#: ../../../core-api/mm-api:115: ../mm/mmap.c:920
msgid ""
"The VMA associated with **addr**, or the next vma. May return ``NULL`` in "
"the case of no vma at addr or above."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1079
msgid "register a newly allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1085 ../mm/kmemleak.c:1153
#: ../mm/kmemleak.c:1169 ../mm/kmemleak.c:1203 ../mm/kmemleak.c:1239
#: ../mm/kmemleak.c:1255 ../mm/kmemleak.c:1286 ../mm/kmemleak.c:1304
#: ../mm/kmemleak.c:1324
msgid "``const void *ptr``"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1080 ../mm/kmemleak.c:1148
#: ../mm/kmemleak.c:1198 ../mm/kmemleak.c:1234 ../mm/kmemleak.c:1250
#: ../mm/kmemleak.c:1281 ../mm/kmemleak.c:1319
msgid "pointer to beginning of the object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1081 ../mm/kmemleak.c:1105
#: ../mm/kmemleak.c:1124 ../mm/kmemleak.c:1339
msgid "size of the object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1083
msgid "``int min_count``"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1082
msgid ""
"minimum number of references to this object. If during memory scanning a "
"number of references less than **min_count** is found, the object is "
"reported as a memory leak. If **min_count** is 0, the object is never "
"reported as a leak. If **min_count** is -1, the object is ignored (not "
"scanned and not reported as a leak)"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1087 ../mm/kmemleak.c:1302
#: ../mm/kmemleak.c:1340
msgid "kmalloc() flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1088
msgid ""
"This function is called from the kernel allocators when a new object (memory "
"block) is allocated (kmem_cache_alloc, kmalloc etc.)."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1103
msgid "register a newly allocated __percpu object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1109 ../mm/kmemleak.c:1187
#: ../mm/kmemleak.c:1272
msgid "``const void __percpu *ptr``"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1104 ../mm/kmemleak.c:1182
msgid "__percpu pointer to beginning of the object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1106
msgid "flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1107
msgid ""
"This function is called from the kernel percpu allocator when a new object "
"(memory block) is allocated (alloc_percpu)."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1122
msgid "register a newly vmalloc'ed object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1128
msgid "``const struct vm_struct *area``"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1123
msgid "pointer to vm_struct"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1125
msgid "__vmalloc() flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1126
msgid ""
"This function is called from the vmalloc() kernel allocator when a new "
"object (memory block) is allocated."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1147
msgid "unregister a previously registered object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1149
msgid ""
"This function is called from the kernel allocators when an object (memory "
"block) is freed (kmem_cache_free, kfree, vfree etc.)."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1163
msgid "partially unregister a previously registered object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1164
msgid ""
"pointer to the beginning or inside the object. This also represents the "
"start of the range to be freed"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1166 ../mm/kmemleak.c:1360
msgid "size to be unregistered"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1167
msgid ""
"This function is called when only a part of a memory block is freed (usually "
"from the bootmem allocator)."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1181
msgid "unregister a previously registered __percpu object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1183
msgid ""
"This function is called from the kernel percpu allocator when an object "
"(memory block) is freed (free_percpu)."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1197
msgid "update object allocation stack trace"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1199
msgid ""
"Override the object allocation stack trace for cases where the actual "
"allocation place is not always useful."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1233
msgid "mark an allocated object as false positive"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1235
msgid ""
"Calling this function on an object will cause the memory block to no longer "
"be reported as leak and always be scanned."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1249
msgid "mark an allocated object as transient false positive"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1251
msgid ""
"Calling this function on an object will cause the memory block to not be "
"reported as a leak temporarily. This may happen, for example, if the object "
"is part of a singly linked list and the ->next reference to it is changed."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1266
msgid "similar to kmemleak_ignore but taking a percpu address argument"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1268
msgid "percpu address of the object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1280
msgid "ignore an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1282
msgid ""
"Calling this function on an object will cause the memory block to be ignored "
"(not scanned and not reported as a leak). This is usually done when it is "
"known that the corresponding block is not a leak and does not contain any "
"references to other allocated memory blocks."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1298
msgid "limit the range to be scanned in an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1299
msgid ""
"pointer to beginning or inside the object. This also represents the start of "
"the scan area"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1301
msgid "size of the scan area"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1303
msgid ""
"This function is used when it is known that only certain parts of an object "
"contain references to other objects. Kmemleak will only scan these areas "
"reducing the number false negatives."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1318
msgid "do not scan an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1320
msgid ""
"This function notifies kmemleak not to scan the given memory block. Useful "
"in situations where it is known that the given object does not contain any "
"references to other objects. Kmemleak will not scan such objects reducing "
"the number of false negatives."
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1336
msgid "similar to kmemleak_alloc but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1342 ../mm/kmemleak.c:1362
#: ../mm/kmemleak.c:1378
msgid "``phys_addr_t phys``"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1338 ../mm/kmemleak.c:1374
msgid "physical address of the object"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1356
msgid "similar to kmemleak_free_part but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1358
msgid ""
"physical address if the beginning or inside an object. This also represents "
"the start of the range to be freed"
msgstr ""

#: ../../../core-api/mm-api:116: ../mm/kmemleak.c:1372
msgid "similar to kmemleak_ignore but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:355
msgid "remap and provide memmap backing for the given resource"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:361
msgid "``struct device *dev``"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:356
msgid "hosting device for **res**"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:358
msgid "``struct dev_pagemap *pgmap``"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:357
msgid "pointer to a struct dev_pagemap"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:359
msgid ""
"1/ At a minimum the range and type members of **pgmap** must be initialized"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:360
msgid "by the caller before passing it to this function"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:362
msgid "2/ The altmap field may optionally be initialized, in which case"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:363
msgid "PGMAP_ALTMAP_VALID must be set in pgmap->flags."
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:365
msgid ""
"3/ The ref field may optionally be provided, in which pgmap->ref must be"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:366
msgid ""
"'live' on entry and will be killed and reaped at "
"devm_memremap_pages_release() time, or if this routine fails."
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:369
msgid "4/ range is expected to be a host memory range that could feasibly be"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:370
msgid ""
"treated as a \"System RAM\" range, i.e. not a device mmio range, but this is "
"not enforced."
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:398
msgid "take a new live reference on the dev_pagemap for **pfn**"
msgstr ""

#: ../../../core-api/mm-api:118: ../mm/memremap.c:399
msgid "page frame number to lookup page_map"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:1030
msgid "Page size granularity for this VMA."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:1031
msgid "The user mapping."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:1032
msgid ""
"Folios in this VMA will be aligned to, and at least the size of the number "
"of bytes returned by this function."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:1036
msgid "The default size of the folios allocated when backing a VMA."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6910
msgid "Unmap a pmd table if it is shared by multiple users"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6916
msgid "``struct mmu_gather *tlb``"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6911
msgid "the current mmu_gather."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6912
msgid "the vma covering the pmd table."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6913
msgid "the address we are trying to unshare."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6915
msgid "``pte_t *ptep``"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6914
msgid "pointer into the (pmd) page table."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6915
msgid ""
"Called with the page table lock held, the i_mmap_rwsem held in write mode "
"and the hugetlb vma lock held in write mode."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6919
msgid ""
"The caller must call huge_pmd_unshare_flush() before dropping the "
"i_mmap_rwsem."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:6922
msgid ""
"1 if it was a shared PMD table and it got unmapped, or 0 if it was not a "
"shared PMD table."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7106
msgid "try to isolate an allocated hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7107
msgid "the folio to isolate"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7109
#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3921
#: ../mm/huge_memory.c:4210
msgid "``struct list_head *list``"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7108
msgid "the list to add the folio to on success"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7109
msgid ""
"Isolate an allocated (refcount > 0) hugetlb folio, marking it as isolated/"
"non-migratable, and moving it from the active list to the given list."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7113
msgid ""
"Isolation will fail if **folio** is not an allocated hugetlb folio, or if it "
"is already isolated/non-migratable."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7116
msgid ""
"On success, an additional folio reference is taken that must be dropped "
"using folio_putback_hugetlb() to undo the isolation."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7120
msgid "True if isolation worked, otherwise False."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7171
msgid "unisolate a hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7172
msgid "the isolated hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7173
msgid ""
"Putback/un-isolate the hugetlb folio that was previous isolated using "
"folio_isolate_hugetlb(): marking it non-isolated/migratable and putting it "
"back onto the active list."
msgstr ""

#: ../../../core-api/mm-api:119: ../mm/hugetlb.c:7177
msgid ""
"Will drop the additional folio reference obtained through "
"folio_isolate_hugetlb()."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:443
msgid "Mark a folio as having seen activity."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:444
msgid "The folio to mark."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:445
msgid "This function will perform one of the following transitions:"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:447
msgid "inactive,unreferenced      ->      inactive,referenced"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:448
msgid "inactive,referenced        ->      active,unreferenced"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:449
msgid "active,unreferenced        ->      active,referenced"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:451
msgid ""
"When a newly allocated folio is not yet visible, so safe for non-atomic ops, "
"__folio_set_referenced() may be substituted for folio_mark_accessed()."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:492
msgid "Add a folio to an LRU list."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:493 ../mm/swap.c:517
msgid "The folio to be added to the LRU."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:494
msgid ""
"Queue the folio for addition to the LRU. The decision on whether to add the "
"page to the [in]active [file|anon] list is deferred until the folio_batch is "
"drained. This gives a chance for the caller of folio_add_lru() have the "
"folio added to the active list using folio_mark_accessed()."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:516
msgid "Add a folio to the appropate LRU list for this VMA."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:518
msgid "VMA in which the folio is mapped."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:519
msgid ""
"If the VMA is mlocked, **folio** is added to the unevictable list. "
"Otherwise, it is treated the same way as folio_add_lru()."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:677
msgid "Deactivate a file folio."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:678
msgid "Folio to deactivate."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:679
msgid ""
"This function hints to the VM that **folio** is a good reclaim candidate, "
"for example if its invalidation fails due to the folio being dirty or under "
"writeback."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:684
msgid "Caller holds a reference on the folio."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:718
msgid "make an anon folio lazyfree"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:719
msgid "folio to deactivate"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:720
msgid ""
"folio_mark_lazyfree() moves **folio** to the inactive file list. This is "
"done to accelerate the reclaim of **folio**."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:937
msgid "Reduce the reference count on a batch of folios."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:940
msgid "``unsigned int *refs``"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:939
msgid "The number of refs to subtract from each folio."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:940
msgid ""
"Like folio_put(), but for a batch of folios.  This is more efficient than "
"writing the loop yourself as it will optimise the locks which need to be "
"taken if the folios are freed.  The folios batch is returned empty and ready "
"to be reused for another batch; there is no need to reinitialise it.  If "
"**refs** is NULL, we subtract one from each folio refcount."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1007
msgid "batched put_page()"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1013
msgid "``release_pages_arg arg``"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1008
msgid "array of pages to release"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1010
msgid "``int nr``"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1010
msgid ""
"Decrement the reference count on all the pages in **arg**.  If it fell to "
"zero, remove the page from the LRU and free it."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1013
msgid ""
"Note that the argument can be an array of pages, encoded pages, or folio "
"pointers. We ignore any encoded bits, and turn any of them into just a folio "
"that gets free'd."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1067
msgid "Prune non-folios from a batch."
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1068
msgid "The batch to prune"
msgstr ""

#: ../../../core-api/mm-api:120: ../mm/swap.c:1069
msgid ""
"find_get_entries() fills a batch with both folios and shadow/swap/DAX "
"entries.  This function prunes all the non-folio entries from **fbatch** "
"without leaving holes, so that it can be passed on to folio-only batch "
"operations."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:242
msgid "css of the memcg associated with a folio"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:243
msgid "folio of interest"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:244
msgid ""
"If memcg is bound to the default hierarchy, css of the memcg associated with "
"**folio** is returned.  The returned css remains associated with **folio** "
"until it is released."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:248
msgid ""
"If memcg is bound to a traditional hierarchy, the css of root_mem_cgroup is "
"returned."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:263
msgid "return inode number of the memcg a page is charged to"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:264
msgid "the page"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:265
msgid ""
"Look up the closest online ancestor of the memory cgroup **page** is charged "
"to and return its inode number or 0 if **page** is not charged to any "
"cgroup. It is safe to call this function without holding a reference to "
"**page**."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:269
msgid ""
"Note, this function is inherently racy, because there is nothing to prevent "
"the cgroup inode from getting torn down and potentially reallocated a moment "
"after page_cgroup_ino() returns, so it only should be used by callers that "
"do not care (such as procfs interfaces)."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:683
msgid "update cgroup memory statistics"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:684 ../mm/memcontrol.c:828
#: ../mm/memcontrol.c:1302
msgid "the memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:686
msgid "``enum memcg_stat_item idx``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:685
msgid "the stat item - can be enum memcg_stat_item or enum node_stat_item"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:687 ../mm/memcontrol.c:764
msgid "``int val``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:686 ../mm/memcontrol.c:763
msgid "delta to add to the counter, can be negative"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:760
msgid "update lruvec memory statistics"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:766 ../mm/memcontrol.c:1269
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:412
msgid "``struct lruvec *lruvec``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:761
msgid "the lruvec"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:763
msgid "``enum node_stat_item idx``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:762
msgid "the stat item"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:764
msgid ""
"The lruvec is the intersection of the NUMA node and a cgroup. This function "
"updates the all three counters that are affected by a change of state at "
"this level: per-node, per-cgroup, per-lruvec."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:827
msgid "account VM events in a cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:830
msgid "``enum vm_event_item idx``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:829
msgid "the event item"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:831
msgid "``unsigned long count``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:830
msgid "the number of events that occurred"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:898
msgid "Obtain a reference on given mm_struct's memcg."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:899
msgid "mm from which memcg should be extracted. It can be NULL."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:900
msgid ""
"Obtain a reference on mm->memcg and returns it if successful. If mm is NULL, "
"then the memcg is chosen as follows: 1) The active memcg, if set. 2) current-"
">mm->memcg, if available 3) root memcg If mem_cgroup is disabled, NULL is "
"returned."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:948
msgid "Obtain a reference on current task's memcg."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:969
msgid "Obtain a reference on a given folio's memcg."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:970
msgid "folio from which memcg should be extracted."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:987
msgid "iterate over memory cgroup hierarchy"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:993 ../mm/memcontrol.c:1097
#: ../mm/memcontrol.c:4707
msgid "``struct mem_cgroup *root``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:988 ../mm/memcontrol.c:1092
#: ../mm/memcontrol.c:1141
msgid "hierarchy root"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:990 ../mm/memcontrol.c:1094
msgid "``struct mem_cgroup *prev``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:989
msgid "previously returned memcg, NULL on first invocation"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:991
msgid "``struct mem_cgroup_reclaim_cookie *reclaim``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:990
msgid "cookie for shared reclaim walks, NULL for full walks"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:991
msgid ""
"Returns references to children of the hierarchy below **root**, or **root** "
"itself, or ``NULL`` after a full round-trip."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:994
msgid ""
"Caller must pass the return value in **prev** on subsequent invocations for "
"reference counting, or use mem_cgroup_iter_break() to cancel a hierarchy "
"walk before the round-trip is complete."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:998
msgid ""
"Reclaimers can specify a node in **reclaim** to divide up the memcgs in the "
"hierarchy among all concurrent reclaimers operating on the same node."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1091
msgid "abort a hierarchy walk prematurely"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1093
msgid "last visited hierarchy member as returned by mem_cgroup_iter()"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1140
msgid "iterate over tasks of a memory cgroup hierarchy"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1143
msgid "``int (*fn)(struct task_struct *, void *)``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1142
msgid "function to call for each task"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1144
msgid "``void *arg``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1143
msgid "argument passed to **fn**"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1144
msgid ""
"This function iterates over tasks attached to **memcg** or to any of its "
"descendants and calls **fn** for each task. If **fn** returns a non-zero "
"value, the function breaks the iteration loop. Otherwise, it will iterate "
"over all tasks and return 0."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1149
msgid "This function must not be called for the root memory cgroup."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1196
#: ../mm/memcontrol.c:1217 ../mm/memcontrol.c:1239
msgid "Lock the lruvec for a folio."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1197
#: ../mm/memcontrol.c:1218 ../mm/memcontrol.c:1240
msgid "Pointer to the folio."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1198
#: ../mm/memcontrol.c:1219 ../mm/memcontrol.c:1242
msgid ""
"These functions are safe to use under any of the following conditions: - "
"folio locked - folio_test_lru false - folio frozen (refcount of 0)"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1204
msgid "The lruvec this folio is on with its lock held."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1225
#: ../mm/memcontrol.c:1248
msgid "The lruvec this folio is on with its lock held and interrupts disabled."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1242
msgid "``unsigned long *flags``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1241
msgid "Pointer to irqsave flags."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1263
msgid "account for adding or removing an lru page"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1264
msgid "mem_cgroup per zone lru vector"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1266
#: ../../../core-api/mm-api:130: ../mm/vmscan.c:409
msgid "``enum lru_list lru``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1265
msgid "index of lru list the page is sitting on"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1267
msgid "``int zid``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1266
msgid "zone id of the accounted pages"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1267
msgid "positive when adding or negative when removing"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1268
msgid ""
"This function must be called under lru_lock, just before a page is added to "
"or just after a page is removed from an lru list."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1301
msgid "calculate chargeable space of a memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1303
msgid ""
"Returns the maximum amount of memory **mem** can be charged with, in pages."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1532
msgid "Print OOM information relevant to memory controller."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1534
#: ../mm/memcontrol.c:1559
msgid "The memory cgroup that went over limit"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1536
msgid "``struct task_struct *p``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1535
msgid "Task that is going to be killed"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1537
msgid ""
"**memcg** and **p**'s mem_cgroup can be different when hierarchy is enabled"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1557
msgid "Print OOM memory information relevant to memory controller."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1713
msgid "get a memory cgroup to clean up after OOM"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1719
msgid "``struct task_struct *victim``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1714
msgid "task to be killed by the OOM killer"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1716
msgid "``struct mem_cgroup *oom_domain``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1715
msgid "memcg in case of memcg OOM, NULL in case of system-wide OOM"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1716
msgid ""
"Returns a pointer to a memory cgroup, which has to be cleaned up by killing "
"all belonging OOM-killable tasks."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1719
msgid "Caller has to call mem_cgroup_put() on the returned non-NULL memcg."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1818
msgid "Try to consume stocked charge on this cpu."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1819
msgid "memcg to consume from."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1821
#: ../mm/memcontrol.c:5075 ../mm/memcontrol.c:5100 ../mm/memcontrol.c:5228
msgid "``unsigned int nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1820
msgid "how many pages to charge."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1821
msgid ""
"Consume the cached charge if enough nr_pages are present otherwise return "
"failure. Also return failure for charge request larger than "
"MEMCG_CHARGE_BATCH or if the local lock is already taken."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:1825
msgid "returns true if successful, false otherwise."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2853
msgid "charge a kmem page to the current memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2854
msgid "page to charge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2855
#: ../mm/memcontrol.c:4754 ../mm/memcontrol.c:4789 ../mm/memcontrol.c:5075
msgid "reclaim mode"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2856
#: ../mm/memcontrol.c:2880
msgid "allocation order"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2857
msgid "Returns 0 on success, an error code on failure."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2878
msgid "uncharge a kmem page"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:2879
msgid "page to uncharge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3376
msgid "retrieve writeback related stats from its memcg"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3382
msgid "``struct bdi_writeback *wb``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3377
msgid "bdi_writeback in question"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3379
msgid "``unsigned long *pfilepages``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3378
msgid "out parameter for number of file pages"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3380
msgid "``unsigned long *pheadroom``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3379
msgid "out parameter for number of allocatable pages according to memcg"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3381
msgid "``unsigned long *pdirty``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3380
msgid "out parameter for number of dirty pages"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3382
msgid "``unsigned long *pwriteback``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3381
msgid "out parameter for number of pages under writeback"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3382
msgid ""
"Determine the numbers of file, headroom, dirty, and writeback pages in "
"**wb**'s memcg.  File, dirty and writeback are self-explanatory.  Headroom "
"is a bit more involved."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3386
msgid ""
"A memcg's headroom is \"min(max, high) - used\".  In the hierarchy, the "
"headroom is calculated as the lowest headroom of itself and the ancestors.  "
"Note that this doesn't consider the actual amount of available memory in the "
"system.  The caller should further cap ***pheadroom** accordingly."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3634
msgid "look up a memcg from a memcg id"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3640
msgid "``unsigned short id``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3635
msgid "the memcg id to look up"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3636
msgid "Caller must hold rcu_read_lock()."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3959
msgid "reset the states of a mem_cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3965
msgid "``struct cgroup_subsys_state *css``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3960
msgid "the target css"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3961
msgid ""
"Reset the states of the mem_cgroup associated with **css**.  This is invoked "
"when the userland requests disabling on the default hierarchy but the memcg "
"is pinned through dependency.  The memcg should stop applying policies and "
"should revert to the vanilla state as it may be made visible again."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:3967
msgid ""
"The current implementation only resets the essential configurations. This "
"needs to be expanded to cover all the visible parts."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4701
msgid "check if memory consumption is in the normal range"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4702
msgid "the top ancestor of the sub-tree being checked"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4703
msgid "the memory cgroup to check"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4704
msgid "WARNING: This function is not stateless! It can only be used as part"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4705
msgid "of a top-down tree iteration, not for isolated queries."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4752
msgid "charge the memcg for a hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4753
msgid "folio being charged"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4755
msgid ""
"This function is called when allocating a huge page folio, after the page "
"has already been obtained and charged to the appropriate hugetlb cgroup "
"controller (if it is enabled)."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4759
msgid ""
"Returns ENOMEM if the memcg is already full. Returns 0 if either the charge "
"was successful, or if we skip the charging."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4786
msgid "Charge a newly allocated folio for swapin."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4787
msgid "folio to charge."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4788
msgid "mm context of the victim"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4791
#: ../mm/memcontrol.c:5179 ../mm/memcontrol.c:5231
msgid "``swp_entry_t entry``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4790
msgid "swap entry for which the folio is allocated"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4791
msgid ""
"This function charges a folio allocated for swapin. Please call this before "
"adding the folio to the swapcache."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4794
msgid "Returns 0 on success. Otherwise, an error code is returned."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4936
msgid "Charge a folio's replacement."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4937
#: ../mm/memcontrol.c:4981
msgid "Currently circulating folio."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4938
#: ../mm/memcontrol.c:4982
msgid "Replacement folio."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4939
msgid ""
"Charge **new** as a replacement folio for **old**. **old** will be uncharged "
"upon free."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4942
#: ../mm/memcontrol.c:4987
msgid "Both folios must be locked, **new->mapping** must be set up."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4980
msgid "Transfer the memcg data from the old to the new folio."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:4983
msgid ""
"Transfer the memcg data from the old folio to the new folio for migration. "
"The old folio's data info will be cleared. Note that the memory counters "
"will remain unchanged throughout the process."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5072
msgid "charge socket memory"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5078
#: ../mm/memcontrol.c:5103
msgid "``const struct sock *sk``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5073
msgid "socket in memcg to charge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5074
msgid "number of pages to charge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5076
msgid ""
"Charges **nr_pages** to **memcg**. Returns ``true`` if the charge fit within "
"**memcg**'s configured limit, ``false`` if it doesn't."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5097
msgid "uncharge socket memory"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5098
msgid "socket in memcg to uncharge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5099
msgid "number of pages to uncharge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5176
msgid "try charging swap space for a folio"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5177
msgid "folio being added to swap"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5178
msgid "swap entry to charge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5179
msgid "Try to charge **folio**'s memcg for the swap space at **entry**."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5181
msgid "Returns 0 on success, -ENOMEM on failure."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5225
msgid "uncharge swap space"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5226
msgid "swap entry to uncharge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5227
msgid "the amount of swap space to uncharge"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5423
msgid "check if this cgroup can zswap"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5429
#: ../mm/memcontrol.c:5474 ../mm/memcontrol.c:5502
msgid "``struct obj_cgroup *objcg``"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5424
#: ../mm/memcontrol.c:5469 ../mm/memcontrol.c:5497
msgid "the object cgroup"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5425
msgid "Check if the hierarchical zswap limit has been reached."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5427
msgid ""
"This doesn't check for specific headroom, and it is not atomic either. But "
"with zswap, the size of the allocation is only known once compression has "
"occurred, and this optimistic pre-check avoids spending cycles on "
"compression when there is already no room left or zswap is disabled "
"altogether somewhere in the hierarchy."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5468
msgid "charge compression backend memory"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5470
#: ../mm/memcontrol.c:5498
msgid "size of compressed object"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5471
msgid ""
"This forces the charge after obj_cgroup_may_zswap() allowed compression and "
"storage in zswap for this cgroup to go ahead."
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5496
msgid "uncharge compression backend memory"
msgstr ""

#: ../../../core-api/mm-api:121: ../mm/memcontrol.c:5499
msgid "Uncharges zswap memory on page in."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:424
msgid "recalculate the block usage of an inode"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:425
msgid "inode to recalc"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:427
msgid "``long alloced``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:426
msgid "the change in number of pages allocated to inode"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:428
msgid "``long swapped``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:427
msgid "the change in number of pages swapped from inode"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:428
msgid ""
"We have to calculate the free blocks since the mm can drop undirtied hole "
"pages behind our back."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:431
msgid ""
"But normally   info->alloced == inode->i_mapping->nrpages + info->swapped So "
"mm freed is info->alloced - (inode->i_mapping->nrpages + info->swapped)"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:435
msgid "true if swapped was incremented from 0, for shmem_writeout()."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1583
msgid "Write the folio to swap"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1584
msgid "The folio to write"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1586
msgid "``struct swap_iocb **plug``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1585
msgid "swap plug"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1587
msgid "``struct list_head *folio_list``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1586
msgid "list to put back folios on split"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:1587
msgid "Move the folio from the page cache to the swap cache."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2664
msgid "find, and lock a shmem folio."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2665
msgid "inode to search"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2666
msgid "the page index."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2668
msgid "``loff_t write_end``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2667
msgid "end of a write, could extend inode size"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2668
msgid "pointer to the folio if found"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2670
msgid "``enum sgp_type sgp``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2669
msgid "SGP_* flags to control behavior"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2670
msgid ""
"Looks up the page cache entry at **inode** & **index**.  If a folio is "
"present, it is returned locked with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2673
msgid ""
"If the caller modifies data in the folio, it must call folio_mark_dirty() "
"before unlocking the folio to ensure that the folio is not reclaimed. There "
"is no need to reserve space before calling folio_mark_dirty()."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2677
msgid "When no folio is found, the behavior depends on **sgp**:"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2678
msgid "for SGP_READ, ***foliop** is ``NULL`` and 0 is returned"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2679
msgid "for SGP_NOALLOC, ***foliop** is ``NULL`` and -ENOENT is returned"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2680
msgid ""
"for all other flags a new folio is allocated, inserted into the page cache "
"and returned locked in **foliop**."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:2685
msgid "0 if successful, else a negative error code."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5882
msgid ""
"get an unlinked file living in tmpfs which must be kernel internal. There "
"will be NO LSM permission checks against the underlying inode. So users of "
"this interface must do LSM checks at a higher layer. The users are the "
"big_key and shm implementations. LSM checks are provided at the key or shm "
"level rather than the inode."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5887 ../mm/shmem.c:5899
#: ../mm/shmem.c:5912
msgid "name for dentry (to be seen in /proc/<pid>/maps)"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5889 ../mm/shmem.c:5901
#: ../mm/shmem.c:5914
msgid "``loff_t size``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5888 ../mm/shmem.c:5900
#: ../mm/shmem.c:5913
msgid "size to be set for the file"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5889 ../mm/shmem.c:5901
#: ../mm/shmem.c:5914
msgid "VM_NORESERVE suppresses pre-accounting of the entire object size"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5898 ../mm/shmem.c:5910
msgid "get an unlinked file living in tmpfs"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5916
msgid "``struct vfsmount *mnt``"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5911
msgid "the tmpfs mount where the file will be created"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5937
msgid "setup a shared anonymous mapping"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5938
msgid "the vma to be mmapped is prepared by do_mmap"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5939 ../mm/shmem.c:5960
msgid "0 on success, or error"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5957
msgid ""
"same as shmem_zero_setup, but determined by VMA descriptor for convenience."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5959
msgid "Describes VMA"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5977
msgid "the folio's address_space"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5978
msgid "the folio index"
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5980
msgid ""
"This behaves as a tmpfs \"read_cache_page_gfp(mapping, index, gfp)\", with "
"any new page allocations done using the specified allocation flags. But "
"read_cache_page_gfp() uses the ->read_folio() method: which does not suit "
"tmpfs, since it may have pages in swapcache, and needs to find those for "
"itself; although drivers/gpu/drm i915 and ttm rely upon this support."
msgstr ""

#: ../../../core-api/mm-api:123: ../mm/shmem.c:5986
msgid ""
"i915_gem_object_get_pages_gtt() mixes __GFP_NORETRY | __GFP_NOWARN in with "
"the mapping_gfp_mask(), to avoid OOMing the machine unnecessarily."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:76
msgid "Helper function to split a THP folio"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:77
msgid "the folio to split"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:79
msgid "``struct page *fault_page``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:78
msgid "struct page associated with the fault if any"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:79
msgid "Returns 0 on success"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:672
msgid "prepare to migrate a range of memory"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:678
msgid "``struct migrate_vma *args``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:673
msgid "contains the vma, start, and pfns arrays for the migration"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:675
msgid ""
"negative errno on failures, 0 when 0 or more pages were migrated without an "
"error."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:677
msgid ""
"Prepare to migrate a range of memory virtual address range by collecting all "
"the pages backing each virtual address in the range, saving them inside the "
"src array.  Then lock those pages and unmap them. Once the pages are locked "
"and unmapped, check whether each page is pinned or not.  Pages that aren't "
"pinned have the MIGRATE_PFN_MIGRATE flag set (by this function) in the "
"corresponding src array entry.  Then restores any pages that are pinned, by "
"remapping and unlocking those pages."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:685
msgid ""
"The caller should then allocate destination memory and copy source memory to "
"it for all those entries (ie with MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE "
"flag set).  Once these are allocated and copied, the caller must update each "
"corresponding entry in the dst array with the pfn value of the destination "
"page and with MIGRATE_PFN_VALID. Destination pages must be locked via "
"lock_page()."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:692
msgid ""
"Note that the caller does not have to migrate all the pages that are marked "
"with MIGRATE_PFN_MIGRATE flag in src array unless this is a migration from "
"device memory to system memory.  If the caller cannot migrate a device page "
"back to system memory, then it must return VM_FAULT_SIGBUS, which has severe "
"consequences for the userspace process, so it must be avoided if at all "
"possible."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:699
msgid ""
"For empty entries inside CPU page table (pte_none() or pmd_none() is true) "
"we do set MIGRATE_PFN_MIGRATE flag inside the corresponding source array "
"thus allowing the caller to allocate device memory for those unbacked "
"virtual addresses.  For this the caller simply has to allocate device memory "
"and properly set the destination entry like for regular migration.  Note "
"that this can still fail, and thus inside the device driver you must check "
"if the migration was successful for those entries after calling "
"migrate_vma_pages(), just like for regular migration."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:708
msgid ""
"After that, the callers must call migrate_vma_pages() to go over each entry "
"in the src array that has the MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE flag "
"set. If the corresponding entry in dst array has MIGRATE_PFN_VALID flag set, "
"then migrate_vma_pages() to migrate struct page information from the source "
"struct page to the destination struct page.  If it fails to migrate the "
"struct page information, then it clears the MIGRATE_PFN_MIGRATE flag in the "
"src array."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:716
msgid ""
"At this point all successfully migrated pages have an entry in the src array "
"with MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE flag set and the dst array "
"entry with MIGRATE_PFN_VALID flag set."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:720
msgid ""
"Once migrate_vma_pages() returns the caller may inspect which pages were "
"successfully migrated, and which were not.  Successfully migrated pages will "
"have the MIGRATE_PFN_MIGRATE flag set for their src array entry."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:724
msgid ""
"It is safe to update device page table after migrate_vma_pages() because "
"both destination and source page are still locked, and the mmap_lock is held "
"in read mode (hence no one can unmap the range being migrated)."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:728
msgid ""
"Once the caller is done cleaning up things and updating its page table (if "
"it chose to do so, this is not an obligation) it finally calls "
"migrate_vma_finalize() to update the CPU page table to point to new pages "
"for successfully migrated pages or otherwise restore the CPU page table to "
"point to the original source pages."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:779
msgid ""
"Insert a huge folio into **migrate->vma->vm_mm** at **addr**. folio is "
"already allocated as a part of the migration process with large page."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:785
#: ../mm/migrate_device.c:1264 ../mm/migrate_device.c:1347
msgid "``struct migrate_vma *migrate``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:787
msgid "migrate_vma arguments"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:788
msgid "address where the folio will be inserted"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:789
msgid "page to be inserted at **addr**"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:791
msgid "``unsigned long *src``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:790
msgid "src pfn which is being migrated"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:792
msgid "``pmd_t *pmdp``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:791
msgid "pointer to the pmd"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:780
msgid ""
"**page** needs to be initialized and setup after it's allocated. The code "
"bits here follow closely the code in __do_huge_pmd_anonymous_page(). This "
"API does not support THP zero pages."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1242
#: ../mm/migrate_device.c:1258
msgid "migrate meta-data from src page to dst page"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1248
#: ../mm/migrate_device.c:1381 ../mm/migrate_device.c:1427
msgid "``unsigned long *src_pfns``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1243
msgid "src_pfns returned from migrate_device_range()"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1245
msgid "``unsigned long *dst_pfns``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1244
msgid "array of pfns allocated by the driver to migrate memory to"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1246
#: ../mm/migrate_device.c:1379 ../mm/migrate_device.c:1424
msgid "``unsigned long npages``"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1245
msgid "number of pages in the range"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1246
msgid ""
"Equivalent to migrate_vma_pages(). This is called to migrate struct page "
"meta-data from source struct page to destination."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1259
#: ../mm/migrate_device.c:1342
msgid "migrate struct containing all migration information"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1260
msgid ""
"This migrates struct page meta-data from source struct page to destination "
"struct page. This effectively finishes the migration from source page to the "
"destination page."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1341
msgid "restore CPU page table entry"
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1343
msgid ""
"This replaces the special migration pte entry with either a mapping to the "
"new page if migration was successful for that page, or to the original page "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1347
msgid ""
"This also unlocks the pages and puts them back on the lru, or drops the "
"extra refcount, for device pages."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1375
#: ../mm/migrate_device.c:1421
msgid "migrate device private pfns to normal memory."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1376
msgid "array large enough to hold migrating source device private pfns."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1377
msgid "starting pfn in the range to migrate."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1378
#: ../mm/migrate_device.c:1423
msgid "number of pages to migrate."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1379
msgid ""
"migrate_vma_setup() is similar in concept to migrate_vma_setup() except that "
"instead of looking up pages based on virtual address mappings a range of "
"device pfns that should be migrated to system memory is used instead."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1383
msgid ""
"This is useful when a driver needs to free device memory but doesn't know "
"the virtual mappings of every page that may be in device memory. For example "
"this is often the case when a driver is being unloaded or unbound from a "
"device."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1387
msgid ""
"Like migrate_vma_setup() this function will take a reference and lock any "
"migrating pages that aren't free before unmapping them. Drivers may then "
"allocate destination pages and start copying data from the device to CPU "
"memory before calling migrate_device_pages()."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1422
msgid "pre-popluated array of source device private pfns to migrate."
msgstr ""

#: ../../../core-api/mm-api:124: ../mm/migrate_device.c:1424
msgid ""
"Similar to migrate_device_range() but supports non-contiguous pre-popluated "
"array of device pages to migrate."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:11
msgid "Private struct for pagetable walk callbacks"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:12
msgid "``range``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:13
msgid "Range for mmu notifiers"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:13
msgid "``tlbflush_start``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:14
msgid "Address of first modified pte"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:14
msgid "``tlbflush_end``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:15
msgid "Address of last modified pte + 1"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:15
msgid "``total``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:16
msgid "Total number of modified ptes"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:25
msgid "Write-protect a pte"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:31
#: ../mm/mapping_dirty_helpers.c:82
msgid "``pte_t *pte``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:26
#: ../mm/mapping_dirty_helpers.c:78
msgid "Pointer to the pte"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:27
msgid "The start of protecting virtual address"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:28
msgid "The end of protecting virtual address"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:30
#: ../mm/mapping_dirty_helpers.c:82
msgid "``struct mm_walk *walk``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:29
#: ../mm/mapping_dirty_helpers.c:81
msgid "pagetable walk callback argument"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:30
msgid ""
"The function write-protects a pte and records the range in virtual address "
"space of touched ptes for efficient range TLB flushes."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:55
msgid "Private struct for the clean_record_pte function."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:56
msgid "``base``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:57
msgid "struct wp_walk we derive from"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:57
msgid "``bitmap_pgoff``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:58
msgid "Address_space Page offset of the first bit in **bitmap**"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:58
msgid "``bitmap``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:59
msgid ""
"Bitmap with one bit for each page offset in the address_space range covered."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:60
msgid "``start``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:61
msgid ""
"Address_space page offset of first modified pte relative to **bitmap_pgoff**"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:62
msgid "``end``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:63
msgid ""
"Address_space page offset of last modified pte relative to **bitmap_pgoff**"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:76
msgid "Clean a pte and record its address space offset in a bitmap"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:79
msgid "The start of virtual address to be clean"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:80
msgid "The end of virtual address to be clean"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:82
msgid ""
"The function cleans a pte and records the range in virtual address space of "
"touched ptes for efficient TLB flushes. It also records dirty ptes in a "
"bitmap representing page offsets in the address_space, as well as the first "
"and last of the bits touched."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:250
msgid "Write-protect all ptes in an address space range"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:251
msgid "The address_space we want to write protect"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:253
#: ../mm/mapping_dirty_helpers.c:282
msgid "``pgoff_t first_index``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:252
#: ../mm/mapping_dirty_helpers.c:281
msgid "The first page offset in the range"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:253
#: ../mm/mapping_dirty_helpers.c:282
msgid "Number of incremental page offsets to cover"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:255
msgid ""
"This function currently skips transhuge page-table entries, since it's "
"intended for dirty-tracking on the PTE level. It will warn on encountering "
"transhuge write-enabled entries, though, and can easily be extended to "
"handle them as well."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:260
msgid ""
"The number of ptes actually write-protected. Note that already write-"
"protected ptes are not counted."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:278
msgid "Clean and record all ptes in an address space range"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:280
msgid "The address_space we want to clean"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:284
msgid "``pgoff_t bitmap_pgoff``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:283
msgid "The page offset of the first bit in **bitmap**"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:285
msgid "``unsigned long *bitmap``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:284
msgid ""
"Pointer to a bitmap of at least **nr** bits. The bitmap needs to cover the "
"whole range **first_index**..**first_index** + **nr**."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:286
msgid ""
"Pointer to number of the first set bit in **bitmap**. is modified as new "
"bits are set by the function."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:289
msgid "``pgoff_t *end``"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:288
msgid ""
"Pointer to the number of the last set bit in **bitmap**. none set. The value "
"is modified as new bits are set by the function."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:290
msgid ""
"When this function returns there is no guarantee that a CPU has not already "
"dirtied new ptes. However it will not clean any ptes not reported in the "
"bitmap. The guarantees are as follows:"
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:294
msgid ""
"All ptes dirty when the function starts executing will end up recorded in "
"the bitmap."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:296
msgid ""
"All ptes dirtied after that will either remain dirty, be recorded in the "
"bitmap or both."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:299
msgid ""
"If a caller needs to make sure all dirty ptes are picked up and none "
"additional are added, it first needs to write-protect the address-space "
"range and make sure new writers are blocked in page_mkwrite() or "
"pfn_mkwrite(). And then after a TLB flush following the write-protection "
"pick up all dirty bits."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:305
msgid ""
"This function currently skips transhuge page-table entries, since it's "
"intended for dirty-tracking on the PTE level. It will warn on encountering "
"transhuge dirty entries, though, and can easily be extended to handle them "
"as well."
msgstr ""

#: ../../../core-api/mm-api:126: ../mm/mapping_dirty_helpers.c:311
msgid "The number of dirty ptes actually cleaned."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:208
msgid "check if the address is served from this chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:214 ../mm/percpu.c:361
#: ../mm/percpu.c:413 ../mm/percpu.c:549 ../mm/percpu.c:740 ../mm/percpu.c:773
#: ../mm/percpu.c:805 ../mm/percpu.c:952 ../mm/percpu.c:1067
#: ../mm/percpu.c:1098 ../mm/percpu.c:1204 ../mm/percpu.c:1272
#: ../mm/percpu.c:1504 ../mm/percpu.c:1528
msgid "``struct pcpu_chunk *chunk``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:209 ../mm/percpu.c:356
#: ../mm/percpu.c:408 ../mm/percpu.c:544 ../mm/percpu.c:735 ../mm/percpu.c:768
#: ../mm/percpu.c:800 ../mm/percpu.c:947 ../mm/percpu.c:1062
#: ../mm/percpu.c:1093 ../mm/percpu.c:1199 ../mm/percpu.c:1267
msgid "chunk of interest"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:210
msgid "percpu address"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:212
msgid "True if the address is served from this chunk."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:308
msgid "check against the contig hint"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:314 ../mm/percpu.c:627
msgid "``struct pcpu_block_md *block``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:309 ../mm/percpu.c:622
msgid "block of interest"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:311 ../mm/percpu.c:803
#: ../mm/percpu.c:950 ../mm/percpu.c:1065
msgid "``int bits``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:310 ../mm/percpu.c:409
msgid "size of allocation"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:312 ../mm/percpu.c:1096
#: ../mm/percpu.c:1202 ../mm/percpu.c:1719
msgid "``size_t align``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:311 ../mm/percpu.c:410
#: ../mm/percpu.c:1201 ../mm/percpu.c:1718
msgid "alignment of area (max PAGE_SIZE)"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:312
msgid ""
"Check to see if the allocation can fit in the block's contig hint. Note, a "
"chunk uses the same hints as a block so this can also check against the "
"chunk's contig hint."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:355
msgid "finds the next hint free area"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:358 ../mm/percpu.c:412
msgid "``int *bit_off``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:357 ../mm/percpu.c:411
#: ../mm/percpu.c:801 ../mm/percpu.c:948 ../mm/percpu.c:1063
msgid "chunk offset"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:359 ../mm/percpu.c:413
msgid "``int *bits``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:358 ../mm/percpu.c:412
msgid "size of free area"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:359
msgid ""
"Helper function for pcpu_for_each_md_free_region.  It checks block-"
">contig_hint and performs aggregation across blocks to find the next hint.  "
"It modifies bit_off and bits in-place to be consumed in the loop."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:407
msgid "finds fit areas for a given allocation request"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:410 ../mm/percpu.c:1095
#: ../mm/percpu.c:1201
msgid "``int alloc_bits``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:411
msgid "``int align``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:413
msgid ""
"Finds the next free region that is viable for use with a given size and "
"alignment.  This only returns if there is a valid area to be used for this "
"allocation.  block->first_free is returned if the allocation request fits "
"within the block to see if the request can be fulfilled prior to the contig "
"hint."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:492
msgid "allocate memory"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:493
msgid "bytes to allocate"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:494 ../mm/percpu.c:1720
msgid "allocation flags"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:495
msgid ""
"Allocate **size** bytes.  If **size** is smaller than PAGE_SIZE, kzalloc() "
"is used; otherwise, the equivalent of vzalloc() is used. This is to "
"facilitate passing through whitelisted flags.  The returned memory is always "
"zeroed."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:501
msgid "Pointer to the allocated area on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:516
msgid "free memory"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:522
msgid "``void *ptr``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:517
msgid "memory to free"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:518
msgid ""
"Free **ptr**.  **ptr** should have been allocated using pcpu_mem_zalloc()."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:543
msgid "put chunk in the appropriate chunk slot"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:546
msgid "``int oslot``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:545
msgid "the previous slot it was on"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:546
msgid ""
"This function is called after an allocation or free changed **chunk**. New "
"slot according to the changed state is determined and **chunk** is moved to "
"the slot.  Note that the reserved chunk is never put on chunk slots."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:552
msgid "pcpu_lock."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:621
msgid "updates a block given a free area"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:624 ../mm/percpu.c:1203
msgid "``int start``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:623
msgid "start offset in block"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:625
msgid "``int end``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:624
msgid "end offset in block"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:625
msgid ""
"Updates a block given a known free area.  The region [start, end) is "
"expected to be the entirety of the free area within a block.  Chooses the "
"best starting offset if the contig hints are equal."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:734
msgid "updates metadata about a chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:737
msgid "``bool full_scan``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:736
msgid "if we should scan from the beginning"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:737
msgid ""
"Iterates over the metadata blocks to find the largest contig area. A full "
"scan can be avoided on the allocation path as this is triggered if we broke "
"the contig_hint.  In doing so, the scan_hint will be before the contig_hint "
"or after if the scan_hint == contig_hint.  This cannot be prevented on "
"freeing as we want to find the largest area possibly spanning blocks."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:770
msgid "``int index``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:769
msgid "index of the metadata block"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:770
msgid ""
"Scans over the block beginning at first_free and updates the block metadata "
"accordingly."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:799
msgid "update hint on allocation path"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:802 ../mm/percpu.c:949
#: ../mm/percpu.c:1064
msgid "``int bit_off``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:802 ../mm/percpu.c:949
msgid "size of request"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:803
msgid ""
"Updates metadata for the allocation path.  The metadata only has to be "
"refreshed by a full scan iff the chunk's contig hint is broken.  Block level "
"scans are required if the block's contig hint is broken."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:946
msgid "updates the block hints on the free path"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:950
msgid ""
"Updates metadata for the allocation path.  This avoids a blind block refresh "
"by making use of the block contig hints.  If this fails, it scans forward "
"and backward to determine the extent of the free area.  This is capped at "
"the boundary of blocks."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:955
msgid ""
"A chunk update is triggered if a page becomes free, a block becomes free, or "
"the free spans across blocks.  This tradeoff is to minimize iterating over "
"the block metadata to update chunk_md->contig_hint. chunk_md->contig_hint "
"may be off by up to a page, but it will never be more than the available "
"space.  If the contig hint is contained in one block, it will be accurate."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1061
msgid "determines if the region is populated"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1066
msgid "``int *next_off``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1065
msgid "return value for the next offset to start searching"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1066
msgid "For atomic allocations, check if the backing pages are populated."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1069
msgid ""
"Bool if the backing pages are populated. next_index is to skip over "
"unpopulated blocks in pcpu_find_block_fit."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1092
msgid "finds the block index to start searching"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1094 ../mm/percpu.c:1200
msgid "size of request in allocation units"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1095
msgid "alignment of area (max PAGE_SIZE bytes)"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1097
msgid "``bool pop_only``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1096
msgid "use populated regions only"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1097
msgid ""
"Given a chunk and an allocation spec, find the offset to begin searching for "
"a free region.  This iterates over the bitmap metadata blocks to find an "
"offset that will be guaranteed to fit the requirements.  It is not quite "
"first fit as if the allocation does not fit in the contig hint of a block or "
"chunk, it is skipped.  This errs on the side of caution to prevent excess "
"iteration.  Poor alignment can cause the allocator to skip over blocks and "
"chunks that have valid free areas."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1106
msgid "The offset in the bitmap to begin searching. -1 if no offset is found."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1198
msgid "allocates an area from a pcpu_chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1202
msgid "bit_off to start searching"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1203
msgid ""
"This function takes in a **start** offset to begin searching to fit an "
"allocation of **alloc_bits** with alignment **align**.  It needs to scan the "
"allocation map because if it fits within the block's contig hint, **start** "
"will be block->first_free. This is an attempt to fill the allocation prior "
"to breaking the contig hint.  The allocation and boundary maps are updated "
"accordingly if it confirms a valid free area."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1212
msgid ""
"Allocated addr offset in **chunk** on success. -1 if no matching area is "
"found."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1266
msgid "frees the corresponding offset"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1269
msgid "``int off``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1268
msgid "addr offset into chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1269
msgid ""
"This function determines the size of an allocation to free using the "
"boundary bitmap and clears the allocation map."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1273
msgid "Number of freed bytes."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1333
msgid "creates chunks that serve the first chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1339
msgid "``unsigned long tmp_addr``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1334
msgid "the start of the region served"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1336
msgid "``int map_size``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1335
msgid "size of the region served"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1336
msgid ""
"This is responsible for creating the chunks that serve the first chunk.  The "
"base_addr is page aligned down of **tmp_addr** while the region end is page "
"aligned up.  Offsets are kept track of to determine the region served. All "
"this is done to appease the bitmap allocator in avoiding partial blocks."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1342
msgid "Chunk serving the region at **tmp_addr** of **map_size**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1498
msgid "post-population bookkeeping"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1499
msgid "pcpu_chunk which got populated"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1501 ../mm/percpu.c:1525
msgid "``int page_start``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1500 ../mm/percpu.c:1524
msgid "the start page"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1502 ../mm/percpu.c:1526
msgid "``int page_end``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1501 ../mm/percpu.c:1525
msgid "the end page"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1502
msgid ""
"Pages in [**page_start**,**page_end**) have been populated to **chunk**.  "
"Update the bookkeeping information accordingly.  Must be called after each "
"successful population."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1522
msgid "post-depopulation bookkeeping"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1523
msgid "pcpu_chunk which got depopulated"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1526
msgid ""
"Pages in [**page_start**,**page_end**) have been depopulated from **chunk**. "
"Update the bookkeeping information accordingly.  Must be called after each "
"successful depopulation."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1579
msgid "determine chunk containing specified address"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1580
msgid "address for which the chunk needs to be determined."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1581
msgid ""
"This is an internal function that handles all but static allocations. Static "
"percpu address values should never be passed into the allocator."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1585
msgid "The address of the found chunk."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1716
msgid "the percpu allocator"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1717
msgid "size of area to allocate in bytes"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1720
msgid "``bool reserved``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1719
msgid "allocate from the reserved chunk if available"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1721
msgid ""
"Allocate percpu area of **size** bytes aligned at **align**.  If **gfp** "
"doesn't contain ``GFP_KERNEL``, the allocation is atomic. If **gfp** has "
"__GFP_NOWARN then no warning will be triggered on invalid or failed "
"allocation requests."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1727
msgid "Percpu pointer to the allocated area on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1935
msgid "manage the amount of free chunks"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1941
msgid "``bool empty_only``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1936
msgid "free chunks only if there are no populated pages"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1937
msgid ""
"If empty_only is ``false``, reclaim all fully free chunks regardless of the "
"number of populated pages.  Otherwise, only reclaim chunks that have no "
"populated pages."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1942 ../mm/percpu.c:1996
#: ../mm/percpu.c:2088
msgid "pcpu_lock (can be dropped temporarily)"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1988
msgid "manage the amount of populated pages"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:1989
msgid ""
"Maintain a certain amount of populated pages to satisfy atomic allocations. "
"It is possible that this is called when physical memory is scarce causing "
"OOM killer to be triggered.  We should avoid doing so until an actual "
"allocation causes the failure as it is possible that requests can be "
"serviced from already backed regions."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2078
msgid "scan over to_depopulate chunks and free empty pages"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2079
msgid ""
"Scan over chunks in the depopulate list and try to release unused populated "
"pages back to the system.  Depopulated chunks are sidelined to prevent "
"repopulating these pages unless required.  Fully free chunks are "
"reintegrated and freed accordingly (1 is kept around).  If we drop below the "
"empty populated pages threshold, reintegrate the chunk if it has empty free "
"pages. Each chunk is scanned in the reverse order to keep populated pages "
"close to the beginning of the chunk."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2183
msgid "manage the amount of free chunks and populated pages"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2189
msgid "``struct work_struct *work``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2184
msgid "unused"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2185
msgid ""
"For each chunk type, manage the number of fully free chunks and the number "
"of populated pages.  An important thing to consider is when pages are freed "
"and how they contribute to the global counts."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2218
msgid "free percpu area"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2224
msgid "``void __percpu *ptr``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2219
msgid "pointer to area to free"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2220
msgid "Free percpu area **ptr**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2223
msgid "Can be called from atomic context."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2303
msgid "test whether address is from static percpu area"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2304
msgid "address to test"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2305
msgid ""
"Test whether **addr** belongs to in-kernel static percpu area.  Module "
"static percpu areas are not considered.  For those, use "
"is_module_percpu_address()."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2310
msgid ""
"``true`` if **addr** is from in-kernel static percpu area, ``false`` "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2319
msgid "convert translated percpu address to physical address"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2320
msgid "the address to be converted to physical address"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2321
msgid ""
"Given **addr** which is dereferenceable address obtained via one of percpu "
"access macros, this function translates it into its physical address.  The "
"caller is responsible for ensuring **addr** stays valid until this function "
"finishes."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2326
msgid ""
"percpu allocator has special setup for the first chunk, which currently "
"supports either embedding in linear address space or vmalloc mapping, and, "
"from the second one, the backing allocator (currently either vm or km) "
"provides translation."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2331
msgid ""
"The addr can be translated simply without checking if it falls into the "
"first chunk. But the current code reflects better how percpu allocator "
"actually works, and the verification can discover both bugs in percpu "
"allocator itself and per_cpu_ptr_to_phys() callers. So we keep current code."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2338
msgid "The physical address for **addr**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2386
msgid "allocate percpu allocation info"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2392
msgid "``int nr_groups``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2387
msgid "the number of groups"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2389
msgid "``int nr_units``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2388
msgid "the number of units"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2389
msgid ""
"Allocate ai which is large enough for **nr_groups** groups containing "
"**nr_units** units.  The returned ai's groups[0].cpu_map points to the "
"cpu_map array which is long enough for **nr_units** and filled with "
"NR_CPUS.  It's the caller's responsibility to initialize cpu_map pointer of "
"other groups."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2396
msgid "Pointer to the allocated pcpu_alloc_info on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2430
msgid "free percpu allocation info"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2436
msgid "``struct pcpu_alloc_info *ai``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2431
msgid "pcpu_alloc_info to free"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2432
msgid "Free **ai** which was allocated by pcpu_alloc_alloc_info()."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2441
msgid "print out information about pcpu_alloc_info"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2447
msgid "``const char *lvl``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2442
msgid "loglevel"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2444 ../mm/percpu.c:2504
msgid "``const struct pcpu_alloc_info *ai``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2443
msgid "allocation info to dump"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2444
msgid "Print out information about **ai** using loglevel **lvl**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2498
msgid "initialize the first percpu chunk"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2499
msgid "pcpu_alloc_info describing how to percpu area is shaped"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2501
msgid "``void *base_addr``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2500
msgid "mapped address"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2501
msgid ""
"Initialize the first percpu chunk which contains the kernel static percpu "
"area.  This function is to be called from arch percpu area setup path."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2505
msgid ""
"**ai** contains all information necessary to initialize the first chunk and "
"prime the dynamic percpu allocator."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2508
msgid "**ai->static_size** is the size of static percpu area."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2510
msgid ""
"**ai->reserved_size**, if non-zero, specifies the amount of bytes to reserve "
"after the static area in the first chunk.  This reserves the first chunk "
"such that it's available only through reserved percpu allocation.  This is "
"primarily used to serve module percpu static areas on architectures where "
"the addressing model has limited offset range for symbol relocations to "
"guarantee module percpu symbols fall inside the relocatable range."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2518
msgid ""
"**ai->dyn_size** determines the number of bytes available for dynamic "
"allocation in the first chunk.  The area between **ai->static_size** + **ai-"
">reserved_size** + **ai->dyn_size** and **ai->unit_size** is unused."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2522
msgid ""
"**ai->unit_size** specifies unit size and must be aligned to PAGE_SIZE and "
"equal to or larger than **ai->static_size** + **ai->reserved_size** + **ai-"
">dyn_size**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2526
msgid ""
"**ai->atom_size** is the allocation atom size and used as alignment for vm "
"areas."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2529
msgid ""
"**ai->alloc_size** is the allocation size and always multiple of **ai-"
">atom_size**.  This is larger than **ai->atom_size** if **ai->unit_size** is "
"larger than **ai->atom_size**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2533
msgid ""
"**ai->nr_groups** and **ai->groups** describe virtual memory layout of "
"percpu areas.  Units which should be colocated are put into the same group.  "
"Dynamic VM areas will be allocated according to these groupings.  If **ai-"
">nr_groups** is zero, a single group containing all units is assumed."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2539
msgid ""
"The caller should have mapped the first chunk at **base_addr** and copied "
"static data to each unit."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2542
msgid ""
"The first chunk will always contain a static and a dynamic region. However, "
"the static region is not managed by any chunk.  If the first chunk also "
"contains a reserved region, it is served by two chunks - one for the "
"reserved region and one for the dynamic region.  They share the same vm, but "
"use offset regions in the area allocation map. The chunk serving the dynamic "
"region is circulated in the chunk slots and available for dynamic allocation "
"like any other chunk."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2772
msgid "build alloc_info considering distances between CPUs"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2778 ../mm/percpu.c:2979
#: ../mm/percpu.c:3174
msgid "``size_t reserved_size``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2773 ../mm/percpu.c:2974
#: ../mm/percpu.c:3169
msgid "the size of reserved percpu area in bytes"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2775 ../mm/percpu.c:2976
msgid "``size_t dyn_size``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2774 ../mm/percpu.c:2975
msgid "minimum free size for dynamic allocation in bytes"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2776 ../mm/percpu.c:2977
msgid "``size_t atom_size``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2775 ../mm/percpu.c:2976
msgid "allocation atom size"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2777 ../mm/percpu.c:2978
msgid "``pcpu_fc_cpu_distance_fn_t cpu_distance_fn``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2776 ../mm/percpu.c:2977
msgid "callback to determine distance between cpus, optional"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2777
msgid ""
"This function determines grouping of units, their mappings to cpus and other "
"parameters considering needed percpu size, allocation atom size and "
"distances between CPUs."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2781
msgid ""
"Groups are always multiples of atom size and CPUs which are of "
"LOCAL_DISTANCE both ways are grouped together and share space for units in "
"the same group.  The returned configuration is guaranteed to have CPUs on "
"different nodes on different groups and >=75% usage of allocated virtual "
"address space."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2788
msgid ""
"On success, pointer to the new allocation_info is returned.  On failure, "
"ERR_PTR value is returned."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2973
msgid "embed the first percpu chunk into bootmem"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2979 ../mm/percpu.c:3171
msgid "``pcpu_fc_cpu_to_node_fn_t cpu_to_nd_fn``"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2978 ../mm/percpu.c:3170
msgid "callback to convert cpu to it's node, optional"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2979
msgid ""
"This is a helper to ease setting up embedded first percpu chunk and can be "
"called where pcpu_setup_first_chunk() is expected."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2982
msgid ""
"If this function is used to setup the first chunk, it is allocated by "
"calling pcpu_fc_alloc and used as-is without being mapped into vmalloc "
"area.  Allocations are always whole multiples of **atom_size** aligned to "
"**atom_size**."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2987
msgid ""
"This enables the first chunk to piggy back on the linear physical mapping "
"which often uses larger page size.  Please note that this can result in very "
"sparse cpu->unit mapping on NUMA machines thus requiring large vmalloc "
"address space.  Don't use this allocator if vmalloc space is not orders of "
"magnitude larger than distances between node memory addresses (ie. 32bit "
"NUMA machines)."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2994
msgid "**dyn_size** specifies the minimum dynamic area size."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:2996
msgid ""
"If the needed size is smaller than the minimum or specified unit size, the "
"leftover is returned using pcpu_fc_free."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:3000 ../mm/percpu.c:3178
msgid "0 on success, -errno on failure."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:3168
msgid "map the first chunk using PAGE_SIZE pages"
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:3171
msgid ""
"This is a helper to ease setting up page-remapped first percpu chunk and can "
"be called where pcpu_setup_first_chunk() is expected."
msgstr ""

#: ../../../core-api/mm-api:128: ../mm/percpu.c:3174
msgid ""
"This is the basic allocator.  Static percpu area is allocated page-by-page "
"into vmalloc area."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:112
msgid "safely attempt to read from a user-space location"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:118
msgid "``void *dst``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:113
msgid "pointer to the buffer that shall take the data"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:115
msgid "``const void __user *src``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:114
msgid "address to read from. This must be a user address."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:115 ../mm/maccess.c:144
msgid "size of the data chunk"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:116
msgid ""
"Safely read from user address **src** to the buffer at **dst**. If a kernel "
"fault happens, handle that and return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:141
msgid "safely attempt to write to a user-space location"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:147
msgid "``void __user *dst``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:142
msgid "address to write to"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:144
msgid "``const void *src``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:143
msgid "pointer to the data that shall be written"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:145
msgid ""
"Safely write to address **dst** from the buffer at **src**.  If a kernel "
"fault happens, handle that and return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:166
msgid "Copy a NUL terminated string from unsafe user address."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:172
msgid "``char *dst``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:168
msgid ""
"Destination address, in kernel space.  This buffer must be at least "
"**count** bytes long."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:171 ../mm/maccess.c:212
msgid "``const void __user *unsafe_addr``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:170
msgid "Unsafe user address."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:172 ../mm/maccess.c:209
msgid "``long count``"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:171
msgid "Maximum number of bytes to copy, including the trailing NUL."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:172
msgid ""
"Copies a NUL-terminated string from unsafe user address to kernel buffer."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:174
msgid ""
"On success, returns the length of the string INCLUDING the trailing NUL."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:176
msgid ""
"If access fails, returns -EFAULT (some data may have been copied and the "
"trailing NUL added)."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:179
msgid ""
"If **count** is smaller than the length of the string, copies **count**-1 "
"bytes, sets the last byte of **dst** buffer to NUL and returns **count**."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:206
msgid "Get the size of a user string INCLUDING final NUL."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:207
msgid "The string to measure."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:208
msgid "Maximum count (including NUL)"
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:209
msgid ""
"Get the size of a NUL-terminated string in user space without pagefault."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:211
msgid "Returns the size of the string INCLUDING the terminating NUL."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:213
msgid ""
"If the string is too long, returns a number larger than **count**. User has "
"to check the return value against \"> count\". On exception (or invalid "
"count), returns 0."
msgstr ""

#: ../../../core-api/mm-api:129: ../mm/maccess.c:217
msgid ""
"Unlike strnlen_user, this can be used from IRQ handler etc. because it "
"disables pagefaults."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:222
msgid "is the usual dirty throttling mechanism available?"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:228
msgid "``struct scan_control *sc``"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:223
msgid "scan_control in question"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:224
msgid ""
"The normal page dirty throttling mechanism in balance_dirty_pages() is "
"completely broken with the legacy memcg and direct stalling in "
"shrink_folio_list() is used for throttling instead, which lacks all the "
"niceties such as fairness, adaptive pausing, bandwidth proportional "
"allocation and configurability."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:230
msgid ""
"This function tests whether the vmscan currently in progress can assume that "
"the normal dirty throttling mechanism is operational."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:406
msgid "Returns the number of pages on the given LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:407
msgid "lru vector"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:408
msgid "lru to use"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:410
msgid "``int zone_idx``"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:409
msgid "zones to consider (use MAX_NR_ZONES - 1 for the whole LRU list)"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:811
msgid "Attempt to remove a folio from its mapping."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:812
msgid "The address space."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:813
msgid "The folio to remove."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:814
msgid ""
"If the folio is dirty, under writeback or if someone else has a ref on it, "
"removal will fail."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:817
msgid ""
"The number of pages removed from the mapping.  0 if the folio could not be "
"removed."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:819
msgid ""
"The caller should have a single refcount on the folio and hold its lock."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:837
msgid "Put previously isolated folio onto appropriate LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:838
msgid "Folio to be returned to an LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:839
msgid ""
"Add previously isolated **folio** to appropriate LRU list. The folio may "
"still be unevictable for other reasons."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:843
msgid "lru_lock must not be held, interrupts must be enabled."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1798
msgid "Try to isolate a folio from its LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1799
msgid "Folio to isolate from its LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1800
msgid ""
"Isolate a **folio** from an LRU list and adjust the vmstat statistic "
"corresponding to whatever LRU list the folio was on."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1803
msgid ""
"The folio will have its LRU flag cleared.  If it was found on the active "
"list, it will have the Active flag set.  If it was found on the unevictable "
"list, it will have the Unevictable flag set.  These flags may need to be "
"cleared by the caller before letting the page go."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1809
msgid ""
"Must be called with an elevated refcount on the folio. This is a fundamental "
"difference from isolate_lru_folios() (which is called without a stable "
"reference)."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1812
msgid "The lru_lock must not be held."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1813
msgid "Interrupts must be enabled."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:1817
msgid ""
"true if the folio was removed from an LRU list. false if the folio was not "
"on an LRU list."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:7829
msgid "Move evictable folios to appropriate zone lru list"
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:7831
msgid "Batch of lru folios to check."
msgstr ""

#: ../../../core-api/mm-api:130: ../mm/vmscan.c:7832
msgid ""
"Checks folios for evictability, if an evictable folio is in the unevictable "
"lru list, moves it to the appropriate evictable lru list. This function "
"should be only used for lru folios."
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:583
msgid "remove sections of pages"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:584
msgid "starting pageframe (must be aligned to start of a section)"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:585
msgid "number of pages to remove (must be multiple of section size)"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:587
msgid "``struct vmem_altmap *altmap``"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:586
msgid "alternative device page map or ``NULL`` if default memmap is used"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:587
msgid ""
"Generic helper function to remove section mappings and sysfs entries for the "
"section of the memory we are removing. Caller needs to make sure that pages "
"are marked reserved and zones are adjust properly by calling offline_pages()."
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2157
msgid "the node ID"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2158
msgid "Offline a node if all memory sections and cpus of the node are removed."
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2161
msgid ""
"The caller must call lock_device_hotplug() to serialize hotplug and online/"
"offline operations before this call."
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2271
msgid "Remove memory if every memory block is offline"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2277
msgid "``u64 start``"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2272
msgid "physical address of the region to remove"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2274
msgid "``u64 size``"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2273
msgid "size of the region to remove"
msgstr ""

#: ../../../core-api/mm-api:131: ../mm/memory_hotplug.c:2275
msgid ""
"The caller must call lock_device_hotplug() to serialize hotplug and online/"
"offline operations before this call, as required by try_offline_node()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:169
msgid "Begin a read side critical section against a VA range"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:175
#: ../mm/mmu_notifier.c:963 ../mm/mmu_notifier.c:1035
msgid "``struct mmu_interval_notifier *interval_sub``"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:171
msgid "The interval subscription"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:172
msgid ""
"mmu_iterval_read_begin()/mmu_iterval_read_retry() implement a collision-"
"retry scheme similar to seqcount for the VA range under subscription. If the "
"mm invokes invalidation during the critical section then "
"mmu_interval_read_retry() will return true."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:177
msgid ""
"This is useful to obtain shadow PTEs where teardown or setup of the SPTEs "
"require a blocking context.  The critical region formed by this can sleep, "
"and the required 'user_lock' can also be a sleeping lock."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:181
msgid ""
"The caller is required to provide a 'user_lock' to serialize both teardown "
"and setup."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:184
msgid "The return value should be passed to mmu_interval_read_retry()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:681
msgid "Register a notifier on a mm"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:687
#: ../mm/mmu_notifier.c:857
msgid "``struct mmu_notifier *subscription``"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:682
msgid "The notifier to attach"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:683
msgid "The mm to attach the notifier to"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:684
msgid ""
"Must not hold mmap_lock nor any other VM related lock when calling this "
"registration function. Must also ensure mm_users can't go down to zero while "
"this runs to avoid races with mmu_notifier_release, so mm has to be current-"
">mm or the mm should be pinned safely such as with get_task_mm(). If the mm "
"is not current->mm, the mm_users pin should be released by calling mmput "
"after mmu_notifier_register returns."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:692
msgid ""
"mmu_notifier_unregister() or mmu_notifier_put() must be always called to "
"unregister the notifier."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:695
msgid ""
"While the caller has a mmu_notifier get the subscription->mm pointer will "
"remain valid, and can be converted to an active mm pointer via "
"mmget_not_zero()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:735
msgid "Return the single struct mmu_notifier for the mm & ops"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:741
msgid "``const struct mmu_notifier_ops *ops``"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:737
msgid "The operations struct being subscribe with"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:738
msgid "The mm to attach notifiers too"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:739
msgid ""
"This function either allocates a new mmu_notifier via ops->alloc_notifier(), "
"or returns an already existing notifier on the list. The value of the ops "
"pointer is used to determine when two notifiers are the same."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:744
msgid ""
"Each call to mmu_notifier_get() must be paired with a call to "
"mmu_notifier_put(). The caller must hold the write side of mm->mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:747
msgid ""
"While the caller has a mmu_notifier get the mm pointer will remain valid, "
"and can be converted to an active mm pointer via mmget_not_zero()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:851
msgid "Release the reference on the notifier"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:852
msgid "The notifier to act on"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:853
msgid ""
"This function must be paired with each mmu_notifier_get(), it releases the "
"reference obtained by the get. If this is the last reference then process to "
"free the notifier will be run asynchronously."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:857
msgid ""
"Unlike mmu_notifier_unregister() the get/put flow only calls ops->release "
"when the mm_struct is destroyed. Instead free_notifier is always called to "
"release any resources held by the user."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:861
msgid ""
"As ops->release is not guaranteed to be called, the user must ensure that "
"all sptes are dropped, and no new sptes can be established before "
"mmu_notifier_put() is called."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:865
msgid ""
"This function can be called from the ops->release callback, however the "
"caller must still ensure it is called pairwise with mmu_notifier_get()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:868
msgid ""
"Modules calling this function must call mmu_notifier_synchronize() in their "
"__exit functions to ensure the async work is completed."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:957
msgid "Insert an interval notifier"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:958
msgid "Interval subscription to register"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:961
msgid "mm_struct to attach to"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:959
msgid "Starting virtual address to monitor"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:961
msgid "``unsigned long length``"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:960
msgid "Length of the range to monitor"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:962
msgid "``const struct mmu_interval_notifier_ops *ops``"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:962
msgid "Interval notifier operations to be called on matching events"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:963
msgid ""
"This function subscribes the interval notifier for notifications from the "
"mm.  Upon return the ops related to mmu_interval_notifier will be called "
"whenever an event that intersects with the given range occurs."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:967
msgid ""
"Upon return the range_notifier may not be present in the interval tree yet. "
"The caller must use the normal interval notifier read flow via "
"mmu_interval_read_begin() to establish SPTEs for this range."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1029
msgid "Remove a interval notifier"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1030
msgid "Interval subscription to unregister"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1031
msgid ""
"This function must be paired with mmu_interval_notifier_insert(). It cannot "
"be called from any ops callback."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1034
msgid ""
"Once this returns ops callbacks are no longer running on other CPUs and will "
"not be called in future."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1083
msgid "Ensure all mmu_notifiers are freed"
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1084
msgid ""
"This function ensures that all outstanding async SRU work from "
"mmu_notifier_put() is completed. After it returns any mmu_notifier_ops "
"associated with an unused mmu_notifier will no longer be called."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1088
msgid ""
"Before using the caller must ensure that all of its mmu_notifiers have been "
"fully released via mmu_notifier_put()."
msgstr ""

#: ../../../core-api/mm-api:132: ../mm/mmu_notifier.c:1091
msgid ""
"Modules using the mmu_notifier_put() API should call this in their __exit "
"function to avoid module unloading races."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:31
msgid "inserts a list of pages into the balloon page list."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:37
#: ../mm/balloon_compaction.c:66
msgid "``struct balloon_dev_info *b_dev_info``"
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:33
msgid "balloon device descriptor where we will insert a new page to"
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:35
#: ../mm/balloon_compaction.c:64
msgid "``struct list_head *pages``"
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:34
msgid "pages to enqueue - allocated using balloon_page_alloc."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:35
msgid ""
"Driver must call this function to properly enqueue balloon pages before "
"definitively removing them from the guest system."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:39
msgid "number of pages that were enqueued."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:60
msgid "removes pages from balloon's page list and returns a list of the pages."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:62
msgid "balloon device descriptor where we will grab a page from."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:63
msgid "pointer to the list of pages that would be returned to the caller."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:65
msgid "``size_t n_req_pages``"
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:64
msgid "number of requested pages."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:65
msgid ""
"Driver must call this function to properly de-allocate a previous enlisted "
"balloon pages before definitively releasing it back to the guest system. "
"This function tries to remove **n_req_pages** from the ballooned pages and "
"return them to the caller in the **pages** list."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:70
msgid ""
"Note that this function may fail to dequeue some pages even if the balloon "
"isn't empty - since the page list can be temporarily empty due to compaction "
"of isolated pages."
msgstr ""

#: ../../../core-api/mm-api:133: ../mm/balloon_compaction.c:75
msgid "number of pages that were added to the **pages** list."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1595
msgid "insert a pmd size pfn"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1596
#: ../mm/huge_memory.c:1704 ../mm/huge_memory.c:1740
msgid "Structure describing the fault"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1597
#: ../mm/huge_memory.c:1705
msgid "pfn to insert"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1599
#: ../mm/huge_memory.c:1707 ../mm/huge_memory.c:1743 ../mm/huge_memory.c:1770
msgid "``bool write``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1598
#: ../mm/huge_memory.c:1706 ../mm/huge_memory.c:1742
msgid "whether it's a write fault"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1599
msgid "Insert a pmd size pfn. See vmf_insert_pfn() for additional info."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1703
msgid "insert a pud size pfn"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1707
msgid "Insert a pud size pfn. See vmf_insert_pfn() for additional info."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1739
msgid "insert a pud size folio mapped by a pud entry"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1741
msgid "folio to insert"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1765
msgid "Mark page table pmd entry as accessed and dirty (for write)"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1766
msgid "The VMA covering **addr**"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1767
msgid "The virtual address"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1769
msgid "``pmd_t *pmd``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1768
msgid "pmd pointer into the page table mapping **addr**"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1769
msgid "Whether it's a write access"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:1771
msgid "whether the pmd entry is changed"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3584
msgid ""
"splits an unmapped **folio** to lower order folios in two ways: uniform "
"split or non-uniform split."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3586
msgid "the to-be-split folio"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3588
msgid "``int new_order``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3587
#: ../mm/huge_memory.c:3686
msgid ""
"the smallest order of the after split folios (since buddy allocator like "
"split generates folios with orders from **folio**'s order - 1 to new_order)."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3591
#: ../mm/huge_memory.c:3919 ../mm/huge_memory.c:4209
msgid "``struct page *split_at``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3590
msgid ""
"in buddy allocator like split, the folio containing **split_at** will be "
"split until its order becomes **new_order**."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3593
msgid "``struct xa_state *xas``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3592
msgid "xa_state pointing to folio->mapping->i_pages and locked by caller"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3593
msgid "**folio->mapping**"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3595
#: ../mm/huge_memory.c:3690 ../mm/huge_memory.c:3922
msgid "``enum split_type split_type``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3594
msgid "if the split is uniform or not (buddy allocator like split)"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3595
msgid ""
"uniform split: the given **folio** into multiple **new_order** small folios, "
"where all small folios have the same order. This is done when split_type is "
"SPLIT_TYPE_UNIFORM."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3598
msgid ""
"buddy allocator like (non-uniform) split: the given **folio** is split into "
"half and one of the half (containing the given page) is split into half "
"until the given **folio**'s order becomes **new_order**. This is done when "
"split_type is SPLIT_TYPE_NON_UNIFORM."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3603
msgid "The high level flow for these two methods are:"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3605
msgid ""
"uniform split: **xas** is split with no expectation of failure and a single "
"__split_folio_to_order() is called to split the **folio** into **new_order** "
"along with stats update."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3608
msgid ""
"non-uniform split: folio_order - **new_order** calls to "
"__split_folio_to_order() are expected to be made in a for loop to split the "
"**folio** to one lower order at a time. The folio containing **split_at** is "
"split in each iteration. **xas** is split into half in each iteration and "
"can fail. A failed **xas** split leaves split folios as is without merging "
"them back."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3615
msgid ""
"After splitting, the caller's folio reference will be transferred to the "
"folio containing **split_at**. The caller needs to unlock and/or free after-"
"split folios if necessary."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3621
#: ../mm/huge_memory.c:3932 ../mm/huge_memory.c:4225
msgid ""
"0 - successful, <0 - failed (if -ENOMEM is returned, **folio** might be "
"split but not to **new_order**, the caller needs to check)"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3684
msgid "check if a folio can be split to a given order"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3685
msgid "folio to be split"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3687
#: ../mm/huge_memory.c:3918 ../mm/huge_memory.c:4110 ../mm/huge_memory.c:4208
msgid "``unsigned int new_order``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3689
msgid "uniform or non-uniform split"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3690
msgid ""
"folio_check_splittable() checks if **folio** can be split to **new_order** "
"using **split_type** method. The truncated folio check must come first."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3694
msgid "folio must be locked."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3696
msgid ""
"0 - **folio** can be split to **new_order**, otherwise an error number is "
"returned."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3915
#: ../mm/huge_memory.c:4205
msgid "split a folio at **split_at** to a **new_order** folio"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3916
#: ../mm/huge_memory.c:4108 ../mm/huge_memory.c:4206 ../mm/huge_memory.c:4237
msgid "folio to split"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3917
#: ../mm/huge_memory.c:4207
msgid "the order of the new folio"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3918
#: ../mm/huge_memory.c:4208
msgid "a page within the new folio"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3920
msgid "``struct page *lock_at``"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3919
msgid "a page within **folio** to be left locked to caller"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3920
msgid "after-split folios will be put on it if non NULL"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3921
msgid "perform uniform split or not (non-uniform split)"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3922
msgid ""
"It calls __split_unmapped_folio() to perform uniform and non-uniform split. "
"It is in charge of checking whether the split is supported or not and "
"preparing **folio** for __split_unmapped_folio()."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:3926
msgid ""
"After splitting, the after-split folio containing **lock_at** remains locked "
"and others are unlocked: 1. for uniform split, **lock_at** points to one of "
"**folio**'s subpages; 2. for buddy allocator like (non-uniform) split, "
"**lock_at** points to **folio**."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4107
msgid "split a large anon folio that is already unmapped"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4109
msgid "the order of folios after split"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4110
msgid ""
"This function is a helper for splitting folios that have already been "
"unmapped. The use case is that the device or the CPU can refuse to migrate "
"THP pages in the middle of migration, due to allocation issues on either "
"side."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4115
msgid ""
"anon_vma_lock is not required to be held, mmap_read_lock() or "
"mmap_write_lock() should be held. **folio** is expected to be locked by the "
"caller. device-private and non device-private folios are supported along "
"with folios that are in the swapcache. **folio** should also be unmapped and "
"isolated from LRU (if applicable)"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4121
msgid ""
"Upon return, the folio is not remapped, split folios are not added to LRU, "
"free_folio_and_swap_cache() is not called, and new folios remain locked."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4125
msgid ""
"0 on success, -EAGAIN if the folio cannot be split (e.g., due to "
"insufficient reference count or extra pins)."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4209
msgid ""
"after-split folios are added to **list** if not null, otherwise to LRU list"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4211
msgid ""
"It has the same prerequisites and returns as "
"split_huge_page_to_list_to_order()."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4214
msgid ""
"Split a folio at **split_at** to a new_order folio, leave the remaining "
"subpages of the original folio as large as possible. For example, in the "
"case of splitting an order-9 folio at its third order-3 subpages to an "
"order-3 folio, there are 2^(9-3)=64 order-3 subpages in the order-9 folio. "
"After the split, there will be a group of folios with different orders and "
"the new folio containing **split_at** is marked in bracket: [order-4, "
"{order-3}, order-3, order-5, order-6, order-7, order-8]."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4222
msgid "After split, folio is left locked for caller."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4236
msgid "get the minimum order **folio** can be split to"
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4238
msgid ""
"min_order_for_split() tells the minimum order **folio** can be split to. If "
"a file-backed folio is truncated, 0 will be returned. Any subsequent split "
"attempt should get -EBUSY from split checking code."
msgstr ""

#: ../../../core-api/mm-api:134: ../mm/huge_memory.c:4243
msgid "**folio**'s minimum order for split"
msgstr ""
