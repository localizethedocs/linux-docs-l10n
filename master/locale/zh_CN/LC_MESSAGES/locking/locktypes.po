# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-10-06 15:47+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../locking/locktypes.rst:7
msgid "Lock types and their rules"
msgstr ""

#: ../../../locking/locktypes.rst:10
msgid "Introduction"
msgstr ""

#: ../../../locking/locktypes.rst:12
msgid ""
"The kernel provides a variety of locking primitives which can be divided "
"into three categories:"
msgstr ""

#: ../../../locking/locktypes.rst:15 ../../../locking/locktypes.rst:27
#: ../../../locking/locktypes.rst:550
msgid "Sleeping locks"
msgstr ""

#: ../../../locking/locktypes.rst:16 ../../../locking/locktypes.rst:54
msgid "CPU local locks"
msgstr ""

#: ../../../locking/locktypes.rst:17 ../../../locking/locktypes.rst:66
msgid "Spinning locks"
msgstr ""

#: ../../../locking/locktypes.rst:19
msgid ""
"This document conceptually describes these lock types and provides rules for "
"their nesting, including the rules for use under PREEMPT_RT."
msgstr ""

#: ../../../locking/locktypes.rst:24
msgid "Lock categories"
msgstr ""

#: ../../../locking/locktypes.rst:29
msgid "Sleeping locks can only be acquired in preemptible task context."
msgstr ""

#: ../../../locking/locktypes.rst:31
msgid ""
"Although implementations allow try_lock() from other contexts, it is "
"necessary to carefully evaluate the safety of unlock() as well as of "
"try_lock().  Furthermore, it is also necessary to evaluate the debugging "
"versions of these primitives.  In short, don't acquire sleeping locks from "
"other contexts unless there is no other option."
msgstr ""

#: ../../../locking/locktypes.rst:37
msgid "Sleeping lock types:"
msgstr ""

#: ../../../locking/locktypes.rst:39
msgid "mutex"
msgstr ""

#: ../../../locking/locktypes.rst:40
msgid "rt_mutex"
msgstr ""

#: ../../../locking/locktypes.rst:41 ../../../locking/locktypes.rst:114
msgid "semaphore"
msgstr ""

#: ../../../locking/locktypes.rst:42 ../../../locking/locktypes.rst:133
msgid "rw_semaphore"
msgstr ""

#: ../../../locking/locktypes.rst:43
msgid "ww_mutex"
msgstr ""

#: ../../../locking/locktypes.rst:44
msgid "percpu_rw_semaphore"
msgstr ""

#: ../../../locking/locktypes.rst:46
msgid ""
"On PREEMPT_RT kernels, these lock types are converted to sleeping locks:"
msgstr ""

#: ../../../locking/locktypes.rst:48 ../../../locking/locktypes.rst:56
#: ../../../locking/locktypes.rst:159
msgid "local_lock"
msgstr ""

#: ../../../locking/locktypes.rst:49 ../../../locking/locktypes.rst:73
#: ../../../locking/locktypes.rst:243
msgid "spinlock_t"
msgstr ""

#: ../../../locking/locktypes.rst:50 ../../../locking/locktypes.rst:74
#: ../../../locking/locktypes.rst:318
msgid "rwlock_t"
msgstr ""

#: ../../../locking/locktypes.rst:58
msgid ""
"On non-PREEMPT_RT kernels, local_lock functions are wrappers around "
"preemption and interrupt disabling primitives. Contrary to other locking "
"mechanisms, disabling preemption or interrupts are pure CPU local "
"concurrency control mechanisms and not suited for inter-CPU concurrency "
"control."
msgstr ""

#: ../../../locking/locktypes.rst:68 ../../../locking/locktypes.rst:233
msgid "raw_spinlock_t"
msgstr ""

#: ../../../locking/locktypes.rst:69 ../../../locking/locktypes.rst:514
msgid "bit spinlocks"
msgstr ""

#: ../../../locking/locktypes.rst:71
msgid "On non-PREEMPT_RT kernels, these lock types are also spinning locks:"
msgstr ""

#: ../../../locking/locktypes.rst:76
msgid ""
"Spinning locks implicitly disable preemption and the lock / unlock functions "
"can have suffixes which apply further protections:"
msgstr ""

#: ../../../locking/locktypes.rst:80
msgid "_bh()"
msgstr ""

#: ../../../locking/locktypes.rst:80
msgid "Disable / enable bottom halves (soft interrupts)"
msgstr ""

#: ../../../locking/locktypes.rst:81
msgid "_irq()"
msgstr ""

#: ../../../locking/locktypes.rst:81
msgid "Disable / enable interrupts"
msgstr ""

#: ../../../locking/locktypes.rst:82
msgid "_irqsave/restore()"
msgstr ""

#: ../../../locking/locktypes.rst:82
msgid "Save and disable / restore interrupt disabled state"
msgstr ""

#: ../../../locking/locktypes.rst:87
msgid "Owner semantics"
msgstr ""

#: ../../../locking/locktypes.rst:89
msgid ""
"The aforementioned lock types except semaphores have strict owner semantics:"
msgstr ""

#: ../../../locking/locktypes.rst:92
msgid "The context (task) that acquired the lock must release it."
msgstr ""

#: ../../../locking/locktypes.rst:94
msgid ""
"rw_semaphores have a special interface which allows non-owner release for "
"readers."
msgstr ""

#: ../../../locking/locktypes.rst:99
msgid "rtmutex"
msgstr ""

#: ../../../locking/locktypes.rst:101
msgid "RT-mutexes are mutexes with support for priority inheritance (PI)."
msgstr ""

#: ../../../locking/locktypes.rst:103
msgid ""
"PI has limitations on non-PREEMPT_RT kernels due to preemption and interrupt "
"disabled sections."
msgstr ""

#: ../../../locking/locktypes.rst:106
msgid ""
"PI clearly cannot preempt preemption-disabled or interrupt-disabled regions "
"of code, even on PREEMPT_RT kernels.  Instead, PREEMPT_RT kernels execute "
"most such regions of code in preemptible task context, especially interrupt "
"handlers and soft interrupts.  This conversion allows spinlock_t and "
"rwlock_t to be implemented via RT-mutexes."
msgstr ""

#: ../../../locking/locktypes.rst:116
msgid "semaphore is a counting semaphore implementation."
msgstr ""

#: ../../../locking/locktypes.rst:118
msgid ""
"Semaphores are often used for both serialization and waiting, but new use "
"cases should instead use separate serialization and wait mechanisms, such as "
"mutexes and completions."
msgstr ""

#: ../../../locking/locktypes.rst:123
msgid "semaphores and PREEMPT_RT"
msgstr ""

#: ../../../locking/locktypes.rst:125
msgid ""
"PREEMPT_RT does not change the semaphore implementation because counting "
"semaphores have no concept of owners, thus preventing PREEMPT_RT from "
"providing priority inheritance for semaphores.  After all, an unknown owner "
"cannot be boosted. As a consequence, blocking on semaphores can result in "
"priority inversion."
msgstr ""

#: ../../../locking/locktypes.rst:135
msgid "rw_semaphore is a multiple readers and single writer lock mechanism."
msgstr ""

#: ../../../locking/locktypes.rst:137
msgid ""
"On non-PREEMPT_RT kernels the implementation is fair, thus preventing writer "
"starvation."
msgstr ""

#: ../../../locking/locktypes.rst:140
msgid ""
"rw_semaphore complies by default with the strict owner semantics, but there "
"exist special-purpose interfaces that allow non-owner release for readers. "
"These interfaces work independent of the kernel configuration."
msgstr ""

#: ../../../locking/locktypes.rst:145
msgid "rw_semaphore and PREEMPT_RT"
msgstr ""

#: ../../../locking/locktypes.rst:147
msgid ""
"PREEMPT_RT kernels map rw_semaphore to a separate rt_mutex-based "
"implementation, thus changing the fairness:"
msgstr ""

#: ../../../locking/locktypes.rst:150
msgid ""
"Because an rw_semaphore writer cannot grant its priority to multiple "
"readers, a preempted low-priority reader will continue holding its lock, "
"thus starving even high-priority writers.  In contrast, because readers can "
"grant their priority to a writer, a preempted low-priority writer will have "
"its priority boosted until it releases the lock, thus preventing that writer "
"from starving readers."
msgstr ""

#: ../../../locking/locktypes.rst:161
msgid ""
"local_lock provides a named scope to critical sections which are protected "
"by disabling preemption or interrupts."
msgstr ""

#: ../../../locking/locktypes.rst:164
msgid ""
"On non-PREEMPT_RT kernels local_lock operations map to the preemption and "
"interrupt disabling and enabling primitives:"
msgstr ""

#: ../../../locking/locktypes.rst:168
msgid "local_lock(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:168
msgid "preempt_disable()"
msgstr ""

#: ../../../locking/locktypes.rst:169
msgid "local_unlock(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:169
msgid "preempt_enable()"
msgstr ""

#: ../../../locking/locktypes.rst:170
msgid "local_lock_irq(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:170
msgid "local_irq_disable()"
msgstr ""

#: ../../../locking/locktypes.rst:171
msgid "local_unlock_irq(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:171
msgid "local_irq_enable()"
msgstr ""

#: ../../../locking/locktypes.rst:172
msgid "local_lock_irqsave(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:172
msgid "local_irq_save()"
msgstr ""

#: ../../../locking/locktypes.rst:173
msgid "local_unlock_irqrestore(&llock)"
msgstr ""

#: ../../../locking/locktypes.rst:173
msgid "local_irq_restore()"
msgstr ""

#: ../../../locking/locktypes.rst:176
msgid ""
"The named scope of local_lock has two advantages over the regular primitives:"
msgstr ""

#: ../../../locking/locktypes.rst:179
msgid ""
"The lock name allows static analysis and is also a clear documentation of "
"the protection scope while the regular primitives are scopeless and opaque."
msgstr ""

#: ../../../locking/locktypes.rst:183
msgid ""
"If lockdep is enabled the local_lock gains a lockmap which allows to "
"validate the correctness of the protection. This can detect cases where e.g. "
"a function using preempt_disable() as protection mechanism is invoked from "
"interrupt or soft-interrupt context. Aside of that "
"lockdep_assert_held(&llock) works as with any other locking primitive."
msgstr ""

#: ../../../locking/locktypes.rst:190
msgid "local_lock and PREEMPT_RT"
msgstr ""

#: ../../../locking/locktypes.rst:192
msgid ""
"PREEMPT_RT kernels map local_lock to a per-CPU spinlock_t, thus changing "
"semantics:"
msgstr ""

#: ../../../locking/locktypes.rst:195
msgid "All spinlock_t changes also apply to local_lock."
msgstr ""

#: ../../../locking/locktypes.rst:198
msgid "local_lock usage"
msgstr ""

#: ../../../locking/locktypes.rst:200
msgid ""
"local_lock should be used in situations where disabling preemption or "
"interrupts is the appropriate form of concurrency control to protect per-CPU "
"data structures on a non PREEMPT_RT kernel."
msgstr ""

#: ../../../locking/locktypes.rst:204
msgid ""
"local_lock is not suitable to protect against preemption or interrupts on a "
"PREEMPT_RT kernel due to the PREEMPT_RT specific spinlock_t semantics."
msgstr ""

#: ../../../locking/locktypes.rst:208
msgid "CPU local scope and bottom-half"
msgstr ""

#: ../../../locking/locktypes.rst:210
msgid ""
"Per-CPU variables that are accessed only in softirq context should not rely "
"on the assumption that this context is implicitly protected due to being non-"
"preemptible. In a PREEMPT_RT kernel, softirq context is preemptible, and "
"synchronizing every bottom-half-disabled section via implicit context "
"results in an implicit per-CPU \"big kernel lock.\""
msgstr ""

#: ../../../locking/locktypes.rst:216
msgid ""
"A local_lock_t together with local_lock_nested_bh() and "
"local_unlock_nested_bh() for locking operations help to identify the locking "
"scope."
msgstr ""

#: ../../../locking/locktypes.rst:220
msgid ""
"When lockdep is enabled, these functions verify that data structure access "
"occurs within softirq context. Unlike local_lock(), local_unlock_nested_bh() "
"does not disable preemption and does not add overhead when used without "
"lockdep."
msgstr ""

#: ../../../locking/locktypes.rst:225
msgid ""
"On a PREEMPT_RT kernel, local_lock_t behaves as a real lock and "
"local_unlock_nested_bh() serializes access to the data structure, which "
"allows removal of serialization via local_bh_disable()."
msgstr ""

#: ../../../locking/locktypes.rst:230
msgid "raw_spinlock_t and spinlock_t"
msgstr ""

#: ../../../locking/locktypes.rst:235
msgid ""
"raw_spinlock_t is a strict spinning lock implementation in all kernels, "
"including PREEMPT_RT kernels.  Use raw_spinlock_t only in real critical core "
"code, low-level interrupt handling and places where disabling preemption or "
"interrupts is required, for example, to safely access hardware state.  "
"raw_spinlock_t can sometimes also be used when the critical section is tiny, "
"thus avoiding RT-mutex overhead."
msgstr ""

#: ../../../locking/locktypes.rst:245
msgid "The semantics of spinlock_t change with the state of PREEMPT_RT."
msgstr ""

#: ../../../locking/locktypes.rst:247
msgid ""
"On a non-PREEMPT_RT kernel spinlock_t is mapped to raw_spinlock_t and has "
"exactly the same semantics."
msgstr ""

#: ../../../locking/locktypes.rst:251
msgid "spinlock_t and PREEMPT_RT"
msgstr ""

#: ../../../locking/locktypes.rst:253
msgid ""
"On a PREEMPT_RT kernel spinlock_t is mapped to a separate implementation "
"based on rt_mutex which changes the semantics:"
msgstr ""

#: ../../../locking/locktypes.rst:256
msgid "Preemption is not disabled."
msgstr ""

#: ../../../locking/locktypes.rst:258
msgid ""
"The hard interrupt related suffixes for spin_lock / spin_unlock operations "
"(_irq, _irqsave / _irqrestore) do not affect the CPU's interrupt disabled "
"state."
msgstr ""

#: ../../../locking/locktypes.rst:262
msgid ""
"The soft interrupt related suffix (_bh()) still disables softirq handlers."
msgstr ""

#: ../../../locking/locktypes.rst:265
msgid "Non-PREEMPT_RT kernels disable preemption to get this effect."
msgstr ""

#: ../../../locking/locktypes.rst:267
msgid ""
"PREEMPT_RT kernels use a per-CPU lock for serialization which keeps "
"preemption enabled. The lock disables softirq handlers and also prevents "
"reentrancy due to task preemption."
msgstr ""

#: ../../../locking/locktypes.rst:271
msgid "PREEMPT_RT kernels preserve all other spinlock_t semantics:"
msgstr ""

#: ../../../locking/locktypes.rst:273
msgid ""
"Tasks holding a spinlock_t do not migrate.  Non-PREEMPT_RT kernels avoid "
"migration by disabling preemption.  PREEMPT_RT kernels instead disable "
"migration, which ensures that pointers to per-CPU variables remain valid "
"even if the task is preempted."
msgstr ""

#: ../../../locking/locktypes.rst:278
msgid ""
"Task state is preserved across spinlock acquisition, ensuring that the task-"
"state rules apply to all kernel configurations.  Non-PREEMPT_RT kernels "
"leave task state untouched.  However, PREEMPT_RT must change task state if "
"the task blocks during acquisition.  Therefore, it saves the current task "
"state before blocking and the corresponding lock wakeup restores it, as "
"shown below::"
msgstr ""

#: ../../../locking/locktypes.rst:294
msgid ""
"Other types of wakeups would normally unconditionally set the task state to "
"RUNNING, but that does not work here because the task must remain blocked "
"until the lock becomes available.  Therefore, when a non-lock wakeup "
"attempts to awaken a task blocked waiting for a spinlock, it instead sets "
"the saved state to RUNNING.  Then, when the lock acquisition completes, the "
"lock wakeup sets the task state to the saved state, in this case setting it "
"to RUNNING::"
msgstr ""

#: ../../../locking/locktypes.rst:314
msgid "This ensures that the real wakeup cannot be lost."
msgstr ""

#: ../../../locking/locktypes.rst:320
msgid "rwlock_t is a multiple readers and single writer lock mechanism."
msgstr ""

#: ../../../locking/locktypes.rst:322
msgid ""
"Non-PREEMPT_RT kernels implement rwlock_t as a spinning lock and the suffix "
"rules of spinlock_t apply accordingly. The implementation is fair, thus "
"preventing writer starvation."
msgstr ""

#: ../../../locking/locktypes.rst:327
msgid "rwlock_t and PREEMPT_RT"
msgstr ""

#: ../../../locking/locktypes.rst:329
msgid ""
"PREEMPT_RT kernels map rwlock_t to a separate rt_mutex-based implementation, "
"thus changing semantics:"
msgstr ""

#: ../../../locking/locktypes.rst:332
msgid "All the spinlock_t changes also apply to rwlock_t."
msgstr ""

#: ../../../locking/locktypes.rst:334
msgid ""
"Because an rwlock_t writer cannot grant its priority to multiple readers, a "
"preempted low-priority reader will continue holding its lock, thus starving "
"even high-priority writers.  In contrast, because readers can grant their "
"priority to a writer, a preempted low-priority writer will have its priority "
"boosted until it releases the lock, thus preventing that writer from "
"starving readers."
msgstr ""

#: ../../../locking/locktypes.rst:343
msgid "PREEMPT_RT caveats"
msgstr ""

#: ../../../locking/locktypes.rst:346
msgid "local_lock on RT"
msgstr ""

#: ../../../locking/locktypes.rst:348
msgid ""
"The mapping of local_lock to spinlock_t on PREEMPT_RT kernels has a few "
"implications. For example, on a non-PREEMPT_RT kernel the following code "
"sequence works as expected::"
msgstr ""

#: ../../../locking/locktypes.rst:355 ../../../locking/locktypes.rst:427
msgid "and is fully equivalent to::"
msgstr ""

#: ../../../locking/locktypes.rst:359
msgid ""
"On a PREEMPT_RT kernel this code sequence breaks because local_lock_irq() is "
"mapped to a per-CPU spinlock_t which neither disables interrupts nor "
"preemption. The following code sequence works perfectly correct on both "
"PREEMPT_RT and non-PREEMPT_RT kernels::"
msgstr ""

#: ../../../locking/locktypes.rst:367
msgid ""
"Another caveat with local locks is that each local_lock has a specific "
"protection scope. So the following substitution is wrong::"
msgstr ""

#: ../../../locking/locktypes.rst:390
msgid ""
"On a non-PREEMPT_RT kernel this works correctly, but on a PREEMPT_RT kernel "
"local_lock_1 and local_lock_2 are distinct and cannot serialize the callers "
"of func3(). Also the lockdep assert will trigger on a PREEMPT_RT kernel "
"because local_lock_irqsave() does not disable interrupts due to the "
"PREEMPT_RT-specific semantics of spinlock_t. The correct substitution is::"
msgstr ""

#: ../../../locking/locktypes.rst:418
msgid "spinlock_t and rwlock_t"
msgstr ""

#: ../../../locking/locktypes.rst:420
msgid ""
"The changes in spinlock_t and rwlock_t semantics on PREEMPT_RT kernels have "
"a few implications.  For example, on a non-PREEMPT_RT kernel the following "
"code sequence works as expected::"
msgstr ""

#: ../../../locking/locktypes.rst:431
msgid "Same applies to rwlock_t and the _irqsave() suffix variants."
msgstr ""

#: ../../../locking/locktypes.rst:433
msgid ""
"On PREEMPT_RT kernel this code sequence breaks because RT-mutex requires a "
"fully preemptible context.  Instead, use spin_lock_irq() or "
"spin_lock_irqsave() and their unlock counterparts.  In cases where the "
"interrupt disabling and locking must remain separate, PREEMPT_RT offers a "
"local_lock mechanism.  Acquiring the local_lock pins the task to a CPU, "
"allowing things like per-CPU interrupt disabled locks to be acquired. "
"However, this approach should be used only where absolutely necessary."
msgstr ""

#: ../../../locking/locktypes.rst:441
msgid ""
"A typical scenario is protection of per-CPU variables in thread context::"
msgstr ""

#: ../../../locking/locktypes.rst:448
msgid ""
"This is correct code on a non-PREEMPT_RT kernel, but on a PREEMPT_RT kernel "
"this breaks. The PREEMPT_RT-specific change of spinlock_t semantics does not "
"allow to acquire p->lock because get_cpu_ptr() implicitly disables "
"preemption. The following substitution works on both kernels::"
msgstr ""

#: ../../../locking/locktypes.rst:460
msgid ""
"migrate_disable() ensures that the task is pinned on the current CPU which "
"in turn guarantees that the per-CPU access to var1 and var2 are staying on "
"the same CPU while the task remains preemptible."
msgstr ""

#: ../../../locking/locktypes.rst:464
msgid ""
"The migrate_disable() substitution is not valid for the following scenario::"
msgstr ""

#: ../../../locking/locktypes.rst:475
msgid ""
"This breaks because migrate_disable() does not protect against reentrancy "
"from a preempting task. A correct substitution for this case is::"
msgstr ""

#: ../../../locking/locktypes.rst:486
msgid ""
"On a non-PREEMPT_RT kernel this protects against reentrancy by disabling "
"preemption. On a PREEMPT_RT kernel this is achieved by acquiring the "
"underlying per-CPU spinlock."
msgstr ""

#: ../../../locking/locktypes.rst:492
msgid "raw_spinlock_t on RT"
msgstr ""

#: ../../../locking/locktypes.rst:494
msgid ""
"Acquiring a raw_spinlock_t disables preemption and possibly also interrupts, "
"so the critical section must avoid acquiring a regular spinlock_t or "
"rwlock_t, for example, the critical section must avoid allocating memory.  "
"Thus, on a non-PREEMPT_RT kernel the following code works perfectly::"
msgstr ""

#: ../../../locking/locktypes.rst:503
msgid ""
"But this code fails on PREEMPT_RT kernels because the memory allocator is "
"fully preemptible and therefore cannot be invoked from truly atomic "
"contexts.  However, it is perfectly fine to invoke the memory allocator "
"while holding normal non-raw spinlocks because they do not disable "
"preemption on PREEMPT_RT kernels::"
msgstr ""

#: ../../../locking/locktypes.rst:516
msgid ""
"PREEMPT_RT cannot substitute bit spinlocks because a single bit is too small "
"to accommodate an RT-mutex.  Therefore, the semantics of bit spinlocks are "
"preserved on PREEMPT_RT kernels, so that the raw_spinlock_t caveats also "
"apply to bit spinlocks."
msgstr ""

#: ../../../locking/locktypes.rst:521
msgid ""
"Some bit spinlocks are replaced with regular spinlock_t for PREEMPT_RT using "
"conditional (#ifdef'ed) code changes at the usage site.  In contrast, usage-"
"site changes are not needed for the spinlock_t substitution. Instead, "
"conditionals in header files and the core locking implementation enable the "
"compiler to do the substitution transparently."
msgstr ""

#: ../../../locking/locktypes.rst:529
msgid "Lock type nesting rules"
msgstr ""

#: ../../../locking/locktypes.rst:531
msgid "The most basic rules are:"
msgstr ""

#: ../../../locking/locktypes.rst:533
msgid ""
"Lock types of the same lock category (sleeping, CPU local, spinning) can "
"nest arbitrarily as long as they respect the general lock ordering rules to "
"prevent deadlocks."
msgstr ""

#: ../../../locking/locktypes.rst:537
msgid ""
"Sleeping lock types cannot nest inside CPU local and spinning lock types."
msgstr ""

#: ../../../locking/locktypes.rst:539
msgid "CPU local and spinning lock types can nest inside sleeping lock types."
msgstr ""

#: ../../../locking/locktypes.rst:541
msgid "Spinning lock types can nest inside all lock types"
msgstr ""

#: ../../../locking/locktypes.rst:543
msgid "These constraints apply both in PREEMPT_RT and otherwise."
msgstr ""

#: ../../../locking/locktypes.rst:545
msgid ""
"The fact that PREEMPT_RT changes the lock category of spinlock_t and "
"rwlock_t from spinning to sleeping and substitutes local_lock with a per-CPU "
"spinlock_t means that they cannot be acquired while holding a raw spinlock.  "
"This results in the following nesting ordering:"
msgstr ""

#: ../../../locking/locktypes.rst:551
msgid "spinlock_t, rwlock_t, local_lock"
msgstr ""

#: ../../../locking/locktypes.rst:552
msgid "raw_spinlock_t and bit spinlocks"
msgstr ""

#: ../../../locking/locktypes.rst:554
msgid ""
"Lockdep will complain if these constraints are violated, both in PREEMPT_RT "
"and otherwise."
msgstr ""
