# SOME DESCRIPTIVE TITLE.
# Copyright (C) The kernel development community
# This file is distributed under the same license as the The Linux Kernel package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: The Linux Kernel master\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2025-09-29 08:26+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_TW\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#: ../../../core-api/mm-api.rst:3
msgid "Memory Management APIs"
msgstr ""

#: ../../../core-api/mm-api.rst:6
msgid "User Space Memory Access"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:93
msgid "``get_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:91
msgid "Get a simple variable from user space."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:389 mm/page_alloc.c:416
#: mm/page_alloc.c:438 mm/page_alloc.c:463 mm/page_alloc.c:488
#: mm/page_alloc.c:508 mm/page_alloc.c:528 mm/page_alloc.c:2071
#: mm/page_alloc.c:3103 mm/page_alloc.c:5243 mm/page_alloc.c:5309
#: mm/page_alloc.c:5337 mm/page_alloc.c:5363 mm/page_alloc.c:5382
#: mm/page_alloc.c:5414 mm/page_alloc.c:5490 mm/page_alloc.c:6365
#: mm/page_alloc.c:6822 mm/page_alloc.c:7015 mm/page_alloc.c:7486
#: ../../../core-api/mm-api:101: mm/mempolicy.c:281 mm/mempolicy.c:313
#: mm/mempolicy.c:2366 mm/mempolicy.c:2449 mm/mempolicy.c:2496
#: mm/mempolicy.c:2900 mm/mempolicy.c:3130 mm/mempolicy.c:3336
#: mm/mempolicy.c:3471 ../../../core-api/mm-api:104:
#: include/linux/mm_inline.h:18 include/linux/mm_inline.h:67
#: include/linux/mm_inline.h:85 ../../../core-api/mm-api:105:
#: include/linux/page-flags.h:298 include/linux/page-flags.h:315
#: include/linux/page-flags.h:760 include/linux/page-flags.h:779
#: include/linux/page-flags.h:861 include/linux/page-flags.h:1057
#: include/linux/page-flags.h:1085 include/linux/page-flags.h:1154
#: include/linux/page-flags.h:1240 ../../../core-api/mm-api:106:
#: include/linux/mm.h:498 include/linux/mm.h:988 include/linux/mm.h:1004
#: include/linux/mm.h:1122 include/linux/mm.h:1155 include/linux/mm.h:1210
#: include/linux/mm.h:1220 include/linux/mm.h:1316 include/linux/mm.h:1349
#: include/linux/mm.h:1368 include/linux/mm.h:1409 include/linux/mm.h:1773
#: include/linux/mm.h:1798 include/linux/mm.h:1814 include/linux/mm.h:1830
#: include/linux/mm.h:1855 include/linux/mm.h:1914 include/linux/mm.h:1925
#: include/linux/mm.h:1994 include/linux/mm.h:2028 include/linux/mm.h:2047
#: include/linux/mm.h:2064 include/linux/mm.h:2077 include/linux/mm.h:2141
#: include/linux/mm.h:2874 include/linux/mm.h:2892 include/linux/mm.h:3427
#: include/linux/mm.h:4026 ../../../core-api/mm-api:108:
#: include/linux/page_ref.h:75 include/linux/page_ref.h:256
#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1623
#: include/linux/mmzone.h:1663 include/linux/mmzone.h:1671
#: include/linux/mmzone.h:1710 include/linux/mmzone.h:1734
#: include/linux/mmzone.h:1759 include/linux/mmzone.h:1783
#: include/linux/mmzone.h:2139 ../../../core-api/mm-api:110: mm/util.c:684
#: ../../../core-api/mm-api:113: mm/rmap.c:165 mm/rmap.c:775 mm/rmap.c:979
#: mm/rmap.c:1172 mm/rmap.c:1217 mm/rmap.c:1326 mm/rmap.c:1351 mm/rmap.c:1383
#: mm/rmap.c:1496 mm/rmap.c:1520 mm/rmap.c:1544 mm/rmap.c:1633 mm/rmap.c:1650
#: mm/rmap.c:1670 mm/rmap.c:1795 mm/rmap.c:1812 mm/rmap.c:1832 mm/rmap.c:2253
#: mm/rmap.c:2583 mm/rmap.c:2630 mm/rmap.c:2857 ../../../core-api/mm-api:114:
#: mm/migrate.c:104 mm/migrate.c:190 mm/migrate.c:215 mm/migrate.c:871
#: mm/migrate.c:996 mm/migrate.c:1018 ../../../core-api/mm-api:115:
#: mm/mmap.c:282 mm/mmap.c:881 mm/mmap.c:901 mm/mmap.c:918
#: ../../../core-api/mm-api:116: mm/kmemleak.c:1083 mm/kmemleak.c:1107
#: mm/kmemleak.c:1126 mm/kmemleak.c:1151 mm/kmemleak.c:1167 mm/kmemleak.c:1185
#: mm/kmemleak.c:1201 mm/kmemleak.c:1237 mm/kmemleak.c:1253 mm/kmemleak.c:1270
#: mm/kmemleak.c:1284 mm/kmemleak.c:1302 mm/kmemleak.c:1322 mm/kmemleak.c:1340
#: mm/kmemleak.c:1360 mm/kmemleak.c:1376 ../../../core-api/mm-api:118:
#: mm/memremap.c:356 mm/memremap.c:399 ../../../core-api/mm-api:119:
#: mm/hugetlb.c:1032 mm/hugetlb.c:7751 mm/hugetlb.c:7816
#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:56
#: arch/x86/lib/usercopy_32.c:76 ../../../core-api/mm-api:120: mm/swap.c:447
#: mm/swap.c:496 mm/swap.c:520 mm/swap.c:681 mm/swap.c:722 mm/swap.c:938
#: mm/swap.c:1008 mm/swap.c:1068 ../../../core-api/mm-api:121: mm/zpool.c:34
#: mm/zpool.c:47 mm/zpool.c:101 mm/zpool.c:136 mm/zpool.c:193 mm/zpool.c:213
#: mm/zpool.c:228 mm/zpool.c:252 mm/zpool.c:271 mm/zpool.c:291 mm/zpool.c:305
#: mm/zpool.c:319 ../../../core-api/mm-api:122: mm/memcontrol.c:245
#: mm/memcontrol.c:266 mm/memcontrol.c:685 mm/memcontrol.c:762
#: mm/memcontrol.c:829 mm/memcontrol.c:900 mm/memcontrol.c:950
#: mm/memcontrol.c:971 mm/memcontrol.c:989 mm/memcontrol.c:1093
#: mm/memcontrol.c:1142 mm/memcontrol.c:1198 mm/memcontrol.c:1219
#: mm/memcontrol.c:1241 mm/memcontrol.c:1265 mm/memcontrol.c:1303
#: mm/memcontrol.c:1534 mm/memcontrol.c:1559 mm/memcontrol.c:1684
#: mm/memcontrol.c:1789 mm/memcontrol.c:2834 mm/memcontrol.c:2859
#: mm/memcontrol.c:3357 mm/memcontrol.c:3615 mm/memcontrol.c:3939
#: mm/memcontrol.c:4679 mm/memcontrol.c:4730 mm/memcontrol.c:4764
#: mm/memcontrol.c:4914 mm/memcontrol.c:4958 mm/memcontrol.c:5032
#: mm/memcontrol.c:5055 mm/memcontrol.c:5132 mm/memcontrol.c:5181
#: mm/memcontrol.c:5379 mm/memcontrol.c:5424 mm/memcontrol.c:5452
#: ../../../core-api/mm-api:124: mm/shmem.c:429 mm/shmem.c:581 mm/shmem.c:1577
#: mm/shmem.c:2681 mm/shmem.c:5905 mm/shmem.c:5921 mm/shmem.c:5933
#: mm/shmem.c:5947 mm/shmem.c:5974 ../../../core-api/mm-api:125:
#: mm/migrate_device.c:477 mm/migrate_device.c:796 mm/migrate_device.c:812
#: mm/migrate_device.c:895 mm/migrate_device.c:929 mm/migrate_device.c:962
#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:29
#: mm/mapping_dirty_helpers.c:80 mm/mapping_dirty_helpers.c:254
#: mm/mapping_dirty_helpers.c:282 ../../../core-api/mm-api:129: mm/percpu.c:212
#: mm/percpu.c:312 mm/percpu.c:359 mm/percpu.c:411 mm/percpu.c:496
#: mm/percpu.c:520 mm/percpu.c:547 mm/percpu.c:625 mm/percpu.c:738
#: mm/percpu.c:771 mm/percpu.c:803 mm/percpu.c:950 mm/percpu.c:1065
#: mm/percpu.c:1096 mm/percpu.c:1202 mm/percpu.c:1270 mm/percpu.c:1337
#: mm/percpu.c:1502 mm/percpu.c:1526 mm/percpu.c:1583 mm/percpu.c:1720
#: mm/percpu.c:1939 mm/percpu.c:1992 mm/percpu.c:2082 mm/percpu.c:2187
#: mm/percpu.c:2222 mm/percpu.c:2307 mm/percpu.c:2323 mm/percpu.c:2390
#: mm/percpu.c:2434 mm/percpu.c:2445 mm/percpu.c:2502 mm/percpu.c:2776
#: mm/percpu.c:2977 mm/percpu.c:3172 ../../../core-api/mm-api:130:
#: mm/maccess.c:116 mm/maccess.c:145 mm/maccess.c:170 mm/maccess.c:210
#: ../../../core-api/mm-api:131: mm/vmscan.c:226 mm/vmscan.c:417
#: mm/vmscan.c:837 mm/vmscan.c:863 mm/vmscan.c:1836 mm/vmscan.c:7854
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:587
#: mm/memory_hotplug.c:2169 mm/memory_hotplug.c:2284
#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:173 mm/mmu_notifier.c:685
#: mm/mmu_notifier.c:739 mm/mmu_notifier.c:855 mm/mmu_notifier.c:961
#: mm/mmu_notifier.c:1033 mm/mmu_notifier.c:1087 ../../../core-api/mm-api:134:
#: mm/balloon_compaction.c:35 mm/balloon_compaction.c:64
#: ../../../core-api/mm-api:135: mm/huge_memory.c:1439 mm/huge_memory.c:1578
#: mm/huge_memory.c:1622 ../../../core-api/mm-api:14: mm/gup.c:3296
#: ../../../core-api/mm-api:37: include/linux/slab.h:361
#: include/linux/slab.h:410 include/linux/slab.h:484 include/linux/slab.h:732
#: include/linux/slab.h:750 include/linux/slab.h:846 include/linux/slab.h:941
#: include/linux/slab.h:957 include/linux/slab.h:988 include/linux/slab.h:1037
#: include/linux/slab.h:1105 ../../../core-api/mm-api:40: mm/slub.c:4282
#: mm/slub.c:4788 mm/slub.c:4873 mm/slub.c:4973 mm/slub.c:5047 mm/slub.c:5100
#: mm/slub.c:5119 mm/slub.c:5137 ../../../core-api/mm-api:43:
#: mm/slab_common.c:258 mm/slab_common.c:368 mm/slab_common.c:552
#: mm/slab_common.c:582 mm/slab_common.c:1211 mm/slab_common.c:2014
#: ../../../core-api/mm-api:46: mm/util.c:42 ../../../core-api/mm-api:52:
#: mm/vmalloc.c:2961 mm/vmalloc.c:2980 mm/vmalloc.c:3014 mm/vmalloc.c:3385
#: mm/vmalloc.c:3449 mm/vmalloc.c:3477 mm/vmalloc.c:3557 mm/vmalloc.c:3939
#: mm/vmalloc.c:3980 mm/vmalloc.c:3999 mm/vmalloc.c:4020 mm/vmalloc.c:4040
#: mm/vmalloc.c:4058 mm/vmalloc.c:4078 mm/vmalloc.c:4198 mm/vmalloc.c:4214
#: mm/vmalloc.c:4573 ../../../core-api/mm-api:61: mm/filemap.c:371
#: mm/filemap.c:446 mm/filemap.c:464 mm/filemap.c:479 mm/filemap.c:551
#: mm/filemap.c:575 mm/filemap.c:597 mm/filemap.c:622 mm/filemap.c:674
#: mm/filemap.c:722 mm/filemap.c:774 mm/filemap.c:812 mm/filemap.c:1489
#: mm/filemap.c:1509 mm/filemap.c:1539 mm/filemap.c:1559 mm/filemap.c:1572
#: mm/filemap.c:1634 mm/filemap.c:1674 mm/filemap.c:1763 mm/filemap.c:1800
#: mm/filemap.c:1899 mm/filemap.c:2193 mm/filemap.c:2214 mm/filemap.c:2286
#: mm/filemap.c:2667 mm/filemap.c:2846 mm/filemap.c:2946 mm/filemap.c:3385
#: mm/filemap.c:3975 mm/filemap.c:3999 mm/filemap.c:4042 mm/filemap.c:4246
#: mm/filemap.c:4301 mm/filemap.c:4332 mm/filemap.c:4365
#: ../../../core-api/mm-api:70: mm/readahead.c:198 mm/readahead.c:742
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2034
#: mm/page-writeback.c:2109 mm/page-writeback.c:2374 mm/page-writeback.c:2483
#: mm/page-writeback.c:2598 mm/page-writeback.c:2753 mm/page-writeback.c:2787
#: mm/page-writeback.c:2823 mm/page-writeback.c:3113 mm/page-writeback.c:3134
#: mm/page-writeback.c:3159 ../../../core-api/mm-api:82: mm/truncate.c:125
#: mm/truncate.c:322 mm/truncate.c:450 mm/truncate.c:469 mm/truncate.c:565
#: mm/truncate.c:641 mm/truncate.c:729 mm/truncate.c:744 mm/truncate.c:779
#: mm/truncate.c:803 mm/truncate.c:867 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:76 include/linux/pagemap.h:97
#: include/linux/pagemap.h:113 include/linux/pagemap.h:125
#: include/linux/pagemap.h:230 include/linux/pagemap.h:450
#: include/linux/pagemap.h:488 include/linux/pagemap.h:553
#: include/linux/pagemap.h:573 include/linux/pagemap.h:587
#: include/linux/pagemap.h:602 include/linux/pagemap.h:621
#: include/linux/pagemap.h:732 include/linux/pagemap.h:758
#: include/linux/pagemap.h:785 include/linux/pagemap.h:802
#: include/linux/pagemap.h:820 include/linux/pagemap.h:840
#: include/linux/pagemap.h:862 include/linux/pagemap.h:881
#: include/linux/pagemap.h:908 include/linux/pagemap.h:930
#: include/linux/pagemap.h:941 include/linux/pagemap.h:956
#: include/linux/pagemap.h:999 include/linux/pagemap.h:1020
#: include/linux/pagemap.h:1087 include/linux/pagemap.h:1112
#: include/linux/pagemap.h:1141 include/linux/pagemap.h:1162
#: include/linux/pagemap.h:1282 include/linux/pagemap.h:1355
#: include/linux/pagemap.h:1377 include/linux/pagemap.h:1419
#: include/linux/pagemap.h:1464 include/linux/pagemap.h:1473
#: include/linux/pagemap.h:1482 include/linux/pagemap.h:1491
#: include/linux/pagemap.h:1500 include/linux/pagemap.h:1515
#: include/linux/pagemap.h:1543 ../../../core-api/mm-api:8:
#: arch/x86/include/asm/uaccess.h:95 arch/x86/include/asm/uaccess.h:115
#: arch/x86/include/asm/uaccess.h:196 arch/x86/include/asm/uaccess.h:215
#: ../../../core-api/mm-api:91: mm/mempool.c:160 mm/mempool.c:182
#: mm/mempool.c:238 mm/mempool.c:261 mm/mempool.c:299 mm/mempool.c:379
#: mm/mempool.c:462 mm/mempool.c:499 ../../../core-api/mm-api:97:
#: mm/memory.c:2050 mm/memory.c:2287 mm/memory.c:2319 mm/memory.c:2401
#: mm/memory.c:2426 mm/memory.c:2497 mm/memory.c:2557 mm/memory.c:2884
#: mm/memory.c:2943 mm/memory.c:4083 mm/memory.c:4114 mm/memory.c:6501
#: mm/memory.c:6608 mm/memory.c:6625 mm/memory.c:6892
msgid "**Parameters**"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:97
#: arch/x86/include/asm/uaccess.h:117 arch/x86/include/asm/uaccess.h:198
#: arch/x86/include/asm/uaccess.h:217
msgid "``x``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:92
#: arch/x86/include/asm/uaccess.h:112
msgid "Variable to store result."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:94
#: arch/x86/include/asm/uaccess.h:114 arch/x86/include/asm/uaccess.h:195
#: arch/x86/include/asm/uaccess.h:214
msgid "``ptr``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:93
#: arch/x86/include/asm/uaccess.h:113
msgid "Source address, in user space."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5254
#: ../../../core-api/mm-api:101: mm/mempolicy.c:2500
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:299
#: include/linux/page-flags.h:1056 include/linux/page-flags.h:1084
#: ../../../core-api/mm-api:106: include/linux/mm.h:1315
#: include/linux/mm.h:1353 include/linux/mm.h:1373 include/linux/mm.h:1413
#: include/linux/mm.h:2032 include/linux/mm.h:2049 include/linux/mm.h:2063
#: ../../../core-api/mm-api:113: mm/rmap.c:781 mm/rmap.c:2256
#: ../../../core-api/mm-api:120: mm/swap.c:683 mm/swap.c:944
#: ../../../core-api/mm-api:124: mm/shmem.c:2696 ../../../core-api/mm-api:129:
#: mm/percpu.c:551 mm/percpu.c:1941 mm/percpu.c:1995 mm/percpu.c:2087
#: mm/percpu.c:2222 ../../../core-api/mm-api:131: mm/vmscan.c:842
#: mm/vmscan.c:864 mm/vmscan.c:1849 ../../../core-api/mm-api:37:
#: include/linux/slab.h:425 ../../../core-api/mm-api:40: mm/slub.c:5102
#: ../../../core-api/mm-api:43: mm/slab_common.c:275
#: ../../../core-api/mm-api:52: mm/vmalloc.c:3390 ../../../core-api/mm-api:61:
#: mm/filemap.c:1489 mm/filemap.c:1514 mm/filemap.c:1634 mm/filemap.c:3982
#: ../../../core-api/mm-api:70: mm/readahead.c:203 ../../../core-api/mm-api:76:
#: mm/page-writeback.c:3114 mm/page-writeback.c:3135 mm/page-writeback.c:3161
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:452
#: include/linux/pagemap.h:804 include/linux/pagemap.h:865
#: include/linux/pagemap.h:956 include/linux/pagemap.h:1003
#: include/linux/pagemap.h:1090 include/linux/pagemap.h:1122
#: include/linux/pagemap.h:1143 include/linux/pagemap.h:1163
#: include/linux/pagemap.h:1418 include/linux/pagemap.h:1544
#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:95
#: arch/x86/include/asm/uaccess.h:115 arch/x86/include/asm/uaccess.h:196
#: arch/x86/include/asm/uaccess.h:215 ../../../core-api/mm-api:97:
#: mm/memory.c:2410 mm/memory.c:2430 mm/memory.c:2521 mm/memory.c:2568
msgid "**Context**"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:95
#: arch/x86/include/asm/uaccess.h:115 arch/x86/include/asm/uaccess.h:196
#: arch/x86/include/asm/uaccess.h:215
msgid "User context only. This function may sleep if pagefaults are enabled."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3 mm/page_alloc.c:440
#: mm/page_alloc.c:2072 mm/page_alloc.c:3104 mm/page_alloc.c:5243
#: mm/page_alloc.c:5309 mm/page_alloc.c:5339 mm/page_alloc.c:5363
#: mm/page_alloc.c:5381 mm/page_alloc.c:5490 mm/page_alloc.c:6826
#: mm/page_alloc.c:7019 mm/page_alloc.c:7486 ../../../core-api/mm-api:101:
#: mm/mempolicy.c:281 mm/mempolicy.c:315 mm/mempolicy.c:2451
#: mm/mempolicy.c:2496 mm/mempolicy.c:2902 mm/mempolicy.c:3130
#: mm/mempolicy.c:3336 mm/mempolicy.c:3472 ../../../core-api/mm-api:102:
#: include/linux/mm_types.h:372 include/linux/mm_types.h:548
#: include/linux/mm_types.h:1454 include/linux/mm_types.h:1608
#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:17
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:297
#: include/linux/page-flags.h:315 include/linux/page-flags.h:760
#: include/linux/page-flags.h:778 include/linux/page-flags.h:1153
#: include/linux/page-flags.h:1239 ../../../core-api/mm-api:106:
#: include/linux/mm.h:497 include/linux/mm.h:987 include/linux/mm.h:1003
#: include/linux/mm.h:1121 include/linux/mm.h:1348 include/linux/mm.h:1368
#: include/linux/mm.h:1408 include/linux/mm.h:1772 include/linux/mm.h:1798
#: include/linux/mm.h:1814 include/linux/mm.h:1830 include/linux/mm.h:1854
#: include/linux/mm.h:1913 include/linux/mm.h:1924 include/linux/mm.h:2027
#: include/linux/mm.h:2046 include/linux/mm.h:2077 include/linux/mm.h:2140
#: include/linux/mm.h:2874 include/linux/mm.h:2891 include/linux/mm.h:4025
#: ../../../core-api/mm-api:108: include/linux/page_ref.h:74
#: include/linux/page_ref.h:255 ../../../core-api/mm-api:109:
#: include/linux/mmzone.h:1670 include/linux/mmzone.h:1711
#: include/linux/mmzone.h:1735 include/linux/mmzone.h:1762
#: include/linux/mmzone.h:1785 include/linux/mmzone.h:2138
#: ../../../core-api/mm-api:110: mm/util.c:683 ../../../core-api/mm-api:113:
#: mm/rmap.c:164 mm/rmap.c:776 mm/rmap.c:981 mm/rmap.c:1175 mm/rmap.c:1222
#: mm/rmap.c:1326 mm/rmap.c:1500 mm/rmap.c:1523 mm/rmap.c:1546 mm/rmap.c:1635
#: mm/rmap.c:1651 mm/rmap.c:1671 mm/rmap.c:1797 mm/rmap.c:1813 mm/rmap.c:1833
#: mm/rmap.c:2253 mm/rmap.c:2583 mm/rmap.c:2632 ../../../core-api/mm-api:114:
#: mm/migrate.c:104 mm/migrate.c:189 mm/migrate.c:216 mm/migrate.c:873
#: mm/migrate.c:998 mm/migrate.c:1020 ../../../core-api/mm-api:115:
#: mm/mmap.c:331 mm/mmap.c:920 ../../../core-api/mm-api:116: mm/kmemleak.c:1089
#: mm/kmemleak.c:1108 mm/kmemleak.c:1127 mm/kmemleak.c:1150 mm/kmemleak.c:1168
#: mm/kmemleak.c:1184 mm/kmemleak.c:1200 mm/kmemleak.c:1236 mm/kmemleak.c:1252
#: mm/kmemleak.c:1283 mm/kmemleak.c:1304 mm/kmemleak.c:1321
#: ../../../core-api/mm-api:118: mm/memremap.c:399
#: ../../../core-api/mm-api:119: mm/hugetlb.c:1031 mm/hugetlb.c:7751
#: mm/hugetlb.c:7815 ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:56
#: arch/x86/lib/usercopy_32.c:76 ../../../core-api/mm-api:120: mm/swap.c:446
#: mm/swap.c:495 mm/swap.c:520 mm/swap.c:680 mm/swap.c:721 mm/swap.c:938
#: mm/swap.c:1008 mm/swap.c:1067 ../../../core-api/mm-api:121: mm/zpool.c:46
#: mm/zpool.c:100 mm/zpool.c:137 mm/zpool.c:192 mm/zpool.c:212 mm/zpool.c:231
#: mm/zpool.c:252 mm/zpool.c:272 mm/zpool.c:292 mm/zpool.c:318
#: ../../../core-api/mm-api:122: mm/memcontrol.c:244 mm/memcontrol.c:265
#: mm/memcontrol.c:763 mm/memcontrol.c:899 mm/memcontrol.c:990
#: mm/memcontrol.c:1143 mm/memcontrol.c:1197 mm/memcontrol.c:1218
#: mm/memcontrol.c:1241 mm/memcontrol.c:1267 mm/memcontrol.c:1302
#: mm/memcontrol.c:1684 mm/memcontrol.c:1789 mm/memcontrol.c:2835
#: mm/memcontrol.c:3360 mm/memcontrol.c:3614 mm/memcontrol.c:3938
#: mm/memcontrol.c:4679 mm/memcontrol.c:4730 mm/memcontrol.c:4766
#: mm/memcontrol.c:4914 mm/memcontrol.c:4958 mm/memcontrol.c:5033
#: mm/memcontrol.c:5132 mm/memcontrol.c:5378 mm/memcontrol.c:5424
#: mm/memcontrol.c:5452 ../../../core-api/mm-api:124: mm/shmem.c:430
#: mm/shmem.c:582 mm/shmem.c:1578 mm/shmem.c:2684 mm/shmem.c:5975
#: ../../../core-api/mm-api:125: mm/migrate_device.c:479
#: mm/migrate_device.c:797 mm/migrate_device.c:811 mm/migrate_device.c:894
#: mm/migrate_device.c:930 mm/migrate_device.c:962
#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:31
#: mm/mapping_dirty_helpers.c:83 mm/mapping_dirty_helpers.c:291
#: ../../../core-api/mm-api:129: mm/percpu.c:3 mm/percpu.c:313 mm/percpu.c:360
#: mm/percpu.c:414 mm/percpu.c:496 mm/percpu.c:519 mm/percpu.c:547
#: mm/percpu.c:626 mm/percpu.c:738 mm/percpu.c:771 mm/percpu.c:804
#: mm/percpu.c:951 mm/percpu.c:1067 mm/percpu.c:1098 mm/percpu.c:1204
#: mm/percpu.c:1270 mm/percpu.c:1337 mm/percpu.c:1503 mm/percpu.c:1527
#: mm/percpu.c:1582 mm/percpu.c:1722 mm/percpu.c:1938 mm/percpu.c:2186
#: mm/percpu.c:2221 mm/percpu.c:2306 mm/percpu.c:2322 mm/percpu.c:2390
#: mm/percpu.c:2433 mm/percpu.c:2445 mm/percpu.c:2502 mm/percpu.c:2778
#: mm/percpu.c:2980 mm/percpu.c:3172 ../../../core-api/mm-api:130:
#: mm/maccess.c:117 mm/maccess.c:146 mm/maccess.c:173 mm/maccess.c:210
#: ../../../core-api/mm-api:131: mm/vmscan.c:225 mm/vmscan.c:837
#: mm/vmscan.c:862 mm/vmscan.c:1835 mm/vmscan.c:7854
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:588
#: mm/memory_hotplug.c:2168 ../../../core-api/mm-api:133: mm/mmu_notifier.c:3
#: mm/mmu_notifier.c:173 mm/mmu_notifier.c:685 mm/mmu_notifier.c:740
#: mm/mmu_notifier.c:854 mm/mmu_notifier.c:964 mm/mmu_notifier.c:1032
#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:36
#: mm/balloon_compaction.c:66 ../../../core-api/mm-api:135:
#: mm/huge_memory.c:1440 mm/huge_memory.c:1579 ../../../core-api/mm-api:14:
#: mm/gup.c:3299 ../../../core-api/mm-api:37: include/linux/slab.h:3
#: include/linux/slab.h:84 include/linux/slab.h:104 include/linux/slab.h:197
#: include/linux/slab.h:229 include/linux/slab.h:339 include/linux/slab.h:367
#: include/linux/slab.h:484 include/linux/slab.h:732 include/linux/slab.h:750
#: include/linux/slab.h:846 include/linux/slab.h:959 include/linux/slab.h:1105
#: ../../../core-api/mm-api:40: mm/slub.c:4283 mm/slub.c:4788 mm/slub.c:4872
#: mm/slub.c:4974 mm/slub.c:5050 mm/slub.c:5099 mm/slub.c:5119 mm/slub.c:5138
#: ../../../core-api/mm-api:43: mm/slab_common.c:3 mm/slab_common.c:262
#: mm/slab_common.c:375 mm/slab_common.c:551 mm/slab_common.c:581
#: mm/slab_common.c:1210 ../../../core-api/mm-api:46: mm/util.c:41
#: ../../../core-api/mm-api:52: mm/vmalloc.c:3 mm/vmalloc.c:3015
#: mm/vmalloc.c:3384 mm/vmalloc.c:3448 mm/vmalloc.c:3479 mm/vmalloc.c:3558
#: mm/vmalloc.c:3942 mm/vmalloc.c:3979 mm/vmalloc.c:4000 mm/vmalloc.c:4019
#: mm/vmalloc.c:4039 mm/vmalloc.c:4058 mm/vmalloc.c:4078 mm/vmalloc.c:4197
#: mm/vmalloc.c:4213 mm/vmalloc.c:4576 ../../../core-api/mm-api:61:
#: mm/filemap.c:371 mm/filemap.c:447 mm/filemap.c:463 mm/filemap.c:480
#: mm/filemap.c:552 mm/filemap.c:576 mm/filemap.c:598 mm/filemap.c:621
#: mm/filemap.c:675 mm/filemap.c:722 mm/filemap.c:775 mm/filemap.c:812
#: mm/filemap.c:1488 mm/filemap.c:1509 mm/filemap.c:1538 mm/filemap.c:1558
#: mm/filemap.c:1571 mm/filemap.c:1633 mm/filemap.c:1764 mm/filemap.c:1801
#: mm/filemap.c:1901 mm/filemap.c:2195 mm/filemap.c:2216 mm/filemap.c:2289
#: mm/filemap.c:2668 mm/filemap.c:2846 mm/filemap.c:2949 mm/filemap.c:3384
#: mm/filemap.c:3977 mm/filemap.c:4000 mm/filemap.c:4043 mm/filemap.c:4246
#: mm/filemap.c:4301 mm/filemap.c:4332 mm/filemap.c:4368
#: ../../../core-api/mm-api:70: mm/readahead.c:199 mm/readahead.c:743
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2034
#: mm/page-writeback.c:2108 mm/page-writeback.c:2375 mm/page-writeback.c:2485
#: mm/page-writeback.c:2753 mm/page-writeback.c:2787 mm/page-writeback.c:2822
#: mm/page-writeback.c:3112 mm/page-writeback.c:3133 mm/page-writeback.c:3158
#: ../../../core-api/mm-api:82: mm/truncate.c:126 mm/truncate.c:323
#: mm/truncate.c:450 mm/truncate.c:468 mm/truncate.c:566 mm/truncate.c:642
#: mm/truncate.c:728 mm/truncate.c:744 mm/truncate.c:779 mm/truncate.c:804
#: mm/truncate.c:868 ../../../core-api/mm-api:85: include/linux/pagemap.h:76
#: include/linux/pagemap.h:97 include/linux/pagemap.h:112
#: include/linux/pagemap.h:124 include/linux/pagemap.h:230
#: include/linux/pagemap.h:449 include/linux/pagemap.h:488
#: include/linux/pagemap.h:552 include/linux/pagemap.h:572
#: include/linux/pagemap.h:587 include/linux/pagemap.h:602
#: include/linux/pagemap.h:620 include/linux/pagemap.h:680
#: include/linux/pagemap.h:731 include/linux/pagemap.h:760
#: include/linux/pagemap.h:785 include/linux/pagemap.h:802
#: include/linux/pagemap.h:820 include/linux/pagemap.h:840
#: include/linux/pagemap.h:862 include/linux/pagemap.h:882
#: include/linux/pagemap.h:908 include/linux/pagemap.h:941
#: include/linux/pagemap.h:999 include/linux/pagemap.h:1086
#: include/linux/pagemap.h:1111 include/linux/pagemap.h:1140
#: include/linux/pagemap.h:1161 include/linux/pagemap.h:1283
#: include/linux/pagemap.h:1321 include/linux/pagemap.h:1358
#: include/linux/pagemap.h:1380 include/linux/pagemap.h:1543
#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:98
#: arch/x86/include/asm/uaccess.h:118 arch/x86/include/asm/uaccess.h:199
#: arch/x86/include/asm/uaccess.h:218 ../../../core-api/mm-api:91:
#: mm/mempool.c:160 mm/mempool.c:182 mm/mempool.c:242 mm/mempool.c:266
#: mm/mempool.c:301 mm/mempool.c:380 mm/mempool.c:463 mm/mempool.c:500
#: ../../../core-api/mm-api:97: mm/memory.c:2051 mm/memory.c:2290
#: mm/memory.c:2320 mm/memory.c:2402 mm/memory.c:2427 mm/memory.c:2499
#: mm/memory.c:2558 mm/memory.c:2944 mm/memory.c:4085 mm/memory.c:6500
#: mm/memory.c:6607 mm/memory.c:6628 mm/memory.c:6895
msgid "**Description**"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:97
#: arch/x86/include/asm/uaccess.h:117
msgid ""
"This macro copies a single simple variable from user space to kernel space.  "
"It supports simple types like char and int, but not larger data types like "
"structures or arrays."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:101
#: arch/x86/include/asm/uaccess.h:121
msgid ""
"**ptr** must have pointer-to-simple-variable type, and the result of "
"dereferencing **ptr** must be assignable to **x** without a cast."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:391 mm/page_alloc.c:417
#: mm/page_alloc.c:438 mm/page_alloc.c:5316 mm/page_alloc.c:5341
#: mm/page_alloc.c:5386 mm/page_alloc.c:5414 mm/page_alloc.c:5497
#: mm/page_alloc.c:6832 mm/page_alloc.c:7030 mm/page_alloc.c:7492
#: ../../../core-api/mm-api:101: mm/mempolicy.c:282 mm/mempolicy.c:2369
#: mm/mempolicy.c:2456 mm/mempolicy.c:2504 mm/mempolicy.c:2905
#: mm/mempolicy.c:3338 ../../../core-api/mm-api:104:
#: include/linux/mm_inline.h:20 include/linux/mm_inline.h:84
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:305
#: include/linux/page-flags.h:765 include/linux/page-flags.h:860
#: include/linux/page-flags.h:1058 include/linux/page-flags.h:1086
#: ../../../core-api/mm-api:106: include/linux/mm.h:502 include/linux/mm.h:989
#: include/linux/mm.h:1134 include/linux/mm.h:1154 include/linux/mm.h:1219
#: include/linux/mm.h:1774 include/linux/mm.h:1800 include/linux/mm.h:1816
#: include/linux/mm.h:1832 include/linux/mm.h:1871 include/linux/mm.h:1993
#: include/linux/mm.h:2036 include/linux/mm.h:2053 include/linux/mm.h:2066
#: include/linux/mm.h:2107 include/linux/mm.h:2876 include/linux/mm.h:3427
#: include/linux/mm.h:4027 ../../../core-api/mm-api:108:
#: include/linux/page_ref.h:84 include/linux/page_ref.h:259
#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1624
#: include/linux/mmzone.h:1716 include/linux/mmzone.h:1743
#: include/linux/mmzone.h:2142 ../../../core-api/mm-api:113: mm/rmap.c:786
#: mm/rmap.c:982 mm/rmap.c:1184 mm/rmap.c:2660 ../../../core-api/mm-api:114:
#: mm/migrate.c:1003 mm/migrate.c:1024 ../../../core-api/mm-api:115:
#: mm/mmap.c:305 mm/mmap.c:882 mm/mmap.c:901 mm/mmap.c:922
#: ../../../core-api/mm-api:119: mm/hugetlb.c:1033 mm/hugetlb.c:7760
#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:57
#: arch/x86/lib/usercopy_32.c:78 ../../../core-api/mm-api:121: mm/zpool.c:111
#: mm/zpool.c:144 mm/zpool.c:215 mm/zpool.c:238 mm/zpool.c:276 mm/zpool.c:319
#: ../../../core-api/mm-api:122: mm/memcontrol.c:1201 mm/memcontrol.c:1222
#: mm/memcontrol.c:1245 ../../../core-api/mm-api:124: mm/shmem.c:435
#: mm/shmem.c:586 mm/shmem.c:2699 ../../../core-api/mm-api:125:
#: mm/migrate_device.c:476 ../../../core-api/mm-api:127:
#: mm/mapping_dirty_helpers.c:260 mm/mapping_dirty_helpers.c:310
#: ../../../core-api/mm-api:129: mm/percpu.c:212 mm/percpu.c:500
#: mm/percpu.c:1068 mm/percpu.c:1105 mm/percpu.c:1211 mm/percpu.c:1272
#: mm/percpu.c:1341 mm/percpu.c:1584 mm/percpu.c:1726 mm/percpu.c:2309
#: mm/percpu.c:2337 mm/percpu.c:2395 mm/percpu.c:2787 mm/percpu.c:2999
#: mm/percpu.c:3177 ../../../core-api/mm-api:131: mm/vmscan.c:839
#: mm/vmscan.c:1845 ../../../core-api/mm-api:134: mm/balloon_compaction.c:38
#: mm/balloon_compaction.c:74 ../../../core-api/mm-api:135:
#: mm/huge_memory.c:1441 mm/huge_memory.c:1580 mm/huge_memory.c:1623
#: ../../../core-api/mm-api:37: include/linux/slab.h:371
#: include/linux/slab.h:428 include/linux/slab.h:734 include/linux/slab.h:770
#: ../../../core-api/mm-api:40: mm/slub.c:4287 mm/slub.c:4998 mm/slub.c:5056
#: mm/slub.c:5151 ../../../core-api/mm-api:43: mm/slab_common.c:278
#: mm/slab_common.c:376 mm/slab_common.c:553 mm/slab_common.c:587
#: ../../../core-api/mm-api:52: mm/vmalloc.c:3020 mm/vmalloc.c:3484
#: mm/vmalloc.c:3950 mm/vmalloc.c:3984 mm/vmalloc.c:4004 mm/vmalloc.c:4025
#: mm/vmalloc.c:4041 mm/vmalloc.c:4063 mm/vmalloc.c:4081 mm/vmalloc.c:4199
#: mm/vmalloc.c:4215 mm/vmalloc.c:4574 ../../../core-api/mm-api:61:
#: mm/filemap.c:373 mm/filemap.c:449 mm/filemap.c:465 mm/filemap.c:482
#: mm/filemap.c:559 mm/filemap.c:605 mm/filemap.c:628 mm/filemap.c:679
#: mm/filemap.c:738 mm/filemap.c:782 mm/filemap.c:1573 mm/filemap.c:1772
#: mm/filemap.c:1809 mm/filemap.c:1907 mm/filemap.c:2198 mm/filemap.c:2219
#: mm/filemap.c:2296 mm/filemap.c:2670 mm/filemap.c:2857 mm/filemap.c:2952
#: mm/filemap.c:3400 mm/filemap.c:3985 mm/filemap.c:4008 mm/filemap.c:4049
#: mm/filemap.c:4257 mm/filemap.c:4304 mm/filemap.c:4341
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2039
#: mm/page-writeback.c:2502 mm/page-writeback.c:2600 mm/page-writeback.c:2790
#: mm/page-writeback.c:2828 mm/page-writeback.c:3141
#: ../../../core-api/mm-api:82: mm/truncate.c:571 mm/truncate.c:644
#: mm/truncate.c:730 ../../../core-api/mm-api:85: include/linux/pagemap.h:605
#: include/linux/pagemap.h:622 include/linux/pagemap.h:763
#: include/linux/pagemap.h:787 include/linux/pagemap.h:807
#: include/linux/pagemap.h:823 include/linux/pagemap.h:868
#: include/linux/pagemap.h:929 include/linux/pagemap.h:943
#: include/linux/pagemap.h:959 include/linux/pagemap.h:1007
#: include/linux/pagemap.h:1093 include/linux/pagemap.h:1166
#: include/linux/pagemap.h:1287 include/linux/pagemap.h:1421
#: include/linux/pagemap.h:1515 include/linux/pagemap.h:1548
#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:104
#: arch/x86/include/asm/uaccess.h:127 arch/x86/include/asm/uaccess.h:205
#: arch/x86/include/asm/uaccess.h:227 ../../../core-api/mm-api:91:
#: mm/mempool.c:244 mm/mempool.c:271 mm/mempool.c:309 mm/mempool.c:386
#: mm/mempool.c:466 ../../../core-api/mm-api:97: mm/memory.c:2341
#: mm/memory.c:2413 mm/memory.c:2433 mm/memory.c:2524 mm/memory.c:2571
#: mm/memory.c:2889 mm/memory.c:2950 mm/memory.c:6524 mm/memory.c:6896
msgid "**Return**"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:105
#: arch/x86/include/asm/uaccess.h:128
msgid ""
"zero on success, or -EFAULT on error. On error, the variable **x** is set to "
"zero."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:113
msgid "``__get_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:111
msgid "Get a simple variable from user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:124
#: arch/x86/include/asm/uaccess.h:224
msgid ""
"Caller must check the pointer with access_ok() before calling this function."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:194
msgid "``put_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:192
msgid "Write a simple value into user space."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:193
#: arch/x86/include/asm/uaccess.h:212
msgid "Value to copy to user space."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:53
#: arch/x86/lib/usercopy_32.c:73 ../../../core-api/mm-api:8:
#: arch/x86/include/asm/uaccess.h:194 arch/x86/include/asm/uaccess.h:213
msgid "Destination address, in user space."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:198
#: arch/x86/include/asm/uaccess.h:217
msgid ""
"This macro copies a single simple value from kernel space to user space.  It "
"supports simple types like char and int, but not larger data types like "
"structures or arrays."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:202
#: arch/x86/include/asm/uaccess.h:221
msgid ""
"**ptr** must have pointer-to-simple-variable type, and **x** must be "
"assignable to the result of dereferencing **ptr**."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:206
#: arch/x86/include/asm/uaccess.h:228
msgid "zero on success, or -EFAULT on error."
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:213
msgid "``__put_user (x, ptr)``"
msgstr ""

#: ../../../core-api/mm-api:8: arch/x86/include/asm/uaccess.h:211
msgid "Write a simple value into user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:52
#: arch/x86/lib/usercopy_32.c:55
msgid "Zero a block of memory in user space."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:58
#: arch/x86/lib/usercopy_32.c:78
msgid "``void __user *to``"
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:55
#: arch/x86/lib/usercopy_32.c:75
msgid "``unsigned long n``"
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:54
#: arch/x86/lib/usercopy_32.c:74
msgid "Number of bytes to zero."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:58
#: arch/x86/lib/usercopy_32.c:79
msgid ""
"number of bytes that could not be cleared. On success, this will be zero."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:72
msgid "Zero a block of memory in user space, with less checking."
msgstr ""

#: ../../../core-api/mm-api:11: arch/x86/lib/usercopy_32.c:75
msgid ""
"Zero a block of memory in user space.  Caller must check the specified block "
"with access_ok() before calling this function."
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3292
msgid "pin user pages in memory"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6824
#: ../../../core-api/mm-api:125: mm/migrate_device.c:928
#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:963
#: ../../../core-api/mm-api:14: mm/gup.c:3298
msgid "``unsigned long start``"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3293
msgid "starting user address"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1496 mm/rmap.c:1633 mm/rmap.c:1795
#: ../../../core-api/mm-api:122: mm/memcontrol.c:1266
#: ../../../core-api/mm-api:14: mm/gup.c:3295
msgid "``int nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3294
msgid "number of pages from start to pin"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3296 ../../../core-api/mm-api:97:
#: mm/memory.c:6894
msgid "``unsigned int gup_flags``"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3295
msgid "flags modifying pin behaviour"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3297 ../../../core-api/mm-api:52:
#: mm/vmalloc.c:3016 mm/vmalloc.c:3479 ../../../core-api/mm-api:97:
#: mm/memory.c:2287 mm/memory.c:2400 mm/memory.c:2425
msgid "``struct page **pages``"
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3296
msgid ""
"array that receives pointers to the pages pinned. Should be at least "
"nr_pages long."
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3298
msgid ""
"Attempt to pin user pages in memory without taking mm->mmap_lock. If not "
"successful, it will fall back to taking the lock and calling "
"get_user_pages()."
msgstr ""

#: ../../../core-api/mm-api:14: mm/gup.c:3302
msgid ""
"Returns number of pages pinned. This may be fewer than the number requested. "
"If nr_pages is 0 or negative, returns 0. If no pages were pinned, returns -"
"errno."
msgstr ""

#: ../../../core-api/mm-api.rst:20
msgid "Memory Allocation Controls"
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:124
msgid ""
"These flags provide hints about how mobile the page is. Pages with similar "
"mobility are placed within the same pageblocks to minimise problems due to "
"external fragmentation."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:128
msgid ""
"``__GFP_MOVABLE`` (also a zone modifier) indicates that the page can be "
"moved by page migration during memory compaction or can be reclaimed."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:131
msgid ""
"``__GFP_RECLAIMABLE`` is used for slab allocations that specify "
"SLAB_RECLAIM_ACCOUNT and whose pages can be freed via shrinkers."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:134
msgid ""
"``__GFP_WRITE`` indicates the caller intends to dirty the page. Where "
"possible, these pages will be spread between local zones to avoid all the "
"dirty pages being in one zone (fair zone allocation policy)."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:138
msgid "``__GFP_HARDWALL`` enforces the cpuset memory allocation policy."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:140
msgid ""
"``__GFP_THISNODE`` forces the allocation to be satisfied from the requested "
"node with no fallbacks or placement policy enforcements."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:143
msgid "``__GFP_ACCOUNT`` causes the allocation to be accounted to kmemcg."
msgstr ""

#: ../../../core-api/mm-api:22: include/linux/gfp_types.h:145
msgid ""
"``__GFP_NO_OBJ_EXT`` causes slab allocation to have no object extension."
msgstr ""

#: ../../../core-api/mm-api:25: include/linux/gfp_types.h:160
msgid ""
"``__GFP_HIGH`` indicates that the caller is high-priority and that granting "
"the request is necessary before the system can make forward progress. For "
"example creating an IO context to clean pages and requests from atomic "
"context."
msgstr ""

#: ../../../core-api/mm-api:25: include/linux/gfp_types.h:165
msgid ""
"``__GFP_MEMALLOC`` allows access to all memory. This should only be used "
"when the caller guarantees the allocation will allow more memory to be freed "
"very shortly e.g. process exiting or swapping. Users either should be the MM "
"or co-ordinating closely with the VM (e.g. swap over NFS). Users of this "
"flag have to be extremely careful to not deplete the reserve completely and "
"implement a throttling mechanism which controls the consumption of the "
"reserve based on the amount of freed memory. Usage of a pre-allocated pool "
"(e.g. mempool) should be always considered before using this flag."
msgstr ""

#: ../../../core-api/mm-api:25: include/linux/gfp_types.h:175
msgid ""
"``__GFP_NOMEMALLOC`` is used to explicitly forbid access to emergency "
"reserves. This takes precedence over the ``__GFP_MEMALLOC`` flag if both are "
"set."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:187
msgid ""
"Please note that all the following flags are only applicable to sleepable "
"allocations (e.g. ``GFP_NOWAIT`` and ``GFP_ATOMIC`` will ignore them)."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:190
msgid "``__GFP_IO`` can start physical IO."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:192
msgid ""
"``__GFP_FS`` can call down to the low-level FS. Clearing the flag avoids the "
"allocator recursing into the filesystem which might already be holding locks."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:196
msgid ""
"``__GFP_DIRECT_RECLAIM`` indicates that the caller may enter direct reclaim. "
"This flag can be cleared to avoid unnecessary delays when a fallback option "
"is available."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:200
msgid ""
"``__GFP_KSWAPD_RECLAIM`` indicates that the caller wants to wake kswapd when "
"the low watermark is reached and have it reclaim pages until the high "
"watermark is reached. A caller may wish to clear this flag when fallback "
"options are available and the reclaim is likely to disrupt the system. The "
"canonical example is THP allocation where a fallback is cheap but reclaim/"
"compaction may cause indirect stalls."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:207
msgid ""
"``__GFP_RECLAIM`` is shorthand to allow/forbid both direct and kswapd "
"reclaim."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:209
msgid ""
"The default allocator behavior depends on the request size. We have a "
"concept of so-called costly allocations (with order > "
"``PAGE_ALLOC_COSTLY_ORDER``). !costly allocations are too essential to fail "
"so they are implicitly non-failing by default (with some exceptions like OOM "
"victims might fail so the caller still has to check for failures) while "
"costly requests try to be not disruptive and back off even without invoking "
"the OOM killer. The following three modifiers might be used to override some "
"of these implicit rules. Please note that all of them must be used along "
"with ``__GFP_DIRECT_RECLAIM`` flag."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:219
msgid ""
"``__GFP_NORETRY``: The VM implementation will try only very lightweight "
"memory direct reclaim to get some memory under memory pressure (thus it can "
"sleep). It will avoid disruptive actions like OOM killer. The caller must "
"handle the failure which is quite likely to happen under heavy memory "
"pressure. The flag is suitable when failure can easily be handled at small "
"cost, such as reduced throughput."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:226
msgid ""
"``__GFP_RETRY_MAYFAIL``: The VM implementation will retry memory reclaim "
"procedures that have previously failed if there is some indication that "
"progress has been made elsewhere.  It can wait for other tasks to attempt "
"high-level approaches to freeing memory such as compaction (which removes "
"fragmentation) and page-out. There is still a definite limit to the number "
"of retries, but it is a larger limit than with ``__GFP_NORETRY``. "
"Allocations with this flag may fail, but only when there is genuinely little "
"unused memory. While these allocations do not directly trigger the OOM "
"killer, their failure indicates that the system is likely to need to use the "
"OOM killer soon.  The caller must handle failure, but can reasonably do so "
"by failing a higher-level request, or completing it only in a much less "
"efficient manner. If the allocation does fail, and the caller is in a "
"position to free some non-essential memory, doing so could benefit the "
"system as a whole."
msgstr ""

#: ../../../core-api/mm-api:28: include/linux/gfp_types.h:244
msgid ""
"``__GFP_NOFAIL``: The VM implementation _must_ retry infinitely: the caller "
"cannot handle allocation failures. The allocation could block indefinitely "
"but will never return with failure. Testing for failure is pointless. It "
"_must_ be blockable and used together with __GFP_DIRECT_RECLAIM. It should "
"_never_ be used in non-sleepable contexts. New users should be evaluated "
"carefully (and the flag should be used only when there is no reasonable "
"failure policy) but it is definitely preferable to use the flag rather than "
"opencode endless loop around allocator. Allocating pages from the buddy with "
"__GFP_NOFAIL and order > 1 is not supported. Please consider using "
"kvmalloc() instead."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:310
msgid ""
"Useful GFP flag combinations that are commonly used. It is recommended that "
"subsystems start with one of these combinations and then set/clear "
"``__GFP_FOO`` flags as necessary."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:314
msgid ""
"``GFP_ATOMIC`` users can not sleep and need the allocation to succeed. A "
"lower watermark is applied to allow access to \"atomic reserves\". The "
"current implementation doesn't support NMI and few other strict non-"
"preemptive contexts (e.g. raw_spin_lock). The same applies to ``GFP_NOWAIT``."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:319
msgid ""
"``GFP_KERNEL`` is typical for kernel-internal allocations. The caller "
"requires ``ZONE_NORMAL`` or a lower zone for direct access but can direct "
"reclaim."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:322
msgid ""
"``GFP_KERNEL_ACCOUNT`` is the same as GFP_KERNEL, except the allocation is "
"accounted to kmemcg."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:325
msgid ""
"``GFP_NOWAIT`` is for kernel allocations that should not stall for direct "
"reclaim, start physical IO or use any filesystem callback.  It is very "
"likely to fail to allocate memory, even for very small allocations."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:329
msgid ""
"``GFP_NOIO`` will use direct reclaim to discard clean pages or slab pages "
"that do not require the starting of any physical IO. Please try to avoid "
"using this flag directly and instead use memalloc_noio_{save,restore} to "
"mark the whole scope which cannot perform any IO with a short explanation "
"why. All allocation requests will inherit GFP_NOIO implicitly."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:336
msgid ""
"``GFP_NOFS`` will use direct reclaim but will not use any filesystem "
"interfaces. Please try to avoid using this flag directly and instead use "
"memalloc_nofs_{save,restore} to mark the whole scope which cannot/shouldn't "
"recurse into the FS layer with a short explanation why. All allocation "
"requests will inherit GFP_NOFS implicitly."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:342
msgid ""
"``GFP_USER`` is for userspace allocations that also need to be directly "
"accessibly by the kernel or hardware. It is typically used by hardware for "
"buffers that are mapped to userspace (e.g. graphics) that hardware still "
"must DMA to. cpuset limits are enforced for these allocations."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:347
msgid ""
"``GFP_DMA`` exists for historical reasons and should be avoided where "
"possible. The flags indicates that the caller requires that the lowest zone "
"be used (``ZONE_DMA`` or 16M on x86-64). Ideally, this would be removed but "
"it would require careful auditing as some users really require it and others "
"use the flag to avoid lowmem reserves in ``ZONE_DMA`` and treat the lowest "
"zone as a type of emergency reserve."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:354
msgid ""
"``GFP_DMA32`` is similar to ``GFP_DMA`` except that the caller requires a 32-"
"bit address. Note that kmalloc(..., GFP_DMA32) does not return DMA32 memory "
"because the DMA32 kmalloc cache array is not implemented. (Reason: there is "
"no such user in kernel)."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:359
msgid ""
"``GFP_HIGHUSER`` is for userspace allocations that may be mapped to "
"userspace, do not need to be directly accessible by the kernel but that "
"cannot move once in use. An example may be a hardware allocation that maps "
"data directly into userspace but has no addressing limitations."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:364
msgid ""
"``GFP_HIGHUSER_MOVABLE`` is for userspace allocations that the kernel does "
"not need direct access to but can use kmap() when access is required. They "
"are expected to be movable via page reclaim or page migration. Typically, "
"pages on the LRU would also be allocated with ``GFP_HIGHUSER_MOVABLE``."
msgstr ""

#: ../../../core-api/mm-api:31: include/linux/gfp_types.h:369
msgid ""
"``GFP_TRANSHUGE`` and ``GFP_TRANSHUGE_LIGHT`` are used for THP allocations. "
"They are compound allocations that will generally fail quickly if memory is "
"not available and will not wake kswapd/kcompactd on failure. The _LIGHT "
"version does not attempt reclaim/compaction at all and is by default used in "
"page fault path, while the non-light is used by khugepaged."
msgstr ""

#: ../../../core-api/mm-api.rst:35
msgid "The Slab Cache"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:84
msgid "``SLAB_HWCACHE_ALIGN``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:82
msgid "Align objects on cache line boundaries."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:83
msgid ""
"Sufficiently large objects are aligned on cache line boundary. For object "
"size smaller than a half of cache line size, the alignment is on the half of "
"cache line size. In general, if object size is smaller than 1/2^n of cache "
"line size, the alignment is adjusted to 1/2^n."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:88
msgid ""
"If explicit alignment is also requested by the respective :c:type:`struct "
"kmem_cache_args <kmem_cache_args>` field, the greater of both is alignments "
"is applied."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:104
msgid "``SLAB_TYPESAFE_BY_RCU``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:102
msgid "**WARNING** READ THIS!"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:103
msgid ""
"This delays freeing the SLAB page by a grace period, it does _NOT_ delay "
"object freeing. This means that if you do kmem_cache_free() that memory "
"location is free to be reused at any time. Thus it may be possible to see "
"another object there in the same RCU grace period."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:108
msgid ""
"This feature only ensures the memory location backing the object stays "
"valid, the trick to using this is relying on an independent object "
"validation pass. Something like:"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:130
msgid ""
"This is useful if we need to approach a kernel structure obliquely, from its "
"address obtained without the usual locking. We can lock the structure to "
"stabilize it and check it's still at the given address, only if we can be "
"sure that the memory has not been meanwhile reused for some other kind of "
"object (which our subsystem's lock might corrupt)."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:136
msgid ""
"rcu_read_lock before reading the address, then rcu_read_unlock after taking "
"the spinlock within the structure expected at that address."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:139
msgid ""
"Note that object identity check has to be done *after* acquiring a "
"reference, therefore user has to ensure proper ordering for loads. "
"Similarly, when initializing objects allocated with SLAB_TYPESAFE_BY_RCU, "
"the newly allocated object has to be fully initialized *before* its refcount "
"gets initialized and proper ordering for stores is required. refcount_{add|"
"inc}_not_zero_acquire() and refcount_set_release() are designed with the "
"proper fences required for reference counting objects allocated with "
"SLAB_TYPESAFE_BY_RCU."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:148
msgid ""
"Note that it is not possible to acquire a lock within a structure allocated "
"with SLAB_TYPESAFE_BY_RCU without first acquiring a reference as described "
"above.  The reason is that SLAB_TYPESAFE_BY_RCU pages are not zeroed before "
"being given to the slab, which means that any locks must be initialized "
"after each and every kmem_struct_alloc(). Alternatively, make the ctor "
"passed to kmem_cache_create() initialize the locks at page-allocation time, "
"as is done in __i915_request_ctor(), sighand_ctor(), and anon_vma_ctor().  "
"Such a ctor permits readers to safely acquire those ctor-initialized locks "
"under rcu_read_lock() protection."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:159
msgid ""
"Note that SLAB_TYPESAFE_BY_RCU was originally named SLAB_DESTROY_BY_RCU."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:197
msgid "``SLAB_ACCOUNT``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:195
msgid "Account allocations to memcg."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:196
msgid ""
"All object allocations from this cache will be memcg accounted, regardless "
"of __GFP_ACCOUNT being or not being passed to individual allocations."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:229
msgid "``SLAB_RECLAIM_ACCOUNT``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:227
msgid "Objects are reclaimable."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:228
msgid ""
"Use this flag for caches that have an associated shrinker. As a result, slab "
"pages are allocated with __GFP_RECLAIMABLE, which affects grouping pages by "
"mobility, and are accounted in SReclaimable counter in /proc/meminfo"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:270
msgid "Less common arguments for kmem_cache_create()"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:341
#: include/linux/mm_types.h:531 ../../../core-api/mm-api:127:
#: mm/mapping_dirty_helpers.c:15 mm/mapping_dirty_helpers.c:59
#: ../../../core-api/mm-api:37: include/linux/slab.h:274
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1308
msgid "**Definition**::"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:397
#: include/linux/mm_types.h:567 ../../../core-api/mm-api:127:
#: mm/mapping_dirty_helpers.c:24 mm/mapping_dirty_helpers.c:69
#: ../../../core-api/mm-api:37: include/linux/slab.h:285
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1316
msgid "**Members**"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:283
msgid "``align``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:284
#: include/linux/slab.h:361
msgid "The required alignment for the objects."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:286
msgid "``0`` means no specific alignment is requested."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:289
msgid "``useroffset``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:290
msgid "Usercopy region offset."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:292
msgid "``0`` is a valid offset, when **usersize** is non-``0``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:295
msgid "``usersize``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:296
msgid "Usercopy region size."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:298
msgid "``0`` means no usercopy region is specified."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:301
msgid "``freeptr_offset``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:302
msgid ""
"Custom offset for the free pointer in :c:type:`SLAB_TYPESAFE_BY_RCU` caches"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:305
msgid ""
"By default :c:type:`SLAB_TYPESAFE_BY_RCU` caches place the free pointer "
"outside of the object. This might cause the object to grow in size. Cache "
"creators that have a reason to avoid this can specify a custom free pointer "
"offset in their struct where the free pointer will be placed."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:311
msgid ""
"Note that placing the free pointer inside the object requires the caller to "
"ensure that no fields are invalidated that are required to guard against "
"object recycling (See :c:type:`SLAB_TYPESAFE_BY_RCU` for details)."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:316
msgid ""
"Using ``0`` as a value for **freeptr_offset** is valid. If "
"**freeptr_offset** is specified, ``use_freeptr_offset`` must be set ``true``."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:319
msgid ""
"Note that **ctor** currently isn't supported with custom free pointers as a "
"**ctor** requires an external free pointer."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:323
msgid "``use_freeptr_offset``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:324
msgid "Whether a **freeptr_offset** is used."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:327
msgid "``ctor``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:328
msgid "A constructor for the objects."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:330
msgid ""
"The constructor is invoked for each object in a newly allocated slab page. "
"It is the cache user's responsibility to free object in the same state as "
"after calling the constructor, or deal appropriately with any differences "
"between a freshly constructed and a reallocated object."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:336
msgid "``NULL`` means no constructor."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:271
msgid ""
"Any uninitialized fields of the structure are interpreted as unused. The "
"exception is **freeptr_offset** where ``0`` is a valid value, so "
"**use_freeptr_offset** must be also set to ``true`` in order to interpret "
"the field as used. For **useroffset** ``0`` is also valid, but only with non-"
"``0`` **usersize**."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:277
msgid ""
"When ``NULL`` args is passed to kmem_cache_create(), it is equivalent to all "
"fields unused."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:357
msgid "Create a kmem cache with a region suitable for copying to userspace."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:135 ../../../core-api/mm-api:124:
#: mm/shmem.c:5907 mm/shmem.c:5923 mm/shmem.c:5932 ../../../core-api/mm-api:37:
#: include/linux/slab.h:363 ../../../core-api/mm-api:43: mm/slab_common.c:260
#: mm/slab_common.c:370
msgid "``const char *name``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:359
#: include/linux/slab.h:407 ../../../core-api/mm-api:43: mm/slab_common.c:255
msgid "A string which is used in /proc/slabinfo to identify this cache."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:361
msgid "``unsigned int size``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:360
#: include/linux/slab.h:408 ../../../core-api/mm-api:43: mm/slab_common.c:256
msgid "The size of objects to be created in this cache."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:362
msgid "``unsigned int align``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:363
#: ../../../core-api/mm-api:43: mm/slab_common.c:260 mm/slab_common.c:369
msgid "``slab_flags_t flags``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:362
msgid "SLAB flags"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:364
#: ../../../core-api/mm-api:43: mm/slab_common.c:370
msgid "``unsigned int useroffset``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:363
msgid "Usercopy region offset"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:365
#: ../../../core-api/mm-api:43: mm/slab_common.c:372
msgid "``unsigned int usersize``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:364
msgid "Usercopy region size"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:366
#: ../../../core-api/mm-api:43: mm/slab_common.c:374
msgid "``void (*ctor)(void *)``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:365
msgid "A constructor for the objects, or ``NULL``."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:366
msgid ""
"This is a legacy wrapper, new code should use either KMEM_CACHE_USERCOPY() "
"if whitelisting a single field is sufficient, or kmem_cache_create() with "
"the necessary parameters passed via the args parameter (see :c:type:`struct "
"kmem_cache_args <kmem_cache_args>`)"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:372
#: include/linux/slab.h:428 ../../../core-api/mm-api:43: mm/slab_common.c:278
msgid "a pointer to the cache on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:408
msgid "``kmem_cache_create (__name, __object_size, __args, ...)``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:406
#: ../../../core-api/mm-api:43: mm/slab_common.c:254
msgid "Create a kmem cache."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:412
msgid "``__name``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:409
msgid "``__object_size``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:410
msgid "``__args``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:409
msgid ""
"Optional arguments, see :c:type:`struct kmem_cache_args <kmem_cache_args>`. "
"Passing ``NULL`` means defaults will be used for all the arguments."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:412
msgid "``...``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1
msgid "variable arguments"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:411
msgid ""
"This is currently implemented as a macro using ``_Generic()`` to call either "
"the new variant of the function, or a legacy one."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:414
msgid ""
"The new variant has 4 parameters: ``kmem_cache_create(name, object_size, "
"args, flags)``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:417
msgid "See __kmem_cache_create_args() which implements this."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:419
msgid ""
"The legacy variant has 5 parameters: ``kmem_cache_create(name, object_size, "
"align, flags, ctor)``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:422
msgid ""
"The align and ctor parameters map to the respective fields of :c:type:"
"`struct kmem_cache_args <kmem_cache_args>`"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:426
#: ../../../core-api/mm-api:43: mm/slab_common.c:276
msgid "Cannot be called within a interrupt, but can be interrupted."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:480
msgid "Report actual allocation size of associated object"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:486
msgid "``const void *objp``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:482
msgid "Pointer returned from a prior kmalloc()-family allocation."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:483
msgid ""
"This should not be used for writing beyond the originally requested "
"allocation size. Either use krealloc() or round up the allocation size with "
"kmalloc_size_roundup() prior to allocation. If this is used to access beyond "
"the originally requested allocation size, UBSAN_BOUNDS and/or FORTIFY_SOURCE "
"may trip, since they only know about the originally allocated size via the "
"__alloc_size attribute."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:728
msgid "Allocate an object"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:734
#: ../../../core-api/mm-api:43: mm/slab_common.c:554
msgid "``struct kmem_cache *cachep``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:729
#: ../../../core-api/mm-api:40: mm/slub.c:4279
msgid "The cache to allocate from."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:731
#: include/linux/slab.h:845 include/linux/slab.h:941 include/linux/slab.h:958
#: include/linux/slab.h:1036 ../../../core-api/mm-api:40: mm/slub.c:4973
#: mm/slub.c:5048 mm/slub.c:5137
msgid "``gfp_t flags``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:730
#: ../../../core-api/mm-api:40: mm/slub.c:4280
msgid "See kmalloc()."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:731
msgid ""
"Allocate an object from this cache. See kmem_cache_zalloc() for a shortcut "
"of adding __GFP_ZERO to flags."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:735
#: ../../../core-api/mm-api:40: mm/slub.c:4288
msgid "pointer to the new object or ``NULL`` in case of error"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:746
msgid "memcg charge an already allocated slab memory"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:752
msgid "``void *objp``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:747
msgid "address of the slab object to memcg charge"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:749
#: ../../../core-api/mm-api:40: mm/slub.c:4281
msgid "``gfp_t gfpflags``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:748
#: include/linux/slab.h:844
msgid "describe the allocation context"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:749
msgid ""
"kmem_cache_charge allows charging a slab object to the current memcg, "
"primarily in cases where charging at allocation time might not be possible "
"because the target memcg is not known (i.e. softirq context)"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:753
msgid ""
"The objp should be pointer returned by the slab allocator functions like "
"kmalloc (with __GFP_ACCOUNT in flags) or kmem_cache_alloc. The memcg charge "
"behavior can be controlled through gfpflags parameter, which affects how the "
"necessary internal metadata can be allocated. Including __GFP_NOFAIL denotes "
"that overcharging is requested instead of failure, but is not applied for "
"the internal metadata allocation."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:760
msgid ""
"There are several cases where it will return true even if the charging was "
"not done: More specifically:"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:764
msgid "For !CONFIG_MEMCG or cgroup_disable=memory systems."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:765
msgid "Already charged slab objects."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:766
msgid ""
"For slab objects from KMALLOC_NORMAL caches - allocated by kmalloc() without "
"__GFP_ACCOUNT"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:768
msgid "Allocating internal metadata has failed"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:771
msgid "true if charge was successful otherwise false."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:842
msgid "allocate kernel memory"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5311 mm/page_alloc.c:5337
#: mm/page_alloc.c:5362 ../../../core-api/mm-api:116: mm/kmemleak.c:1082
#: mm/kmemleak.c:1106 mm/kmemleak.c:1125 mm/kmemleak.c:1167 mm/kmemleak.c:1302
#: mm/kmemleak.c:1340 mm/kmemleak.c:1361 ../../../core-api/mm-api:121:
#: mm/zpool.c:227 ../../../core-api/mm-api:122: mm/memcontrol.c:5423
#: mm/memcontrol.c:5451 ../../../core-api/mm-api:129: mm/percpu.c:498
#: mm/percpu.c:1722 ../../../core-api/mm-api:130: mm/maccess.c:116
#: mm/maccess.c:145 ../../../core-api/mm-api:37: include/linux/slab.h:848
#: include/linux/slab.h:940 include/linux/slab.h:1039 include/linux/slab.h:1107
#: ../../../core-api/mm-api:40: mm/slub.c:5136 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:734
msgid "``size_t size``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:843
#: include/linux/slab.h:1034 ../../../core-api/mm-api:40: mm/slub.c:4971
msgid "how many bytes of memory are required."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:845
msgid ""
"kmalloc is the normal method of allocating memory for objects smaller than "
"page size in the kernel."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:848
msgid ""
"The allocated object address is aligned to at least ARCH_KMALLOC_MINALIGN "
"bytes. For **size** of power of two bytes, the alignment is also guaranteed "
"to be at least to the size. For other sizes, the alignment is guaranteed to "
"be at least the largest power-of-two divisor of **size**."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:853
msgid ""
"The **flags** argument may be one of the GFP flags defined at include/linux/"
"gfp_types.h and described at :ref:`Documentation/core-api/mm-api.rst <mm-api-"
"gfp-flags>`"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:857
msgid ""
"The recommended usage of the **flags** is described at :ref:`Documentation/"
"core-api/memory-allocation.rst <memory_allocation>`"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:860
msgid "Below is a brief outline of the most useful GFP flags"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:862
msgid "``GFP_KERNEL``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:863
msgid "Allocate normal kernel ram. May sleep."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:865
msgid "``GFP_NOWAIT``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:866
msgid "Allocation will not sleep."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:868
msgid "``GFP_ATOMIC``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:869
msgid "Allocation will not sleep.  May use emergency pools."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:871
msgid ""
"Also it is possible to set different flags by OR'ing in one or more of the "
"following additional **flags**:"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:874
msgid "``__GFP_ZERO``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:875
msgid "Zero the allocated memory before returning. Also see kzalloc()."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:877
msgid "``__GFP_HIGH``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:878
msgid "This allocation has high priority and may use emergency pools."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:880
msgid "``__GFP_NOFAIL``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:881
msgid ""
"Indicate that this allocation is in no way allowed to fail (think twice "
"before using)."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:884
msgid "``__GFP_NORETRY``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:885
msgid "If memory is not immediately available, then give up at once."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:888
msgid "``__GFP_NOWARN``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:889
msgid "If allocation fails, don't issue any warnings."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:891
msgid "``__GFP_RETRY_MAYFAIL``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:892
msgid "Try really hard to succeed the allocation but fail eventually."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:937
msgid "allocate memory for an array."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:943
msgid "``size_t n``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:938
#: include/linux/slab.h:985
msgid "number of elements."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:939
#: include/linux/slab.h:986
msgid "element size."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:940
#: include/linux/slab.h:987 include/linux/slab.h:1035
msgid "the type of memory to allocate (see kmalloc)."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:953
msgid "reallocate memory for an array."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:959
msgid "``void *p``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:954
msgid "pointer to the memory chunk to reallocate"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:956
msgid "``size_t new_n``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:955
msgid "new number of elements to alloc"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:957
#: ../../../core-api/mm-api:40: mm/slub.c:4972
msgid "``size_t new_size``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:956
msgid "new size of a single member of the array"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:957
msgid "the type of memory to allocate (see kmalloc)"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:958
#: ../../../core-api/mm-api:40: mm/slub.c:4976 mm/slub.c:5140
msgid ""
"If __GFP_ZERO logic is requested, callers must ensure that, starting with "
"the initial memory allocation, every subsequent call to this API for the "
"same memory allocation is flagged with __GFP_ZERO. Otherwise, it is possible "
"that __GFP_ZERO is not fully honored by this API."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:963
msgid "See krealloc_noprof() for further details."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:965
#: ../../../core-api/mm-api:40: mm/slub.c:4995 mm/slub.c:5145
msgid ""
"In any case, the contents of the object pointed to are preserved up to the "
"lesser of the new and old sizes."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:986
msgid "``kcalloc (n, size, flags)``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:984
msgid "allocate memory for an array. The memory is set to zero."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:314
#: ../../../core-api/mm-api:37: include/linux/slab.h:990
msgid "``n``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:987
#: ../../../core-api/mm-api:40: mm/slub.c:5049
msgid "``size``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:338
#: ../../../core-api/mm-api:37: include/linux/slab.h:988
msgid "``flags``"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1033
msgid "allocate memory. The memory is set to zero."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1101
msgid "Report allocation bucket size for the given size"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1103
msgid "Number of bytes to round up from."
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1104
msgid ""
"This returns the number of bytes that would be available in a kmalloc() "
"allocation of **size** bytes. For example, a 126 byte request would be "
"rounded up to the next sized kmalloc bucket, 128 bytes. (This is strictly "
"for the general-purpose kmalloc()-based allocations, and is not for the pre-"
"sized kmem_cache_alloc()-based allocations.)"
msgstr ""

#: ../../../core-api/mm-api:37: include/linux/slab.h:1110
msgid ""
"Use this to kmalloc() the full bucket size ahead of time instead of using "
"ksize() to query the size after an allocation."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4278
msgid "Allocate an object on the specified node"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4284 mm/slub.c:4790
msgid "``struct kmem_cache *s``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5492
#: ../../../core-api/mm-api:101: mm/mempolicy.c:283 mm/mempolicy.c:315
#: ../../../core-api/mm-api:40: mm/slub.c:4282 mm/slub.c:5049
#: ../../../core-api/mm-api:52: mm/vmalloc.c:3014 mm/vmalloc.c:3940
#: mm/vmalloc.c:3999 mm/vmalloc.c:4057 mm/vmalloc.c:4077
msgid "``int node``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4281
msgid "node number of the target node."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4282
msgid ""
"Identical to kmem_cache_alloc but it will allocate memory on the given node, "
"which can improve the performance for cpu bound structures."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4285
msgid "Fallback to other node is possible if __GFP_THISNODE is not set."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4784
msgid "Deallocate an object"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4785
msgid "The cache the allocation was from."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4787
msgid "``void *x``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4786
msgid "The previously allocated object."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4787
msgid "Free an object which was previously allocated from this cache."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4869
msgid "free previously allocated memory"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4875
msgid "``const void *object``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4870
msgid "pointer returned by kmalloc() or kmem_cache_alloc()"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4871
msgid "If **object** is NULL, no operation is performed."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4969
msgid "reallocate memory. The contents will remain unchanged."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4975 mm/slub.c:5139
#: ../../../core-api/mm-api:43: mm/slab_common.c:1213
msgid "``const void *p``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4970
msgid "object to reallocate memory for."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4972
msgid "the type of memory to allocate."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4973
msgid ""
"If **p** is ``NULL``, krealloc() behaves exactly like kmalloc().  If "
"**new_size** is 0 and **p** is not a ``NULL`` pointer, the object pointed to "
"is freed."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4981
msgid ""
"When slub_debug_orig_size() is off, krealloc() only knows about the bucket "
"size of an allocation (but not the exact size it was allocated with) and "
"hence implements the following semantics for shrinking and growing buffers "
"with __GFP_ZERO::"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4991
msgid ""
"Otherwise, the original allocation size 'orig_size' could be used to "
"precisely clear the requested size, and the new size will also be stored as "
"the new 'orig_size'."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:4999 mm/slub.c:5152
msgid "pointer to the allocated memory or ``NULL`` in case of error"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5043
msgid ""
"attempt to allocate physically contiguous memory, but upon failure, fall "
"back to non-contiguous (vmalloc) allocation."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5045
msgid "size of the request."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5047
msgid "``b``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5046
msgid "which set of kmalloc buckets to allocate from."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5047
msgid ""
"gfp mask for the allocation - must be compatible (superset) with GFP_KERNEL."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5048
msgid "numa node to allocate from"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5049
msgid ""
"Uses kmalloc to get the memory but if the allocation fails then falls back "
"to the vmalloc allocator. Use kvfree for freeing the memory."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5052
msgid ""
"GFP_NOWAIT and GFP_ATOMIC are not supported, neither is the __GFP_NORETRY "
"modifier. __GFP_RETRY_MAYFAIL is supported, and it should be used only if "
"kmalloc is preferable to the vmalloc fallback, due to visible performance "
"drawbacks."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5057
msgid "pointer to the allocated memory of ``NULL`` in case of failure"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5096
msgid "Free memory."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5102 mm/slub.c:5121
#: ../../../core-api/mm-api:52: mm/vmalloc.c:3387 mm/vmalloc.c:3451
msgid "``const void *addr``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5097
msgid "Pointer to allocated memory."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5098
msgid ""
"kvfree frees memory allocated by any of vmalloc(), kmalloc() or kvmalloc(). "
"It is slightly more efficient to use kfree() or vfree() if you are certain "
"that you know which one to use."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5103
msgid "Either preemptible task context or not-NMI interrupt."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5115
msgid "Free a data object containing sensitive information."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5116
msgid "address of the data object to be freed."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5118 ../../../core-api/mm-api:61:
#: mm/filemap.c:2947 ../../../core-api/mm-api:85: include/linux/pagemap.h:759
msgid "``size_t len``"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5117
msgid "length of the data object."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5118
msgid ""
"Use the special memzero_explicit() function to clear the content of a "
"kvmalloc'ed object containing sensitive data to make sure that the compiler "
"won't optimize out the data clearing."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5133
msgid "reallocate memory; contents remain unchanged"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5134
msgid "object to reallocate memory for"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5135
msgid "the size to reallocate"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5136
msgid "the flags for the page level allocator"
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5137
msgid ""
"If **p** is ``NULL``, kvrealloc() behaves exactly like kvmalloc(). If "
"**size** is 0 and **p** is not a ``NULL`` pointer, the object pointed to is "
"freed."
msgstr ""

#: ../../../core-api/mm-api:40: mm/slub.c:5148
msgid ""
"This function must not be called concurrently with itself or kvfree() for "
"the same memory allocation."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:257
msgid "``unsigned int object_size``"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:258
msgid "``struct kmem_cache_args *args``"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:257
msgid ""
"Additional arguments for the cache creation (see :c:type:`struct "
"kmem_cache_args <kmem_cache_args>`)."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:259
msgid ""
"See the desriptions of individual flags. The common ones are listed in the "
"description below."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:261
msgid ""
"Not to be called directly, use the kmem_cache_create() wrapper with the same "
"parameters."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:264
msgid "Commonly used **flags**:"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:266
msgid ":c:type:`SLAB_ACCOUNT` - Account allocations to memcg."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:268
msgid ":c:type:`SLAB_HWCACHE_ALIGN` - Align objects on cache line boundaries."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:270
msgid ":c:type:`SLAB_RECLAIM_ACCOUNT` - Objects are reclaimable."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:272
msgid ""
":c:type:`SLAB_TYPESAFE_BY_RCU` - Slab page (not individual objects) freeing "
"delayed by a grace period - see the full description before using."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:364
msgid ""
"Create a set of caches that handle dynamic sized allocations via "
"kmem_buckets_alloc()"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:366
msgid ""
"A prefix string which is used in /proc/slabinfo to identify this cache. The "
"individual caches with have their sizes as the suffix."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:368
msgid "SLAB flags (see kmem_cache_create() for details)."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:369
msgid ""
"Starting offset within an allocation that may be copied to/from userspace."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:371
msgid ""
"How many bytes, starting at **useroffset**, may be copied to/from userspace."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:373
msgid "A constructor for the objects, run when new allocations are made."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:374
msgid "Cannot be called within an interrupt, but can be interrupted."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:377
msgid ""
"a pointer to the cache on success, NULL on failure. When CONFIG_SLAB_BUCKETS "
"is not enabled, ZERO_SIZE_PTR is returned, and subsequent calls to "
"kmem_buckets_alloc() will fall back to kmalloc(). (i.e. callers only need to "
"check for NULL on failure.)"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:548
msgid "Shrink a cache."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:549
msgid "The cache to shrink."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:550
msgid ""
"Releases as many slabs as possible for a cache. To help debugging, a zero "
"exit status indicates all slabs were released."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:554
msgid "``0`` if all slabs were released, non-zero otherwise"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:578
msgid "Print available slab provenance information"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:584
msgid "``void *object``"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:579
msgid "slab object for which to find provenance information."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:580
msgid ""
"This function uses pr_cont(), so that the caller is expected to have printed "
"out whatever preamble is appropriate.  The provenance information depends on "
"the type of object and on how much debugging is enabled. For a slab-cache "
"object, the fact that it is a slab object is printed, and, if available, the "
"slab name, return address, and stack trace from the allocation and last free "
"path of that object."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:588
msgid ""
"``true`` if the pointer is to a not-yet-freed object from kmalloc() or "
"kmem_cache_alloc(), either ``true`` or ``false`` if the pointer is to an "
"already-freed object, and ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:1207
msgid "Clear sensitive information in memory before freeing"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:1208
msgid "object to free memory of"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:1209
msgid ""
"The memory of the object **p** points to is zeroed before freed. If **p** is "
"``NULL``, kfree_sensitive() does nothing."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:255
#: ../../../core-api/mm-api:43: mm/slab_common.c:1212
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2498
#: mm/page-writeback.c:2602 ../../../core-api/mm-api:82: mm/truncate.c:452
#: ../../../core-api/mm-api:91: mm/mempool.c:384 ../../../core-api/mm-api:97:
#: mm/memory.c:2887
msgid "**Note**"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:1213
msgid ""
"this function zeroes the whole allocated buffer which can be a good deal "
"bigger than the requested buffer size passed to kmalloc(). So be careful "
"when using this function in performance sensitive code."
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:2010
msgid "Wait until all in-flight kvfree_rcu() complete."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5416 mm/page_alloc.c:6367
#: ../../../core-api/mm-api:122: mm/memcontrol.c:952
#: ../../../core-api/mm-api:129: mm/percpu.c:1994 mm/percpu.c:2084
#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1089
#: ../../../core-api/mm-api:43: mm/slab_common.c:2016
#: ../../../core-api/mm-api:52: mm/vmalloc.c:2963
msgid "``void``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:1
#: ../../../core-api/mm-api:122: mm/memcontrol.c:1
#: ../../../core-api/mm-api:129: mm/percpu.c:1 ../../../core-api/mm-api:133:
#: mm/mmu_notifier.c:1 ../../../core-api/mm-api:43: mm/slab_common.c:1
#: ../../../core-api/mm-api:52: mm/vmalloc.c:1
msgid "no arguments"
msgstr ""

#: ../../../core-api/mm-api:43: mm/slab_common.c:2011
msgid ""
"Note that a single argument of kvfree_rcu() call has a slow path that "
"triggers synchronize_rcu() following by freeing a pointer. It is done before "
"the return from the function. Therefore for any single-argument call that "
"will result in a kfree() to a cache that is to be destroyed during module "
"exit, it is developer's responsibility to ensure that all such calls have "
"returned before the call to kmem_cache_destroy()."
msgstr ""

#: ../../../core-api/mm-api:46: mm/util.c:38
msgid "conditionally free memory"
msgstr ""

#: ../../../core-api/mm-api:46: mm/util.c:44
msgid "``const void *x``"
msgstr ""

#: ../../../core-api/mm-api:46: mm/util.c:39
msgid "pointer to the memory"
msgstr ""

#: ../../../core-api/mm-api:46: mm/util.c:40
msgid "Function calls kfree only if **x** is not in .rodata section."
msgstr ""

#: ../../../core-api/mm-api.rst:50
msgid "Virtually Contiguous Mappings"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2957
msgid "unmap outstanding lazy aliases in the vmap layer"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2958
msgid ""
"The vmap/vmalloc layer lazily flushes kernel virtual mappings primarily to "
"amortize TLB flushing overheads. What this means is that any page you have "
"now, may, in a former life, have been mapped into kernel virtual address by "
"the vmap layer and so there might be some CPUs with TLB entries still "
"referencing that page (additional to the regular 1:1 kernel mapping)."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2964
msgid ""
"vm_unmap_aliases flushes all such lazy mappings. After it returns, we can be "
"sure that none of the pages we have control over will have any aliases from "
"the vmap layer."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2976
msgid "unmap linear kernel address space set up by vm_map_ram"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2982
msgid "``const void *mem``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2977
msgid "the pointer returned by vm_map_ram"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2979 mm/vmalloc.c:3013
#: mm/vmalloc.c:3476 mm/vmalloc.c:3556
msgid "``unsigned int count``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:2978
msgid "the count passed to that vm_map_ram call (cannot unmap partial)"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3010
msgid "map pages linearly into kernel virtual address (vmalloc space)"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3011
msgid "an array of pointers to the pages to be mapped"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1006 ../../../core-api/mm-api:52:
#: mm/vmalloc.c:3012
msgid "number of pages"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3013
msgid "prefer to allocate data structures on this node"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3014
msgid ""
"If you use this function for less than VMAP_MAX_ALLOC pages, it could be "
"faster than vmap so it's good.  But if you mix long-life and short-life "
"objects with vm_map_ram(), it could consume lots of address space through "
"fragmentation (especially on a 32bit machine).  You could see failures in "
"the end.  Please use this function for short-lived objects."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3021
msgid "a pointer to the address that has been mapped, or ``NULL`` on failure"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3381
msgid "Release memory allocated by vmalloc()"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3382
msgid "Memory base address"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3383
msgid ""
"Free the virtually continuous memory area starting at **addr**, as obtained "
"from one of the vmalloc() family of APIs.  This will usually also free the "
"physical memory underlying the virtual allocation, but that memory is "
"reference counted, so it will not be freed until the last user goes away."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3388
msgid "If **addr** is NULL, no operation is performed."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3391
msgid ""
"May sleep if called *not* from interrupt context. Must not be called in NMI "
"context (strictly speaking, it could be if we have "
"CONFIG_ARCH_HAVE_NMI_SAFE_CMPXCHG, but making the calling conventions for "
"vfree() arch-dependent would be a really bad idea)."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3445
msgid "release virtual mapping obtained by vmap()"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3446
msgid "memory base address"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3447
msgid ""
"Free the virtually contiguous memory area starting at **addr**, which was "
"created from the page array passed to vmap()."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3450
msgid "Must not be called in interrupt context."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3473
msgid "map an array of pages into virtually contiguous space"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3474
msgid "array of page pointers"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3475 mm/vmalloc.c:3555
msgid "number of pages to map"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:464
#: ../../../core-api/mm-api:115: mm/mmap.c:320 ../../../core-api/mm-api:124:
#: mm/shmem.c:5909 mm/shmem.c:5921 mm/shmem.c:5934 ../../../core-api/mm-api:52:
#: mm/vmalloc.c:3477
msgid "``unsigned long flags``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3476
msgid "vm_area->flags"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3478 mm/vmalloc.c:3557
#: ../../../core-api/mm-api:97: mm/memory.c:2886
msgid "``pgprot_t prot``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3477 mm/vmalloc.c:3556
msgid "page protection for the mapping"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3478
msgid ""
"Maps **count** pages from **pages** into contiguous kernel virtual space. If "
"**flags** contains ``VM_MAP_PUT_PAGES`` the ownership of the pages array "
"itself (which must be kmalloc or vmalloc memory) and one reference per pages "
"in it are transferred from the caller to vmap(), and will be freed / dropped "
"when vfree() is called on the return value."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3485
msgid "the address of the area or ``NULL`` on failure"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3553
msgid "map an array of PFNs into virtually contiguous space"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3559
msgid "``unsigned long *pfns``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3554
msgid "array of PFNs"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3557
msgid ""
"Maps **count** PFNs from **pfns** into contiguous kernel virtual space and "
"returns the start address of the mapping."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3935 mm/vmalloc.c:3976
msgid "allocate virtually contiguous memory"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3941 mm/vmalloc.c:3982
#: mm/vmalloc.c:4001 mm/vmalloc.c:4022 mm/vmalloc.c:4042 mm/vmalloc.c:4060
#: mm/vmalloc.c:4080 mm/vmalloc.c:4200 mm/vmalloc.c:4216
#: ../../../core-api/mm-api:97: mm/memory.c:2050 mm/memory.c:2885
msgid "``unsigned long size``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3936 mm/vmalloc.c:3977
#: mm/vmalloc.c:3996 mm/vmalloc.c:4017 mm/vmalloc.c:4037 mm/vmalloc.c:4055
#: mm/vmalloc.c:4075 mm/vmalloc.c:4195 mm/vmalloc.c:4211
msgid "allocation size"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3938
msgid "``unsigned long align``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3937
msgid "desired alignment"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5308 mm/page_alloc.c:5338
#: mm/page_alloc.c:6823 mm/page_alloc.c:7014 ../../../core-api/mm-api:122:
#: mm/memcontrol.c:5032 ../../../core-api/mm-api:52: mm/vmalloc.c:3939
#: mm/vmalloc.c:3998 ../../../core-api/mm-api:85: include/linux/pagemap.h:881
#: ../../../core-api/mm-api:91: mm/mempool.c:264 mm/mempool.c:379
msgid "``gfp_t gfp_mask``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3938 mm/vmalloc.c:3997
msgid "flags for the page level allocator"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3939 mm/vmalloc.c:3998
msgid "node to use for allocation or NUMA_NO_NODE"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3941
msgid "``const void *caller``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3940
msgid "caller's return address"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3941
msgid ""
"Allocate enough pages to cover **size** from the page level allocator with "
"**gfp_mask** flags.  Map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3944
msgid ""
"Reclaim modifiers in **gfp_mask** - __GFP_NORETRY, __GFP_RETRY_MAYFAIL and "
"__GFP_NOFAIL are not supported"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3947
msgid ""
"Any use of gfp flags outside of GFP_KERNEL should be consulted with mm "
"people."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3951 mm/vmalloc.c:3985
#: mm/vmalloc.c:4005 mm/vmalloc.c:4026 mm/vmalloc.c:4042 mm/vmalloc.c:4064
#: mm/vmalloc.c:4082 mm/vmalloc.c:4200 mm/vmalloc.c:4216
msgid "pointer to the allocated memory or ``NULL`` on error"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3978 mm/vmalloc.c:4057
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3981 mm/vmalloc.c:4022
#: mm/vmalloc.c:4060
msgid ""
"For tight control over page level allocator and protection flags use "
"__vmalloc() instead."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3995
msgid "allocate virtually contiguous memory, allow huge pages"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:3999
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space. If **size** is greater than "
"or equal to PMD_SIZE, allow using huge pages for the memory"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4016
msgid "allocate virtually contiguous memory with zero fill"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4018 mm/vmalloc.c:4077
msgid ""
"Allocate enough pages to cover **size** from the page level allocator and "
"map them into contiguous kernel virtual space. The memory allocated is set "
"to zero."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4036
msgid "allocate zeroed virtually contiguous memory for userspace"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4038
msgid ""
"The resulting memory area is zeroed so it can be mapped to userspace without "
"leaking data."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4054
msgid "allocate memory on a specific node"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4056 mm/vmalloc.c:4076
msgid "numa node"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4074
msgid "allocate memory on a specific node with zero fill"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4194
msgid "allocate virtually contiguous memory (32bit addressable)"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4196
msgid ""
"Allocate enough 32bit PA addressable pages to cover **size** from the page "
"level allocator and map them into contiguous kernel virtual space."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4210
msgid "allocate zeroed virtually contiguous 32bit memory"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4212
msgid ""
"The resulting memory area is 32bit addressable and zeroed so it can be "
"mapped to userspace without leaking data."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4569
msgid "map vmalloc pages to userspace"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2449
#: ../../../core-api/mm-api:113: mm/rmap.c:167 mm/rmap.c:1221 mm/rmap.c:1325
#: mm/rmap.c:1350 mm/rmap.c:1383 mm/rmap.c:1497 mm/rmap.c:1520 mm/rmap.c:1543
#: mm/rmap.c:1634 mm/rmap.c:1650 mm/rmap.c:1670 mm/rmap.c:1796 mm/rmap.c:1812
#: mm/rmap.c:1832 ../../../core-api/mm-api:119: mm/hugetlb.c:1034
#: ../../../core-api/mm-api:120: mm/swap.c:519 ../../../core-api/mm-api:124:
#: mm/shmem.c:5949 ../../../core-api/mm-api:52: mm/vmalloc.c:4575
#: ../../../core-api/mm-api:97: mm/memory.c:2052 mm/memory.c:2289
#: mm/memory.c:2321 mm/memory.c:2403 mm/memory.c:2428 mm/memory.c:2499
#: mm/memory.c:2559 mm/memory.c:2886 mm/memory.c:2945 mm/memory.c:6627
msgid "``struct vm_area_struct *vma``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4570
msgid "vma to cover (map full range of vma)"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:211 mm/percpu.c:1585
#: mm/percpu.c:2325 ../../../core-api/mm-api:52: mm/vmalloc.c:4572
msgid "``void *addr``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4571
msgid "vmalloc memory"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:323 ../../../core-api/mm-api:52:
#: mm/vmalloc.c:4573
msgid "``unsigned long pgoff``"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4572
msgid "number of pages into addr before first page to map"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4574
msgid "0 for success, -Exxx on failure"
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4575
msgid ""
"This function checks that addr is a valid vmalloc'ed area, and that it is "
"big enough to cover the vma. Will return failure if that criteria isn't met."
msgstr ""

#: ../../../core-api/mm-api:52: mm/vmalloc.c:4579
msgid "Similar to remap_pfn_range() (see mm/memory.c)"
msgstr ""

#: ../../../core-api/mm-api.rst:56
msgid "File Mapping and Page Cache"
msgstr ""

#: ../../../core-api/mm-api.rst:59
msgid "Filemap"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:367
msgid "start writeback on mapping dirty pages in range"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1174 mm/rmap.c:2860
#: ../../../core-api/mm-api:114: mm/migrate.c:873 mm/migrate.c:998
#: mm/migrate.c:1020 ../../../core-api/mm-api:124: mm/shmem.c:583
#: mm/shmem.c:5976 ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:256
#: mm/mapping_dirty_helpers.c:284 ../../../core-api/mm-api:131: mm/vmscan.c:839
#: ../../../core-api/mm-api:61: mm/filemap.c:373 mm/filemap.c:448
#: mm/filemap.c:466 mm/filemap.c:481 mm/filemap.c:553 mm/filemap.c:577
#: mm/filemap.c:624 mm/filemap.c:676 mm/filemap.c:1765 mm/filemap.c:1802
#: mm/filemap.c:1901 mm/filemap.c:2195 mm/filemap.c:2216 mm/filemap.c:2288
#: mm/filemap.c:3977 mm/filemap.c:4001 mm/filemap.c:4044
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2036
#: mm/page-writeback.c:2111 mm/page-writeback.c:2376 mm/page-writeback.c:2485
#: mm/page-writeback.c:2600 mm/page-writeback.c:2755
#: ../../../core-api/mm-api:82: mm/truncate.c:324 mm/truncate.c:452
#: mm/truncate.c:471 mm/truncate.c:567 mm/truncate.c:643 mm/truncate.c:731
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:78
#: include/linux/pagemap.h:99 include/linux/pagemap.h:115
#: include/linux/pagemap.h:232 include/linux/pagemap.h:452
#: include/linux/pagemap.h:490 include/linux/pagemap.h:757
#: include/linux/pagemap.h:787 include/linux/pagemap.h:804
#: include/linux/pagemap.h:822 include/linux/pagemap.h:842
#: include/linux/pagemap.h:864 include/linux/pagemap.h:883
#: include/linux/pagemap.h:910 include/linux/pagemap.h:1284
#: include/linux/pagemap.h:1357 include/linux/pagemap.h:1379
#: ../../../core-api/mm-api:97: mm/memory.c:4085 mm/memory.c:4116
msgid "``struct address_space *mapping``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:368 ../../../core-api/mm-api:76:
#: mm/page-writeback.c:2371 mm/page-writeback.c:2480 mm/page-writeback.c:2595
msgid "address space structure to write"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:370 ../../../core-api/mm-api:76:
#: mm/page-writeback.c:2482 mm/page-writeback.c:2597 mm/page-writeback.c:2789
msgid "``struct writeback_control *wbc``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:369
msgid "the writeback_control controlling the writeout"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:370
msgid ""
"Call writepages on the mapping using the provided wbc to control the "
"writeout."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:374 mm/filemap.c:450
#: mm/filemap.c:466 mm/filemap.c:739 mm/filemap.c:783
#: ../../../core-api/mm-api:91: mm/mempool.c:245 mm/mempool.c:310
#: ../../../core-api/mm-api:97: mm/memory.c:2342 mm/memory.c:2889
#: mm/memory.c:2951
msgid "``0`` on success, negative error code otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:442
msgid "start writeback on a range"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:443 mm/filemap.c:461
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:905
msgid "target address_space"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:445 mm/filemap.c:4365
msgid "``loff_t start``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:444
msgid "index to start writeback on"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:446 mm/filemap.c:4366
msgid "``loff_t end``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:445
msgid "last (inclusive) index for writeback"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:446
msgid ""
"This is a non-integrity writeback helper, to start writing back folios for "
"the indicated range."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:460
msgid "mostly a non-blocking flush"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:462
msgid ""
"This is a mostly non-blocking flush.  Not suitable for data-integrity "
"purposes - I/O may not be started against all dirty pages."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:475
msgid "check if a page exists in range."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:476 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:1279
msgid "address space within which to check"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:478 mm/filemap.c:550
#: mm/filemap.c:574 mm/filemap.c:596 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:1281
msgid "``loff_t start_byte``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:477 mm/filemap.c:549
#: mm/filemap.c:573 mm/filemap.c:595 mm/filemap.c:672 mm/filemap.c:772
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1280
msgid "offset in bytes where the range starts"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:479 mm/filemap.c:551
#: mm/filemap.c:575 mm/filemap.c:597 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:1282
msgid "``loff_t end_byte``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:478 mm/filemap.c:550
#: mm/filemap.c:574 mm/filemap.c:596 mm/filemap.c:673 mm/filemap.c:773
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1281
msgid "offset in bytes where the range ends (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:479
msgid ""
"Find at least one page in the range supplied, usually used to check if "
"direct writing in this range will trigger a writeback."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:483
msgid ""
"``true`` if at least one page exists in the specified range, ``false`` "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:547 mm/filemap.c:571
#: mm/filemap.c:593
msgid "wait for writeback to complete"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:548 mm/filemap.c:572
#: mm/filemap.c:619
msgid "address space structure to wait for"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:551
msgid ""
"Walk the list of under-writeback pages of the given address space in the "
"given range and wait for all of them.  Check error status of the address "
"space and return it."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:555
msgid ""
"Since the error status of the address space is cleared by this function, "
"callers are responsible for checking the return value and handling and/or "
"reporting the error."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:560 mm/filemap.c:629
#: mm/filemap.c:680
msgid "error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:575
msgid ""
"Walk the list of under-writeback pages of the given address space in the "
"given range and wait for all of them.  Unlike filemap_fdatawait_range(), "
"this function does not clear error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:579 mm/filemap.c:624
msgid ""
"Use this function if callers don't handle errors themselves.  Expected call "
"sites are system-wide / filesystem-wide data flushers: e.g. sync(2), "
"fsfreeze(8)"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:284 ../../../core-api/mm-api:61:
#: mm/filemap.c:599 mm/filemap.c:724 mm/filemap.c:776 mm/filemap.c:3976
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:127
#: include/linux/pagemap.h:1355 include/linux/pagemap.h:1377
msgid "``struct file *file``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:594
msgid "file pointing to address space structure to wait for"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:597
msgid ""
"Walk the list of under-writeback pages of the address space that file refers "
"to, in the given range and wait for all of them.  Check error status of the "
"address space vs. the file->f_wb_err cursor and return it."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:601
msgid ""
"Since the error status of the file is advanced by this function, callers are "
"responsible for checking the return value and handling and/or reporting the "
"error."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:606
msgid "error status of the address space vs. the file->f_wb_err cursor."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:618
msgid "wait for writeback without clearing errors"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:620
msgid ""
"Walk the list of under-writeback pages of the given address space and wait "
"for all of them.  Unlike filemap_fdatawait(), this function does not clear "
"error status of the address space."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:670 mm/filemap.c:770
msgid "write out & wait on a file range"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:671
msgid "the address_space for the pages"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:673 mm/filemap.c:773
#: ../../../core-api/mm-api:82: mm/truncate.c:321 mm/truncate.c:449
#: mm/truncate.c:866
msgid "``loff_t lstart``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:674 mm/filemap.c:774
#: ../../../core-api/mm-api:82: mm/truncate.c:322 mm/truncate.c:867
msgid "``loff_t lend``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:674 mm/filemap.c:774
msgid "Write out and wait upon file offsets lstart->lend, inclusive."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:676 mm/filemap.c:776
msgid ""
"Note that **lend** is inclusive (describes the last byte to be written) so "
"that this function can be used to write to the very end-of-file (end = -1)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:718
msgid ""
"report wb error (if any) that was previously and advance wb_err to current "
"one"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:720
msgid "struct file on which the error is being reported"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:721
msgid ""
"When userland calls fsync (or something like nfsd does the equivalent), we "
"want to report any writeback errors that occurred since the last fsync (or "
"since the file was opened if there haven't been any)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:725
msgid ""
"Grab the wb_err from the mapping. If it matches what we have in the file, "
"then just quickly return 0. The file is all caught up."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:728
msgid ""
"If it doesn't match, then take the mapping value, set the \"seen\" flag in "
"it and try to swap it into place. If it works, or another task beat us to it "
"with the new value, then update the f_wb_err and return the error portion. "
"The error at this point must be reported via proper channels (a'la fsync, or "
"NFS COMMIT operation, etc.)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:734
msgid ""
"While we handle mapping->wb_err with atomic operations, the f_wb_err value "
"is protected by the f_lock since we must ensure that it reflects the latest "
"value swapped in for this file descriptor."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:771
msgid "file pointing to address_space with pages"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:779
msgid ""
"After writing out and waiting on the data, we check and advance the f_wb_err "
"cursor to the latest value, and return any errors detected there."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:808
msgid "replace a pagecache folio with a new one"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4916 mm/memcontrol.c:4960
#: ../../../core-api/mm-api:61: mm/filemap.c:814
msgid "``struct folio *old``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:809
msgid "folio to be replaced"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4913 mm/memcontrol.c:4957
#: ../../../core-api/mm-api:61: mm/filemap.c:811
msgid "``struct folio *new``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:810
msgid "folio to replace with"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:811
msgid ""
"This function replaces a folio in the pagecache with a new one.  On success "
"it acquires the pagecache reference for the new folio and drops it for the "
"old folio.  Both the old and new folios must be locked.  This function does "
"not add the new folio to the LRU, the caller must do that."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:817
msgid "The remove + add is atomic.  This function cannot fail."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1485
msgid "Unlock a locked folio."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2902
#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:20
#: include/linux/mm_inline.h:69 include/linux/mm_inline.h:87
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:762
#: ../../../core-api/mm-api:106: include/linux/mm.h:1006
#: include/linux/mm.h:1318 include/linux/mm.h:1351 include/linux/mm.h:1370
#: include/linux/mm.h:1800 include/linux/mm.h:1816 include/linux/mm.h:1832
#: include/linux/mm.h:1857 include/linux/mm.h:2030 include/linux/mm.h:2079
#: ../../../core-api/mm-api:108: include/linux/page_ref.h:258
#: ../../../core-api/mm-api:110: mm/util.c:686 ../../../core-api/mm-api:113:
#: mm/rmap.c:981 mm/rmap.c:1328 mm/rmap.c:1353 mm/rmap.c:1498 mm/rmap.c:1522
#: mm/rmap.c:1546 mm/rmap.c:1635 mm/rmap.c:1652 mm/rmap.c:1672 mm/rmap.c:1797
#: mm/rmap.c:1814 mm/rmap.c:1834 mm/rmap.c:2255 mm/rmap.c:2585 mm/rmap.c:2859
#: ../../../core-api/mm-api:119: mm/hugetlb.c:7753 mm/hugetlb.c:7818
#: ../../../core-api/mm-api:120: mm/swap.c:449 mm/swap.c:498 mm/swap.c:522
#: mm/swap.c:683 mm/swap.c:724 ../../../core-api/mm-api:122:
#: mm/memcontrol.c:247 mm/memcontrol.c:973 mm/memcontrol.c:1200
#: mm/memcontrol.c:1221 mm/memcontrol.c:1243 mm/memcontrol.c:4732
#: mm/memcontrol.c:4766 mm/memcontrol.c:5134 ../../../core-api/mm-api:124:
#: mm/shmem.c:1579 ../../../core-api/mm-api:131: mm/vmscan.c:836
#: mm/vmscan.c:865 mm/vmscan.c:1838 ../../../core-api/mm-api:135:
#: mm/huge_memory.c:1621 ../../../core-api/mm-api:61: mm/filemap.c:1491
#: mm/filemap.c:1511 mm/filemap.c:1541 mm/filemap.c:1561 mm/filemap.c:1574
#: mm/filemap.c:1636 mm/filemap.c:1676 mm/filemap.c:4334
#: ../../../core-api/mm-api:76: mm/page-writeback.c:2483
#: mm/page-writeback.c:2752 mm/page-writeback.c:2786 mm/page-writeback.c:2825
#: mm/page-writeback.c:3115 mm/page-writeback.c:3136 mm/page-writeback.c:3161
#: ../../../core-api/mm-api:82: mm/truncate.c:127 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:555 include/linux/pagemap.h:575
#: include/linux/pagemap.h:589 include/linux/pagemap.h:604
#: include/linux/pagemap.h:623 include/linux/pagemap.h:932
#: include/linux/pagemap.h:943 include/linux/pagemap.h:958
#: include/linux/pagemap.h:1089 include/linux/pagemap.h:1114
#: include/linux/pagemap.h:1164 include/linux/pagemap.h:1378
#: include/linux/pagemap.h:1517 include/linux/pagemap.h:1542
msgid "``struct folio *folio``"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:312
#: include/linux/page-flags.h:757 include/linux/page-flags.h:776
#: ../../../core-api/mm-api:106: include/linux/mm.h:985 include/linux/mm.h:1001
#: include/linux/mm.h:1119 include/linux/mm.h:1152 include/linux/mm.h:1313
#: include/linux/mm.h:1346 include/linux/mm.h:1365 include/linux/mm.h:1770
#: include/linux/mm.h:1852 include/linux/mm.h:1991 include/linux/mm.h:2044
#: include/linux/mm.h:2061 include/linux/mm.h:2075
#: ../../../core-api/mm-api:108: include/linux/page_ref.h:72
#: include/linux/page_ref.h:253 ../../../core-api/mm-api:110: mm/util.c:681
#: ../../../core-api/mm-api:61: mm/filemap.c:1486 mm/filemap.c:1506
#: mm/filemap.c:1536 mm/filemap.c:1631 ../../../core-api/mm-api:76:
#: mm/page-writeback.c:2785 mm/page-writeback.c:2820
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:550
#: include/linux/pagemap.h:570 include/linux/pagemap.h:953
#: include/linux/pagemap.h:1017 include/linux/pagemap.h:1541
msgid "The folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1487
msgid "Unlocks the folio and wakes up any thread sleeping on the page lock."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1490 mm/filemap.c:1515
msgid ""
"May be called from interrupt or process context.  May not be called from NMI "
"context."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1505
msgid "End read on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1508
msgid "``bool success``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1507
msgid "True if all reads completed successfully."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1508
msgid ""
"When all reads against a folio have completed, filesystems should call this "
"function to let the pagecache know that no more reads are outstanding.  This "
"will unlock the folio and wake up any thread sleeping on the lock.  The "
"folio will also be marked uptodate if all reads succeeded."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1535
msgid "Clear PG_private_2 and wake any waiters."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1537
msgid ""
"Clear the PG_private_2 bit on a folio and wake up any sleepers waiting for "
"it.  The folio reference held for PG_private_2 being set is released."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1540
msgid ""
"This is, for example, used when a netfs folio is being written to a local "
"disk cache, thereby allowing writes to the cache for the same folio to be "
"serialised."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1555 mm/filemap.c:1557
#: mm/filemap.c:1568
msgid "Wait for PG_private_2 to be cleared on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1556 mm/filemap.c:1569
#: ../../../core-api/mm-api:76: mm/page-writeback.c:3156
msgid "The folio to wait on."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1570
msgid ""
"Wait for PG_private_2 to be cleared on a folio or until a fatal signal is "
"received by the calling task."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1574
msgid "0 if successful."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1575
msgid "-EINTR if a fatal signal was encountered."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1630
msgid "End writeback against a folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1632
msgid "The folio must actually be under writeback."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1635
msgid "May be called from process or interrupt context."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1670
msgid "Get a lock on the folio, assuming we need to sleep to get it."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1671
msgid "The folio to lock"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1759
msgid "Find the next gap in the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1760 mm/filemap.c:1797
msgid "Mapping."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:580 mm/shmem.c:2680 mm/shmem.c:5973
#: ../../../core-api/mm-api:61: mm/filemap.c:1762 mm/filemap.c:1799
#: mm/filemap.c:1898 mm/filemap.c:3974 mm/filemap.c:3998 mm/filemap.c:4041
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:487
#: include/linux/pagemap.h:758 include/linux/pagemap.h:784
#: include/linux/pagemap.h:801 include/linux/pagemap.h:819
#: include/linux/pagemap.h:861 include/linux/pagemap.h:880
#: include/linux/pagemap.h:907 include/linux/pagemap.h:940
#: include/linux/pagemap.h:955 include/linux/pagemap.h:1356
msgid "``pgoff_t index``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1761 mm/filemap.c:1798
msgid "Index."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1763 mm/filemap.c:1800
msgid "``unsigned long max_scan``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1762 mm/filemap.c:1799
msgid "Maximum range to search."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1763
msgid ""
"Search the range [index, min(index + max_scan - 1, ULONG_MAX)] for the gap "
"with the lowest index."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1766
msgid ""
"This function may be called under the rcu_read_lock.  However, this will not "
"atomically search a snapshot of the cache at a single point in time. For "
"example, if a gap is created at index 5, then subsequently a gap is created "
"at index 10, page_cache_next_miss covering both indices may return 10 if "
"called under the rcu_read_lock."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1773
msgid ""
"The index of the gap if found, otherwise an index outside the range "
"specified (in which case 'return - index >= max_scan' will be true). In the "
"rare case of index wrap-around, 0 will be returned."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1796
msgid "Find the previous gap in the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1800
msgid ""
"Search the range [max(index - max_scan + 1, 0), index] for the gap with the "
"highest index."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1803
msgid ""
"This function may be called under the rcu_read_lock.  However, this will not "
"atomically search a snapshot of the cache at a single point in time. For "
"example, if a gap is created at index 10, then subsequently a gap is created "
"at index 5, page_cache_prev_miss() covering both indices may return 5 if "
"called under the rcu_read_lock."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1810
msgid ""
"The index of the gap if found, otherwise an index outside the range "
"specified (in which case 'index - return >= max_scan' will be true). In the "
"rare case of wrap-around, ULONG_MAX will be returned."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1895
msgid "Find and get a reference to a folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1896 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:782 include/linux/pagemap.h:799
msgid "The address_space to search."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:579 ../../../core-api/mm-api:61:
#: mm/filemap.c:1897 ../../../core-api/mm-api:85: include/linux/pagemap.h:486
#: include/linux/pagemap.h:783 include/linux/pagemap.h:800
msgid "The page index."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1899
msgid "``fgf_t fgp_flags``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1898
msgid "``FGP`` flags modify how the folio is returned."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2368 mm/mempolicy.c:2451
#: mm/mempolicy.c:2498 ../../../core-api/mm-api:106: include/linux/mm.h:2876
#: ../../../core-api/mm-api:116: mm/kmemleak.c:1088 mm/kmemleak.c:1107
#: mm/kmemleak.c:1126 mm/kmemleak.c:1303 mm/kmemleak.c:1341
#: ../../../core-api/mm-api:121: mm/zpool.c:136 mm/zpool.c:228
#: ../../../core-api/mm-api:122: mm/memcontrol.c:2833 mm/memcontrol.c:4729
#: mm/memcontrol.c:4764 ../../../core-api/mm-api:124: mm/shmem.c:5974
#: ../../../core-api/mm-api:129: mm/percpu.c:495 mm/percpu.c:1721
#: ../../../core-api/mm-api:61: mm/filemap.c:1900 mm/filemap.c:3999
#: mm/filemap.c:4042 mm/filemap.c:4331
msgid "``gfp_t gfp``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1899
msgid "Memory allocation flags to use if ``FGP_CREAT`` is specified."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1900
msgid "Looks up the page cache entry at **mapping** & **index**."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1902
msgid ""
"If ``FGP_LOCK`` or ``FGP_CREAT`` are specified then the function may sleep "
"even if the ``GFP`` flags specified for ``FGP_CREAT`` are atomic."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1905
msgid ""
"If this function returns a folio, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:1908
msgid "The found folio or an ERR_PTR() otherwise."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2189
msgid "Get a batch of folios"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2190 mm/filemap.c:2211
#: mm/filemap.c:2283
msgid "The address_space to search"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:287
#: ../../../core-api/mm-api:61: mm/filemap.c:2192 mm/filemap.c:2213
#: mm/filemap.c:2285
msgid "``pgoff_t *start``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2191 mm/filemap.c:2212
#: mm/filemap.c:2284
msgid "The starting page index"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2193 mm/filemap.c:2214
#: mm/filemap.c:2286 ../../../core-api/mm-api:76: mm/page-writeback.c:2374
#: ../../../core-api/mm-api:82: mm/truncate.c:565 mm/truncate.c:641
msgid "``pgoff_t end``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2192 mm/filemap.c:2213
#: mm/filemap.c:2285
msgid "The final page index (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1070 ../../../core-api/mm-api:131:
#: mm/vmscan.c:7856 ../../../core-api/mm-api:61: mm/filemap.c:2194
#: mm/filemap.c:2215 mm/filemap.c:2288
msgid "``struct folio_batch *fbatch``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2193
msgid "The batch to fill."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2194
msgid ""
"Search for and return a batch of folios in the mapping starting at index "
"**start** and up to index **end** (inclusive).  The folios are returned in "
"**fbatch** with an elevated reference count."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2199
msgid ""
"The number of folios which were found. We also update **start** to index the "
"next folio for the traversal."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2210
msgid "Get a batch of contiguous folios"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2214 mm/filemap.c:2287
msgid "The batch to fill"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2215
msgid ""
"filemap_get_folios_contig() works exactly like filemap_get_folios(), except "
"the returned folios are guaranteed to be contiguous. This may not return all "
"contiguous folios if the batch gets filled up."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2220
msgid ""
"The number of folios found. Also update **start** to be positioned for "
"traversal of the next folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2282
msgid "Get a batch of folios matching **tag**"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2287
msgid "``xa_mark_t tag``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2286
msgid "The tag index"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2288
msgid ""
"The first folio may start before **start**; if it does, it will contain "
"**start**.  The final folio may extend beyond **end**; if it does, it will "
"contain **end**.  The folios have ascending indices.  There may be gaps "
"between the folios if there are indices which have no folio in the page "
"cache.  If folios are added to or removed from the page cache while this is "
"running, they may or may not be found by this call. Only returns folios that "
"are tagged with **tag**."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2297
msgid ""
"The number of folios found. Also update **start** to index the next folio "
"for traversal."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2663
msgid "Read data from the page cache."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2669 mm/filemap.c:2848
#: mm/filemap.c:4248 mm/filemap.c:4303
msgid "``struct kiocb *iocb``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2664
msgid "The iocb to read."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2666 mm/filemap.c:2845
msgid "``struct iov_iter *iter``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2665
msgid "Destination for the data."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2667
msgid "``ssize_t already_read``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2666
msgid "Number of bytes already read by the caller."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2667
msgid ""
"Copies data from the page cache.  If the data is not currently present, uses "
"the readahead and read_folio address_space operations to fetch it."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2671
msgid ""
"Total number of bytes copied, including those already read by the caller.  "
"If an error happens before any bytes are copied, returns a negative error "
"number."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2842
msgid "generic filesystem read routine"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2843
msgid "kernel I/O control block"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2844
msgid "destination for the data read"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2845
msgid ""
"This is the \"read_iter()\" routine for all filesystems that can use the "
"page cache directly."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2848
msgid ""
"The IOCB_NOWAIT flag in iocb->ki_flags indicates that -EAGAIN shall be "
"returned when no data can be read without waiting for I/O requests to "
"complete; it doesn't prevent readahead."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2852
msgid ""
"The IOCB_NOIO flag in iocb->ki_flags indicates that no new I/O requests "
"shall be made for the read or for readahead.  When no data can be read, -"
"EAGAIN shall be returned.  When readahead would be triggered, a partial, "
"possibly empty read shall be returned."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2858
msgid "number of bytes copied, even for partial reads"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2859
msgid "negative error code (or 0 if IOCB_NOIO) if nothing was read"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2942
msgid "Splice data from a file's pagecache into a pipe"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2948
msgid "``struct file *in``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2943
msgid "The file to read from"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2945
msgid "``loff_t *ppos``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2944
msgid "Pointer to the file position to read from"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2946
msgid "``struct pipe_inode_info *pipe``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2945
msgid "The pipe to splice into"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2946
msgid "The amount to splice"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2948 ../../../core-api/mm-api:76:
#: mm/page-writeback.c:2033
msgid "``unsigned int flags``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2947
msgid "The SPLICE_F_* flags"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2948
msgid ""
"This function gets folios from a file's pagecache and splices them into the "
"pipe.  Readahead will be called as necessary to fill more folios.  This may "
"be used for blockdevs also."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:2953
msgid ""
"On success, the number of bytes read will be returned and ***ppos** will be "
"updated if appropriate; 0 will be returned if there is no more data to be "
"read; -EAGAIN will be returned if the pipe had no space, and some other "
"negative error code will be returned on error.  A short read may occur if "
"the pipe has insufficient space, we reach the end of the data or we hit a "
"hole."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3381
msgid "read in file data for page fault handling"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2900
#: ../../../core-api/mm-api:135: mm/huge_memory.c:1441 mm/huge_memory.c:1580
#: mm/huge_memory.c:1624 ../../../core-api/mm-api:61: mm/filemap.c:3387
msgid "``struct vm_fault *vmf``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3382
msgid "struct vm_fault containing details of the fault"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3383
msgid ""
"filemap_fault() is invoked via the vma operations vector for a mapped memory "
"region to read in file data during a page fault."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3386
msgid ""
"The goto's are kind of ugly, but this streamlines the normal case of having "
"it in the page cache, and handles the special cases reasonably without "
"having a lot of duplicated code."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3390
msgid "vma->vm_mm->mmap_lock must be held on entry."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3392
msgid ""
"If our return value has VM_FAULT_RETRY set, it's because the mmap_lock may "
"be dropped before doing I/O or by lock_folio_maybe_drop_mmap()."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3395
msgid ""
"If our return value does not have VM_FAULT_RETRY set, the mmap_lock has not "
"been released."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3398
msgid "We never return with VM_FAULT_RETRY and a bit from VM_FAULT_ERROR set."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3401
msgid "bitwise-OR of ``VM_FAULT_`` codes."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3971
msgid "Read into page cache, fill it if needed."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3972
msgid "The address_space to read from."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3973
msgid "The index to read."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3975
msgid "``filler_t filler``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3974
msgid "Function to perform the read, or NULL to use aops->read_folio()."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3975
msgid "Passed to filler function, may be NULL if not required."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3976
msgid ""
"Read one page into the page cache.  If it succeeds, the folio returned will "
"contain **index**, but it may not be the first page of the folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3979
msgid ""
"If the filler function returns an error, it will be returned to the caller."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3983
msgid "May sleep.  Expects mapping->invalidate_lock to be held."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3984
msgid "An uptodate folio on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3995
msgid "Read into page cache, using specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3996
msgid "The address_space for the folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3997
msgid "The index that the allocated folio will contain."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3998
msgid "The page allocator flags to use if allocating."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:3999
msgid ""
"This is the same as \"read_cache_folio(mapping, index, NULL, NULL)\", but "
"with any new memory allocations done using the specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4002
msgid ""
"The most likely error from this function is EIO, but ENOMEM is possible and "
"so is EINTR.  If ->read_folio returns another error, that will be returned "
"to the caller."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4006 mm/filemap.c:4047
msgid "The function expects mapping->invalidate_lock to be already held."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4009
msgid "Uptodate folio on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5970 ../../../core-api/mm-api:61:
#: mm/filemap.c:4038
msgid "read into page cache, using specified page allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4039 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:878
msgid "the page's address_space"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4040 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:838 include/linux/pagemap.h:860
#: include/linux/pagemap.h:906
msgid "the page index"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5973 ../../../core-api/mm-api:61:
#: mm/filemap.c:4041
msgid "the page allocator flags to use if allocating"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4042
msgid ""
"This is the same as \"read_mapping_page(mapping, index, NULL)\", but with "
"any new page allocations done using the specified allocation flags."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4045
msgid "If the page does not get brought uptodate, return -EIO."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4050
msgid "up to date page on success, ERR_PTR() on failure."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4242 mm/filemap.c:4297
msgid "write data to a file"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4243
msgid "IO state structure (file, offset, etc.)"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4245 mm/filemap.c:4300
msgid "``struct iov_iter *from``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4244 mm/filemap.c:4299
msgid "iov_iter with data to write"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4245
msgid ""
"This function does all the work needed for actually writing data to a file. "
"It does all basic checks, removes SUID from the file, updates modification "
"times and calls proper subroutines depending on whether we do direct IO or a "
"standard buffered write."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4250
msgid ""
"It expects i_rwsem to be grabbed unless we work on a block device or similar "
"object which does not need locking at all."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4253
msgid ""
"This function does *not* take care of syncing data in case of O_SYNC write. "
"A caller has to handle it. This is mainly due to the fact that we want to "
"avoid syncing under i_rwsem."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4258 mm/filemap.c:4306
msgid "number of bytes written, even for truncated writes"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4259
msgid "negative error code if no data has been written at all"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4298
msgid "IO state structure"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4300
msgid ""
"This is a wrapper around __generic_file_write_iter() to be used by most "
"filesystems. It takes care of syncing the file in case of O_SYNC file and "
"acquires i_rwsem as needed."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4304
msgid ""
"negative error code if no data has been written at all of vfs_fsync_range() "
"failed for a synchronous write"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4328
msgid "Release fs-specific metadata on a folio."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4329
msgid "The folio which the kernel is trying to free."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4330
msgid "Memory allocation flags (and I/O mode)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4331
msgid ""
"The address_space is trying to release any data attached to a folio "
"(presumably at folio->private)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4334
msgid ""
"This will also be called if the private_2 flag is set on a page, indicating "
"that the folio has other metadata associated with it."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4337
msgid ""
"The **gfp** argument specifies whether I/O may be performed to release this "
"page (__GFP_IO), and whether the call may block (__GFP_RECLAIM & __GFP_FS)."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4342
msgid "``true`` if the release was successful, otherwise ``false``."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4361
msgid "Invalidate/forcibly write back a range of an inode's pagecache"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:431 mm/shmem.c:2683
#: ../../../core-api/mm-api:61: mm/filemap.c:4367 ../../../core-api/mm-api:82:
#: mm/truncate.c:746 mm/truncate.c:781 mm/truncate.c:805 mm/truncate.c:869
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1514
#: include/linux/pagemap.h:1545
msgid "``struct inode *inode``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4362
msgid "The inode to flush"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4364
msgid "``bool flush``"
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4363
msgid "Set to write back rather than simply invalidate."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4364
msgid "First byte to in range."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4365
msgid ""
"Last byte in range (inclusive), or LLONG_MAX for everything from start "
"onwards."
msgstr ""

#: ../../../core-api/mm-api:61: mm/filemap.c:4367
msgid ""
"Invalidate all the folios on an inode that contribute to the specified "
"range, possibly writing them back first.  Whilst the operation is "
"undertaken, the invalidate lock is held to prevent new folios from being "
"installed."
msgstr ""

#: ../../../core-api/mm-api.rst:65
msgid "Readahead"
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:12
msgid ""
"Readahead is used to read content into the page cache before it is "
"explicitly requested by the application.  Readahead only ever attempts to "
"read folios that are not yet in the page cache.  If a folio is present but "
"not up-to-date, readahead will not try to read it. In that case a simple -"
">read_folio() will be requested."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:18
msgid ""
"Readahead is triggered when an application read request (whether a system "
"call or a page fault) finds that the requested folio is not in the page "
"cache, or that it is in the page cache and has the readahead flag set.  This "
"flag indicates that the folio was read as part of a previous readahead "
"request and now that it has been accessed, it is time for the next readahead."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:25
msgid ""
"Each readahead request is partly synchronous read, and partly async "
"readahead.  This is reflected in the struct file_ra_state which contains -"
">size being the total number of pages, and ->async_size which is the number "
"of pages in the async section.  The readahead flag will be set on the first "
"folio in this async section to trigger a subsequent readahead.  Once a "
"series of sequential reads has been established, there should be no need for "
"a synchronous component and all readahead request will be fully asynchronous."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:34
msgid ""
"When either of the triggers causes a readahead, three numbers need to be "
"determined: the start of the region to read, the size of the region, and the "
"size of the async tail."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:38
msgid ""
"The start of the region is simply the first page address at or after the "
"accessed address, which is not currently populated in the page cache.  This "
"is found with a simple search in the page cache."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:42
msgid ""
"The size of the async tail is determined by subtracting the size that was "
"explicitly requested from the determined request size, unless this would be "
"less than zero - then zero is used.  NOTE THIS CALCULATION IS WRONG WHEN THE "
"START OF THE REGION IS NOT THE ACCESSED PAGE.  ALSO THIS CALCULATION IS NOT "
"USED CONSISTENTLY."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:48
msgid ""
"The size of the region is normally determined from the size of the previous "
"readahead which loaded the preceding pages.  This may be discovered from the "
"struct file_ra_state for simple sequential reads, or from examining the "
"state of the page cache when multiple sequential reads are interleaved.  "
"Specifically: where the readahead was triggered by the readahead flag, the "
"size of the previous readahead is assumed to be the number of pages from the "
"triggering page to the start of the new readahead.  In these cases, the size "
"of the previous readahead is scaled, often doubled, for the new readahead, "
"though see get_next_ra_size() for details."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:59
msgid ""
"If the size of the previous read cannot be determined, the number of "
"preceding pages in the page cache is used to estimate the size of a previous "
"read.  This estimate could easily be misled by random reads being "
"coincidentally adjacent, so it is ignored unless it is larger than the "
"current request, and it is not scaled up, unless it is at the start of file."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:66
msgid ""
"In general readahead is accelerated at the start of the file, as reads from "
"there are often sequential.  There are other minor adjustments to the "
"readahead size in various special cases and these are best discovered by "
"reading the code."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:71
msgid ""
"The above calculation, based on the previous readahead size, determines the "
"size of the readahead, to which any requested read size may be added."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:75
msgid ""
"Readahead requests are sent to the filesystem using the ->readahead() "
"address space operation, for which mpage_readahead() is a canonical "
"implementation.  ->readahead() should normally initiate reads on all folios, "
"but may fail to read any or all folios without causing an I/O error.  The "
"page cache reading code will issue a ->read_folio() request for any folio "
"which ->readahead() did not read, and only an error from this will be final."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:83
msgid ""
"->readahead() will generally call readahead_folio() repeatedly to get each "
"folio from those prepared for readahead.  It may fail to read a folio by:"
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:87
msgid ""
"not calling readahead_folio() sufficiently many times, effectively ignoring "
"some folios, as might be appropriate if the path to storage is congested."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:91
msgid ""
"failing to actually submit a read request for a given folio, possibly due to "
"insufficient resources, or"
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:94
msgid "getting an error during subsequent processing of a request."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:96
msgid ""
"In the last two cases, the folio should be unlocked by the filesystem to "
"indicate that the read attempt has failed.  In the first case the folio will "
"be unlocked by the VFS."
msgstr ""

#: ../../../core-api/mm-api:67: mm/readahead.c:100
msgid ""
"Those folios not in the final ``async_size`` of the request should be "
"considered to be important and ->readahead() should not fail them due to "
"congestion or temporary resource unavailability, but should wait for "
"necessary resources (e.g.  memory or indexing information) to become "
"available.  Folios in the final ``async_size`` may be considered less urgent "
"and failure to read them is more acceptable. In this case it is best to use "
"filemap_remove_folio() to remove the folios from the page cache as is "
"automatically done for folios that were not fetched with readahead_folio().  "
"This will allow a subsequent synchronous readahead request to try them "
"again.  If they are left in the page cache, then they will be read "
"individually using ->read_folio() which may be less efficient."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:194
msgid "Start unchecked readahead."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:200 mm/readahead.c:744
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1421
msgid "``struct readahead_control *ractl``"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:195
msgid "Readahead control."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:197
msgid "``unsigned long nr_to_read``"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:196
msgid "The number of pages to read."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:198
msgid "``unsigned long lookahead_size``"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:197
msgid "Where to start the next readahead."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:198
msgid ""
"This function is for filesystems to call when they want to start readahead "
"beyond a file's stated i_size.  This is almost certainly not the function "
"you want to call.  Use page_cache_async_readahead() or "
"page_cache_sync_readahead() instead."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:204
msgid ""
"File is referenced by caller.  Mutexes may be held by caller. May sleep, but "
"will not reenter filesystem to reclaim memory."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:738
msgid "Expand a readahead request"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:739
msgid "The request to be expanded"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:741
msgid "``loff_t new_start``"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:740
msgid "The revised start"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:742
msgid "``size_t new_len``"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:741
msgid "The revised size of the request"
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:742
msgid ""
"Attempt to expand a readahead request outwards from the current size to the "
"specified size by inserting locked pages before and after the current window "
"to increase the size to the new window.  This may involve the insertion of "
"THPs, in which case the window may get expanded even beyond what was "
"requested."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:748
msgid ""
"The algorithm will stop if it encounters a conflicting page already in the "
"pagecache and leave a smaller expansion than requested."
msgstr ""

#: ../../../core-api/mm-api:70: mm/readahead.c:751
msgid ""
"The caller must check for this by examining the revised **ractl** object for "
"a different expansion than was requested."
msgstr ""

#: ../../../core-api/mm-api.rst:74
msgid "Writeback"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2030
msgid "Balance dirty memory state."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2031
#: mm/page-writeback.c:2106
msgid "address_space which was dirtied."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2032
msgid "BDP flags."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2033
#: mm/page-writeback.c:2107
msgid ""
"Processes which are dirtying memory should call in here once for each page "
"which was newly dirtied.  The function will periodically check the system's "
"dirty state and will initiate writeback if needed."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2037
msgid "See balance_dirty_pages_ratelimited() for details."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2040
msgid ""
"If **flags** contains BDP_ASYNC, it may return -EAGAIN to indicate that "
"memory is out of balance and the caller must wait for I/O to complete.  "
"Otherwise, it will return 0 to indicate that either memory was already in "
"balance, or it was able to sleep until the amount of dirty memory returned "
"to balance."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2105
msgid "balance dirty memory state."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2111
msgid ""
"Once we're over the dirty memory limit we decrease the ratelimiting by a "
"lot, to prevent individual processes from overshooting the limit by "
"(ratelimit_pages) each."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2370
msgid "tag pages to be written by writeback"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2373
#: ../../../core-api/mm-api:82: mm/truncate.c:564 mm/truncate.c:640
#: ../../../core-api/mm-api:97: mm/memory.c:4082
msgid "``pgoff_t start``"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2372
msgid "starting page index"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2373
msgid "ending page index (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2374
msgid ""
"This function scans the page range from **start** to **end** (inclusive) and "
"tags all pages that have DIRTY tag set with a special TOWRITE tag.  The "
"caller can then use the TOWRITE tag to identify pages eligible for "
"writeback. This mechanism is used to avoid livelocking of writeback by a "
"process steadily creating new dirty pages in the file (thus it is important "
"for this function to be quick so that it can tag pages faster than a "
"dirtying process can create them)."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2479
msgid "iterate folio of a mapping for writeback"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2481
msgid "writeback context"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2482
msgid "previously iterated folio (``NULL`` to start)"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2484
msgid "``int *error``"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2483
msgid "in-out pointer for writeback errors (see below)"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2484
msgid ""
"This function returns the next folio for the writeback operation described "
"by **wbc** on **mapping** and  should be called in a while loop in the -"
">writepages implementation."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2488
msgid ""
"To start the writeback operation, ``NULL`` is passed in the **folio** "
"argument, and for every subsequent iteration the folio returned previously "
"should be passed back in."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2492
msgid ""
"If there was an error in the per-folio writeback inside the writeback_iter() "
"loop, **error** should be set to the error value."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2495
msgid ""
"Once the writeback described in **wbc** has finished, this function will "
"return ``NULL`` and if there was an error in any iteration restore it to "
"**error**."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2499
msgid ""
"callers should not manually break out of the loop using break or goto but "
"must keep calling writeback_iter() until it returns ``NULL``."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2502
msgid "the folio to write or ``NULL`` if the loop is done."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2594
msgid ""
"walk the list of dirty pages of the given address space and write all of "
"them."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2596
msgid "subtract the number of written pages from ***wbc->nr_to_write**"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2598
msgid "``writepage_t writepage``"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2597
msgid "function called for each page"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2599
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:586
#: include/linux/pagemap.h:601
msgid "``void *data``"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2598
msgid "data passed to writepage function"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2600
msgid "``0`` on success, negative error code otherwise"
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2602
msgid "please use writeback_iter() instead."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2749
msgid "Mark a folio dirty for filesystems which do not use buffer_heads."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2750
msgid "Address space this folio belongs to."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2751
msgid "Folio to be marked as dirty."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2752
msgid ""
"Filesystems which do not use buffer heads should call this function from "
"their dirty_folio address space operation.  It ignores the contents of "
"folio_get_private(), so if the filesystem marks individual blocks as dirty, "
"the filesystem should handle that itself."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2757
msgid ""
"This is also sometimes used by filesystems which use buffer_heads when a "
"single buffer is being dirtied: we want to set the folio dirty in that case, "
"but not all the buffers.  This is a \"bottom-up\" dirtying, whereas "
"block_dirty_folio() is a \"top-down\" dirtying."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2762
msgid ""
"The caller must ensure this doesn't race with truncation.  Most will simply "
"hold the folio lock, but e.g. zap_pte_range() calls with the folio mapped "
"and the pte lock held, which also locks out truncation."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2783
msgid "Decline to write a dirty folio."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2784
msgid "The writeback control."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2786
msgid ""
"When a writepage implementation decides that it doesn't want to write "
"**folio** for some reason, it should call this function, unlock **folio** "
"and return 0."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2791
msgid ""
"True if we redirtied the folio.  False if someone else dirtied it first."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2819
msgid "Mark a folio as being modified."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2821
msgid ""
"The folio may not be truncated while this function is running. Holding the "
"folio lock is sufficient to prevent truncation, but some callers cannot "
"acquire a sleeping lock.  These callers instead hold the page table lock for "
"a page table which contains at least one page in this folio.  Truncation "
"will block on the page table lock as it unmaps pages before removing the "
"folio from its mapping."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:2829
msgid "True if the folio was newly dirtied, false if it was already dirty."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3109
#: mm/page-writeback.c:3130
msgid "Wait for a folio to finish writeback."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3110
#: mm/page-writeback.c:3131
msgid "The folio to wait for."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3111
msgid ""
"If the folio is currently being written back to storage, wait for the I/O to "
"complete."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3115
#: mm/page-writeback.c:3136 mm/page-writeback.c:3162
msgid ""
"Sleeps.  Must be called in process context and with no spinlocks held.  "
"Caller should hold a reference on the folio. If the folio is not locked, "
"writeback may start again after writeback has finished."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3132
msgid ""
"If the folio is currently being written back to storage, wait for the I/O to "
"complete or a fatal signal to arrive."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3140
msgid "0 on success, -EINTR if we get a fatal signal while waiting."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3155
msgid "wait for writeback to finish, if necessary."
msgstr ""

#: ../../../core-api/mm-api:76: mm/page-writeback.c:3157
msgid ""
"This function determines if the given folio is related to a backing device "
"that requires folio contents to be held stable during writeback. If so, then "
"it will wait for any pending writeback to complete."
msgstr ""

#: ../../../core-api/mm-api.rst:80
msgid "Truncate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:121
msgid "Invalidate part or all of a folio."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:122
msgid "The folio which is affected."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:124
msgid "``size_t offset``"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:123
msgid "start of the range to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:125
msgid "``size_t length``"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:124
msgid "length of the range to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:125
msgid ""
"folio_invalidate() is called when all or part of the folio has become "
"invalidated by a truncate operation."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:128
msgid ""
"folio_invalidate() does not have to release all buffers, but it must ensure "
"that no dirty buffer is left outside **offset** and that no I/O is underway "
"against any of the blocks which are outside the truncation point.  Because "
"the caller is about to free (and possibly reuse) those blocks on-disk."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:318
msgid "truncate range of pages specified by start & end byte offsets"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:319 mm/truncate.c:447
#: mm/truncate.c:466
msgid "mapping to truncate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:320 mm/truncate.c:448
msgid "offset from which to truncate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:321
msgid "offset to which to truncate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:322
msgid ""
"Truncate the page cache, removing the pages that are between specified "
"offsets (and zeroing out partial pages if lstart or lend + 1 is not page "
"aligned)."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:326
msgid ""
"Truncate takes two passes - the first pass is nonblocking.  It will not "
"block on page locks and it will not block on writeback.  The second pass "
"will wait.  This is to prevent as much IO as possible in the affected "
"region. The first pass will remove most pages, so the search cost of the "
"second pass is low."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:332
msgid ""
"We pass down the cache-hot hint to the page freeing code.  Even if the "
"mapping is large, it is probably the case that the final pages are the most "
"recently touched, and freeing happens in ascending file offset order."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:336
msgid ""
"Note that since ->invalidate_folio() accepts range to invalidate "
"truncate_inode_pages_range is able to handle cases where lend + 1 is not "
"page aligned properly."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:446
msgid "truncate *all* the pages from an offset"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:449
msgid ""
"Called under (and serialised by) inode->i_rwsem and mapping->invalidate_lock."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:453
msgid ""
"When this function returns, there can be a page in the process of deletion "
"(inside __filemap_remove_folio()) in the specified range.  Thus mapping-"
">nrpages can be non-zero when this function returns even after truncation of "
"the whole mapping."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:465
msgid "truncate *all* pages before inode dies"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:467
msgid "Called under (and serialized by) inode->i_rwsem."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:469
msgid ""
"Filesystems have to use this in the .evict_inode path to inform the VM that "
"this is the final truncate and the inode is going away."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:561
msgid "Invalidate all clean, unlocked cache of one inode"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:562
msgid "the address_space which holds the cache to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:563
msgid "the offset 'from' which to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:564
msgid "the offset 'to' which to invalidate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:565
msgid ""
"This function removes pages that are clean, unmapped and unlocked, as well "
"as shadow entries. It will not block on IO activity."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:568
msgid ""
"If you want to remove all the pages of one inode, regardless of their use "
"and writeback state, use truncate_inode_pages()."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:572
msgid "The number of indices that had their contents invalidated"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:637
msgid "remove range of pages from an address_space"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:638 mm/truncate.c:726
msgid "the address_space"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:639
msgid "the page offset 'from' which to invalidate"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:640
msgid "the page offset 'to' which to invalidate (inclusive)"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:641 mm/truncate.c:727
msgid ""
"Any pages which are found to be mapped into pagetables are unmapped prior to "
"invalidation."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:645 mm/truncate.c:731
msgid "-EBUSY if any pages could not be invalidated."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:725
msgid "remove all pages from an address_space"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:740
msgid "unmap and remove pagecache that has been truncated"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:741 mm/truncate.c:776
#: mm/truncate.c:864
msgid "inode"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:743 mm/truncate.c:778
msgid "``loff_t newsize``"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:742 mm/truncate.c:777
msgid "new file size"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:743
msgid ""
"inode's new i_size must already be written before truncate_pagecache is "
"called."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:746 mm/truncate.c:867
msgid ""
"This function should typically be called before the filesystem releases "
"resources associated with the freed range (eg. deallocates blocks). This "
"way, pagecache will always stay logically coherent with on-disk format, and "
"the filesystem would not have to deal with situations such as writepage "
"being called for a page that has already had its underlying blocks "
"deallocated."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:775
msgid "update inode and pagecache for a new file size"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:778
msgid ""
"truncate_setsize updates i_size and performs pagecache truncation (if "
"necessary) to **newsize**. It will be typically be called from the "
"filesystem's setattr function when ATTR_SIZE is passed in."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:782
msgid ""
"Must be called with a lock serializing truncates and writes (generally "
"i_rwsem but e.g. xfs uses a different lock) and before all filesystem "
"specific block truncation has been performed."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:799
msgid "update pagecache after extension of i_size"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:800
msgid "inode for which i_size was extended"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:802
msgid "``loff_t from``"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:801
msgid "original inode size"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:803
msgid "``loff_t to``"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:802
msgid "new inode size"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:803
msgid ""
"Handle extension of inode size either caused by extending truncate or by "
"write starting after current i_size.  We mark the page straddling current "
"i_size RO so that page_mkwrite() is called on the first write access to the "
"page.  The filesystem will update its per-block information before user "
"writes to the page via mmap after the i_size has been changed."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:810
msgid ""
"The function must be called after i_size is updated so that page fault "
"coming after we unlock the folio will already see the new i_size. The "
"function must be called while we still hold i_rwsem - this not only makes "
"sure i_size is stable but also that userspace cannot observe new i_size "
"value before we are prepared to store mmap writes at new inode size."
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:863
msgid "unmap and remove pagecache that is hole-punched"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:865
msgid "offset of beginning of hole"
msgstr ""

#: ../../../core-api/mm-api:82: mm/truncate.c:866
msgid "offset of last byte of hole"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:72
msgid "set a writeback error on an address_space"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:73
msgid "mapping in which to set writeback error"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:75
msgid "``int err``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:74
msgid "error to be set in mapping"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:75
#: include/linux/pagemap.h:229
msgid ""
"When writeback fails in some way, we must record that error so that "
"userspace can be informed when fsync and the like are called.  We endeavor "
"to report errors on any file that was open at the time of the error.  Some "
"internal callers also need to know when writeback errors have occurred."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:80
msgid ""
"When a writeback error occurs, most filesystems will want to call "
"filemap_set_wb_err to record the error in the mapping so that it will be "
"automatically reported whenever fsync is called on the file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:93
msgid "has an error occurred since the mark was sampled?"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:94
msgid "mapping to check for writeback errors"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:96
msgid "``errseq_t since``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:95
msgid "previously-sampled errseq_t"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:96
msgid ""
"Grab the errseq_t value from the mapping, and see if it has changed "
"\"since\" the given value was sampled."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:99
msgid "If it has then report the latest error set, otherwise return 0."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:109
#: include/linux/pagemap.h:121
msgid "sample the current errseq_t to test for later errors"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:110
msgid "mapping to be sampled"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:111
msgid ""
"Writeback errors are always reported relative to a particular sample point "
"in the past. This function provides those sample points."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:122
msgid "file pointer to be sampled"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:123
msgid ""
"Grab the most current superblock-level errseq_t value for the given struct "
"file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:226
msgid "record a writeback error in the address_space"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:227
msgid "the mapping in which an error should be set"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:229
msgid "``int error``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:228
msgid "the error to set in the mapping"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:234
msgid ""
"When a writeback error occurs, most filesystems will want to call "
"mapping_set_error to record the error in the mapping so that it can be "
"reported when the application calls fsync(2)."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:446
msgid "Indicate the file supports large folios."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:447
msgid "The address space of the file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:448
msgid ""
"The filesystem should call this function in its inode constructor to "
"indicate that the VFS can use large folios to cache the contents of the file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:453
msgid ""
"This should not be called while the inode is active as it is non-atomic."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:484
msgid "Align index for this mapping."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:485
msgid "The address_space."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:487
msgid ""
"The index of a folio must be naturally aligned.  If you are adding a new "
"folio to the page cache and need to know what index to give it, call this "
"function."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:549
msgid "Find the file mapping this folio belongs to."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:551
msgid ""
"For folios which are in the page cache, return the mapping that this page "
"belongs to.  Anonymous folios return NULL, even if they're in the swap "
"cache.  Other kinds of folio also return NULL."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:555
msgid ""
"This is ONLY used by architecture cache flushing code.  If you aren't "
"writing cache flushing code, you want either folio_mapping() or "
"folio_file_mapping()."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:569
msgid "Get the host inode for this folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:571
msgid ""
"For folios which are in the page cache, return the inode that this folio "
"belongs to."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:574
msgid "Do not call this for folios which aren't in the page cache."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:583
msgid "Attach private data to a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:584
msgid "Folio to attach data to."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:585
msgid "Data to attach to folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:586
msgid ""
"Attaching private data to a folio increments the page's reference count. The "
"data must be detached before the folio will be freed."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:598
msgid "Change private data on a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:599
msgid "Folio to change the data on."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:600
msgid "Data to set on the folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:601
msgid ""
"Change the private data attached to a folio and return the old data.  The "
"page must previously have had data attached and the data must be detached "
"before the folio will be freed."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:606
msgid "Data that was previously attached to the folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:617
msgid "Detach private data from a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:618
msgid "Folio to detach data from."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:619
msgid ""
"Removes the data that was previously attached to the folio and decrements "
"the refcount on the page."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:623
msgid "Data that was attached to the folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:678
msgid "Flags for getting folios from the page cache."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:679
msgid ""
"Most users of the page cache will not need to use these flags; there are "
"convenience functions such as filemap_get_folio() and filemap_lock_folio().  "
"For users which need more control over exactly what is done with the folios, "
"these flags to __filemap_get_folio() are available."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:685
msgid "``FGP_ACCESSED`` - The folio will be marked accessed."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:686
msgid "``FGP_LOCK`` - The folio is returned locked."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:687
msgid ""
"``FGP_CREAT`` - If no folio is present then a new folio is allocated, added "
"to the page cache and the VM's LRU list.  The folio is returned locked."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:690
msgid ""
"``FGP_FOR_MMAP`` - The caller wants to do its own locking dance if the folio "
"is already in cache.  If the folio was allocated, unlock it before returning "
"so the caller can do the same dance."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:693
msgid "``FGP_WRITE`` - The folio will be written to by the caller."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:694
msgid "``FGP_NOFS`` - __GFP_FS will get cleared in gfp."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:695
msgid "``FGP_NOWAIT`` - Don't block on the folio lock."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:696
msgid "``FGP_STABLE`` - Wait for the folio to be stable (finished writeback)"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:697
msgid "``FGP_DONTCACHE`` - Uncached buffered IO"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:698
msgid ""
"``FGP_WRITEBEGIN`` - The flags to use in a filesystem write_begin() "
"implementation."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:728
msgid "Encode a length in the fgf_t flags."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:729
msgid "The suggested size of the folio to create."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:730
msgid ""
"The caller of __filemap_get_folio() can use this to suggest a preferred size "
"for the folio that is created.  If there is already a folio at the index, it "
"will be returned, no matter what its size.  If a folio is freshly created, "
"it may be of a different size than requested due to alignment constraints, "
"memory pressure, or the presence of other folios at nearby indices."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:754
msgid "Get folio for write_begin with flags."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:760
msgid "``const struct kiocb *iocb``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:755
msgid "The kiocb passed from write_begin (may be NULL)."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:756
msgid "The address space to search."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:757
msgid "The page cache index."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:758
msgid "Length of data being written."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:759
msgid ""
"This is a helper for filesystem write_begin() implementations. It wraps "
"__filemap_get_folio(), setting appropriate flags in the write begin context."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:764
msgid "A folio or an ERR_PTR."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:781
msgid "Find and get a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:784
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If a folio is "
"present, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:788
#: include/linux/pagemap.h:806
msgid ""
"A folio or ERR_PTR(-ENOENT) if there is no folio in the cache for this "
"index.  Will not return a shadow, swap or DAX entry."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:798
msgid "Find and lock a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:801
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If a folio is "
"present, it is returned locked with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2697 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:805 include/linux/pagemap.h:866
msgid "May sleep."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:816
msgid "grab a folio from the page cache"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:817
msgid "The address space to search"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:818
msgid "The page index"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:819
msgid ""
"Looks up the page cache entry at **mapping** & **index**. If no folio is "
"found, a new folio is created. The folio is locked, marked as accessed, and "
"returned."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:824
msgid ""
"A found or created folio. ERR_PTR(-ENOMEM) if no folio is found and failed "
"to create a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:836
msgid "find and get a page reference"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:837
#: include/linux/pagemap.h:859
msgid "the address_space to search"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:839
msgid "``pgoff_t offset``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:839
msgid ""
"Looks up the page cache slot at **mapping** & **offset**.  If there is a "
"page cache page, it is returned with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:842
msgid "Otherwise, ``NULL`` is returned."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:858
msgid "locate, pin and lock a pagecache page"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:861
msgid ""
"Looks up the page cache entry at **mapping** & **index**.  If there is a "
"page cache page, it is returned locked and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:867
msgid ""
"A struct page or ``NULL`` if there is no page in the cache for this index."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:877
msgid "locate or add a pagecache page"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:879
msgid "the page's index into the mapping"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:880
msgid "page allocation mode"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:881
msgid ""
"Looks up the page cache slot at **mapping** & **offset**.  If there is a "
"page cache page, it is returned locked and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:885
msgid ""
"If the page is not present, a new page is allocated using **gfp_mask** and "
"added to the page cache and the VM's LRU list.  The page is returned locked "
"and with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:889
msgid "On memory exhaustion, ``NULL`` is returned."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:891
msgid ""
"find_or_create_page() may sleep, even if **gfp_flags** specifies an atomic "
"allocation!"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:904
msgid "returns locked page at given index in given cache"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:907
msgid ""
"Returns locked page at given index in given cache, creating it if needed, "
"but do not wait if the page is locked or to reclaim memory. This is intended "
"for speculative data generators, where the data can be regenerated if the "
"page couldn't be grabbed.  This routine should be safe to call while holding "
"the lock for another page."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:913
msgid ""
"Clear __GFP_FS when allocating the page to avoid recursion into the fs and "
"deadlock against the caller's locked page."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:926
msgid "Get the index of the next folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:927
msgid "The current folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:929
msgid "The index of the folio which follows this folio in the file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:937
msgid "The page for a particular index."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:938
msgid "The folio which contains this index."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:939
msgid "The index we want to look up."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:940
msgid ""
"Sometimes after looking up a folio in the page cache, we need to obtain the "
"specific page for an index (eg a page fault)."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:944
msgid "The page containing the file data for this index."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:952
msgid "Does this folio contain this index?"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:954
msgid "The page index within the file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:956
msgid ""
"The caller should have the folio locked and ensure e.g., shmem did not move "
"this folio to the swap cache."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:958
msgid "true or false."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:995
msgid "Calculate the logical page offset of this page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:781
#: include/linux/page-flags.h:863 include/linux/page-flags.h:1242
#: ../../../core-api/mm-api:106: include/linux/mm.h:990 include/linux/mm.h:1124
#: include/linux/mm.h:1157 include/linux/mm.h:1775 include/linux/mm.h:1927
#: include/linux/mm.h:1996 include/linux/mm.h:2049 include/linux/mm.h:2066
#: include/linux/mm.h:2143 ../../../core-api/mm-api:108:
#: include/linux/page_ref.h:77 ../../../core-api/mm-api:113: mm/rmap.c:777
#: mm/rmap.c:1385 ../../../core-api/mm-api:85: include/linux/pagemap.h:1001
#: include/linux/pagemap.h:1022
msgid "``const struct folio *folio``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:996
msgid "The folio containing this page."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:391 mm/page_alloc.c:418
#: mm/page_alloc.c:440 mm/page_alloc.c:490 mm/page_alloc.c:510
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1059
#: include/linux/page-flags.h:1087 include/linux/page-flags.h:1156
#: ../../../core-api/mm-api:106: include/linux/mm.h:1916
#: ../../../core-api/mm-api:113: mm/rmap.c:774 mm/rmap.c:1382
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:998
msgid "``const struct page *page``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:997
msgid "The page which we need the offset of."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:998
msgid ""
"For file pages, this is the offset from the beginning of the file in units "
"of PAGE_SIZE.  For anonymous pages, this is the offset from the beginning of "
"the anon_vma in units of PAGE_SIZE.  This will return nonsense for KSM pages."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1004
msgid ""
"Caller must have a reference on the folio or otherwise prevent it from being "
"split or freed."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1007
msgid "The offset in units of PAGE_SIZE."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1016
msgid "Returns the byte position of this folio in its file."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1083
msgid "Attempt to lock a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1084
msgid "The folio to attempt to lock."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1085
msgid ""
"Sometimes it is undesirable to wait for a folio to be unlocked (eg when the "
"locks are being taken in the wrong order, or if making progress through a "
"batch of folios is more important than processing them in order).  Usually "
"folio_lock() is the correct function to call."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1056
#: include/linux/page-flags.h:1084 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:1091
msgid "Any context."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1092
msgid "Whether the lock was successfully acquired."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1108
msgid "Lock this folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1109
#: include/linux/pagemap.h:1159
msgid "The folio to lock."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1110
msgid ""
"The folio lock protects against many things, probably more than it should.  "
"It is primarily held while a folio is being brought uptodate, either from "
"its backing file or from swap.  It is also held while a folio is being "
"truncated from its address_space, so holding the lock is sufficient to keep "
"folio->mapping stable."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1116
msgid ""
"The folio lock is also held while write() is modifying the page to provide "
"POSIX atomicity guarantees (as long as the write does not cross a page "
"boundary).  Other modifications to the data in the folio do not hold the "
"folio lock and can race with writes, eg DMA and stores to mapped pages."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1123
msgid ""
"May sleep.  If you need to acquire the locks of two or more folios, they "
"must be in order of ascending index, if they are in the same address_space.  "
"If they are in different address_spaces, acquire the lock of the folio which "
"belongs to the address_space which has the lowest address in memory first."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1137
msgid "Lock the folio containing this page."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:465 mm/page_alloc.c:530
#: mm/page_alloc.c:2070 mm/page_alloc.c:3105 mm/page_alloc.c:5245
#: ../../../core-api/mm-api:106: include/linux/mm.h:1212
#: include/linux/mm.h:1222 ../../../core-api/mm-api:113: mm/rmap.c:1495
#: mm/rmap.c:1519 mm/rmap.c:1632 mm/rmap.c:1649 mm/rmap.c:1669 mm/rmap.c:1794
#: mm/rmap.c:1811 mm/rmap.c:1831 ../../../core-api/mm-api:114: mm/migrate.c:106
#: mm/migrate.c:192 ../../../core-api/mm-api:122: mm/memcontrol.c:268
#: mm/memcontrol.c:2836 mm/memcontrol.c:2861 ../../../core-api/mm-api:85:
#: include/linux/pagemap.h:1143 ../../../core-api/mm-api:97: mm/memory.c:2319
msgid "``struct page *page``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1138
msgid "The page to lock."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1139
msgid ""
"See folio_lock() for a description of what the lock protects. This is a "
"legacy function and new code should probably use folio_lock() instead."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1144
msgid ""
"May sleep.  Pages in the same folio share a lock, so do not attempt to lock "
"two pages which share a folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1158
msgid "Lock this folio, interruptible by a fatal signal."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1160
msgid ""
"Attempts to lock the folio, like folio_lock(), except that the sleep to "
"acquire the lock is interruptible by a fatal signal."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1164
msgid "May sleep; see folio_lock()."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1165
msgid "0 if the lock was acquired; -EINTR if a fatal signal was received."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1278
msgid "check if range potentially needs writeback"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1282
msgid ""
"Find at least one page in the range supplied, usually used to check if "
"direct writing in this range will trigger a writeback. Used by O_DIRECT read/"
"write with IOCB_NOWAIT, to see if the caller needs to do "
"filemap_write_and_wait_range() before proceeding."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1288
msgid ""
"``true`` if the caller should do filemap_write_and_wait_range() before doing "
"O_DIRECT to a page in this range, ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1304
msgid "Describes a readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1314
msgid "``file``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1315
msgid ""
"The file, used primarily by network filesystems for authentication. May be "
"NULL if invoked internally by the filesystem."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:341
#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1316
msgid "``mapping``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1317
msgid "Readahead this filesystem object."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1317
msgid "``ra``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1318
msgid "File readahead state.  May be NULL."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1305
msgid ""
"A readahead request is for consecutive pages.  Filesystems which implement "
"the ->readahead method should call readahead_folio() or __readahead_batch() "
"in a loop and attempt to start reads into each folio in the request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1310
msgid ""
"Most of the fields in this struct are private and should be accessed by the "
"functions below."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1351
msgid "generic file readahead"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1352
#: include/linux/pagemap.h:1374
msgid "address_space which holds the pagecache and I/O vectors"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1354
#: include/linux/pagemap.h:1376
msgid "``struct file_ra_state *ra``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1353
#: include/linux/pagemap.h:1375
msgid "file_ra_state which holds the readahead state"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1354
#: include/linux/pagemap.h:1376
msgid "Used by the filesystem for authentication."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1355
msgid "Index of first page to be read."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1357
#: include/linux/pagemap.h:1379
msgid "``unsigned long req_count``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1356
#: include/linux/pagemap.h:1378
msgid "Total number of pages being read by the caller."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1357
msgid ""
"page_cache_sync_readahead() should be called when a cache miss happened: it "
"will submit the read.  The readahead logic may decide to piggyback more "
"pages onto the read request if access patterns suggest it will improve "
"performance."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1373
msgid "file readahead for marked pages"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1377
msgid "The folio which triggered the readahead call."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1379
msgid ""
"page_cache_async_readahead() should be called when a page is used which is "
"marked as PageReadahead; this is a marker to suggest that the application "
"has used up enough of the readahead window that we should start pulling in "
"more pages."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1415
msgid "Get the next folio to read."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1416
msgid "The current readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1418
msgid ""
"The folio is locked.  The caller should unlock the folio once all I/O to "
"that folio has completed."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1420
msgid "A pointer to the next folio, or ``NULL`` if we are done."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1460
msgid "The byte offset into the file of this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1466
#: include/linux/pagemap.h:1475 include/linux/pagemap.h:1484
#: include/linux/pagemap.h:1493 include/linux/pagemap.h:1502
msgid "``struct readahead_control *rac``"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1461
#: include/linux/pagemap.h:1470 include/linux/pagemap.h:1479
#: include/linux/pagemap.h:1488 include/linux/pagemap.h:1497
msgid "The readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1469
msgid "The number of bytes in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1478
msgid "The index of the first page in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1487
msgid "The number of pages in this readahead request."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1496
msgid "The number of bytes in the current batch."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1511
msgid "check if folio was truncated"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1512
msgid "the folio to check"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1513
msgid "the inode to check the folio against"
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1515
msgid ""
"the number of bytes in the folio up to EOF, or -EFAULT if the folio was "
"truncated."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1539
msgid "How many blocks fit in this folio."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1540
msgid "The inode which contains the blocks."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1542
msgid "If the block size is larger than the size of this folio, return zero."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1545
msgid ""
"The caller should hold a refcount on the folio to prevent it from being "
"split."
msgstr ""

#: ../../../core-api/mm-api:85: include/linux/pagemap.h:1547
msgid "The number of filesystem blocks covered by this folio."
msgstr ""

#: ../../../core-api/mm-api.rst:89
msgid "Memory pools"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:156
msgid "exit a mempool initialized with mempool_init()"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:162 mm/mempool.c:184
#: mm/mempool.c:240 mm/mempool.c:301 mm/mempool.c:381 mm/mempool.c:464
#: mm/mempool.c:498
msgid "``mempool_t *pool``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:157
msgid "pointer to the memory pool which was initialized with mempool_init()."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:159 mm/mempool.c:181
msgid ""
"Free all reserved elements in **pool** and **pool** itself.  This function "
"only sleeps if the free_fn() function sleeps."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:162
msgid ""
"May be called on a zeroed but uninitialized mempool (i.e. allocated with "
"kzalloc())."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:178
msgid "deallocate a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:179 mm/mempool.c:296
#: mm/mempool.c:376 mm/mempool.c:460 mm/mempool.c:497
msgid "pointer to the memory pool which was allocated via mempool_create()."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:234
msgid "initialize a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:235
msgid "pointer to the memory pool that should be initialized"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:237 mm/mempool.c:263
msgid "``int min_nr``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:236 mm/mempool.c:258
msgid ""
"the minimum number of elements guaranteed to be allocated for this pool."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:239 mm/mempool.c:261
msgid "``mempool_alloc_t *alloc_fn``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:238 mm/mempool.c:260
msgid "user-defined element-allocation function."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:240 mm/mempool.c:262
msgid "``mempool_free_t *free_fn``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:239 mm/mempool.c:261
msgid "user-defined element-freeing function."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:241 mm/mempool.c:263
msgid "``void *pool_data``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:240 mm/mempool.c:262
msgid "optional private data available to the user-defined functions."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:241
msgid ""
"Like mempool_create(), but initializes the pool in (i.e. embedded in another "
"structure)."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:257
msgid "create a memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:263
msgid "memory allocation flags"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:265
msgid "``int node_id``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:264
msgid "numa node to allocate on"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:265
msgid ""
"this function creates and allocates a guaranteed size, preallocated memory "
"pool. The pool can be used from the mempool_alloc() and mempool_free() "
"functions. This function might sleep. Both the alloc_fn() and the free_fn() "
"functions might sleep - as long as the mempool_alloc() function is not "
"called from IRQ contexts."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:272
msgid "pointer to the created memory pool object or ``NULL`` on error."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:295
msgid "resize an existing memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:299
msgid "``int new_min_nr``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:298
msgid ""
"the new minimum number of elements guaranteed to be allocated for this pool."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:300
msgid ""
"This function shrinks/grows the pool. In the case of growing, it cannot be "
"guaranteed that the pool will be grown to the new size immediately, but new "
"mempool_free() calls will refill it. This function may sleep."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:305
msgid ""
"Note, the caller must guarantee that no mempool_destroy is called while this "
"function is running. mempool_alloc() & mempool_free() might be called (eg. "
"from IRQ contexts) while this function executes."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:375
msgid "allocate an element from a specific memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:378
msgid "the usual allocation bitmask."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:379
msgid ""
"this function only sleeps if the alloc_fn() function sleeps or returns NULL. "
"Note that due to preallocation, this function *never* fails when called from "
"process contexts. (it might fail if called from an IRQ context.)"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:384
msgid "using __GFP_ZERO is not supported."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:386
msgid "pointer to the allocated element or ``NULL`` on error."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:458
msgid ""
"allocate an element from preallocated elements belonging to a specific "
"memory pool"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:462
msgid ""
"This function is similar to mempool_alloc, but it only attempts allocating "
"an element from the preallocated elements. It does not sleep and immediately "
"returns if no preallocated elements are available."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:467
msgid ""
"pointer to the allocated element or ``NULL`` if no elements are available."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:495
msgid "return an element to the pool."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:501
msgid "``void *element``"
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:496
msgid "pool element pointer."
msgstr ""

#: ../../../core-api/mm-api:91: mm/mempool.c:499
msgid "this function only sleeps if the free_fn() function sleeps."
msgstr ""

#: ../../../core-api/mm-api.rst:95
msgid "More Memory Management Functions"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2046
msgid "remove ptes mapping the vma"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2047
msgid "vm_area_struct holding ptes to be zapped"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1351 mm/rmap.c:1384 mm/rmap.c:1498
#: mm/rmap.c:1521 mm/rmap.c:1544 ../../../core-api/mm-api:97: mm/memory.c:2049
msgid "``unsigned long address``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2048
msgid "starting address of pages to zap"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2049
msgid "number of bytes to zap"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2050
msgid "This function only unmaps ptes assigned to VM_PFNMAP vmas."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2052
msgid "The entire address range must be fully contained within the vma."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2283
msgid "insert multiple pages into user vma, batching the pmd lock."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2284 mm/memory.c:2316
#: mm/memory.c:2398 mm/memory.c:2423 mm/memory.c:2494 mm/memory.c:2554
#: mm/memory.c:2881 mm/memory.c:2940
msgid "user vma to map to"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2450 mm/mempolicy.c:2901
#: ../../../core-api/mm-api:106: include/linux/mm.h:3426
#: ../../../core-api/mm-api:113: mm/rmap.c:2629 ../../../core-api/mm-api:115:
#: mm/mmap.c:313 mm/mmap.c:900 mm/mmap.c:918 ../../../core-api/mm-api:127:
#: mm/mapping_dirty_helpers.c:28 mm/mapping_dirty_helpers.c:80
#: ../../../core-api/mm-api:129: mm/percpu.c:2309 ../../../core-api/mm-api:97:
#: mm/memory.c:2286 mm/memory.c:2318 mm/memory.c:2496 mm/memory.c:2556
#: mm/memory.c:2883 mm/memory.c:6624 mm/memory.c:6891
msgid "``unsigned long addr``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2285
msgid "target start user address of these pages"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2286
msgid "source kernel pages"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2288
msgid "``unsigned long *num``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2287
msgid ""
"in: number of pages to map. out: number of pages that were *not* mapped. (0 "
"means all pages were successfully mapped)."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2289
msgid "Preferred over vm_insert_page() when inserting multiple pages."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2291
msgid ""
"In case of error, we may have mapped a subset of the provided pages. It is "
"the caller's responsibility to account for this case."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2294
msgid "The same restrictions apply as in vm_insert_page()."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2315
msgid "insert single page into user vma"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2317 mm/memory.c:2495
#: mm/memory.c:2555
msgid "target user address of this page"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2318
msgid "source kernel page"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2319
msgid ""
"This allows drivers to insert individual pages they've allocated into a user "
"vma. The zeropage is supported in some VMAs, see vm_mixed_zeropage_allowed()."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2323
msgid ""
"The page has to be a nice clean _individual_ kernel allocation. If you "
"allocate a compound page, you need to have marked it as such (__GFP_COMP), "
"or manually just split the page up yourself (see split_page())."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2328
msgid ""
"NOTE! Traditionally this was done with \"remap_pfn_range()\" which took an "
"arbitrary page protection parameter. This doesn't allow that. Your vma "
"protection will have to be set up correctly, which means that if you want a "
"shared writable mapping, you'd better ask for a shared writable mapping!"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2334
msgid "The page does not need to be reserved."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2336
msgid ""
"Usually this function is called from f_op->mmap() handler under mm-"
">mmap_lock write-lock, so it can change vma->vm_flags. Caller must set "
"VM_MIXEDMAP on vma if it wants to call this function from other places, for "
"example from page-fault handler."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2397
msgid "maps range of kernel pages starts with non zero offset"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2399 mm/memory.c:2424
msgid "pointer to array of source kernel pages"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2401 mm/memory.c:2426
msgid "``unsigned long num``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2400 mm/memory.c:2425
msgid "number of pages in page array"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2401
msgid ""
"Maps an object consisting of **num** pages, catering for the user's "
"requested vm_pgoff"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2404
msgid ""
"If we fail to insert any page into the vma, the function will return "
"immediately leaving any previously inserted pages present.  Callers from the "
"mmap handler may immediately return the error as their caller will destroy "
"the vma, removing any successfully inserted pages. Other callers should make "
"their own arrangements for calling unmap_region()."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2411 mm/memory.c:2431
msgid "Process context. Called by mmap handlers."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2412 mm/memory.c:2432
msgid "0 on success and error code otherwise."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2422
msgid "map range of kernel pages starts with zero offset"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2426
msgid ""
"Similar to vm_map_pages(), except that it explicitly sets the offset to 0. "
"This function is intended for the drivers that did not consider vm_pgoff."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2493
msgid "insert single pfn into user vma with specified pgprot"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:389 mm/page_alloc.c:415
#: mm/page_alloc.c:437 mm/page_alloc.c:463 mm/page_alloc.c:487
#: mm/page_alloc.c:507 ../../../core-api/mm-api:109:
#: include/linux/mmzone.h:2141 ../../../core-api/mm-api:113: mm/rmap.c:1173
#: mm/rmap.c:1219 ../../../core-api/mm-api:118: mm/memremap.c:401
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:589
#: ../../../core-api/mm-api:135: mm/huge_memory.c:1438 mm/huge_memory.c:1577
#: ../../../core-api/mm-api:97: mm/memory.c:2497 mm/memory.c:2557
#: mm/memory.c:2884
msgid "``unsigned long pfn``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2496 mm/memory.c:2556
msgid "source kernel pfn"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1797
#: include/linux/mm.h:1813 include/linux/mm.h:1829 ../../../core-api/mm-api:97:
#: mm/memory.c:2498
msgid "``pgprot_t pgprot``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2497
msgid "pgprot flags for the inserted page"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2498
msgid ""
"This is exactly like vmf_insert_pfn(), except that it allows drivers to "
"override pgprot on a per-page basis."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2501
msgid ""
"This only makes sense for IO mappings, and it makes no sense for COW "
"mappings.  In general, using multiple vmas is preferable; "
"vmf_insert_pfn_prot should only be used if using multiple VMAs is "
"impractical."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2506
msgid ""
"pgprot typically only differs from **vma->vm_page_prot** when drivers set "
"caching- and encryption bits different than those of **vma->vm_page_prot**, "
"because the caching- or encryption mode may not be known at mmap() time."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2510
msgid ""
"This is ok as long as **vma->vm_page_prot** is not used by the core vm to "
"set caching and encryption bits for those vmas (except for COW pages). This "
"is ensured by core vm only modifying these page table entries using "
"functions that don't touch caching- or encryption bits, using pte_modify() "
"if needed. (See for example mprotect())."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2516
msgid ""
"Also when new page-table entries are created, this is only done using the "
"fault() callback, and never using the value of vma->vm_page_prot, except for "
"page-table entries that point to anonymous pages as the result of COW."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2522 mm/memory.c:2569
msgid "Process context.  May allocate using ``GFP_KERNEL``."
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1442 mm/huge_memory.c:1581
#: mm/huge_memory.c:1623 ../../../core-api/mm-api:97: mm/memory.c:2523
#: mm/memory.c:2570
msgid "vm_fault_t value."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2553
msgid "insert single pfn into user vma"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2557
msgid ""
"Similar to vm_insert_page, this allows drivers to insert individual pages "
"they've allocated into a user vma. Same comments apply."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2560
msgid ""
"This function should only be called from a vm_ops->fault handler, and in "
"that case the handler should return the result of this function."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2563
msgid "vma cannot be a COW mapping."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2565
msgid ""
"As this is called only for pages that do not currently exist, we do not need "
"to flush old virtual caches or the TLB."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2880
msgid "remap kernel memory to userspace"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2882
msgid "target page aligned user address to start at"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2883
msgid "page frame number of kernel physical memory address"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2884
msgid "size of mapping area"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2885
msgid "page protection flags for this mapping"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2887
msgid "this is only safe if the mm semaphore is held when called."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2939
msgid "remap memory to userspace"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2942
msgid "``phys_addr_t start``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2941
msgid "start of the physical memory to be mapped"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:316 ../../../core-api/mm-api:97:
#: mm/memory.c:2943
msgid "``unsigned long len``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1064 ../../../core-api/mm-api:97:
#: mm/memory.c:2942
msgid "size of area"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2943
msgid ""
"This is a simplified io_remap_pfn_range() for common driver use. The driver "
"just needs to give us the physical memory range to be mapped, we'll figure "
"out the rest from the vma information."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:2947
msgid ""
"NOTE! Some drivers might want to tweak vma->vm_page_prot first to get "
"whatever write-combining details or similar."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4079
msgid "Unmap pages from processes."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4080
msgid "The address space containing pages to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4081
msgid "Index of first page to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:254
#: mm/mapping_dirty_helpers.c:283 ../../../core-api/mm-api:97: mm/memory.c:4083
msgid "``pgoff_t nr``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4082
msgid "Number of pages to be unmapped.  0 to unmap to end of file."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4084
msgid "``bool even_cows``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4083
msgid "Whether to unmap even private COWed pages."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4084
msgid ""
"Unmap the pages in this address space from any userspace process which has "
"them mmaped.  Generally, you want to remove COWed pages as well when a file "
"is being truncated, but not when invalidating pages from the page cache."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4110
msgid ""
"unmap the portion of all mmaps in the specified address_space corresponding "
"to the specified byte range in the underlying file."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4114
msgid "the address space containing mmaps to be unmapped."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4116
msgid "``loff_t const holebegin``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4115
msgid ""
"byte in first page to unmap, relative to the start of the underlying file.  "
"This will be rounded down to a PAGE_SIZE boundary.  Note that this is "
"different from truncate_pagecache(), which must keep the partial page.  In "
"contrast, we must get rid of partial pages."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4121
msgid "``loff_t const holelen``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4120
msgid ""
"size of prospective hole in bytes.  This will be rounded up to a PAGE_SIZE "
"boundary.  A holelen of zero truncates to the end of the file."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4124
msgid "``int even_cows``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:4123
msgid ""
"1 when truncating a file, unmap even private COWed pages; but 0 when "
"invalidating pagecache, don't throw away private data."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6497
msgid "Look up a pfn mapping at a user virtual address"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6503 mm/memory.c:6610
msgid "``struct follow_pfnmap_args *args``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6498 mm/memory.c:6605
msgid "Pointer to struct **follow_pfnmap_args**"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6499
msgid ""
"The caller needs to setup args->vma and args->address to point to the "
"virtual address as the target of such lookup.  On a successful return, the "
"results will be put into other output fields."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6503
msgid ""
"After the caller finished using the fields, the caller must invoke another "
"follow_pfnmap_end() to proper releases the locks and resources of such look "
"up request."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6507
msgid ""
"During the start() and end() calls, the results in **args** will be valid as "
"proper locks will be held.  After the end() is called, all the fields in "
"**follow_pfnmap_args** will be invalid to be further accessed.  Further use "
"of such information after end() may require proper synchronizations by the "
"caller with page table updates, otherwise it can create a security bug."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6514
msgid ""
"If the PTE maps a refcounted page, callers are responsible to protect "
"against invalidation with MMU notifiers; otherwise access to the PFN at a "
"later point in time can trigger use-after-free."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6518
msgid ""
"Only IO mappings and raw PFN mappings are allowed.  The mmap semaphore "
"should be taken for read, and the mmap semaphore cannot be released before "
"the end() is invoked."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6522
msgid "This function must not be used to modify PTE content."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6525
msgid "zero on success, negative otherwise."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6604
msgid "End a follow_pfnmap_start() process"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6606
msgid ""
"Must be used in pair of follow_pfnmap_start().  See the start() function "
"above for more information."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6621
msgid "generic implementation for iomem mmap access"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6622
msgid "the vma to access"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6623
msgid "userspace address, not relative offset within **vma**"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6625 mm/memory.c:6892
msgid "``void *buf``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6624
msgid "buffer to read/write"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6626 mm/memory.c:6893
msgid "``int len``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6625
msgid "length of transfer"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6627
msgid "``int write``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6626
msgid "set to FOLL_WRITE when writing, otherwise reading"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6627
msgid ""
"This is a generic implementation for :c:type:`vm_operations_struct.access "
"<vm_operations_struct>` for an iomem mapping. This callback is used by "
"access_process_vm() when the **vma** is not page based."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6888
msgid "copy a string from another process's address space."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6894
msgid "``struct task_struct *tsk``"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6889
msgid "the task of the target address space"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6890
msgid "start address to read from"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6891
msgid "destination buffer"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6892
msgid "number of bytes to copy"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6893
msgid "flags modifying lookup behaviour"
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6894
msgid "The caller must hold a reference on **mm**."
msgstr ""

#: ../../../core-api/mm-api:97: mm/memory.c:6897
msgid ""
"number of bytes copied from **addr** (source) to **buf** (destination); not "
"including the trailing NUL. Always guaranteed to leave NUL-terminated "
"buffer. On any error, return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:385
msgid ""
"Return the requested group of flags for a pageblock_nr_pages block of pages"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:387 mm/page_alloc.c:413
#: mm/page_alloc.c:435 mm/page_alloc.c:461 mm/page_alloc.c:485
#: mm/page_alloc.c:505 mm/page_alloc.c:525
msgid "The page within the block of interest"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:388 mm/page_alloc.c:414
#: mm/page_alloc.c:436 mm/page_alloc.c:462 mm/page_alloc.c:486
#: mm/page_alloc.c:506
msgid "The target page frame number"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:390 mm/page_alloc.c:465
#: ../../../core-api/mm-api:105: include/linux/page-flags.h:759
msgid "``unsigned long mask``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:389 mm/page_alloc.c:464
msgid "mask of bits that the caller is interested in"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:391
msgid "pageblock_bits flags"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:412
msgid "Check if a standalone bit of a pageblock is set"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:416 mm/page_alloc.c:488
#: mm/page_alloc.c:508
msgid "``enum pageblock_bits pb_bit``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:415
msgid "pageblock bit to check"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:417
msgid "true if the bit is set, otherwise false"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:434
msgid "Return the migratetype of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:438
msgid "The migratetype of the pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:439
msgid ""
"Use get_pfnblock_migratetype() if caller already has both **page** and "
"**pfn** to save a call to page_to_pfn()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:459
msgid ""
"Set the requested group of flags for a pageblock_nr_pages block of pages"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:463
msgid "The flags to set"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:484
msgid "Set a standalone bit of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:487
msgid "pageblock bit to set"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:504
msgid "Clear a standalone bit of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:507
msgid "pageblock bit to clear"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:524
msgid "Set the migratetype of a pageblock"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:527
msgid "``enum migratetype migratetype``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:526
msgid "migratetype to set"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2067
msgid "move free pages in block for page isolation"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2073
#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1625
msgid "``struct zone *zone``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2068
msgid "the zone"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2069
msgid "the pageblock page"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2071
msgid "``bool isolate``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2070
msgid "to isolate the given pageblock or unisolate it"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2071
msgid ""
"This is similar to move_freepages_block(), but handles the special case "
"encountered in page isolation, where the block of interest might be part of "
"a larger buddy spanning multiple pageblocks."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2075
msgid ""
"Unlike the regular page allocator path, which moves pages while stealing "
"buddies off the freelist, page isolation is interested in arbitrary pfn "
"ranges that may have overlapping buddies on both ends."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2079
msgid ""
"This function handles that. Straddling buddies are split into individual "
"pageblocks. Only the block of interest is moved."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:2082
msgid "Returns ``true`` if pages could be moved, ``false`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3099
msgid "Return a now-isolated page back where we got it"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3100
msgid "Page that was isolated"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3102 mm/page_alloc.c:5242
#: mm/page_alloc.c:7485 ../../../core-api/mm-api:101: mm/mempolicy.c:2365
#: mm/mempolicy.c:2495 ../../../core-api/mm-api:106: include/linux/mm.h:2873
msgid "``unsigned int order``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3101
msgid "Order of the isolated page"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3103
msgid "``int mt``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3102
msgid "The page's pageblock's migratetype"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:3103
msgid ""
"This function is meant to return a page pulled from the free lists via "
"__isolate_free_page back to the free lists they were pulled from."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5239
msgid "Free pages allocated with alloc_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5240
msgid "The page pointer returned from alloc_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5241
msgid "The order of the allocation."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5242
msgid ""
"This function can free multi-page allocations that are not compound pages.  "
"It does not check that the **order** passed in matches that of the "
"allocation, so it is easy to leak memory.  Freeing more memory than was "
"allocated will probably emit a warning."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5247
msgid ""
"If the last reference to this page is speculative, it will be released by "
"put_page() which only frees the first page of a non-compound allocation.  To "
"prevent the remaining pages from being leaked, we free the subsequent pages "
"here.  If you want to use the page's reference count to decide when to free "
"the allocation, you should allocate a compound page, and use put_page() "
"instead of __free_pages()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5255
msgid ""
"May be called in interrupt context or while holding a normal spinlock, but "
"not in NMI context or while holding a raw spinlock."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5305
msgid "allocate an exact number physically-contiguous pages."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5306 mm/page_alloc.c:5336
msgid "the number of bytes to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5307 mm/page_alloc.c:5337
msgid "GFP flags for the allocation, must not contain __GFP_COMP"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5308
msgid ""
"This function is similar to alloc_pages(), except that it allocates the "
"minimum number of pages to satisfy the request.  alloc_pages() can only "
"allocate memory in power-of-two pages."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5312
msgid "This function is also limited by MAX_PAGE_ORDER."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5314
msgid ""
"Memory allocated by this function must be released by free_pages_exact()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5317 mm/page_alloc.c:5342
msgid "pointer to the allocated area or ``NULL`` in case of error."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5333
msgid "allocate an exact number of physically-contiguous pages on a node."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5339 mm/page_alloc.c:7017
#: mm/page_alloc.c:7488 ../../../core-api/mm-api:101: mm/mempolicy.c:2368
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2171
msgid "``int nid``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5335
msgid "the preferred node ID where memory should be allocated"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5338
msgid ""
"Like alloc_pages_exact(), but try to allocate on node nid first before "
"falling back."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5359
msgid "release memory allocated via alloc_pages_exact()"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5365
msgid "``void *virt``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5360
msgid "the value returned by alloc_pages_exact."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5361
msgid "size of allocation, same value as passed to alloc_pages_exact()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5362
msgid "Release the memory allocated by a previous call to alloc_pages_exact."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5378 mm/page_alloc.c:5410
msgid "count number of pages beyond high watermark"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5384
msgid "``int offset``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5379
msgid "The zone index of the highest zone"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5380
msgid ""
"nr_free_zone_pages() counts the number of pages which are beyond the high "
"watermark within all zones at or below a given zone index.  For each zone, "
"the number of pages is calculated as:"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5384
msgid "nr_free_zone_pages = managed_pages - high_pages"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5387
msgid "number of pages beyond high watermark."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5411
msgid ""
"nr_free_buffer_pages() counts the number of pages which are beyond the high "
"watermark within ZONE_DMA and ZONE_NORMAL."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5415
msgid "number of pages beyond high watermark within ZONE_DMA and ZONE_NORMAL."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5486
msgid "find the next node that should appear in a given node's fallback list"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5487
msgid "node whose fallback list we're appending"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5489
msgid "``nodemask_t *used_node_mask``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5488
msgid "nodemask_t of already used nodes"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5489
msgid ""
"We use a number of factors to determine which is the next node that should "
"appear on a given node's fallback list.  The node should not have appeared "
"already in **node**'s fallback list, and it should be the next closest node "
"according to the distance array (which contains arbitrary distance values "
"from each node to each node in the system), and should also prefer nodes "
"with no CPUs, since presumably they'll have very little allocation pressure "
"on them otherwise."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:5498
msgid "node id of the found node or ``NUMA_NO_NODE`` if no node is found."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6361
msgid ""
"called when min_free_kbytes changes or when memory is hot-{added|removed}"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6362
msgid ""
"Ensures that the watermark[min,low,high] values for each zone are set "
"correctly with respect to min_free_kbytes."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6818
msgid "tries to allocate given range of pages"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6819
msgid "start PFN to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6821
#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:29
#: mm/mapping_dirty_helpers.c:81
msgid "``unsigned long end``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6820
msgid "one-past-the-last PFN to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6822
msgid "``acr_flags_t alloc_flags``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6821
msgid "allocation information"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6822
msgid ""
"GFP mask. Node/zone/placement hints are ignored; only some action and "
"reclaim modifiers are supported. Reclaim modifiers control allocation "
"behavior during compaction/migration/reclaim."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6825
msgid ""
"The PFN range does not have to be pageblock aligned. The PFN range must "
"belong to a single zone."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6828
msgid ""
"The first thing this routine does is attempt to MIGRATE_ISOLATE all "
"pageblocks in the range.  Once isolated, the pageblocks should not be "
"modified by others."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:6833
msgid ""
"zero on success or negative error code.  On success all pages which PFN is "
"in [start, end) are allocated for the caller and need to be freed with "
"free_contig_range()."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7011
msgid "tries to find and allocate contiguous range of pages"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7017
#: ../../../core-api/mm-api:113: mm/rmap.c:1174 mm/rmap.c:1219 mm/rmap.c:2866
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:586
msgid "``unsigned long nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7012
msgid "Number of contiguous pages to allocate"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7013
msgid ""
"GFP mask. Node/zone/placement hints limit the search; only some action and "
"reclaim modifiers are supported. Reclaim modifiers control allocation "
"behavior during compaction/migration/reclaim."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7016
msgid "Target node"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7018
msgid "``nodemask_t *nodemask``"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7017
msgid "Mask for other possible nodes"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7018
msgid ""
"This routine is a wrapper around alloc_contig_range(). It scans over zones "
"on an applicable zonelist to find a contiguous pfn range which can then be "
"tried for allocation with alloc_contig_range(). This routine is intended for "
"allocation requests which can not be fulfilled with the buddy allocator."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7023
msgid ""
"The allocated memory is always aligned to a page boundary. If nr_pages is a "
"power of two, then allocated range is also guaranteed to be aligned to same "
"nr_pages (e.g. 1GB request would be aligned to 1GB)."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7027
msgid ""
"Allocated pages can be freed with free_contig_range() or by manually calling "
"__free_page() on each allocated page."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7031
msgid "pointer to contiguous pages on success, or NULL if not successful."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7482
msgid "opportunistic reentrant allocation from any context"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7483
msgid "node to allocate from"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7484
msgid "allocation order size"
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7485
msgid ""
"Allocates pages of a given order from the given node. This is safe to call "
"from any context (from atomic, NMI, and also reentrant allocator -> "
"tracepoint -> alloc_pages_nolock_noprof). Allocation is best effort and to "
"be expected to fail easily so nobody should rely on the success. Failures "
"are not reported via warn_alloc(). See always fail conditions below."
msgstr ""

#: ../../../core-api/mm-api:100: mm/page_alloc.c:7493
msgid ""
"allocated page or NULL on failure. NULL does not mean EBUSY or EAGAIN. It "
"means ENOMEM. There is no reason to call it again and expect !NULL."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:277
msgid "Find nearest node by state"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:278
msgid "Node id to start the search"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:280
msgid "``unsigned int state``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:279
msgid "State to filter the search"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:280
msgid "Lookup the closest node by distance if **nid** is not in state."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:283
msgid "this **node** if it is in state, otherwise the closest node by distance"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:309
msgid "Find the node in **mask** at the nearest distance from **node**."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:312
msgid "a valid node ID to start the search from."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:314
msgid "``nodemask_t *mask``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:313
msgid "a pointer to a nodemask representing the allowed nodes."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:314
msgid ""
"This function iterates over all nodes in **mask** and calculates the "
"distance from the starting **node**, then it returns the node ID that is the "
"closest to **node**, or MAX_NUMNODES if no node is found."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:318
msgid ""
"Note that **node** must be a valid node ID usable with node_distance(), "
"providing an invalid node ID (e.g., NUMA_NO_NODE) may result in crashes or "
"unexpected behavior."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2362
msgid "Allocate pages according to NUMA mempolicy."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2363 mm/mempolicy.c:2446
#: mm/mempolicy.c:2493
msgid "GFP flags."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2364
msgid "Order of the page allocation."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2366 mm/mempolicy.c:3471
msgid "``struct mempolicy *pol``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2365
msgid "Pointer to the NUMA mempolicy."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2367
msgid "``pgoff_t ilx``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2366
msgid "Index for interleave mempolicy (also distinguishes alloc_pages())."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2367
msgid "Preferred node (usually numa_node_id() but **mpol** may override it)."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2369 mm/mempolicy.c:2503
msgid "The page on success or NULL if allocation fails."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2445
msgid "Allocate a folio for a VMA."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2448
#: ../../../core-api/mm-api:122: mm/memcontrol.c:2834 mm/memcontrol.c:2858
msgid "``int order``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2447
msgid "Order of the folio."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2448
msgid "Pointer to VMA."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2449
msgid "Virtual address of the allocation.  Must be inside **vma**."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2450
msgid ""
"Allocate a folio for a specific address in **vma**, using the appropriate "
"NUMA policy.  The caller must hold the mmap_lock of the mm_struct of the VMA "
"to prevent it from going away.  Should be used for all allocations for "
"folios that will be mapped into user space, excepting hugetlbfs, and "
"excepting where direct use of folio_alloc_mpol() is more appropriate."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2457
msgid "The folio on success or NULL if allocation fails."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2492
msgid "Allocate pages."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2494
msgid "Power of two of number of pages to allocate."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2495
msgid ""
"Allocate 1 << **order** contiguous pages.  The physical address of the first "
"page is naturally aligned (eg an order-3 allocation will be aligned to a "
"multiple of 8 * PAGE_SIZE bytes).  The NUMA policy of the current process is "
"honoured when in process context."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2501
msgid ""
"Can be called from any context, providing the appropriate GFP flags are used."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2896
msgid "check whether current folio node is valid in policy"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2898
msgid "folio to be checked"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2899
msgid "structure describing the fault"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2900
msgid ""
"virtual address in **vma** for shared policy lookup and interleave policy"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2901
msgid ""
"Lookup current policy node id for vma,addr and \"compare to\" folio's node "
"id.  Policy determination \"mimics\" alloc_page_vma(). Called from fault "
"path where we know the vma and faulting address."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:2906
msgid ""
"NUMA_NO_NODE if the page is in a node that is valid for this policy, or a "
"suitable node ID to allocate a replacement folio from."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3126
msgid "initialize shared policy for inode"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3132
msgid "``struct shared_policy *sp``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3127
msgid "pointer to inode shared policy"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3129
msgid "``struct mempolicy *mpol``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3128
msgid "struct mempolicy to install"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3129
msgid ""
"Install non-NULL **mpol** in inode's shared policy rb-tree. On entry, the "
"current task has a reference on a non-NULL **mpol**. This must be released "
"on exit. This is called at get_inode() calls and we can use GFP_KERNEL."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3332
msgid "parse string to mempolicy, for tmpfs mpol mount option."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3338
msgid "``char *str``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3333
msgid "string containing mempolicy to parse"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3335
msgid "``struct mempolicy **mpol``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3334
msgid "pointer to struct mempolicy pointer, returned on success."
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3335
msgid "Format of input:"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3336
msgid "<mode>[=<flags>][:<nodelist>]"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3339
msgid "``0`` on success, else ``1``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3467
msgid "format a mempolicy structure for printing"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3473
msgid "``char *buffer``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3468
msgid "to contain formatted mempolicy string"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3470
msgid "``int maxlen``"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3469
msgid "length of **buffer**"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3470
msgid "pointer to mempolicy to be formatted"
msgstr ""

#: ../../../core-api/mm-api:101: mm/mempolicy.c:3471
msgid ""
"Convert **pol** into a string.  If **buffer** is too short, truncate the "
"string. Recommend a **maxlen** of at least 51 for the longest mode, "
"\"weighted interleave\", plus the longest flag flags, \"relative|"
"balancing\", and to display at least a few node ids."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:337
msgid "Represents a contiguous set of bytes."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:339
msgid "Identical to the page flags."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1
msgid "``{unnamed_union}``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:2
msgid "anonymous"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:339
msgid "``lru``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:340
msgid "Least Recently Used list; tracks how recently this folio was used."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:340
msgid "``mlock_count``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:341
msgid "Number of times this folio has been pinned by mlock()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:354
msgid "``pgmap``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:355
msgid "Metadata for ZONE_DEVICE mappings"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:342
msgid ""
"The file this page belongs to, or refers to the anon_vma for anonymous "
"memory."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:343
msgid "``index``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:344
msgid ""
"Offset within the file, in units of pages.  For anonymous memory, this is "
"the index from the beginning of the mmap."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:345
msgid "``share``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:346
msgid ""
"number of DAX mappings that reference this folio. See dax_associate_entry."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:347
msgid "``private``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:348
msgid "Filesystem per-folio data (see folio_attach_private())."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:348
msgid "``swap``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:349
msgid "Used for swp_entry_t if folio_test_swapcache()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:349
msgid "``_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:350
msgid ""
"Do not access this member directly.  Use folio_mapcount() to find out how "
"many times this folio is mapped by userspace."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:351
msgid "``_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:352
msgid ""
"Do not access this member directly.  Use folio_ref_count() to find how many "
"references there are to this folio."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:353
msgid "``memcg_data``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:354
msgid "Memory Control Group data."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:370
msgid "``_unused_slab_obj_exts``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:371
msgid "Placeholder to match obj_exts in struct slab."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:355
msgid "``virtual``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:356
msgid "Virtual address in the kernel direct map."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:356
msgid "``_last_cpupid``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:357
msgid "IDs of last CPU and last process that accessed the folio."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:358
msgid "``_large_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:359
msgid "Do not use directly, call folio_mapcount()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:359
msgid "``_nr_pages_mapped``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:360
msgid "Do not use outside of rmap and debug code."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:357
msgid "``_entire_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:358
msgid "Do not use directly, call folio_entire_mapcount()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:360
msgid "``_pincount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:361
msgid "Do not use directly, call folio_maybe_dma_pinned()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:364
msgid "``_mm_id_mapcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:363
#: include/linux/mm_types.h:364 include/linux/mm_types.h:365
msgid "Do not use outside of rmap code."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:362
msgid "``_mm_id``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:363
msgid "``_mm_ids``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:361
msgid "``_nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:362
msgid "Do not use directly, call folio_nr_pages()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:369
msgid "``_deferred_list``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:370
msgid "Folios to be split under memory pressure."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:365
msgid "``_hugetlb_subpool``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:366
msgid "Do not use directly, use accessor in hugetlb.h."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:366
msgid "``_hugetlb_cgroup``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:367
#: include/linux/mm_types.h:368
msgid "Do not use directly, use accessor in hugetlb_cgroup.h."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:367
msgid "``_hugetlb_cgroup_rsvd``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:368
msgid "``_hugetlb_hwpoison``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:369
msgid "Do not use directly, call raw_hwp_list_head()."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:371
msgid ""
"A folio is a physically, virtually and logically contiguous set of bytes.  "
"It is a power-of-two in size, and it is aligned to that same power-of-two.  "
"It is at least as large as ``PAGE_SIZE``.  If it is in the page cache, it is "
"at a file offset which is a multiple of that power-of-two.  It may be mapped "
"into userspace at an address which is at an arbitrary page offset, but its "
"kernel virtual address is aligned to its size."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:527
msgid "Memory descriptor for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:528
msgid "``__page_flags``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:529
msgid "Same as page flags. Powerpc only."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:529
msgid "``pt_rcu_head``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:530
msgid "For freeing page table pages."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:530
msgid "``pt_list``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:531
msgid ""
"List of used page tables. Used for s390 gmap shadow pages (which are not "
"linked into the user page tables) and x86 pgds."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1
msgid "``{unnamed_struct}``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:533
msgid "``_pt_pad_1``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:534
msgid "Padding that aliases with page's compound head."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:534
msgid "``pmd_huge_pte``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:535
msgid "Protected by ptdesc->ptl, used for THPs."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:535
msgid "``__page_mapping``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:536
msgid "Aliases with page->mapping. Unused for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:536
msgid "``pt_index``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:537
msgid "Used for s390 gmap."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:537
msgid "``pt_mm``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:538
msgid "Used for x86 pgds."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:538
msgid "``pt_frag_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:539
msgid "For fragmented page table tracking. Powerpc only."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:539
msgid "``pt_share_count``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:540
msgid "Used for HugeTLB PMD page table share count."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:540
msgid "``_pt_pad_2``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:541
msgid "Padding to ensure proper alignment."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:541
msgid "``ptl``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:542
msgid "Lock for the page table."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:542
msgid "``__page_type``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:543
msgid "Same as page->page_type. Unused for page tables."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:543
msgid "``__page_refcount``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:544
msgid "Same as page refcount."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:544
msgid "``pt_memcg_data``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:545
msgid "Memcg data. Tracked for page tables here."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:545
msgid ""
"This struct overlays struct page for now. Do not modify without a good "
"understanding of the issues."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1452
msgid "Return type for page fault handlers."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1453
msgid "Page fault handlers return a bitmask of ``VM_FAULT`` values."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1459
msgid ""
"Page fault handlers return a bitmask of these values to tell the core VM "
"what happened when handling the fault. Used to decide whether a process gets "
"delivered SIGBUS or just gets major/minor fault counters bumped up."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1463
#: include/linux/mm_types.h:1564
msgid "**Constants**"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1465
msgid "``VM_FAULT_OOM``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1466
msgid "Out Of Memory"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1468
msgid "``VM_FAULT_SIGBUS``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1469
msgid "Bad access"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1471
msgid "``VM_FAULT_MAJOR``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1472
msgid "Page read from storage"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1474
msgid "``VM_FAULT_HWPOISON``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1475
msgid "Hit poisoned small page"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1477
msgid "``VM_FAULT_HWPOISON_LARGE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1478
msgid "Hit poisoned large page. Index encoded in upper bits"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1481
msgid "``VM_FAULT_SIGSEGV``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1482
msgid "segmentation fault"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1484
msgid "``VM_FAULT_NOPAGE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1485
msgid "->fault installed the pte, not return page"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1487
msgid "``VM_FAULT_LOCKED``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1488
msgid "->fault locked the returned page"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1490
msgid "``VM_FAULT_RETRY``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1491
msgid "->fault blocked, must retry"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1493
msgid "``VM_FAULT_FALLBACK``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1494
msgid "huge page fault failed, fall back to small"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1496
msgid "``VM_FAULT_DONE_COW``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1497
msgid "->fault has fully handled COW"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1499
msgid "``VM_FAULT_NEEDDSYNC``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1500
msgid ""
"->fault did not modify page tables and needs fsync() to complete (for "
"synchronous page faults in DAX)"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1504
msgid "``VM_FAULT_COMPLETED``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1505
msgid "->fault completed, meanwhile mmap lock released"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1507
msgid "``VM_FAULT_HINDEX_MASK``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1508
msgid "mask HINDEX value"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1560
msgid "Fault flag definitions."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1566
msgid "``FAULT_FLAG_WRITE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1567
msgid "Fault was a write fault."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1569
msgid "``FAULT_FLAG_MKWRITE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1570
msgid "Fault was mkwrite of existing PTE."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1572
msgid "``FAULT_FLAG_ALLOW_RETRY``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1573
msgid "Allow to retry the fault if blocked."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1575
msgid "``FAULT_FLAG_RETRY_NOWAIT``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1576
msgid "Don't drop mmap_lock and wait when retrying."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1578
msgid "``FAULT_FLAG_KILLABLE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1579
msgid "The fault task is in SIGKILL killable region."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1581
msgid "``FAULT_FLAG_TRIED``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1582
msgid "The fault has been tried once."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1584
msgid "``FAULT_FLAG_USER``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1585
msgid "The fault originated in userspace."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1587
msgid "``FAULT_FLAG_REMOTE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1588
msgid "The fault is not for current task/mm."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1590
msgid "``FAULT_FLAG_INSTRUCTION``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1591
msgid "The fault was during an instruction fetch."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1593
msgid "``FAULT_FLAG_INTERRUPTIBLE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1594
msgid "The fault can be interrupted by non-fatal signals."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1596
msgid "``FAULT_FLAG_UNSHARE``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1597
msgid ""
"The fault is an unsharing request to break COW in a COW mapping, making sure "
"that an exclusive anon page is mapped after the fault."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1601
msgid "``FAULT_FLAG_ORIG_PTE_VALID``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1602
msgid ""
"whether the fault has vmf->orig_pte cached. We should only access orig_pte "
"if this flag set."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1605
msgid "``FAULT_FLAG_VMA_LOCK``"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1606
msgid "The fault is handled under VMA lock."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1577
msgid ""
"About **FAULT_FLAG_ALLOW_RETRY** and **FAULT_FLAG_TRIED**: we can specify "
"whether we would allow page faults to retry by specifying these two fault "
"flags correctly.  Currently there can be three legal combinations:"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1581
msgid "ALLOW_RETRY and !TRIED:  this means the page fault allows retry, and"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1582
msgid "this is the first try"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1584
msgid "ALLOW_RETRY and TRIED:   this means the page fault allows retry, and"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1585
msgid "we've already tried at least once"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1587
msgid "!ALLOW_RETRY and !TRIED: this means the page fault does not allow retry"
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1589
msgid ""
"The unlisted combination (!ALLOW_RETRY && TRIED) is illegal and should never "
"be used.  Note that page faults can be allowed to retry for multiple times, "
"in which case we'll have an initial fault with flags (a) then later on "
"continuous faults with flags (b).  We should always try to detect pending "
"signals before a retry to make sure the continuous page faults can still be "
"interrupted if necessary."
msgstr ""

#: ../../../core-api/mm-api:102: include/linux/mm_types.h:1596
msgid ""
"The combination FAULT_FLAG_WRITE|FAULT_FLAG_UNSHARE is illegal. "
"FAULT_FLAG_UNSHARE is ignored and treated like an ordinary read fault when "
"applied to mappings that are not COW mappings."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:14
msgid "Should the folio be on a file LRU or anon LRU?"
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:15
#: include/linux/mm_inline.h:82 ../../../core-api/mm-api:105:
#: include/linux/page-flags.h:858 ../../../core-api/mm-api:113: mm/rmap.c:976
msgid "The folio to test."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:16
msgid ""
"We would like to get this info without a page flag, but the state needs to "
"survive until the folio is last deleted from the LRU, which could be as far "
"down as __page_cache_release."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:21
msgid ""
"An integer (not a boolean!) used to sort a folio onto the right LRU list and "
"to account folios correctly. 1 if **folio** is a regular filesystem backed "
"page cache folio or a lazily freed anonymous folio (e.g. via MADV_FREE). 0 "
"if **folio** is a normal anonymous folio, a tmpfs folio or otherwise ram or "
"swap backed folio."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:63
msgid "Clear page lru flags before releasing a page."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:64
msgid "The folio that was on lru and now has a zero reference."
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:81
msgid "Which LRU list should a folio be on?"
msgstr ""

#: ../../../core-api/mm-api:104: include/linux/mm_inline.h:84
msgid ""
"The LRU list a folio should be on, as an index into the array of LRU lists."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:296
msgid "``page_folio (p)``"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:294
msgid "Converts from page to folio."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:300
msgid "``p``"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:295
#: ../../../core-api/mm-api:114: mm/migrate.c:101
msgid "The page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:296
msgid ""
"Every page is part of a folio.  This function cannot be called on a NULL "
"pointer."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:300
msgid ""
"No reference, nor lock is required on **page**.  If the caller does not hold "
"a reference, this call may race with a folio split, so it should re-check "
"the folio still contains this page after gaining a reference on the folio."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:304
msgid "The folio which contains this page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:313
msgid "``folio_page (folio, n)``"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:311
msgid "Return a page from a folio."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:317
msgid "``folio``"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:313
msgid "The page number to return."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:314
msgid ""
"**n** is relative to the start of the folio.  This function does not check "
"that the page number lies within **folio**; the caller is presumed to have a "
"reference to the page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:756
msgid "Change some folio flags."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:758
msgid "Bits set in this word will be changed."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:759
msgid ""
"This must only be used for flags which are changed with the folio lock "
"held.  For example, it is unsafe to use for PG_dirty as that can be set "
"without the folio lock held.  It can also only be used on flags which are in "
"the range 0-6 as some of the implementations only affect those bits."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:766
msgid "Whether there are tasks waiting on the folio."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:775
msgid "Is this folio up to date?"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:777
msgid ""
"The uptodate flag is set on a folio when every byte in the folio is at least "
"as new as the corresponding bytes on storage.  Anonymous and CoW folios are "
"always uptodate.  If the folio is not uptodate, some of the bytes in it may "
"be; see the is_partially_uptodate() address_space operation."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:857
msgid "Does this folio contain more than one page?"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:860
msgid "True if the folio is larger than one page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1053
msgid "Determine if the page belongs to the slab allocator"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1054
#: include/linux/page-flags.h:1082 include/linux/page-flags.h:1151
msgid "The page to test."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1057
msgid "True for slab pages, false for any other kind of page."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1081
msgid "Determine if the page belongs to hugetlbfs"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1085
msgid ""
"True for hugetlbfs pages, false for anon pages or pages belonging to other "
"filesystems."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1150
msgid "test for a movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1152
msgid ""
"Test whether this is a movable_ops page. Such pages will stay that way until "
"freed."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1155
msgid "Returns true if this is a movable_ops page, otherwise false."
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1236
msgid "Determine if folio has private stuff"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1237
msgid "The folio to be checked"
msgstr ""

#: ../../../core-api/mm-api:105: include/linux/page-flags.h:1238
msgid ""
"Determine if a folio has private stuff, indicating that release routines "
"should be invoked upon it."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:494
msgid "check ALLOW_RETRY the first time"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:500
msgid "``enum fault_flag flags``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:495
msgid "Fault flags."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:496
msgid ""
"This is mostly used for places where we want to try to avoid taking the "
"mmap_lock for too long a time when waiting for another condition to change, "
"in which case we can try to be polite to release the mmap_lock in the first "
"round to avoid potential starvation of other processes that would also want "
"the mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:503
msgid ""
"true if the page fault allows retry and this is the first attempt of the "
"fault handling; false otherwise."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:984
msgid "The allocation order of a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:986
msgid ""
"A folio is composed of 2^order pages.  See get_order() for the definition of "
"order."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:990
msgid "The order of the folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1000
msgid "Reset the folio order and derived _nr_pages"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1002
msgid ""
"Reset the order and derived _nr_pages to 0. Must only be used in the process "
"of splitting large folios."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1118
msgid "Number of mappings of this folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1120
msgid ""
"The folio mapcount corresponds to the number of present user page table "
"entries that reference any part of a folio. Each such present user page "
"table entry must be paired with exactly on folio reference."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1124
msgid ""
"For ordindary folios, each user page table entry (PTE/PMD/PUD/...) counts "
"exactly once."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1127
msgid ""
"For hugetlb folios, each abstracted \"hugetlb\" user page table entry that "
"references the entire folio counts exactly once, even when such special page "
"table entries are comprised of multiple ordinary page table entries."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1131
msgid ""
"Will report 0 for pages which cannot be mapped into userspace, such as slab, "
"page tables and similar."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1135
msgid "The number of times this folio is mapped."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1151
msgid "Is this folio mapped into userspace?"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1154
msgid "True if any page in this folio is referenced by user page tables."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1206
msgid "Order of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1207
#: include/linux/mm.h:1217
msgid "Head page of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1216
msgid "Size of a transparent huge page."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1219
msgid "Number of bytes in this page."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1312
msgid "Increment the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1315
msgid ""
"May be called in any context, as long as you know that you have a refcount "
"on the folio.  If you do not already have one, folio_try_get() may be the "
"right interface for you to use."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1345
msgid "Decrement the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1347
msgid ""
"If the folio's reference count reaches zero, the memory will be released "
"back to the page allocator and may be used by another allocation "
"immediately.  Do not access the memory or the struct folio after calling "
"folio_put() unless you can be sure that it wasn't the last reference."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1354
#: include/linux/mm.h:1374 include/linux/mm.h:1414
#: ../../../core-api/mm-api:120: mm/swap.c:945
msgid ""
"May be called in process or interrupt context, but not in NMI context.  May "
"be called while holding a spinlock."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1364
msgid "Reduce the reference count on a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1367
msgid "``int refs``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1366
msgid "The amount to subtract from the folio's reference count."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1367
msgid ""
"If the folio's reference count reaches zero, the memory will be released "
"back to the page allocator and may be used by another allocation "
"immediately.  Do not access the memory or the struct folio after calling "
"folio_put_refs() unless you can be sure that these weren't the last "
"references."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1405
msgid "Decrement the reference count on an array of folios."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1411
#: ../../../core-api/mm-api:120: mm/swap.c:940
msgid "``struct folio_batch *folios``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1406
#: ../../../core-api/mm-api:120: mm/swap.c:935
msgid "The folios."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1407
msgid ""
"Like folio_put(), but for a batch of folios.  This is more efficient than "
"writing the loop yourself as it will optimise the locks which need to be "
"taken if the folios are freed.  The folios batch is returned empty and ready "
"to be reused for another batch; there is no need to reinitialise it."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1769
msgid "Return the Page Frame Number of a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1771
msgid ""
"A folio may contain multiple pages.  The pages have consecutive Page Frame "
"Numbers."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1775
msgid "The Page Frame Number of the first page in the folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1794
msgid "Create a PTE for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1795
msgid "The folio to create a PTE for"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1796
#: include/linux/mm.h:1812 include/linux/mm.h:1828
msgid "The page protection bits to use"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1797
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_ptes()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1801
#: include/linux/mm.h:1817 include/linux/mm.h:1833
msgid "A page table entry suitable for mapping this folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1810
msgid "Create a PMD for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1811
msgid "The folio to create a PMD for"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1813
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_pmd_at()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1826
msgid "Create a PUD for this folio"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1827
msgid "The folio to create a PUD for"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1829
msgid ""
"Create a page table entry for the first page of this folio. This is suitable "
"for passing to set_pud_at()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1851
msgid "Report if a folio may be pinned for DMA."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1853
msgid ""
"This function checks if a folio has been pinned via a call to a function in "
"the pin_user_pages() family."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1856
msgid ""
"For small folios, the return value is partially fuzzy: false is not fuzzy, "
"because it means \"definitely not pinned for DMA\", but true means "
"\"probably pinned for DMA, but possibly a false positive due to having at "
"least GUP_PIN_COUNTING_BIAS worth of normal folio references\"."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1861
msgid ""
"False positives are OK, because: a) it's unlikely for a folio to get that "
"many refcounts, and b) all the callers of this routine are expected to be "
"able to deal gracefully with a false positive."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1865
msgid ""
"For most large folios, the result will be exactly correct. That's because we "
"have more tracking data available: the _pincount field is used instead of "
"the GUP_PIN_COUNTING_BIAS scheme."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1869
msgid ""
"For more information, please see Documentation/core-api/pin_user_pages.rst."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1872
msgid ""
"True, if it is likely that the folio has been \"dma-pinned\". False, if the "
"folio is definitely not dma-pinned."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1910
msgid "Query if a page is a zero page"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1911
msgid "The page to query"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1912
msgid "This returns true if **page** is one of the permanent zero pages."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1921
msgid "Query if a folio is a zero page"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1922
msgid "The folio to query"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1923
msgid "This returns true if **folio** is one of the permanent zero pages."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1990
msgid "The number of pages in the folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:1993
msgid "A positive power of two."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2024
msgid "Move to the next physical folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2025
msgid "The folio we're currently operating on."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2026
msgid ""
"If you have physically contiguous memory which may span more than one folio "
"(eg a :c:type:`struct bio_vec <bio_vec>`), use this function to move from "
"one folio to the next.  Do not use it if the memory is only virtually "
"contiguous as the folios are almost certainly not adjacent to each other.  "
"This is the folio equivalent to writing ``page++``."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2033
msgid ""
"We assume that the folios are refcounted and/or locked at a higher level and "
"do not adjust the reference counts."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2035
msgid "The next struct folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2043
msgid "The size of the memory described by this folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2045
msgid ""
"A folio represents a number of bytes which is a power-of-two in size. This "
"function tells you which power-of-two the folio is.  See also folio_size() "
"and folio_order()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2050
#: include/linux/mm.h:2063
msgid ""
"The caller should have a reference on the folio to prevent it from being "
"split.  It is not necessary for the folio to be locked."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2052
msgid "The base-2 logarithm of the size of this folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2060
msgid "The number of bytes in a folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2065
msgid "The number of bytes in this folio."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2073
msgid "Whether the folio is mapped into the page tables of more than one MM"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2076
msgid ""
"This function checks if the folio maybe currently mapped into more than one "
"MM (\"maybe mapped shared\"), or if the folio is certainly mapped into a "
"single MM (\"mapped exclusively\")."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2080
msgid ""
"For KSM folios, this function also returns \"mapped shared\" when a folio is "
"mapped multiple times into the same MM, because the individual page mappings "
"are independent."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2084
msgid ""
"For small anonymous folios and anonymous hugetlb folios, the return value "
"will be exactly correct: non-KSM folios can only be mapped at most once into "
"an MM, and they cannot be partially mapped. KSM folios are considered shared "
"even if mapped multiple times into the same MM."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2089
msgid "For other folios, the result can be fuzzy:"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2090
msgid ""
"For partially-mappable large folios (THP), the return value can wrongly "
"indicate \"mapped shared\" (false positive) if a folio was mapped by more "
"than two MMs at one point in time."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2093
msgid ""
"For pagecache folios (including hugetlb), the return value can wrongly "
"indicate \"mapped shared\" (false positive) when two VMAs in the same MM "
"cover the same file range."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2097
msgid ""
"Further, this function only considers current page table mappings that are "
"tracked using the folio mapcount(s)."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2100
msgid "This function does not consider:"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2101
msgid ""
"If the folio might get mapped in the (near) future (e.g., swapcache, "
"pagecache, temporary unmapping for migration)."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2103
msgid "If the folio is mapped differently (VM_PFNMAP)."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2104
msgid ""
"If hugetlb page table sharing applies. Callers might want to check "
"hugetlb_pmd_shared()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2108
msgid "Whether the folio is estimated to be mapped into more than one MM."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2137
msgid "calculate the expected folio refcount"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2138
msgid "the folio"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2139
msgid ""
"Calculate the expected folio refcount, taking references from the pagecache, "
"swapcache, PG_private and page table mappings into account. Useful in "
"combination with folio_ref_count() to detect unexpected references (e.g., "
"GUP or other temporary references)."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2144
msgid ""
"Does currently not consider references from the LRU cache. If the folio was "
"isolated from the LRU (which is the case during migration or split), the LRU "
"cache does not apply."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2148
msgid ""
"Calling this function on an unmapped folio -- !folio_mapped() -- that is "
"locked will return a stable result."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2151
msgid ""
"Calling this function on a mapped folio will not result in a stable result, "
"because nothing stops additional page table mappings from coming (e.g., "
"fork()) or going (e.g., munmap())."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2155
msgid ""
"Calling this function without the folio lock will also not result in a "
"stable result: for example, the folio might get dropped from the swapcache "
"concurrently."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2159
msgid ""
"However, even when called without the folio lock or on a mapped folio, this "
"function can be used to detect unexpected references early (for example, if "
"it makes sense to even lock the folio and unmap it)."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2163
msgid ""
"The caller must add any reference (e.g., from folio_try_get()) it might be "
"holding itself to the result."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2166
msgid "Returns the expected folio refcount."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2870
msgid "Allocate pagetables"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2871
msgid "GFP flags"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2872
msgid "desired pagetable order"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2873
msgid ""
"pagetable_alloc allocates memory for page tables as well as a page table "
"descriptor to describe that memory."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2877
msgid "The ptdesc describing the allocated page tables."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2888
msgid "Free pagetables"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2894
msgid "``struct ptdesc *pt``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2889
msgid "The page table descriptor"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:2890
msgid ""
"pagetable_free frees the memory of all page tables described by a page table "
"descriptor and the memory for the descriptor itself."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:3423
msgid "Find a VMA at a specific address"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:3429
#: ../../../core-api/mm-api:113: mm/rmap.c:2632 ../../../core-api/mm-api:115:
#: mm/mmap.c:883 mm/mmap.c:903 mm/mmap.c:920 ../../../core-api/mm-api:122:
#: mm/memcontrol.c:902 mm/memcontrol.c:4763 ../../../core-api/mm-api:133:
#: mm/mmu_notifier.c:684 mm/mmu_notifier.c:739 mm/mmu_notifier.c:960
msgid "``struct mm_struct *mm``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:3424
#: ../../../core-api/mm-api:115: mm/mmap.c:878
msgid "The process address space."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:3425
msgid "The user address."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:3427
msgid "The vm_area_struct at the given address, ``NULL`` otherwise."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:4022
msgid "Are transhuge page-table entries considered special?"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:4028
#: ../../../core-api/mm-api:113: mm/rmap.c:775
msgid "``const struct vm_area_struct *vma``"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:4023
msgid "Pointer to the struct vm_area_struct to consider"
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:4024
msgid ""
"Whether transhuge page-table entries are considered \"special\" following "
"the definition in vm_normal_page()."
msgstr ""

#: ../../../core-api/mm-api:106: include/linux/mm.h:4028
msgid ""
"true if transhuge page-table entries should be considered special, false "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:71
msgid "The reference count on this folio."
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:73
msgid ""
"The refcount is usually incremented by calls to folio_get() and decremented "
"by calls to folio_put().  Some typical users of the folio refcount:"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:77
msgid "Each reference from a page table"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:78
msgid "The page cache"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:79
msgid "Filesystem private data"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:80
msgid "The LRU list"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:81
msgid "Pipes"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:82
msgid "Direct IO which references this page in the process address space"
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:85
msgid "The number of references to this folio."
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:252
msgid "Attempt to increase the refcount on a folio."
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:254
msgid ""
"If you do not already have a reference to a folio, you can attempt to get "
"one using this function.  It may fail if, for example, the folio has been "
"freed since you found a pointer to it, or it is frozen for the purposes of "
"splitting or migration."
msgstr ""

#: ../../../core-api/mm-api:108: include/linux/page_ref.h:260
msgid "True if the reference count was successfully incremented."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1619
msgid ""
"helper function to quickly check if a struct zone is a highmem zone or not. "
"This is an attempt to keep references to ZONE_{DMA/NORMAL/HIGHMEM/etc} in "
"general code to a minimum."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1622
#: include/linux/mmzone.h:1668
msgid "pointer to struct zone variable"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1623
msgid "1 for a highmem zone, 0 otherwise"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1661
msgid "``for_each_online_pgdat (pgdat)``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1659
msgid "helper macro to iterate over all online nodes"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1665
msgid "``pgdat``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1660
msgid "pointer to a pg_data_t variable"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1669
msgid "``for_each_zone (zone)``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1667
msgid "helper macro to iterate over all memory zones"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1673
#: include/linux/mmzone.h:1761 include/linux/mmzone.h:1785
msgid "``zone``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1669
msgid ""
"The user only needs to declare the zone variable, for_each_zone fills it in."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1706
msgid ""
"Returns the next zone at or below highest_zoneidx within the allowed "
"nodemask using a cursor within a zonelist as a starting point"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1712
msgid "``struct zoneref *z``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1707
msgid "The cursor used as a starting point for the search"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1709
#: include/linux/mmzone.h:1733
msgid "``enum zone_type highest_zoneidx``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1708
#: include/linux/mmzone.h:1732 include/linux/mmzone.h:1759
#: include/linux/mmzone.h:1783
msgid "The zone index of the highest zone to return"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1710
#: include/linux/mmzone.h:1734
msgid "``nodemask_t *nodes``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1709
#: include/linux/mmzone.h:1733
msgid "An optional nodemask to filter the zonelist with"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1710
msgid ""
"This function returns the next zone at or below a given zone index that is "
"within the allowed nodemask using a cursor as the starting point for the "
"search. The zoneref returned is a cursor that represents the current zone "
"being examined. It should be advanced by one before calling "
"next_zones_zonelist again."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1717
msgid ""
"the next zone at or below highest_zoneidx within the allowed nodemask using "
"a cursor within a zonelist as a starting point"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1730
msgid ""
"Returns the first zone at or below highest_zoneidx within the allowed "
"nodemask in a zonelist"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1736
msgid "``struct zonelist *zonelist``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1731
msgid "The zonelist to search for a suitable zone"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1734
msgid ""
"This function returns the first zone at or below a given zone index that is "
"within the allowed nodemask. The zoneref returned is a cursor that can be "
"used to iterate the zonelist with next_zones_zonelist by advancing it by one "
"before calling."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1739
msgid ""
"When no eligible zone is found, zoneref->zone is NULL (zoneref itself is "
"never NULL). This may happen either genuinely, or due to concurrent nodemask "
"update due to cpuset modification."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1744
msgid "Zoneref pointer for the first suitable zone found"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1757
msgid "``for_each_zone_zonelist_nodemask (zone, z, zlist, highidx, nodemask)``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1755
msgid ""
"helper macro to iterate over valid zones in a zonelist at or below a given "
"zone index and within a nodemask"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1756
#: include/linux/mmzone.h:1780
msgid "The current zone in the iterator"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1758
#: include/linux/mmzone.h:1782
msgid "``z``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1757
msgid "The current pointer within zonelist->_zonerefs being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1759
#: include/linux/mmzone.h:1783
msgid "``zlist``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1758
#: include/linux/mmzone.h:1782
msgid "The zonelist being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1760
#: include/linux/mmzone.h:1784
msgid "``highidx``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1761
msgid "``nodemask``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1760
msgid "Nodemask allowed by the allocator"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1761
msgid ""
"This iterator iterates though all zones at or below a given zone index and "
"within a given nodemask"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1781
msgid "``for_each_zone_zonelist (zone, z, zlist, highidx)``"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1779
msgid ""
"helper macro to iterate over valid zones in a zonelist at or below a given "
"zone index"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1781
msgid "The current pointer within zonelist->zones being iterated"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:1784
msgid "This iterator iterates though all zones at or below a given zone index."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:2135
msgid "check if there is a valid memory map entry for a PFN"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:2136
msgid "the page frame number to check"
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:2137
msgid ""
"Check if there is a valid memory map entry aka struct page for the **pfn**. "
"Note, that availability of the memory map entry does not imply that there is "
"actual usable memory at that **pfn**. The struct page may represent a hole "
"or an unusable page frame."
msgstr ""

#: ../../../core-api/mm-api:109: include/linux/mmzone.h:2143
msgid "1 for PFNs that have memory map entries and 0 otherwise"
msgstr ""

#: ../../../core-api/mm-api:110: mm/util.c:680
msgid "Find the mapping where this folio is stored."
msgstr ""

#: ../../../core-api/mm-api:110: mm/util.c:682
msgid ""
"For folios which are in the page cache, return the mapping that this page "
"belongs to.  Folios in the swap cache return the swap mapping this page is "
"stored in (which is different from the mapping for the swap file or swap "
"device where the data is stored)."
msgstr ""

#: ../../../core-api/mm-api:110: mm/util.c:687
msgid ""
"You can call this for folios which aren't in the swap cache or page cache "
"and it will return NULL."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:161
msgid "attach an anon_vma to a memory region"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:162
msgid "the memory region in question"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:163
msgid ""
"This makes sure the memory mapping described by 'vma' has an 'anon_vma' "
"attached to it, so that we can associate the anonymous pages mapped into it "
"with that anon_vma."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:167
msgid ""
"The common case will be that we already have one, which is handled inline by "
"anon_vma_prepare(). But if not we either need to find an adjacent mapping "
"that we can re-use the anon_vma from (very common when the only reason for "
"splitting a vma has been mprotect()), or we allocate a new one."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:174
msgid ""
"Anon-vma allocations are very subtle, because we may have optimistically "
"looked up an anon_vma in folio_lock_anon_vma_read() and that may actually "
"touch the rwsem even in the newly allocated vma (it depends on RCU to make "
"sure that the anon_vma isn't actually destroyed)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:180
msgid ""
"As a result, we need to do proper anon_vma locking even for the new "
"allocation. At the same time, we do not want to do any locking for the "
"common case of already having an anon_vma."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:771
msgid "The virtual address of a page in this VMA."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:772
msgid "The folio containing the page."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:773
msgid "The page within the folio."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:774
msgid "The VMA we need to know the address in."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:775
msgid ""
"Calculates the user virtual address of this page in the specified VMA. It is "
"the caller's responsibility to check the page is actually within the VMA.  "
"There may not currently be a PTE pointing at this page, but if a page fault "
"occurs at this address, this is the page which will be accessed."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:782
msgid ""
"Caller should hold a reference to the folio.  Caller should hold a lock (eg "
"the i_mmap_lock or the mmap_lock) which keeps the VMA from being altered."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:786
msgid "The virtual address corresponding to this page in the VMA."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:975
msgid "Test if the folio was referenced."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:978
msgid "``int is_locked``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:977
msgid "Caller holds lock on the folio."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:979 ../../../core-api/mm-api:122:
#: mm/memcontrol.c:687 mm/memcontrol.c:831 mm/memcontrol.c:1144
#: mm/memcontrol.c:1305 mm/memcontrol.c:1536 mm/memcontrol.c:1561
#: mm/memcontrol.c:1791 mm/memcontrol.c:4678 mm/memcontrol.c:5034
#: mm/memcontrol.c:5057
msgid "``struct mem_cgroup *memcg``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:978
msgid "target memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:980
msgid "``vm_flags_t *vm_flags``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:979
msgid "A combination of all the vma->vm_flags which referenced the folio."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:980
msgid "Quick test_and_clear_referenced for all mappings of a folio,"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:983
msgid ""
"The number of mappings which referenced the folio. Return -1 if the function "
"bailed out due to rmap lock contention."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1168
msgid "Write-protect all mappings in a specified range."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1170
msgid "The mapping whose reverse mapping should be traversed."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1172 mm/rmap.c:1220
msgid "``pgoff_t pgoff``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1171
msgid "The page offset at which **pfn** is mapped within **mapping**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1172
msgid "The PFN of the page mapped in **mapping** at **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1173
msgid "The number of physically contiguous base pages spanned."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1174
msgid ""
"Traverses the reverse mapping, finding all VMAs which contain a shared "
"mapping of the pages in the specified range in **mapping**, and write-"
"protects them (that is, updates the page tables to mark the mappings read-"
"only such that a write protection fault arises when the mappings are written "
"to)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1179
msgid ""
"The **pfn** value need not refer to a folio, but rather can reference a "
"kernel allocation which is mapped into userland. We therefore do not require "
"that the page maps to a folio with a valid mapping or index field, rather "
"the caller specifies these in **mapping** and **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1185
msgid "the number of write-protected PTEs, or an error."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1213
msgid ""
"Cleans the PTEs (including PMDs) mapped with range of [**pfn**, **pfn** + "
"**nr_pages**) at the specific offset (**pgoff**) within the **vma** of "
"shared mappings. And since clean PTEs should also be readonly, write "
"protects them too."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1217
msgid "start pfn."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1218
msgid "number of physically contiguous pages srarting with **pfn**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1219
msgid "page offset that the **pfn** mapped with."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1220
msgid "vma that **pfn** mapped within."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1221
msgid "Returns the number of cleaned PTEs (including PMDs)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1322
msgid "move a folio to our anon_vma"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1323
msgid "The folio to move to our anon_vma"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1324
msgid "The vma the folio belongs to"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1325
msgid ""
"When a folio belongs exclusively to one process after a COW event, that "
"folio can be moved into the anon_vma that belongs to just that process, so "
"the rmap code will not search the parent or sibling processes."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1347
msgid "set up a new anonymous rmap for a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1348
msgid "The folio to set up the new anonymous rmap for."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1349
msgid "VM area to add the folio to."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1350
msgid "User virtual address of the mapping"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1352
msgid "``bool exclusive``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1351
msgid "Whether the folio is exclusive to the process."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1379
msgid "sanity check anonymous rmap addition"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1380
msgid "The folio containing **page**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1381
msgid "the page to check the mapping of"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1382 mm/rmap.c:1542
msgid "the vm area in which the mapping is added"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1383 mm/rmap.c:1543
msgid "the user virtual address mapped"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1492
msgid "add PTE mappings to a page range of an anon folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1493 mm/rmap.c:1630
msgid "The folio to add the mappings to"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1494 mm/rmap.c:1518 mm/rmap.c:1631
#: mm/rmap.c:1648 mm/rmap.c:1668
msgid "The first page to add"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1495
msgid "The number of pages which will be mapped"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1496 mm/rmap.c:1633
msgid "The vm area in which the mappings are added"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1497 mm/rmap.c:1520
msgid "The user virtual address of the first page to map"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1499 mm/rmap.c:1522 mm/rmap.c:1545
msgid "``rmap_t flags``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1498 mm/rmap.c:1521 mm/rmap.c:1544
msgid "The rmap flags"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1499
msgid ""
"The page range of folio is defined by [first_page, first_page + nr_pages)"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1501
msgid ""
"The caller needs to hold the page table lock, and the page must be locked in "
"the anon_vma case: to serialize mapping,index checking after setting, and to "
"ensure that an anon folio is not being upgraded racily to a KSM folio (but "
"KSM folios are never downgraded)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1516
msgid "add a PMD mapping to a page range of an anon folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1517 mm/rmap.c:1647 mm/rmap.c:1667
msgid "The folio to add the mapping to"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1519 mm/rmap.c:1649 mm/rmap.c:1669
msgid "The vm area in which the mapping is added"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1522
msgid ""
"The page range of folio is defined by [first_page, first_page + HPAGE_PMD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1524
msgid ""
"The caller needs to hold the page table lock, and the page must be locked in "
"the anon_vma case: to serialize mapping,index checking after setting."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1540
msgid "Add mapping to a new anonymous folio."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1541
msgid "The folio to add the mapping to."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1545
msgid ""
"Like folio_add_anon_rmap_*() but must only be called on *new* folios. This "
"means the inc-and-test can be bypassed. The folio doesn't necessarily need "
"to be locked while it's exclusive unless two threads map it concurrently. "
"However, the folio must be locked if it's shared."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1551
msgid "If the folio is pmd-mappable, it is accounted as a THP."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1629
msgid "add PTE mappings to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1632
msgid "The number of pages that will be mapped using PTEs"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1634 mm/rmap.c:1796
msgid "The page range of the folio is defined by [page, page + nr_pages)"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1636 mm/rmap.c:1652 mm/rmap.c:1672
#: mm/rmap.c:1798 mm/rmap.c:1814 mm/rmap.c:1834
msgid "The caller needs to hold the page table lock."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1646
msgid "add a PMD mapping to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1650 mm/rmap.c:1812
msgid "The page range of the folio is defined by [page, page + HPAGE_PMD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1666
msgid "add a PUD mapping to a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1670 mm/rmap.c:1832
msgid "The page range of the folio is defined by [page, page + HPAGE_PUD_NR)"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1791
msgid "remove PTE mappings from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1792
msgid "The folio to remove the mappings from"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1793 mm/rmap.c:1810 mm/rmap.c:1830
msgid "The first page to remove"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1794
msgid "The number of pages that will be removed from the mapping"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1795
msgid "The vm area from which the mappings are removed"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1808
msgid "remove a PMD mapping from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1809 mm/rmap.c:1829
msgid "The folio to remove the mapping from"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1811 mm/rmap.c:1831
msgid "The vm area from which the mapping is removed"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:1828
msgid "remove a PUD mapping from a page range of a folio"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2249
msgid "Try to remove all page table mappings to a folio."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2250
msgid "The folio to unmap."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2252 mm/rmap.c:2582
msgid "``enum ttu_flags flags``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2251 mm/rmap.c:2581
msgid "action and flags"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2252
msgid ""
"Tries to remove all the page table entries which are mapping this folio.  It "
"is the caller's responsibility to check if the folio is still mapped if "
"needed (use TTU_SYNC to prevent accounting races)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2257
msgid "Caller must hold the folio lock."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2579
msgid "try to replace all page table mappings with swap entries"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2580
msgid "the folio to replace page table entries for"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2582
msgid ""
"Tries to remove all the page table entries which are mapping this folio and "
"replace them with special swap entries. Caller must hold the folio lock."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2626
msgid "Mark a page for exclusive use by a device"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2627
msgid "mm_struct of associated target process"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2628
msgid "the virtual address to mark for exclusive device access"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2630
msgid "``void *owner``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2629
msgid "passed to MMU_NOTIFY_EXCLUSIVE range notifier to allow filtering"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2631 ../../../core-api/mm-api:124:
#: mm/shmem.c:2682
msgid "``struct folio **foliop``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2630
msgid "folio pointer will be stored here on success."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2631
msgid ""
"This function looks up the page mapped at the given address, grabs a folio "
"reference, locks the folio and replaces the PTE with special device-"
"exclusive PFN swap entry, preventing access through the process page tables. "
"The function will return with the folio locked and referenced."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2636
msgid ""
"On fault, the device-exclusive entries are replaced with the original PTE "
"under folio lock, after calling MMU notifiers."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2639
msgid ""
"Only anonymous non-hugetlb folios are supported and the VMA must have write "
"permissions such that we can fault in the anonymous page writable in order "
"to mark it exclusive. The caller must hold the mmap_lock in read mode."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2644
msgid ""
"A driver using this to program access from a device must use a mmu notifier "
"critical section to hold a device specific lock during programming. Once "
"programming is complete it should drop the folio lock and reference after "
"which point CPU access to the page will revoke the exclusive access."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2649 ../../../core-api/mm-api:118:
#: mm/memremap.c:356
msgid "**Notes**"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2650
msgid ""
"This function always operates on individual PTEs mapping individual pages. "
"PMD-sized THPs are first remapped to be mapped by PTEs before the conversion "
"happens on a single PTE corresponding to **addr**."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2653
msgid ""
"While concurrent access through the process page tables is prevented, "
"concurrent access through other page references (e.g., earlier GUP "
"invocation) is not handled and not supported."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2656
msgid ""
"device-exclusive entries are considered \"clean\" and \"old\" by core-mm. "
"Device drivers must update the folio state when informed by MMU notifiers."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2661
msgid "pointer to mapped page on success, otherwise a negative error."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2853
msgid ""
"Traverse the reverse mapping for a file-backed mapping of a page mapped "
"within a specified page cache object at a specified offset."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2856
msgid ""
"Either the folio whose mappings to traverse, or if NULL, the callbacks "
"specified in **rwc** will be configured such as to be able to look up "
"mappings correctly."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2859
msgid ""
"The page cache object whose mapping VMAs we intend to traverse. If **folio** "
"is non-NULL, this should be equal to folio_mapping(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2863
msgid "``pgoff_t pgoff_start``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2862
msgid ""
"The offset within **mapping** of the page which we are looking up. If "
"**folio** is non-NULL, this should be equal to folio_pgoff(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2865
msgid ""
"The number of pages mapped by the mapping. If **folio** is non-NULL, this "
"should be equal to folio_nr_pages(folio)."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2868
msgid "``struct rmap_walk_control *rwc``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2867
msgid ""
"The reverse mapping walk control object describing how the traversal should "
"proceed."
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2870
msgid "``bool locked``"
msgstr ""

#: ../../../core-api/mm-api:113: mm/rmap.c:2869
msgid "Is the **mapping** already locked? If not, we acquire the lock."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:100
msgid "isolate a movable_ops page for migration"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:103
msgid "``isolate_mode_t mode``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:102
msgid "The isolation mode."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:103
msgid ""
"Try to isolate a movable_ops page for migration. Will fail if the page is "
"not a movable_ops page, if the page is already isolated for migration or if "
"the page was just was released by its owner."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:107
msgid ""
"Once isolated, the page cannot get freed until it is either putback or "
"migrated."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:110
msgid "Returns true if isolation succeeded, otherwise false."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:186
msgid "putback an isolated movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:187
msgid "The isolated page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:188
msgid "Putback an isolated movable_ops page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:190
msgid "After the page was putback, it might get freed instantly."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:211
msgid "migrate an isolated movable_ops page"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:217
msgid "``struct page *dst``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:212
msgid "The destination page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:214
msgid "``struct page *src``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:213
msgid "The source page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:215 mm/migrate.c:872
#: mm/migrate.c:997 mm/migrate.c:1019
msgid "``enum migrate_mode mode``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:214
msgid "The migration mode."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:215
msgid "Migrate an isolated movable_ops page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:217
msgid ""
"If the src page was already released by its owner, the src page is un-"
"isolated (putback) and migration succeeds; the migration core will be the "
"owner of both pages."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:221
msgid ""
"If the src page was not released by its owner and the migration was "
"successful, the owner of the src page and the dst page are swapped and the "
"src page is un-isolated."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:225
msgid ""
"If migration fails, the ownership stays unmodified and the src page remains "
"isolated: migration may be retried later or the page can be putback."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:228
msgid ""
"TODO: migration core will treat both pages as folios and lock them before "
"this call to unlock them after this call. Further, the folio refcounts on "
"src and dst are also released by migration core. These pages will not be "
"folios in the future, so that must be reworked."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:233
msgid ""
"Returns MIGRATEPAGE_SUCCESS on success, otherwise a negative error code."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:867
msgid "Simple folio migration."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:868
msgid "The address_space containing the folio."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:870 mm/migrate.c:995
#: mm/migrate.c:1017
msgid "``struct folio *dst``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:869
msgid "The folio to migrate the data to."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:871 mm/migrate.c:996
#: mm/migrate.c:1018
msgid "``struct folio *src``"
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:870
msgid "The folio containing the current data."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:871
msgid "How to migrate the page."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:872
msgid ""
"Common logic to directly migrate a single LRU folio suitable for folios that "
"do not have private data."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:875
msgid "Folios are locked upon entry and exit."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:992 mm/migrate.c:1014
msgid "Migration function for folios with buffers."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:993 mm/migrate.c:1015
msgid "The address space containing **src**."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:994 mm/migrate.c:1016
msgid "The folio to migrate to."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:995 mm/migrate.c:1017
msgid "The folio to migrate from."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:996 mm/migrate.c:1018
msgid "How to migrate the folio."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:997
msgid ""
"This function can only be used if the underlying filesystem guarantees that "
"no other references to **src** exist. For example attached buffer heads are "
"accessed only under the folio lock.  If your filesystem cannot provide this "
"guarantee, buffer_migrate_folio_norefs() may be more appropriate."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:1004 mm/migrate.c:1025
msgid "0 on success or a negative errno on failure."
msgstr ""

#: ../../../core-api/mm-api:114: mm/migrate.c:1019
msgid ""
"Like buffer_migrate_folio() except that this variant is more careful and "
"checks that there are also no buffer head references. This function is the "
"right one for mappings where buffer heads are directly looked up and "
"referenced (such as block device mappings)."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:278
msgid ""
"Perform a userland memory mapping into the current process address space of "
"length **len** with protection bits **prot**, mmap flags **flags** (from "
"which VMA flags will be inferred), and any additional VMA flags to apply "
"**vm_flags**. If this is a file-backed mapping then the file is specified in "
"**file** and page offset into the file via **pgoff**."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:310
msgid ""
"An optional struct file pointer describing the file which is to be mapped, "
"if a file-backed mapping."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:312
msgid ""
"If non-zero, hints at (or if **flags** has MAP_FIXED set, specifies) the "
"address at which to perform this mapping. See mmap (2) for details. Must be "
"page-aligned."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:315
msgid ""
"The length of the mapping. Will be page-aligned and must be at least 1 page "
"in size."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:318
msgid "``unsigned long prot``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:317
msgid ""
"Protection bits describing access required to the mapping. See mmap (2) for "
"details."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:319
msgid ""
"Flags specifying how the mapping should be performed, see mmap (2) for "
"details."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:322
msgid "``vm_flags_t vm_flags``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:321
msgid "VMA flags which should be set by default, or 0 otherwise."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:322
msgid "Page offset into the **file** if file-backed, should be 0 otherwise."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:324
msgid "``unsigned long *populate``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:323
msgid ""
"A pointer to a value which will be set to 0 if no population of the range is "
"required, or the number of bytes to populate if it is. Must be non-NULL. See "
"mmap (2) for details as to under what circumstances population of the range "
"occurs."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:328
msgid "``struct list_head *uf``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:327
msgid ""
"An optional pointer to a list head to track userfaultfd unmap events should "
"unmapping events arise. If provided, it is up to the caller to manage this."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:279
msgid ""
"This function does not perform security checks on the file and assumes, if "
"**uf** is non-NULL, the caller has provided a list head to track unmap "
"events for userfaultfd **uf**."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:283
msgid ""
"It also simply indicates whether memory population is required by setting "
"**populate**, which must be non-NULL, expecting the caller to actually "
"perform this task itself if appropriate."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:287
msgid ""
"This function will invoke architecture-specific (and if provided and "
"relevant, file system-specific) logic to determine the most appropriate "
"unmapped area in which to place the mapping if not MAP_FIXED."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:291
msgid ""
"Callers which require userland mmap() behaviour should invoke vm_mmap(), "
"which is also exported for module use."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:294
msgid ""
"Those which require this behaviour less security checks, userfaultfd and "
"populate behaviour, and who handle the mmap write lock themselves, should "
"call this function."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:298
msgid ""
"Note that the returned address may reside within a merged VMA if an "
"appropriate merge were to take place, so it doesn't necessarily specify the "
"start of a VMA, rather only the start of a valid mapped range of length "
"**len** bytes, rounded down to the nearest page size."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:303
msgid "The caller must write-lock current->mm->mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:331
msgid ""
"Either an error, or the address at which the requested mapping has been "
"performed."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:877
msgid "Look up the first VMA which intersects the interval"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:880
msgid "``unsigned long start_addr``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:879
msgid "The inclusive start user address."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:881
msgid "``unsigned long end_addr``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:880
msgid "The exclusive end user address."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:882
msgid ""
"The first VMA within the provided range, ``NULL`` otherwise.  Assumes "
"start_addr < end_addr."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:897
msgid "Find the VMA for a given address, or the next VMA."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:898 mm/mmap.c:916
msgid "The mm_struct to check"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:899 mm/mmap.c:917
msgid "The address"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:901
msgid ""
"The VMA associated with addr, or the next VMA. May return ``NULL`` in the "
"case of no VMA at addr or above."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:914
msgid ""
"Find the VMA for a given address, or the next vma and set ``pprev`` to the "
"previous VMA, if any."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:919
msgid "``struct vm_area_struct **pprev``"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:918
msgid "The pointer to set to the previous VMA"
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:919
msgid ""
"Note that RCU lock is missing here since the external mmap_lock() is used "
"instead."
msgstr ""

#: ../../../core-api/mm-api:115: mm/mmap.c:923
msgid ""
"The VMA associated with **addr**, or the next vma. May return ``NULL`` in "
"the case of no vma at addr or above."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1079
msgid "register a newly allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1085 mm/kmemleak.c:1153
#: mm/kmemleak.c:1169 mm/kmemleak.c:1203 mm/kmemleak.c:1239 mm/kmemleak.c:1255
#: mm/kmemleak.c:1286 mm/kmemleak.c:1304 mm/kmemleak.c:1324
msgid "``const void *ptr``"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1080 mm/kmemleak.c:1148
#: mm/kmemleak.c:1198 mm/kmemleak.c:1234 mm/kmemleak.c:1250 mm/kmemleak.c:1281
#: mm/kmemleak.c:1319
msgid "pointer to beginning of the object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1081 mm/kmemleak.c:1105
#: mm/kmemleak.c:1124 mm/kmemleak.c:1339
msgid "size of the object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1083
msgid "``int min_count``"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1082
msgid ""
"minimum number of references to this object. If during memory scanning a "
"number of references less than **min_count** is found, the object is "
"reported as a memory leak. If **min_count** is 0, the object is never "
"reported as a leak. If **min_count** is -1, the object is ignored (not "
"scanned and not reported as a leak)"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1087 mm/kmemleak.c:1302
#: mm/kmemleak.c:1340
msgid "kmalloc() flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1088
msgid ""
"This function is called from the kernel allocators when a new object (memory "
"block) is allocated (kmem_cache_alloc, kmalloc etc.)."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1103
msgid "register a newly allocated __percpu object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1109 mm/kmemleak.c:1187
#: mm/kmemleak.c:1272
msgid "``const void __percpu *ptr``"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1104 mm/kmemleak.c:1182
msgid "__percpu pointer to beginning of the object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1106
msgid "flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1107
msgid ""
"This function is called from the kernel percpu allocator when a new object "
"(memory block) is allocated (alloc_percpu)."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1122
msgid "register a newly vmalloc'ed object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1128
msgid "``const struct vm_struct *area``"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1123
msgid "pointer to vm_struct"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1125
msgid "__vmalloc() flags used for kmemleak internal memory allocations"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1126
msgid ""
"This function is called from the vmalloc() kernel allocator when a new "
"object (memory block) is allocated."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1147
msgid "unregister a previously registered object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1149
msgid ""
"This function is called from the kernel allocators when an object (memory "
"block) is freed (kmem_cache_free, kfree, vfree etc.)."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1163
msgid "partially unregister a previously registered object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1164
msgid ""
"pointer to the beginning or inside the object. This also represents the "
"start of the range to be freed"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1166 mm/kmemleak.c:1360
msgid "size to be unregistered"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1167
msgid ""
"This function is called when only a part of a memory block is freed (usually "
"from the bootmem allocator)."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1181
msgid "unregister a previously registered __percpu object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1183
msgid ""
"This function is called from the kernel percpu allocator when an object "
"(memory block) is freed (free_percpu)."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1197
msgid "update object allocation stack trace"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1199
msgid ""
"Override the object allocation stack trace for cases where the actual "
"allocation place is not always useful."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1233
msgid "mark an allocated object as false positive"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1235
msgid ""
"Calling this function on an object will cause the memory block to no longer "
"be reported as leak and always be scanned."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1249
msgid "mark an allocated object as transient false positive"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1251
msgid ""
"Calling this function on an object will cause the memory block to not be "
"reported as a leak temporarily. This may happen, for example, if the object "
"is part of a singly linked list and the ->next reference to it is changed."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1266
msgid "similar to kmemleak_ignore but taking a percpu address argument"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1268
msgid "percpu address of the object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1280
msgid "ignore an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1282
msgid ""
"Calling this function on an object will cause the memory block to be ignored "
"(not scanned and not reported as a leak). This is usually done when it is "
"known that the corresponding block is not a leak and does not contain any "
"references to other allocated memory blocks."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1298
msgid "limit the range to be scanned in an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1299
msgid ""
"pointer to beginning or inside the object. This also represents the start of "
"the scan area"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1301
msgid "size of the scan area"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1303
msgid ""
"This function is used when it is known that only certain parts of an object "
"contain references to other objects. Kmemleak will only scan these areas "
"reducing the number false negatives."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1318
msgid "do not scan an allocated object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1320
msgid ""
"This function notifies kmemleak not to scan the given memory block. Useful "
"in situations where it is known that the given object does not contain any "
"references to other objects. Kmemleak will not scan such objects reducing "
"the number of false negatives."
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1336
msgid "similar to kmemleak_alloc but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1342 mm/kmemleak.c:1362
#: mm/kmemleak.c:1378
msgid "``phys_addr_t phys``"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1338 mm/kmemleak.c:1374
msgid "physical address of the object"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1356
msgid "similar to kmemleak_free_part but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1358
msgid ""
"physical address if the beginning or inside an object. This also represents "
"the start of the range to be freed"
msgstr ""

#: ../../../core-api/mm-api:116: mm/kmemleak.c:1372
msgid "similar to kmemleak_ignore but taking a physical address argument"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:352
msgid "remap and provide memmap backing for the given resource"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:358
msgid "``struct device *dev``"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:353
msgid "hosting device for **res**"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:355 mm/memremap.c:398
msgid "``struct dev_pagemap *pgmap``"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:354
msgid "pointer to a struct dev_pagemap"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:356
msgid ""
"1/ At a minimum the range and type members of **pgmap** must be initialized"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:357
msgid "by the caller before passing it to this function"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:359
msgid "2/ The altmap field may optionally be initialized, in which case"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:360
msgid "PGMAP_ALTMAP_VALID must be set in pgmap->flags."
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:362
msgid ""
"3/ The ref field may optionally be provided, in which pgmap->ref must be"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:363
msgid ""
"'live' on entry and will be killed and reaped at "
"devm_memremap_pages_release() time, or if this routine fails."
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:366
msgid "4/ range is expected to be a host memory range that could feasibly be"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:367
msgid ""
"treated as a \"System RAM\" range, i.e. not a device mmio range, but this is "
"not enforced."
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:395
msgid "take a new live reference on the dev_pagemap for **pfn**"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:396
msgid "page frame number to lookup page_map"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:397
msgid "optional known pgmap that already has a reference"
msgstr ""

#: ../../../core-api/mm-api:118: mm/memremap.c:398
msgid ""
"If **pgmap** is non-NULL and covers **pfn** it will be returned as-is.  If "
"**pgmap** is non-NULL but does not cover **pfn** the reference to it will be "
"released."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:1028
msgid "Page size granularity for this VMA."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:1029
msgid "The user mapping."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:1030
msgid ""
"Folios in this VMA will be aligned to, and at least the size of the number "
"of bytes returned by this function."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:1034
msgid "The default size of the folios allocated when backing a VMA."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7747
msgid "try to isolate an allocated hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7748
msgid "the folio to isolate"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7750
msgid "``struct list_head *list``"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7749
msgid "the list to add the folio to on success"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7750
msgid ""
"Isolate an allocated (refcount > 0) hugetlb folio, marking it as isolated/"
"non-migratable, and moving it from the active list to the given list."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7754
msgid ""
"Isolation will fail if **folio** is not an allocated hugetlb folio, or if it "
"is already isolated/non-migratable."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7757
msgid ""
"On success, an additional folio reference is taken that must be dropped "
"using folio_putback_hugetlb() to undo the isolation."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7761
msgid "True if isolation worked, otherwise False."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7812
msgid "unisolate a hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7813
msgid "the isolated hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7814
msgid ""
"Putback/un-isolate the hugetlb folio that was previous isolated using "
"folio_isolate_hugetlb(): marking it non-isolated/migratable and putting it "
"back onto the active list."
msgstr ""

#: ../../../core-api/mm-api:119: mm/hugetlb.c:7818
msgid ""
"Will drop the additional folio reference obtained through "
"folio_isolate_hugetlb()."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:443
msgid "Mark a folio as having seen activity."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:444
msgid "The folio to mark."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:445
msgid "This function will perform one of the following transitions:"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:447
msgid "inactive,unreferenced      ->      inactive,referenced"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:448
msgid "inactive,referenced        ->      active,unreferenced"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:449
msgid "active,unreferenced        ->      active,referenced"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:451
msgid ""
"When a newly allocated folio is not yet visible, so safe for non-atomic ops, "
"__folio_set_referenced() may be substituted for folio_mark_accessed()."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:492
msgid "Add a folio to an LRU list."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:493 mm/swap.c:517
msgid "The folio to be added to the LRU."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:494
msgid ""
"Queue the folio for addition to the LRU. The decision on whether to add the "
"page to the [in]active [file|anon] list is deferred until the folio_batch is "
"drained. This gives a chance for the caller of folio_add_lru() have the "
"folio added to the active list using folio_mark_accessed()."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:516
msgid "Add a folio to the appropate LRU list for this VMA."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:518
msgid "VMA in which the folio is mapped."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:519
msgid ""
"If the VMA is mlocked, **folio** is added to the unevictable list. "
"Otherwise, it is treated the same way as folio_add_lru()."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:677
msgid "Deactivate a file folio."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:678
msgid "Folio to deactivate."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:679
msgid ""
"This function hints to the VM that **folio** is a good reclaim candidate, "
"for example if its invalidation fails due to the folio being dirty or under "
"writeback."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:684
msgid "Caller holds a reference on the folio."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:718
msgid "make an anon folio lazyfree"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:719
msgid "folio to deactivate"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:720
msgid ""
"folio_mark_lazyfree() moves **folio** to the inactive file list. This is "
"done to accelerate the reclaim of **folio**."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:934
msgid "Reduce the reference count on a batch of folios."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:937
msgid "``unsigned int *refs``"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:936
msgid "The number of refs to subtract from each folio."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:937
msgid ""
"Like folio_put(), but for a batch of folios.  This is more efficient than "
"writing the loop yourself as it will optimise the locks which need to be "
"taken if the folios are freed.  The folios batch is returned empty and ready "
"to be reused for another batch; there is no need to reinitialise it.  If "
"**refs** is NULL, we subtract one from each folio refcount."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1004
msgid "batched put_page()"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1010
msgid "``release_pages_arg arg``"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1005
msgid "array of pages to release"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1007
msgid "``int nr``"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1007
msgid ""
"Decrement the reference count on all the pages in **arg**.  If it fell to "
"zero, remove the page from the LRU and free it."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1010
msgid ""
"Note that the argument can be an array of pages, encoded pages, or folio "
"pointers. We ignore any encoded bits, and turn any of them into just a folio "
"that gets free'd."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1064
msgid "Prune non-folios from a batch."
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1065
msgid "The batch to prune"
msgstr ""

#: ../../../core-api/mm-api:120: mm/swap.c:1066
msgid ""
"find_get_entries() fills a batch with both folios and shadow/swap/DAX "
"entries.  This function prunes all the non-folio entries from **fbatch** "
"without leaving holes, so that it can be passed on to folio-only batch "
"operations."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:30
msgid "register a zpool implementation."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:36 mm/zpool.c:49
msgid "``struct zpool_driver *driver``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:31
msgid "driver to register"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:43
msgid "unregister a zpool implementation."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:44
msgid "driver to unregister."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:45
msgid ""
"Module usage counting is used to prevent using a driver while/after "
"unloading, so if this is called from module exit function, this should never "
"fail; if called from other than the module exit function, and this returns "
"failure, the driver is in use and must remain available."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:97
msgid "Check if the pool driver is available"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:103
msgid "``char *type``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:98
msgid "The type of the zpool to check (e.g. zsmalloc)"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:99
msgid ""
"This checks if the **type** pool driver is available.  This will try to load "
"the requested module, if needed, but there is no guarantee the module will "
"still be loaded and available immediately after calling.  If this returns "
"true, the caller should assume the pool is available, but must be prepared "
"to handle the **zpool_create_pool\\(\\)** returning failure.  However if "
"this returns false, the caller should assume the requested pool type is not "
"available; either the requested pool type module does not exist, or could "
"not be loaded, and calling **zpool_create_pool\\(\\)** with the pool type "
"will fail."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:109
msgid "The **type** string must be null-terminated."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:112
msgid "true if **type** pool is available, false if not"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:132
msgid "Create a new zpool"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:138
msgid "``const char *type``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:133
msgid "The type of the zpool to create (e.g. zsmalloc)"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:134
msgid "The name of the zpool (e.g. zram0, zswap)"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:135
msgid "The GFP flags to use when allocating the pool."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:136
msgid ""
"This creates a new zpool of the specified type.  The gfp flags will be used "
"when allocating memory, if the implementation supports it.  If the ops param "
"is NULL, then the created zpool will not be evictable."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:140 mm/zpool.c:213 mm/zpool.c:236
msgid "Implementations must guarantee this to be thread-safe."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:142
msgid "The **type** and **name** strings must be null-terminated."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:145
msgid "New zpool on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:189
msgid "Destroy a zpool"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:195 mm/zpool.c:215 mm/zpool.c:230
#: mm/zpool.c:254 mm/zpool.c:273 mm/zpool.c:293 mm/zpool.c:307 mm/zpool.c:321
msgid "``struct zpool *zpool``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:190
msgid "The zpool to destroy."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:191
msgid ""
"Implementations must guarantee this to be thread-safe, however only when "
"destroying different pools.  The same pool should only be destroyed once, "
"and should not be used after it is destroyed."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:196
msgid "This destroys an existing zpool.  The zpool should not be in use."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:209
msgid "Get the type of the zpool"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:210 mm/zpool.c:316
msgid "The zpool to check"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:211
msgid "This returns the type of the pool."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:216
msgid "The type of zpool."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:224
msgid "Allocate memory"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:225
msgid "The zpool to allocate from."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:226
msgid "The amount of memory to allocate."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:227
msgid "The GFP flags to use when allocating memory."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:229
msgid "``unsigned long *handle``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:228
msgid "Pointer to the handle to set"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:230
msgid "``const int nid``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:229
msgid "The preferred node id."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:230
msgid ""
"This allocates the requested amount of memory from the pool. The gfp flags "
"will be used when allocating memory, if the implementation supports it.  The "
"provided **handle** will be set to the allocated object handle. The "
"allocation will prefer the NUMA node specified by **nid**."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:239
msgid "0 on success, negative value on error."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:248
msgid "Free previously allocated memory"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:249
msgid "The zpool that allocated the memory."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:251 mm/zpool.c:270 mm/zpool.c:290
#: mm/zpool.c:304
msgid "``unsigned long handle``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:250
msgid "The handle to the memory to free."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:251
msgid ""
"This frees previously allocated memory.  This does not guarantee that the "
"pool will actually free memory, only that the memory in the pool will become "
"available for use by the pool."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:255
msgid ""
"Implementations must guarantee this to be thread-safe, however only when "
"freeing different handles.  The same handle should only be freed once, and "
"should not be used after freeing."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:267
msgid "Start reading from a previously allocated handle."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:268 mm/zpool.c:288 mm/zpool.c:302
msgid "The zpool that the handle was allocated from"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:269 mm/zpool.c:289 mm/zpool.c:303
msgid "The handle to read from"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:271
msgid "``void *local_copy``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:270
msgid "A local buffer to use if needed."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:271
msgid ""
"This starts a read operation of a previously allocated handle. The passed "
"**local_copy** buffer may be used if needed by copying the memory into. "
"zpool_obj_read_end() MUST be called after the read is completed to undo any "
"actions taken (e.g. release locks)."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:277
msgid ""
"A pointer to the handle memory to be read, if **local_copy** is used, the "
"returned pointer is **local_copy**."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:287
msgid "Finish reading from a previously allocated handle."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:291 mm/zpool.c:305
msgid "``void *handle_mem``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:290
msgid "The pointer returned by zpool_obj_read_begin()"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:291
msgid "Finishes a read operation previously started by zpool_obj_read_begin()."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:301
msgid "Write to a previously allocated handle."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:304
msgid "The memory to copy from into the handle."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:306
msgid "``size_t mem_len``"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:305
msgid "The length of memory to be written."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:315
msgid "The total size of the pool"
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:317
msgid "This returns the total size in pages of the pool."
msgstr ""

#: ../../../core-api/mm-api:121: mm/zpool.c:320
msgid "Total size of the zpool in pages."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:241
msgid "css of the memcg associated with a folio"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:242
msgid "folio of interest"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:243
msgid ""
"If memcg is bound to the default hierarchy, css of the memcg associated with "
"**folio** is returned.  The returned css remains associated with **folio** "
"until it is released."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:247
msgid ""
"If memcg is bound to a traditional hierarchy, the css of root_mem_cgroup is "
"returned."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:262
msgid "return inode number of the memcg a page is charged to"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:263
msgid "the page"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:264
msgid ""
"Look up the closest online ancestor of the memory cgroup **page** is charged "
"to and return its inode number or 0 if **page** is not charged to any "
"cgroup. It is safe to call this function without holding a reference to "
"**page**."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:268
msgid ""
"Note, this function is inherently racy, because there is nothing to prevent "
"the cgroup inode from getting torn down and potentially reallocated a moment "
"after page_cgroup_ino() returns, so it only should be used by callers that "
"do not care (such as procfs interfaces)."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:681
msgid "update cgroup memory statistics"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:682 mm/memcontrol.c:826
#: mm/memcontrol.c:1300
msgid "the memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:684
msgid "``enum memcg_stat_item idx``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:683
msgid "the stat item - can be enum memcg_stat_item or enum node_stat_item"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:685 mm/memcontrol.c:762
msgid "``int val``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:684 mm/memcontrol.c:761
msgid "delta to add to the counter, can be negative"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:758
msgid "update lruvec memory statistics"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:764 mm/memcontrol.c:1267
#: ../../../core-api/mm-api:131: mm/vmscan.c:419
msgid "``struct lruvec *lruvec``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:759
msgid "the lruvec"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:761
msgid "``enum node_stat_item idx``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:760
msgid "the stat item"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:762
msgid ""
"The lruvec is the intersection of the NUMA node and a cgroup. This function "
"updates the all three counters that are affected by a change of state at "
"this level: per-node, per-cgroup, per-lruvec."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:825
msgid "account VM events in a cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:828
msgid "``enum vm_event_item idx``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:827
msgid "the event item"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:829
msgid "``unsigned long count``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:828
msgid "the number of events that occurred"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:896
msgid "Obtain a reference on given mm_struct's memcg."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:897
msgid "mm from which memcg should be extracted. It can be NULL."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:898
msgid ""
"Obtain a reference on mm->memcg and returns it if successful. If mm is NULL, "
"then the memcg is chosen as follows: 1) The active memcg, if set. 2) current-"
">mm->memcg, if available 3) root memcg If mem_cgroup is disabled, NULL is "
"returned."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:946
msgid "Obtain a reference on current task's memcg."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:967
msgid "Obtain a reference on a given folio's memcg."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:968
msgid "folio from which memcg should be extracted."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:985
msgid "iterate over memory cgroup hierarchy"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:991 mm/memcontrol.c:1095
#: mm/memcontrol.c:4681
msgid "``struct mem_cgroup *root``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:986 mm/memcontrol.c:1090
#: mm/memcontrol.c:1139
msgid "hierarchy root"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:988 mm/memcontrol.c:1092
msgid "``struct mem_cgroup *prev``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:987
msgid "previously returned memcg, NULL on first invocation"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:989
msgid "``struct mem_cgroup_reclaim_cookie *reclaim``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:988
msgid "cookie for shared reclaim walks, NULL for full walks"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:989
msgid ""
"Returns references to children of the hierarchy below **root**, or **root** "
"itself, or ``NULL`` after a full round-trip."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:992
msgid ""
"Caller must pass the return value in **prev** on subsequent invocations for "
"reference counting, or use mem_cgroup_iter_break() to cancel a hierarchy "
"walk before the round-trip is complete."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:996
msgid ""
"Reclaimers can specify a node in **reclaim** to divide up the memcgs in the "
"hierarchy among all concurrent reclaimers operating on the same node."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1089
msgid "abort a hierarchy walk prematurely"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1091
msgid "last visited hierarchy member as returned by mem_cgroup_iter()"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1138
msgid "iterate over tasks of a memory cgroup hierarchy"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1141
msgid "``int (*fn)(struct task_struct *, void *)``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1140
msgid "function to call for each task"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1142
msgid "``void *arg``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1141
msgid "argument passed to **fn**"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1142
msgid ""
"This function iterates over tasks attached to **memcg** or to any of its "
"descendants and calls **fn** for each task. If **fn** returns a non-zero "
"value, the function breaks the iteration loop. Otherwise, it will iterate "
"over all tasks and return 0."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1147
msgid "This function must not be called for the root memory cgroup."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1194 mm/memcontrol.c:1215
#: mm/memcontrol.c:1237
msgid "Lock the lruvec for a folio."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1195 mm/memcontrol.c:1216
#: mm/memcontrol.c:1238
msgid "Pointer to the folio."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1196 mm/memcontrol.c:1217
#: mm/memcontrol.c:1240
msgid ""
"These functions are safe to use under any of the following conditions: - "
"folio locked - folio_test_lru false - folio frozen (refcount of 0)"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1202
msgid "The lruvec this folio is on with its lock held."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1223 mm/memcontrol.c:1246
msgid "The lruvec this folio is on with its lock held and interrupts disabled."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1240
msgid "``unsigned long *flags``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1239
msgid "Pointer to irqsave flags."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1261
msgid "account for adding or removing an lru page"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1262
msgid "mem_cgroup per zone lru vector"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1264
#: ../../../core-api/mm-api:131: mm/vmscan.c:416
msgid "``enum lru_list lru``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1263
msgid "index of lru list the page is sitting on"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1265
msgid "``int zid``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1264
msgid "zone id of the accounted pages"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1265
msgid "positive when adding or negative when removing"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1266
msgid ""
"This function must be called under lru_lock, just before a page is added to "
"or just after a page is removed from an lru list."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1299
msgid "calculate chargeable space of a memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1301
msgid ""
"Returns the maximum amount of memory **mem** can be charged with, in pages."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1530
msgid "Print OOM information relevant to memory controller."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1532 mm/memcontrol.c:1557
msgid "The memory cgroup that went over limit"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1534
msgid "``struct task_struct *p``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1533
msgid "Task that is going to be killed"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1535
#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2169
#: mm/memory_hotplug.c:2284
msgid "**NOTE**"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1535
msgid ""
"**memcg** and **p**'s mem_cgroup can be different when hierarchy is enabled"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1555
msgid "Print OOM memory information relevant to memory controller."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1680
msgid "get a memory cgroup to clean up after OOM"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1686
msgid "``struct task_struct *victim``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1681
msgid "task to be killed by the OOM killer"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1683
msgid "``struct mem_cgroup *oom_domain``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1682
msgid "memcg in case of memcg OOM, NULL in case of system-wide OOM"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1683
msgid ""
"Returns a pointer to a memory cgroup, which has to be cleaned up by killing "
"all belonging OOM-killable tasks."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1686
msgid "Caller has to call mem_cgroup_put() on the returned non-NULL memcg."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1785
msgid "Try to consume stocked charge on this cpu."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1786
msgid "memcg to consume from."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1788 mm/memcontrol.c:5031
#: mm/memcontrol.c:5054 mm/memcontrol.c:5180
msgid "``unsigned int nr_pages``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1787
msgid "how many pages to charge."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1788
msgid ""
"Consume the cached charge if enough nr_pages are present otherwise return "
"failure. Also return failure for charge request larger than "
"MEMCG_CHARGE_BATCH or if the local lock is already taken."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:1792
msgid "returns true if successful, false otherwise."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2830
msgid "charge a kmem page to the current memory cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2831
msgid "page to charge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2832 mm/memcontrol.c:4728
#: mm/memcontrol.c:4763 mm/memcontrol.c:5031
msgid "reclaim mode"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2833 mm/memcontrol.c:2857
msgid "allocation order"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2834
msgid "Returns 0 on success, an error code on failure."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2855
msgid "uncharge a kmem page"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:2856
msgid "page to uncharge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3353
msgid "retrieve writeback related stats from its memcg"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3359
msgid "``struct bdi_writeback *wb``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3354
msgid "bdi_writeback in question"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3356
msgid "``unsigned long *pfilepages``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3355
msgid "out parameter for number of file pages"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3357
msgid "``unsigned long *pheadroom``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3356
msgid "out parameter for number of allocatable pages according to memcg"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3358
msgid "``unsigned long *pdirty``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3357
msgid "out parameter for number of dirty pages"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3359
msgid "``unsigned long *pwriteback``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3358
msgid "out parameter for number of pages under writeback"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3359
msgid ""
"Determine the numbers of file, headroom, dirty, and writeback pages in "
"**wb**'s memcg.  File, dirty and writeback are self-explanatory.  Headroom "
"is a bit more involved."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3363
msgid ""
"A memcg's headroom is \"min(max, high) - used\".  In the hierarchy, the "
"headroom is calculated as the lowest headroom of itself and the ancestors.  "
"Note that this doesn't consider the actual amount of available memory in the "
"system.  The caller should further cap ***pheadroom** accordingly."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3611
msgid "look up a memcg from a memcg id"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3617
msgid "``unsigned short id``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3612
msgid "the memcg id to look up"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3613
msgid "Caller must hold rcu_read_lock()."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3935
msgid "reset the states of a mem_cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3941
msgid "``struct cgroup_subsys_state *css``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3936
msgid "the target css"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3937
msgid ""
"Reset the states of the mem_cgroup associated with **css**.  This is invoked "
"when the userland requests disabling on the default hierarchy but the memcg "
"is pinned through dependency.  The memcg should stop applying policies and "
"should revert to the vanilla state as it may be made visible again."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:3943
msgid ""
"The current implementation only resets the essential configurations. This "
"needs to be expanded to cover all the visible parts."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4675
msgid "check if memory consumption is in the normal range"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4676
msgid "the top ancestor of the sub-tree being checked"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4677
msgid "the memory cgroup to check"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4678
msgid "WARNING: This function is not stateless! It can only be used as part"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4679
msgid "of a top-down tree iteration, not for isolated queries."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4726
msgid "charge the memcg for a hugetlb folio"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4727
msgid "folio being charged"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4729
msgid ""
"This function is called when allocating a huge page folio, after the page "
"has already been obtained and charged to the appropriate hugetlb cgroup "
"controller (if it is enabled)."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4733
msgid ""
"Returns ENOMEM if the memcg is already full. Returns 0 if either the charge "
"was successful, or if we skip the charging."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4760
msgid "Charge a newly allocated folio for swapin."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4761
msgid "folio to charge."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4762
msgid "mm context of the victim"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4765 mm/memcontrol.c:5131
#: mm/memcontrol.c:5183
msgid "``swp_entry_t entry``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4764
msgid "swap entry for which the folio is allocated"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4765
msgid ""
"This function charges a folio allocated for swapin. Please call this before "
"adding the folio to the swapcache."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4768
msgid "Returns 0 on success. Otherwise, an error code is returned."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4910
msgid "Charge a folio's replacement."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4911 mm/memcontrol.c:4955
msgid "Currently circulating folio."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4912 mm/memcontrol.c:4956
msgid "Replacement folio."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4913
msgid ""
"Charge **new** as a replacement folio for **old**. **old** will be uncharged "
"upon free."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4916 mm/memcontrol.c:4961
msgid "Both folios must be locked, **new->mapping** must be set up."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4954
msgid "Transfer the memcg data from the old to the new folio."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:4957
msgid ""
"Transfer the memcg data from the old folio to the new folio for migration. "
"The old folio's data info will be cleared. Note that the memory counters "
"will remain unchanged throughout the process."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5028
msgid "charge socket memory"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5029
msgid "memcg to charge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5030
msgid "number of pages to charge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5032
msgid ""
"Charges **nr_pages** to **memcg**. Returns ``true`` if the charge fit within "
"**memcg**'s configured limit, ``false`` if it doesn't."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5051
msgid "uncharge socket memory"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5052
msgid "memcg to uncharge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5053
msgid "number of pages to uncharge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5128
msgid "try charging swap space for a folio"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5129
msgid "folio being added to swap"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5130
msgid "swap entry to charge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5131
msgid "Try to charge **folio**'s memcg for the swap space at **entry**."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5133
msgid "Returns 0 on success, -ENOMEM on failure."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5177
msgid "uncharge swap space"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5178
msgid "swap entry to uncharge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5179
msgid "the amount of swap space to uncharge"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5375
msgid "check if this cgroup can zswap"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5381 mm/memcontrol.c:5426
#: mm/memcontrol.c:5454
msgid "``struct obj_cgroup *objcg``"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5376 mm/memcontrol.c:5421
#: mm/memcontrol.c:5449
msgid "the object cgroup"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5377
msgid "Check if the hierarchical zswap limit has been reached."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5379
msgid ""
"This doesn't check for specific headroom, and it is not atomic either. But "
"with zswap, the size of the allocation is only known once compression has "
"occurred, and this optimistic pre-check avoids spending cycles on "
"compression when there is already no room left or zswap is disabled "
"altogether somewhere in the hierarchy."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5420
msgid "charge compression backend memory"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5422 mm/memcontrol.c:5450
msgid "size of compressed object"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5423
msgid ""
"This forces the charge after obj_cgroup_may_zswap() allowed compression and "
"storage in zwap for this cgroup to go ahead."
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5448
msgid "uncharge compression backend memory"
msgstr ""

#: ../../../core-api/mm-api:122: mm/memcontrol.c:5451
msgid "Uncharges zswap memory on page in."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:425
msgid "recalculate the block usage of an inode"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:426
msgid "inode to recalc"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:428
msgid "``long alloced``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:427
msgid "the change in number of pages allocated to inode"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:429
msgid "``long swapped``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:428
msgid "the change in number of pages swapped from inode"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:429
msgid ""
"We have to calculate the free blocks since the mm can drop undirtied hole "
"pages behind our back."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:432
msgid ""
"But normally   info->alloced == inode->i_mapping->nrpages + info->swapped So "
"mm freed is info->alloced - (inode->i_mapping->nrpages + info->swapped)"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:436
msgid "true if swapped was incremented from 0, for shmem_writeout()."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:577
msgid "Get allowable folio orders for the given file size."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:578
msgid "Target address_space."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:581 mm/shmem.c:2681
msgid "``loff_t write_end``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:580
msgid "end of a write, could extend inode size."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:581
msgid ""
"This returns huge orders for folios (when supported) based on the file size "
"which the mapping currently allows at the given index. The index is relevant "
"due to alignment considerations the mapping might have. The returned order "
"may be less than the size passed."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:587
msgid "The orders."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1573
msgid "Write the folio to swap"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1574
msgid "The folio to write"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1576
msgid "``struct swap_iocb **plug``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1575
msgid "swap plug"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1577
msgid "``struct list_head *folio_list``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1576
msgid "list to put back folios on split"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:1577
msgid "Move the folio from the page cache to the swap cache."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2677
msgid "find, and lock a shmem folio."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2678
msgid "inode to search"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2679
msgid "the page index."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2680
msgid "end of a write, could extend inode size"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2681
msgid "pointer to the folio if found"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2683
msgid "``enum sgp_type sgp``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2682
msgid "SGP_* flags to control behavior"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2683
msgid ""
"Looks up the page cache entry at **inode** & **index**.  If a folio is "
"present, it is returned locked with an increased refcount."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2686
msgid ""
"If the caller modifies data in the folio, it must call folio_mark_dirty() "
"before unlocking the folio to ensure that the folio is not reclaimed. There "
"is no need to reserve space before calling folio_mark_dirty()."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2690
msgid "When no folio is found, the behavior depends on **sgp**:"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2691
msgid "for SGP_READ, ***foliop** is ``NULL`` and 0 is returned"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2692
msgid "for SGP_NOALLOC, ***foliop** is ``NULL`` and -ENOENT is returned"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2693
msgid ""
"for all other flags a new folio is allocated, inserted into the page cache "
"and returned locked in **foliop**."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:2698
msgid "0 if successful, else a negative error code."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5901
msgid ""
"get an unlinked file living in tmpfs which must be kernel internal. There "
"will be NO LSM permission checks against the underlying inode. So users of "
"this interface must do LSM checks at a higher layer. The users are the "
"big_key and shm implementations. LSM checks are provided at the key or shm "
"level rather than the inode."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5906 mm/shmem.c:5918
#: mm/shmem.c:5931
msgid "name for dentry (to be seen in /proc/<pid>/maps)"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5908 mm/shmem.c:5920
#: mm/shmem.c:5933
msgid "``loff_t size``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5907 mm/shmem.c:5919
#: mm/shmem.c:5932
msgid "size to be set for the file"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5908 mm/shmem.c:5920
#: mm/shmem.c:5933
msgid "VM_NORESERVE suppresses pre-accounting of the entire object size"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5917 mm/shmem.c:5929
msgid "get an unlinked file living in tmpfs"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5935
msgid "``struct vfsmount *mnt``"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5930
msgid "the tmpfs mount where the file will be created"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5943
msgid "setup a shared anonymous mapping"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5944
msgid "the vma to be mmapped is prepared by do_mmap"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5971
msgid "the folio's address_space"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5972
msgid "the folio index"
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5974
msgid ""
"This behaves as a tmpfs \"read_cache_page_gfp(mapping, index, gfp)\", with "
"any new page allocations done using the specified allocation flags. But "
"read_cache_page_gfp() uses the ->read_folio() method: which does not suit "
"tmpfs, since it may have pages in swapcache, and needs to find those for "
"itself; although drivers/gpu/drm i915 and ttm rely upon this support."
msgstr ""

#: ../../../core-api/mm-api:124: mm/shmem.c:5980
msgid ""
"i915_gem_object_get_pages_gtt() mixes __GFP_NORETRY | __GFP_NOWARN in with "
"the mapping_gfp_mask(), to avoid OOMing the machine unnecessarily."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:473
msgid "prepare to migrate a range of memory"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:479
msgid "``struct migrate_vma *args``"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:474
msgid "contains the vma, start, and pfns arrays for the migration"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:476
msgid ""
"negative errno on failures, 0 when 0 or more pages were migrated without an "
"error."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:478
msgid ""
"Prepare to migrate a range of memory virtual address range by collecting all "
"the pages backing each virtual address in the range, saving them inside the "
"src array.  Then lock those pages and unmap them. Once the pages are locked "
"and unmapped, check whether each page is pinned or not.  Pages that aren't "
"pinned have the MIGRATE_PFN_MIGRATE flag set (by this function) in the "
"corresponding src array entry.  Then restores any pages that are pinned, by "
"remapping and unlocking those pages."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:486
msgid ""
"The caller should then allocate destination memory and copy source memory to "
"it for all those entries (ie with MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE "
"flag set).  Once these are allocated and copied, the caller must update each "
"corresponding entry in the dst array with the pfn value of the destination "
"page and with MIGRATE_PFN_VALID. Destination pages must be locked via "
"lock_page()."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:493
msgid ""
"Note that the caller does not have to migrate all the pages that are marked "
"with MIGRATE_PFN_MIGRATE flag in src array unless this is a migration from "
"device memory to system memory.  If the caller cannot migrate a device page "
"back to system memory, then it must return VM_FAULT_SIGBUS, which has severe "
"consequences for the userspace process, so it must be avoided if at all "
"possible."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:500
msgid ""
"For empty entries inside CPU page table (pte_none() or pmd_none() is true) "
"we do set MIGRATE_PFN_MIGRATE flag inside the corresponding source array "
"thus allowing the caller to allocate device memory for those unbacked "
"virtual addresses.  For this the caller simply has to allocate device memory "
"and properly set the destination entry like for regular migration.  Note "
"that this can still fail, and thus inside the device driver you must check "
"if the migration was successful for those entries after calling "
"migrate_vma_pages(), just like for regular migration."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:509
msgid ""
"After that, the callers must call migrate_vma_pages() to go over each entry "
"in the src array that has the MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE flag "
"set. If the corresponding entry in dst array has MIGRATE_PFN_VALID flag set, "
"then migrate_vma_pages() to migrate struct page information from the source "
"struct page to the destination struct page.  If it fails to migrate the "
"struct page information, then it clears the MIGRATE_PFN_MIGRATE flag in the "
"src array."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:517
msgid ""
"At this point all successfully migrated pages have an entry in the src array "
"with MIGRATE_PFN_VALID and MIGRATE_PFN_MIGRATE flag set and the dst array "
"entry with MIGRATE_PFN_VALID flag set."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:521
msgid ""
"Once migrate_vma_pages() returns the caller may inspect which pages were "
"successfully migrated, and which were not.  Successfully migrated pages will "
"have the MIGRATE_PFN_MIGRATE flag set for their src array entry."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:525
msgid ""
"It is safe to update device page table after migrate_vma_pages() because "
"both destination and source page are still locked, and the mmap_lock is held "
"in read mode (hence no one can unmap the range being migrated)."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:529
msgid ""
"Once the caller is done cleaning up things and updating its page table (if "
"it chose to do so, this is not an obligation) it finally calls "
"migrate_vma_finalize() to update the CPU page table to point to new pages "
"for successfully migrated pages or otherwise restore the CPU page table to "
"point to the original source pages."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:792
#: mm/migrate_device.c:808
msgid "migrate meta-data from src page to dst page"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:798
#: mm/migrate_device.c:931 mm/migrate_device.c:964
msgid "``unsigned long *src_pfns``"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:793
msgid "src_pfns returned from migrate_device_range()"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:795
msgid "``unsigned long *dst_pfns``"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:794
msgid "array of pfns allocated by the driver to migrate memory to"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:796
#: mm/migrate_device.c:929 mm/migrate_device.c:961
msgid "``unsigned long npages``"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:795
msgid "number of pages in the range"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:796
msgid ""
"Equivalent to migrate_vma_pages(). This is called to migrate struct page "
"meta-data from source struct page to destination."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:814
#: mm/migrate_device.c:897
msgid "``struct migrate_vma *migrate``"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:809
#: mm/migrate_device.c:892
msgid "migrate struct containing all migration information"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:810
msgid ""
"This migrates struct page meta-data from source struct page to destination "
"struct page. This effectively finishes the migration from source page to the "
"destination page."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:891
msgid "restore CPU page table entry"
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:893
msgid ""
"This replaces the special migration pte entry with either a mapping to the "
"new page if migration was successful for that page, or to the original page "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:897
msgid ""
"This also unlocks the pages and puts them back on the lru, or drops the "
"extra refcount, for device pages."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:925
#: mm/migrate_device.c:958
msgid "migrate device private pfns to normal memory."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:926
msgid "array large enough to hold migrating source device private pfns."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:927
msgid "starting pfn in the range to migrate."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:928
#: mm/migrate_device.c:960
msgid "number of pages to migrate."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:929
msgid ""
"migrate_vma_setup() is similar in concept to migrate_vma_setup() except that "
"instead of looking up pages based on virtual address mappings a range of "
"device pfns that should be migrated to system memory is used instead."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:933
msgid ""
"This is useful when a driver needs to free device memory but doesn't know "
"the virtual mappings of every page that may be in device memory. For example "
"this is often the case when a driver is being unloaded or unbound from a "
"device."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:937
msgid ""
"Like migrate_vma_setup() this function will take a reference and lock any "
"migrating pages that aren't free before unmapping them. Drivers may then "
"allocate destination pages and start copying data from the device to CPU "
"memory before calling migrate_device_pages()."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:959
msgid "pre-popluated array of source device private pfns to migrate."
msgstr ""

#: ../../../core-api/mm-api:125: mm/migrate_device.c:961
msgid ""
"Similar to migrate_device_range() but supports non-contiguous pre-popluated "
"array of device pages to migrate."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:11
msgid "Private struct for pagetable walk callbacks"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:12
msgid "``range``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:13
msgid "Range for mmu notifiers"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:13
msgid "``tlbflush_start``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:14
msgid "Address of first modified pte"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:14
msgid "``tlbflush_end``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:15
msgid "Address of last modified pte + 1"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:15
msgid "``total``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:16
msgid "Total number of modified ptes"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:25
msgid "Write-protect a pte"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:31
#: mm/mapping_dirty_helpers.c:82
msgid "``pte_t *pte``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:26
#: mm/mapping_dirty_helpers.c:78
msgid "Pointer to the pte"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:27
msgid "The start of protecting virtual address"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:28
msgid "The end of protecting virtual address"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:30
#: mm/mapping_dirty_helpers.c:82
msgid "``struct mm_walk *walk``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:29
#: mm/mapping_dirty_helpers.c:81
msgid "pagetable walk callback argument"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:30
msgid ""
"The function write-protects a pte and records the range in virtual address "
"space of touched ptes for efficient range TLB flushes."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:55
msgid "Private struct for the clean_record_pte function."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:56
msgid "``base``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:57
msgid "struct wp_walk we derive from"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:57
msgid "``bitmap_pgoff``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:58
msgid "Address_space Page offset of the first bit in **bitmap**"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:58
msgid "``bitmap``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:59
msgid ""
"Bitmap with one bit for each page offset in the address_space range covered."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:60
msgid "``start``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:61
msgid ""
"Address_space page offset of first modified pte relative to **bitmap_pgoff**"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:62
msgid "``end``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:63
msgid ""
"Address_space page offset of last modified pte relative to **bitmap_pgoff**"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:76
msgid "Clean a pte and record its address space offset in a bitmap"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:79
msgid "The start of virtual address to be clean"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:80
msgid "The end of virtual address to be clean"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:82
msgid ""
"The function cleans a pte and records the range in virtual address space of "
"touched ptes for efficient TLB flushes. It also records dirty ptes in a "
"bitmap representing page offsets in the address_space, as well as the first "
"and last of the bits touched."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:250
msgid "Write-protect all ptes in an address space range"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:251
msgid "The address_space we want to write protect"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:253
#: mm/mapping_dirty_helpers.c:282
msgid "``pgoff_t first_index``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:252
#: mm/mapping_dirty_helpers.c:281
msgid "The first page offset in the range"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:253
#: mm/mapping_dirty_helpers.c:282
msgid "Number of incremental page offsets to cover"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:255
msgid ""
"This function currently skips transhuge page-table entries, since it's "
"intended for dirty-tracking on the PTE level. It will warn on encountering "
"transhuge write-enabled entries, though, and can easily be extended to "
"handle them as well."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:260
msgid ""
"The number of ptes actually write-protected. Note that already write-"
"protected ptes are not counted."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:278
msgid "Clean and record all ptes in an address space range"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:280
msgid "The address_space we want to clean"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:284
msgid "``pgoff_t bitmap_pgoff``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:283
msgid "The page offset of the first bit in **bitmap**"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:285
msgid "``unsigned long *bitmap``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:284
msgid ""
"Pointer to a bitmap of at least **nr** bits. The bitmap needs to cover the "
"whole range **first_index**..**first_index** + **nr**."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:286
msgid ""
"Pointer to number of the first set bit in **bitmap**. is modified as new "
"bits are set by the function."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:289
msgid "``pgoff_t *end``"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:288
msgid ""
"Pointer to the number of the last set bit in **bitmap**. none set. The value "
"is modified as new bits are set by the function."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:290
msgid ""
"When this function returns there is no guarantee that a CPU has not already "
"dirtied new ptes. However it will not clean any ptes not reported in the "
"bitmap. The guarantees are as follows:"
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:294
msgid ""
"All ptes dirty when the function starts executing will end up recorded in "
"the bitmap."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:296
msgid ""
"All ptes dirtied after that will either remain dirty, be recorded in the "
"bitmap or both."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:299
msgid ""
"If a caller needs to make sure all dirty ptes are picked up and none "
"additional are added, it first needs to write-protect the address-space "
"range and make sure new writers are blocked in page_mkwrite() or "
"pfn_mkwrite(). And then after a TLB flush following the write-protection "
"pick up all dirty bits."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:305
msgid ""
"This function currently skips transhuge page-table entries, since it's "
"intended for dirty-tracking on the PTE level. It will warn on encountering "
"transhuge dirty entries, though, and can easily be extended to handle them "
"as well."
msgstr ""

#: ../../../core-api/mm-api:127: mm/mapping_dirty_helpers.c:311
msgid "The number of dirty ptes actually cleaned."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:208
msgid "check if the address is served from this chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:214 mm/percpu.c:361
#: mm/percpu.c:413 mm/percpu.c:549 mm/percpu.c:740 mm/percpu.c:773
#: mm/percpu.c:805 mm/percpu.c:952 mm/percpu.c:1067 mm/percpu.c:1098
#: mm/percpu.c:1204 mm/percpu.c:1272 mm/percpu.c:1504 mm/percpu.c:1528
msgid "``struct pcpu_chunk *chunk``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:209 mm/percpu.c:356
#: mm/percpu.c:408 mm/percpu.c:544 mm/percpu.c:735 mm/percpu.c:768
#: mm/percpu.c:800 mm/percpu.c:947 mm/percpu.c:1062 mm/percpu.c:1093
#: mm/percpu.c:1199 mm/percpu.c:1267
msgid "chunk of interest"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:210
msgid "percpu address"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:212
msgid "True if the address is served from this chunk."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:308
msgid "check against the contig hint"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:314 mm/percpu.c:627
msgid "``struct pcpu_block_md *block``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:309 mm/percpu.c:622
msgid "block of interest"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:311 mm/percpu.c:803
#: mm/percpu.c:950 mm/percpu.c:1065
msgid "``int bits``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:310 mm/percpu.c:409
msgid "size of allocation"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:312 mm/percpu.c:1096
#: mm/percpu.c:1202 mm/percpu.c:1719
msgid "``size_t align``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:311 mm/percpu.c:410
#: mm/percpu.c:1201 mm/percpu.c:1718
msgid "alignment of area (max PAGE_SIZE)"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:312
msgid ""
"Check to see if the allocation can fit in the block's contig hint. Note, a "
"chunk uses the same hints as a block so this can also check against the "
"chunk's contig hint."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:355
msgid "finds the next hint free area"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:358 mm/percpu.c:412
msgid "``int *bit_off``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:357 mm/percpu.c:411
#: mm/percpu.c:801 mm/percpu.c:948 mm/percpu.c:1063
msgid "chunk offset"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:359 mm/percpu.c:413
msgid "``int *bits``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:358 mm/percpu.c:412
msgid "size of free area"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:359
msgid ""
"Helper function for pcpu_for_each_md_free_region.  It checks block-"
">contig_hint and performs aggregation across blocks to find the next hint.  "
"It modifies bit_off and bits in-place to be consumed in the loop."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:407
msgid "finds fit areas for a given allocation request"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:410 mm/percpu.c:1095
#: mm/percpu.c:1201
msgid "``int alloc_bits``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:411
msgid "``int align``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:413
msgid ""
"Finds the next free region that is viable for use with a given size and "
"alignment.  This only returns if there is a valid area to be used for this "
"allocation.  block->first_free is returned if the allocation request fits "
"within the block to see if the request can be fulfilled prior to the contig "
"hint."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:492
msgid "allocate memory"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:493
msgid "bytes to allocate"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:494 mm/percpu.c:1720
msgid "allocation flags"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:495
msgid ""
"Allocate **size** bytes.  If **size** is smaller than PAGE_SIZE, kzalloc() "
"is used; otherwise, the equivalent of vzalloc() is used. This is to "
"facilitate passing through whitelisted flags.  The returned memory is always "
"zeroed."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:501
msgid "Pointer to the allocated area on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:516
msgid "free memory"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:522
msgid "``void *ptr``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:517
msgid "memory to free"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:518
msgid ""
"Free **ptr**.  **ptr** should have been allocated using pcpu_mem_zalloc()."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:543
msgid "put chunk in the appropriate chunk slot"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:546
msgid "``int oslot``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:545
msgid "the previous slot it was on"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:546
msgid ""
"This function is called after an allocation or free changed **chunk**. New "
"slot according to the changed state is determined and **chunk** is moved to "
"the slot.  Note that the reserved chunk is never put on chunk slots."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:552
msgid "pcpu_lock."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:621
msgid "updates a block given a free area"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:624 mm/percpu.c:1203
msgid "``int start``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:623
msgid "start offset in block"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:625
msgid "``int end``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:624
msgid "end offset in block"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:625
msgid ""
"Updates a block given a known free area.  The region [start, end) is "
"expected to be the entirety of the free area within a block.  Chooses the "
"best starting offset if the contig hints are equal."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:734
msgid "updates metadata about a chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:737
msgid "``bool full_scan``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:736
msgid "if we should scan from the beginning"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:737
msgid ""
"Iterates over the metadata blocks to find the largest contig area. A full "
"scan can be avoided on the allocation path as this is triggered if we broke "
"the contig_hint.  In doing so, the scan_hint will be before the contig_hint "
"or after if the scan_hint == contig_hint.  This cannot be prevented on "
"freeing as we want to find the largest area possibly spanning blocks."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:770
msgid "``int index``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:769
msgid "index of the metadata block"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:770
msgid ""
"Scans over the block beginning at first_free and updates the block metadata "
"accordingly."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:799
msgid "update hint on allocation path"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:802 mm/percpu.c:949
#: mm/percpu.c:1064
msgid "``int bit_off``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:802 mm/percpu.c:949
msgid "size of request"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:803
msgid ""
"Updates metadata for the allocation path.  The metadata only has to be "
"refreshed by a full scan iff the chunk's contig hint is broken.  Block level "
"scans are required if the block's contig hint is broken."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:946
msgid "updates the block hints on the free path"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:950
msgid ""
"Updates metadata for the allocation path.  This avoids a blind block refresh "
"by making use of the block contig hints.  If this fails, it scans forward "
"and backward to determine the extent of the free area.  This is capped at "
"the boundary of blocks."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:955
msgid ""
"A chunk update is triggered if a page becomes free, a block becomes free, or "
"the free spans across blocks.  This tradeoff is to minimize iterating over "
"the block metadata to update chunk_md->contig_hint. chunk_md->contig_hint "
"may be off by up to a page, but it will never be more than the available "
"space.  If the contig hint is contained in one block, it will be accurate."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1061
msgid "determines if the region is populated"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1066
msgid "``int *next_off``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1065
msgid "return value for the next offset to start searching"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1066
msgid "For atomic allocations, check if the backing pages are populated."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1069
msgid ""
"Bool if the backing pages are populated. next_index is to skip over "
"unpopulated blocks in pcpu_find_block_fit."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1092
msgid "finds the block index to start searching"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1094 mm/percpu.c:1200
msgid "size of request in allocation units"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1095
msgid "alignment of area (max PAGE_SIZE bytes)"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1097
msgid "``bool pop_only``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1096
msgid "use populated regions only"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1097
msgid ""
"Given a chunk and an allocation spec, find the offset to begin searching for "
"a free region.  This iterates over the bitmap metadata blocks to find an "
"offset that will be guaranteed to fit the requirements.  It is not quite "
"first fit as if the allocation does not fit in the contig hint of a block or "
"chunk, it is skipped.  This errs on the side of caution to prevent excess "
"iteration.  Poor alignment can cause the allocator to skip over blocks and "
"chunks that have valid free areas."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1106
msgid "The offset in the bitmap to begin searching. -1 if no offset is found."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1198
msgid "allocates an area from a pcpu_chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1202
msgid "bit_off to start searching"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1203
msgid ""
"This function takes in a **start** offset to begin searching to fit an "
"allocation of **alloc_bits** with alignment **align**.  It needs to scan the "
"allocation map because if it fits within the block's contig hint, **start** "
"will be block->first_free. This is an attempt to fill the allocation prior "
"to breaking the contig hint.  The allocation and boundary maps are updated "
"accordingly if it confirms a valid free area."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1212
msgid ""
"Allocated addr offset in **chunk** on success. -1 if no matching area is "
"found."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1266
msgid "frees the corresponding offset"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1269
msgid "``int off``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1268
msgid "addr offset into chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1269
msgid ""
"This function determines the size of an allocation to free using the "
"boundary bitmap and clears the allocation map."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1273
msgid "Number of freed bytes."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1333
msgid "creates chunks that serve the first chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1339
msgid "``unsigned long tmp_addr``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1334
msgid "the start of the region served"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1336
msgid "``int map_size``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1335
msgid "size of the region served"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1336
msgid ""
"This is responsible for creating the chunks that serve the first chunk.  The "
"base_addr is page aligned down of **tmp_addr** while the region end is page "
"aligned up.  Offsets are kept track of to determine the region served. All "
"this is done to appease the bitmap allocator in avoiding partial blocks."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1342
msgid "Chunk serving the region at **tmp_addr** of **map_size**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1498
msgid "post-population bookkeeping"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1499
msgid "pcpu_chunk which got populated"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1501 mm/percpu.c:1525
msgid "``int page_start``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1500 mm/percpu.c:1524
msgid "the start page"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1502 mm/percpu.c:1526
msgid "``int page_end``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1501 mm/percpu.c:1525
msgid "the end page"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1502
msgid ""
"Pages in [**page_start**,**page_end**) have been populated to **chunk**.  "
"Update the bookkeeping information accordingly.  Must be called after each "
"successful population."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1522
msgid "post-depopulation bookkeeping"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1523
msgid "pcpu_chunk which got depopulated"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1526
msgid ""
"Pages in [**page_start**,**page_end**) have been depopulated from **chunk**. "
"Update the bookkeeping information accordingly.  Must be called after each "
"successful depopulation."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1579
msgid "determine chunk containing specified address"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1580
msgid "address for which the chunk needs to be determined."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1581
msgid ""
"This is an internal function that handles all but static allocations. Static "
"percpu address values should never be passed into the allocator."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1585
msgid "The address of the found chunk."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1716
msgid "the percpu allocator"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1717
msgid "size of area to allocate in bytes"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1720
msgid "``bool reserved``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1719
msgid "allocate from the reserved chunk if available"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1721
msgid ""
"Allocate percpu area of **size** bytes aligned at **align**.  If **gfp** "
"doesn't contain ``GFP_KERNEL``, the allocation is atomic. If **gfp** has "
"__GFP_NOWARN then no warning will be triggered on invalid or failed "
"allocation requests."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1727
msgid "Percpu pointer to the allocated area on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1935
msgid "manage the amount of free chunks"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1941
msgid "``bool empty_only``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1936
msgid "free chunks only if there are no populated pages"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1937
msgid ""
"If empty_only is ``false``, reclaim all fully free chunks regardless of the "
"number of populated pages.  Otherwise, only reclaim chunks that have no "
"populated pages."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1942 mm/percpu.c:1996
#: mm/percpu.c:2088
msgid "pcpu_lock (can be dropped temporarily)"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1988
msgid "manage the amount of populated pages"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:1989
msgid ""
"Maintain a certain amount of populated pages to satisfy atomic allocations. "
"It is possible that this is called when physical memory is scarce causing "
"OOM killer to be triggered.  We should avoid doing so until an actual "
"allocation causes the failure as it is possible that requests can be "
"serviced from already backed regions."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2078
msgid "scan over to_depopulate chunks and free empty pages"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2079
msgid ""
"Scan over chunks in the depopulate list and try to release unused populated "
"pages back to the system.  Depopulated chunks are sidelined to prevent "
"repopulating these pages unless required.  Fully free chunks are "
"reintegrated and freed accordingly (1 is kept around).  If we drop below the "
"empty populated pages threshold, reintegrate the chunk if it has empty free "
"pages. Each chunk is scanned in the reverse order to keep populated pages "
"close to the beginning of the chunk."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2183
msgid "manage the amount of free chunks and populated pages"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2189
msgid "``struct work_struct *work``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2184
msgid "unused"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2185
msgid ""
"For each chunk type, manage the number of fully free chunks and the number "
"of populated pages.  An important thing to consider is when pages are freed "
"and how they contribute to the global counts."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2218
msgid "free percpu area"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2224
msgid "``void __percpu *ptr``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2219
msgid "pointer to area to free"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2220
msgid "Free percpu area **ptr**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2223
msgid "Can be called from atomic context."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2303
msgid "test whether address is from static percpu area"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2304
msgid "address to test"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2305
msgid ""
"Test whether **addr** belongs to in-kernel static percpu area.  Module "
"static percpu areas are not considered.  For those, use "
"is_module_percpu_address()."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2310
msgid ""
"``true`` if **addr** is from in-kernel static percpu area, ``false`` "
"otherwise."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2319
msgid "convert translated percpu address to physical address"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2320
msgid "the address to be converted to physical address"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2321
msgid ""
"Given **addr** which is dereferenceable address obtained via one of percpu "
"access macros, this function translates it into its physical address.  The "
"caller is responsible for ensuring **addr** stays valid until this function "
"finishes."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2326
msgid ""
"percpu allocator has special setup for the first chunk, which currently "
"supports either embedding in linear address space or vmalloc mapping, and, "
"from the second one, the backing allocator (currently either vm or km) "
"provides translation."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2331
msgid ""
"The addr can be translated simply without checking if it falls into the "
"first chunk. But the current code reflects better how percpu allocator "
"actually works, and the verification can discover both bugs in percpu "
"allocator itself and per_cpu_ptr_to_phys() callers. So we keep current code."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2338
msgid "The physical address for **addr**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2386
msgid "allocate percpu allocation info"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2392
msgid "``int nr_groups``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2387
msgid "the number of groups"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2389
msgid "``int nr_units``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2388
msgid "the number of units"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2389
msgid ""
"Allocate ai which is large enough for **nr_groups** groups containing "
"**nr_units** units.  The returned ai's groups[0].cpu_map points to the "
"cpu_map array which is long enough for **nr_units** and filled with "
"NR_CPUS.  It's the caller's responsibility to initialize cpu_map pointer of "
"other groups."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2396
msgid "Pointer to the allocated pcpu_alloc_info on success, NULL on failure."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2430
msgid "free percpu allocation info"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2436
msgid "``struct pcpu_alloc_info *ai``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2431
msgid "pcpu_alloc_info to free"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2432
msgid "Free **ai** which was allocated by pcpu_alloc_alloc_info()."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2441
msgid "print out information about pcpu_alloc_info"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2447
msgid "``const char *lvl``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2442
msgid "loglevel"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2444 mm/percpu.c:2504
msgid "``const struct pcpu_alloc_info *ai``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2443
msgid "allocation info to dump"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2444
msgid "Print out information about **ai** using loglevel **lvl**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2498
msgid "initialize the first percpu chunk"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2499
msgid "pcpu_alloc_info describing how to percpu area is shaped"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2501
msgid "``void *base_addr``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2500
msgid "mapped address"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2501
msgid ""
"Initialize the first percpu chunk which contains the kernel static percpu "
"area.  This function is to be called from arch percpu area setup path."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2505
msgid ""
"**ai** contains all information necessary to initialize the first chunk and "
"prime the dynamic percpu allocator."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2508
msgid "**ai->static_size** is the size of static percpu area."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2510
msgid ""
"**ai->reserved_size**, if non-zero, specifies the amount of bytes to reserve "
"after the static area in the first chunk.  This reserves the first chunk "
"such that it's available only through reserved percpu allocation.  This is "
"primarily used to serve module percpu static areas on architectures where "
"the addressing model has limited offset range for symbol relocations to "
"guarantee module percpu symbols fall inside the relocatable range."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2518
msgid ""
"**ai->dyn_size** determines the number of bytes available for dynamic "
"allocation in the first chunk.  The area between **ai->static_size** + **ai-"
">reserved_size** + **ai->dyn_size** and **ai->unit_size** is unused."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2522
msgid ""
"**ai->unit_size** specifies unit size and must be aligned to PAGE_SIZE and "
"equal to or larger than **ai->static_size** + **ai->reserved_size** + **ai-"
">dyn_size**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2526
msgid ""
"**ai->atom_size** is the allocation atom size and used as alignment for vm "
"areas."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2529
msgid ""
"**ai->alloc_size** is the allocation size and always multiple of **ai-"
">atom_size**.  This is larger than **ai->atom_size** if **ai->unit_size** is "
"larger than **ai->atom_size**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2533
msgid ""
"**ai->nr_groups** and **ai->groups** describe virtual memory layout of "
"percpu areas.  Units which should be colocated are put into the same group.  "
"Dynamic VM areas will be allocated according to these groupings.  If **ai-"
">nr_groups** is zero, a single group containing all units is assumed."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2539
msgid ""
"The caller should have mapped the first chunk at **base_addr** and copied "
"static data to each unit."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2542
msgid ""
"The first chunk will always contain a static and a dynamic region. However, "
"the static region is not managed by any chunk.  If the first chunk also "
"contains a reserved region, it is served by two chunks - one for the "
"reserved region and one for the dynamic region.  They share the same vm, but "
"use offset regions in the area allocation map. The chunk serving the dynamic "
"region is circulated in the chunk slots and available for dynamic allocation "
"like any other chunk."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2772
msgid "build alloc_info considering distances between CPUs"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2778 mm/percpu.c:2979
#: mm/percpu.c:3174
msgid "``size_t reserved_size``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2773 mm/percpu.c:2974
#: mm/percpu.c:3169
msgid "the size of reserved percpu area in bytes"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2775 mm/percpu.c:2976
msgid "``size_t dyn_size``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2774 mm/percpu.c:2975
msgid "minimum free size for dynamic allocation in bytes"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2776 mm/percpu.c:2977
msgid "``size_t atom_size``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2775 mm/percpu.c:2976
msgid "allocation atom size"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2777 mm/percpu.c:2978
msgid "``pcpu_fc_cpu_distance_fn_t cpu_distance_fn``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2776 mm/percpu.c:2977
msgid "callback to determine distance between cpus, optional"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2777
msgid ""
"This function determines grouping of units, their mappings to cpus and other "
"parameters considering needed percpu size, allocation atom size and "
"distances between CPUs."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2781
msgid ""
"Groups are always multiples of atom size and CPUs which are of "
"LOCAL_DISTANCE both ways are grouped together and share space for units in "
"the same group.  The returned configuration is guaranteed to have CPUs on "
"different nodes on different groups and >=75% usage of allocated virtual "
"address space."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2788
msgid ""
"On success, pointer to the new allocation_info is returned.  On failure, "
"ERR_PTR value is returned."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2973
msgid "embed the first percpu chunk into bootmem"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2979 mm/percpu.c:3171
msgid "``pcpu_fc_cpu_to_node_fn_t cpu_to_nd_fn``"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2978 mm/percpu.c:3170
msgid "callback to convert cpu to it's node, optional"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2979
msgid ""
"This is a helper to ease setting up embedded first percpu chunk and can be "
"called where pcpu_setup_first_chunk() is expected."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2982
msgid ""
"If this function is used to setup the first chunk, it is allocated by "
"calling pcpu_fc_alloc and used as-is without being mapped into vmalloc "
"area.  Allocations are always whole multiples of **atom_size** aligned to "
"**atom_size**."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2987
msgid ""
"This enables the first chunk to piggy back on the linear physical mapping "
"which often uses larger page size.  Please note that this can result in very "
"sparse cpu->unit mapping on NUMA machines thus requiring large vmalloc "
"address space.  Don't use this allocator if vmalloc space is not orders of "
"magnitude larger than distances between node memory addresses (ie. 32bit "
"NUMA machines)."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2994
msgid "**dyn_size** specifies the minimum dynamic area size."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:2996
msgid ""
"If the needed size is smaller than the minimum or specified unit size, the "
"leftover is returned using pcpu_fc_free."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:3000 mm/percpu.c:3178
msgid "0 on success, -errno on failure."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:3168
msgid "map the first chunk using PAGE_SIZE pages"
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:3171
msgid ""
"This is a helper to ease setting up page-remapped first percpu chunk and can "
"be called where pcpu_setup_first_chunk() is expected."
msgstr ""

#: ../../../core-api/mm-api:129: mm/percpu.c:3174
msgid ""
"This is the basic allocator.  Static percpu area is allocated page-by-page "
"into vmalloc area."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:112
msgid "safely attempt to read from a user-space location"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:118
msgid "``void *dst``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:113
msgid "pointer to the buffer that shall take the data"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:115
msgid "``const void __user *src``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:114
msgid "address to read from. This must be a user address."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:115 mm/maccess.c:144
msgid "size of the data chunk"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:116
msgid ""
"Safely read from user address **src** to the buffer at **dst**. If a kernel "
"fault happens, handle that and return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:141
msgid "safely attempt to write to a user-space location"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:147
msgid "``void __user *dst``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:142
msgid "address to write to"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:144
msgid "``const void *src``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:143
msgid "pointer to the data that shall be written"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:145
msgid ""
"Safely write to address **dst** from the buffer at **src**.  If a kernel "
"fault happens, handle that and return -EFAULT."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:166
msgid "Copy a NUL terminated string from unsafe user address."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:172
msgid "``char *dst``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:168
msgid ""
"Destination address, in kernel space.  This buffer must be at least "
"**count** bytes long."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:171 mm/maccess.c:212
msgid "``const void __user *unsafe_addr``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:170
msgid "Unsafe user address."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:172 mm/maccess.c:209
msgid "``long count``"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:171
msgid "Maximum number of bytes to copy, including the trailing NUL."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:172
msgid ""
"Copies a NUL-terminated string from unsafe user address to kernel buffer."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:174
msgid ""
"On success, returns the length of the string INCLUDING the trailing NUL."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:176
msgid ""
"If access fails, returns -EFAULT (some data may have been copied and the "
"trailing NUL added)."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:179
msgid ""
"If **count** is smaller than the length of the string, copies **count**-1 "
"bytes, sets the last byte of **dst** buffer to NUL and returns **count**."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:206
msgid "Get the size of a user string INCLUDING final NUL."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:207
msgid "The string to measure."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:208
msgid "Maximum count (including NUL)"
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:209
msgid ""
"Get the size of a NUL-terminated string in user space without pagefault."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:211
msgid "Returns the size of the string INCLUDING the terminating NUL."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:213
msgid ""
"If the string is too long, returns a number larger than **count**. User has "
"to check the return value against \"> count\". On exception (or invalid "
"count), returns 0."
msgstr ""

#: ../../../core-api/mm-api:130: mm/maccess.c:217
msgid ""
"Unlike strnlen_user, this can be used from IRQ handler etc. because it "
"disables pagefaults."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:222
msgid "is the usual dirty throttling mechanism available?"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:228
msgid "``struct scan_control *sc``"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:223
msgid "scan_control in question"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:224
msgid ""
"The normal page dirty throttling mechanism in balance_dirty_pages() is "
"completely broken with the legacy memcg and direct stalling in "
"shrink_folio_list() is used for throttling instead, which lacks all the "
"niceties such as fairness, adaptive pausing, bandwidth proportional "
"allocation and configurability."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:230
msgid ""
"This function tests whether the vmscan currently in progress can assume that "
"the normal dirty throttling mechanism is operational."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:413
msgid "Returns the number of pages on the given LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:414
msgid "lru vector"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:415
msgid "lru to use"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:417
msgid "``int zone_idx``"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:416
msgid "zones to consider (use MAX_NR_ZONES - 1 for the whole LRU list)"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:833
msgid "Attempt to remove a folio from its mapping."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:834
msgid "The address space."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:835
msgid "The folio to remove."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:836
msgid ""
"If the folio is dirty, under writeback or if someone else has a ref on it, "
"removal will fail."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:839
msgid ""
"The number of pages removed from the mapping.  0 if the folio could not be "
"removed."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:841
msgid ""
"The caller should have a single refcount on the folio and hold its lock."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:859
msgid "Put previously isolated folio onto appropriate LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:860
msgid "Folio to be returned to an LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:861
msgid ""
"Add previously isolated **folio** to appropriate LRU list. The folio may "
"still be unevictable for other reasons."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:865
msgid "lru_lock must not be held, interrupts must be enabled."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1832
msgid "Try to isolate a folio from its LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1833
msgid "Folio to isolate from its LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1834
msgid ""
"Isolate a **folio** from an LRU list and adjust the vmstat statistic "
"corresponding to whatever LRU list the folio was on."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1837
msgid ""
"The folio will have its LRU flag cleared.  If it was found on the active "
"list, it will have the Active flag set.  If it was found on the unevictable "
"list, it will have the Unevictable flag set.  These flags may need to be "
"cleared by the caller before letting the page go."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1843
msgid ""
"Must be called with an elevated refcount on the folio. This is a fundamental "
"difference from isolate_lru_folios() (which is called without a stable "
"reference)."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1846
msgid "The lru_lock must not be held."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1847
msgid "Interrupts must be enabled."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:1851
msgid ""
"true if the folio was removed from an LRU list. false if the folio was not "
"on an LRU list."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:7850
msgid "Move evictable folios to appropriate zone lru list"
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:7852
msgid "Batch of lru folios to check."
msgstr ""

#: ../../../core-api/mm-api:131: mm/vmscan.c:7853
msgid ""
"Checks folios for evictability, if an evictable folio is in the unevictable "
"lru list, moves it to the appropriate evictable lru list. This function "
"should be only used for lru folios."
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:583
msgid "remove sections of pages"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:584
msgid "starting pageframe (must be aligned to start of a section)"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:585
msgid "number of pages to remove (must be multiple of section size)"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:587
msgid "``struct vmem_altmap *altmap``"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:586
msgid "alternative device page map or ``NULL`` if default memmap is used"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:587
msgid ""
"Generic helper function to remove section mappings and sysfs entries for the "
"section of the memory we are removing. Caller needs to make sure that pages "
"are marked reserved and zones are adjust properly by calling offline_pages()."
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2166
msgid "the node ID"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2167
msgid "Offline a node if all memory sections and cpus of the node are removed."
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2170
msgid ""
"The caller must call lock_device_hotplug() to serialize hotplug and online/"
"offline operations before this call."
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2280
msgid "Remove memory if every memory block is offline"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2286
msgid "``u64 start``"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2281
msgid "physical address of the region to remove"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2283
msgid "``u64 size``"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2282
msgid "size of the region to remove"
msgstr ""

#: ../../../core-api/mm-api:132: mm/memory_hotplug.c:2284
msgid ""
"The caller must call lock_device_hotplug() to serialize hotplug and online/"
"offline operations before this call, as required by try_offline_node()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:169
msgid "Begin a read side critical section against a VA range"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:175 mm/mmu_notifier.c:963
#: mm/mmu_notifier.c:1035
msgid "``struct mmu_interval_notifier *interval_sub``"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:171
msgid "The interval subscription"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:172
msgid ""
"mmu_iterval_read_begin()/mmu_iterval_read_retry() implement a collision-"
"retry scheme similar to seqcount for the VA range under subscription. If the "
"mm invokes invalidation during the critical section then "
"mmu_interval_read_retry() will return true."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:177
msgid ""
"This is useful to obtain shadow PTEs where teardown or setup of the SPTEs "
"require a blocking context.  The critical region formed by this can sleep, "
"and the required 'user_lock' can also be a sleeping lock."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:181
msgid ""
"The caller is required to provide a 'user_lock' to serialize both teardown "
"and setup."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:184
msgid "The return value should be passed to mmu_interval_read_retry()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:681
msgid "Register a notifier on a mm"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:687 mm/mmu_notifier.c:857
msgid "``struct mmu_notifier *subscription``"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:682
msgid "The notifier to attach"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:683
msgid "The mm to attach the notifier to"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:684
msgid ""
"Must not hold mmap_lock nor any other VM related lock when calling this "
"registration function. Must also ensure mm_users can't go down to zero while "
"this runs to avoid races with mmu_notifier_release, so mm has to be current-"
">mm or the mm should be pinned safely such as with get_task_mm(). If the mm "
"is not current->mm, the mm_users pin should be released by calling mmput "
"after mmu_notifier_register returns."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:692
msgid ""
"mmu_notifier_unregister() or mmu_notifier_put() must be always called to "
"unregister the notifier."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:695
msgid ""
"While the caller has a mmu_notifier get the subscription->mm pointer will "
"remain valid, and can be converted to an active mm pointer via "
"mmget_not_zero()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:735
msgid "Return the single struct mmu_notifier for the mm & ops"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:741
msgid "``const struct mmu_notifier_ops *ops``"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:737
msgid "The operations struct being subscribe with"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:738
msgid "The mm to attach notifiers too"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:739
msgid ""
"This function either allocates a new mmu_notifier via ops->alloc_notifier(), "
"or returns an already existing notifier on the list. The value of the ops "
"pointer is used to determine when two notifiers are the same."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:744
msgid ""
"Each call to mmu_notifier_get() must be paired with a call to "
"mmu_notifier_put(). The caller must hold the write side of mm->mmap_lock."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:747
msgid ""
"While the caller has a mmu_notifier get the mm pointer will remain valid, "
"and can be converted to an active mm pointer via mmget_not_zero()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:851
msgid "Release the reference on the notifier"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:852
msgid "The notifier to act on"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:853
msgid ""
"This function must be paired with each mmu_notifier_get(), it releases the "
"reference obtained by the get. If this is the last reference then process to "
"free the notifier will be run asynchronously."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:857
msgid ""
"Unlike mmu_notifier_unregister() the get/put flow only calls ops->release "
"when the mm_struct is destroyed. Instead free_notifier is always called to "
"release any resources held by the user."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:861
msgid ""
"As ops->release is not guaranteed to be called, the user must ensure that "
"all sptes are dropped, and no new sptes can be established before "
"mmu_notifier_put() is called."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:865
msgid ""
"This function can be called from the ops->release callback, however the "
"caller must still ensure it is called pairwise with mmu_notifier_get()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:868
msgid ""
"Modules calling this function must call mmu_notifier_synchronize() in their "
"__exit functions to ensure the async work is completed."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:957
msgid "Insert an interval notifier"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:958
msgid "Interval subscription to register"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:961
msgid "mm_struct to attach to"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:959
msgid "Starting virtual address to monitor"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:961
msgid "``unsigned long length``"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:960
msgid "Length of the range to monitor"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:962
msgid "``const struct mmu_interval_notifier_ops *ops``"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:962
msgid "Interval notifier operations to be called on matching events"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:963
msgid ""
"This function subscribes the interval notifier for notifications from the "
"mm.  Upon return the ops related to mmu_interval_notifier will be called "
"whenever an event that intersects with the given range occurs."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:967
msgid ""
"Upon return the range_notifier may not be present in the interval tree yet. "
"The caller must use the normal interval notifier read flow via "
"mmu_interval_read_begin() to establish SPTEs for this range."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1029
msgid "Remove a interval notifier"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1030
msgid "Interval subscription to unregister"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1031
msgid ""
"This function must be paired with mmu_interval_notifier_insert(). It cannot "
"be called from any ops callback."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1034
msgid ""
"Once this returns ops callbacks are no longer running on other CPUs and will "
"not be called in future."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1083
msgid "Ensure all mmu_notifiers are freed"
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1084
msgid ""
"This function ensures that all outstanding async SRU work from "
"mmu_notifier_put() is completed. After it returns any mmu_notifier_ops "
"associated with an unused mmu_notifier will no longer be called."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1088
msgid ""
"Before using the caller must ensure that all of its mmu_notifiers have been "
"fully released via mmu_notifier_put()."
msgstr ""

#: ../../../core-api/mm-api:133: mm/mmu_notifier.c:1091
msgid ""
"Modules using the mmu_notifier_put() API should call this in their __exit "
"function to avoid module unloading races."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:31
msgid "inserts a list of pages into the balloon page list."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:37
#: mm/balloon_compaction.c:66
msgid "``struct balloon_dev_info *b_dev_info``"
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:33
msgid "balloon device descriptor where we will insert a new page to"
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:35
#: mm/balloon_compaction.c:64
msgid "``struct list_head *pages``"
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:34
msgid "pages to enqueue - allocated using balloon_page_alloc."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:35
msgid ""
"Driver must call this function to properly enqueue balloon pages before "
"definitively removing them from the guest system."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:39
msgid "number of pages that were enqueued."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:60
msgid "removes pages from balloon's page list and returns a list of the pages."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:62
msgid "balloon device descriptor where we will grab a page from."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:63
msgid "pointer to the list of pages that would be returned to the caller."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:65
msgid "``size_t n_req_pages``"
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:64
msgid "number of requested pages."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:65
msgid ""
"Driver must call this function to properly de-allocate a previous enlisted "
"balloon pages before definitively releasing it back to the guest system. "
"This function tries to remove **n_req_pages** from the ballooned pages and "
"return them to the caller in the **pages** list."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:70
msgid ""
"Note that this function may fail to dequeue some pages even if the balloon "
"isn't empty - since the page list can be temporarily empty due to compaction "
"of isolated pages."
msgstr ""

#: ../../../core-api/mm-api:134: mm/balloon_compaction.c:75
msgid "number of pages that were added to the **pages** list."
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1435
msgid "insert a pmd size pfn"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1436 mm/huge_memory.c:1575
#: mm/huge_memory.c:1619
msgid "Structure describing the fault"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1437 mm/huge_memory.c:1576
msgid "pfn to insert"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1439 mm/huge_memory.c:1578
#: mm/huge_memory.c:1622
msgid "``bool write``"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1438 mm/huge_memory.c:1577
#: mm/huge_memory.c:1621
msgid "whether it's a write fault"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1439
msgid "Insert a pmd size pfn. See vmf_insert_pfn() for additional info."
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1574
msgid "insert a pud size pfn"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1578
msgid "Insert a pud size pfn. See vmf_insert_pfn() for additional info."
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1618
msgid "insert a pud size folio mapped by a pud entry"
msgstr ""

#: ../../../core-api/mm-api:135: mm/huge_memory.c:1620
msgid "folio to insert"
msgstr ""
